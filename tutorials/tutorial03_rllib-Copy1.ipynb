{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 03: Running RLlib Experiments\n",
    "\n",
    "This tutorial walks you through the process of running traffic simulations in Flow with trainable RLlib-powered agents. Autonomous agents will learn to maximize a certain reward over the rollouts, using the [**RLlib**](https://ray.readthedocs.io/en/latest/rllib.html) library ([citation](https://arxiv.org/abs/1712.09381)) ([installation instructions](https://flow.readthedocs.io/en/latest/flow_setup.html#optional-install-ray-rllib)). Simulations of this form will depict the propensity of RL agents to influence the traffic of a human fleet in order to make the whole fleet more efficient (for some given metrics). \n",
    "\n",
    "In this tutorial, we simulate an initially perturbed single lane ring road, where we introduce a single autonomous vehicle. We witness that, after some training, that the autonomous vehicle learns to dissipate the formation and propagation of \"phantom jams\" which form when only human driver dynamics are involved.\n",
    "\n",
    "## 1. Components of a Simulation\n",
    "All simulations, both in the presence and absence of RL, require two components: a *network*, and an *environment*. Networks describe the features of the transportation network used in simulation. This includes the positions and properties of nodes and edges constituting the lanes and junctions, as well as properties of the vehicles, traffic lights, inflows, etc... in the network. Environments, on the other hand, initialize, reset, and advance simulations, and act as the primary interface between the reinforcement learning algorithm and the network. Moreover, custom environments may be used to modify the dynamical features of an network. Finally, in the RL case, it is in the *environment* that the state/action spaces and the reward function are defined. \n",
    "\n",
    "## 2. Setting up a Network\n",
    "Flow contains a plethora of pre-designed networks used to replicate highways, intersections, and merges in both closed and open settings. All these networks are located in flow/networks. For this tutorial, which involves a single lane ring road, we will use the network `RingNetwork`.\n",
    "\n",
    "### 2.1 Setting up Network Parameters\n",
    "\n",
    "The network mentioned at the start of this section, as well as all other networks in Flow, are parameterized by the following arguments: \n",
    "* name\n",
    "* vehicles\n",
    "* net_params\n",
    "* initial_config\n",
    "\n",
    "These parameters are explained in detail in `tutorial01_sumo.ipynb`. Moreover, all parameters excluding vehicles (covered in section 2.2) do not change from the previous tutorial. Accordingly, we specify them nearly as we have before, and leave further explanations of the parameters to `tutorial01_sumo.ipynb`.\n",
    "\n",
    "We begin by choosing the network the experiment will be trained on. We use one of Flow's builtin networks, located in `flow.networks`. A list of all available networks can be found by running the script below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flow.networks as networks\n",
    "\n",
    "# print(networks.__all__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we choose to use the ring road network. The network class is then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.networks import RingNetwork\n",
    "\n",
    "# ring road network class\n",
    "network_name = RingNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One key difference between SUMO and RLlib experiments is that, in RLlib experiments, the network classes do not need to be defined; instead users should simply name the network class they wish to use. Later on, an environment setup module will import the correct network class based on the provided names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input parameter classes to the network class\n",
    "from flow.core.params import NetParams, InitialConfig\n",
    "\n",
    "# name of the network\n",
    "name = \"c_mpg+plus\"\n",
    "\n",
    "# network-specific parameters\n",
    "from flow.networks.ring import ADDITIONAL_NET_PARAMS\n",
    "net_params = NetParams(additional_params=ADDITIONAL_NET_PARAMS)\n",
    "\n",
    "# initial configuration to vehicles\n",
    "initial_config = InitialConfig(spacing=\"uniform\", perturbation=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Adding Trainable Autonomous Vehicles\n",
    "The `Vehicles` class stores state information on all vehicles in the network. This class is used to identify the dynamical features of a vehicle and whether it is controlled by a reinforcement learning agent. Morover, information pertaining to the observations and reward function can be collected from various `get` methods within this class.\n",
    "\n",
    "The dynamics of vehicles in the `Vehicles` class can either be depicted by sumo or by the dynamical methods located in flow/controllers. For human-driven vehicles, we use the IDM model for acceleration behavior, with exogenous gaussian acceleration noise with std 0.2 m/s2 to induce perturbations that produce stop-and-go behavior. In addition, we use the `ContinousRouter` routing controller so that the vehicles may maintain their routes closed networks.\n",
    "\n",
    "As we have done in `tutorial01_sumo.ipynb`, human-driven vehicles are defined in the `VehicleParams` class as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vehicles class\n",
    "from flow.core.params import VehicleParams\n",
    "\n",
    "# vehicles dynamics models\n",
    "from flow.controllers import IDMController, ContinuousRouter\n",
    "\n",
    "vehicles = VehicleParams()\n",
    "#vehicles.add(\"human\",\n",
    "#             acceleration_controller=(IDMController, {}),\n",
    "#             routing_controller=(ContinuousRouter, {}),\n",
    "#             num_vehicles=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above addition to the `Vehicles` class only accounts for 21 of the 22 vehicles that are placed in the network. We now add an additional trainable autuonomous vehicle whose actions are dictated by an RL agent. This is done by specifying an `RLController` as the acceleraton controller to the vehicle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.controllers import RLController"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this controller serves primarirly as a placeholder that marks the vehicle as a component of the RL agent, meaning that lane changing and routing actions can also be specified by the RL agent to this vehicle.\n",
    "\n",
    "We finally add the vehicle as follows, while again using the `ContinuousRouter` to perpetually maintain the vehicle within the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from flow.energy_models.toyota_energy import TacomaEnergy\n",
    "# vehicles.add(veh_id=\"rl\",\n",
    "#              acceleration_controller=(RLController, {}),\n",
    "#              routing_controller=(ContinuousRouter, {}),\n",
    "#              initial_speed =20,\n",
    "#              energy_model = TacomaEnergy,\n",
    "#              num_vehicles=1)\n",
    "\n",
    "\n",
    "vehicles.add(veh_id=\"rl\",\n",
    "             acceleration_controller=(RLController, {}),\n",
    "             routing_controller=(ContinuousRouter, {}),\n",
    "             initial_speed =0,\n",
    "             num_vehicles=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setting up an Environment\n",
    "\n",
    "Several environments in Flow exist to train RL agents of different forms (e.g. autonomous vehicles, traffic lights) to perform a variety of different tasks. The use of an environment allows us to view the cumulative reward simulation rollouts receive, along with to specify the state/action spaces.\n",
    "\n",
    "Sumo envrionments in Flow are parametrized by three components:\n",
    "* `SumoParams`\n",
    "* `EnvParams`\n",
    "* `Network`\n",
    "\n",
    "### 3.1 SumoParams\n",
    "`SumoParams` specifies simulation-specific variables. These variables include the length of any simulation step and whether to render the GUI when running the experiment. For this example, we consider a simulation step length of 0.1s and deactivate the GUI. \n",
    "\n",
    "**Note** For training purposes, it is highly recommanded to deactivate the GUI in order to avoid global slow down. In such case, one just needs to specify the following: `render=False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import SumoParams\n",
    "\n",
    "sim_params = SumoParams(sim_step=0.1, render=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 EnvParams\n",
    "\n",
    "`EnvParams` specifies environment and experiment-specific parameters that either affect the training process or the dynamics of various components within the network. For the environment `WaveAttenuationPOEnv`, these parameters are used to dictate bounds on the accelerations of the autonomous vehicles, as well as the range of ring lengths (and accordingly network densities) the agent is trained on.\n",
    "\n",
    "Finally, it is important to specify here the *horizon* of the experiment, which is the duration of one episode (during which the RL-agent acquire data). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import EnvParams\n",
    "\n",
    "# Define horizon as a variable to ensure consistent use across notebook\n",
    "HORIZON=2500\n",
    "\n",
    "env_params = EnvParams(\n",
    "    # length of one rollout\n",
    "    horizon=HORIZON,\n",
    "\n",
    "    additional_params={\n",
    "        # maximum acceleration of autonomous vehicles\n",
    "        \"max_accel\": 4,\n",
    "        # maximum deceleration of autonomous vehicles\n",
    "        \"max_decel\": -4,\n",
    "        # bounds on the ranges of ring road lengths the autonomous vehicle \n",
    "        # is trained on\n",
    "        \"ring_length\": [220, 270],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Initializing a Gym Environment\n",
    "\n",
    "Now, we have to specify our Gym Environment and the algorithm that our RL agents will use. Similar to the network, we choose to use on of Flow's builtin environments, a list of which is provided by the script below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Env', 'AccelEnv', 'LaneChangeAccelEnv', 'LaneChangeAccelPOEnv', 'TrafficLightGridTestEnv', 'MergePOEnv', 'BottleneckEnv', 'BottleneckAccelEnv', 'WaveAttenuationEnv', 'WaveAttenuationPOEnv', 'EnergyOptEnv', 'EnergyOptSPDEnv', 'TrafficLightGridEnv', 'TrafficLightGridPOEnv', 'TrafficLightGridBenchmarkEnv', 'BottleneckDesiredVelocityEnv', 'TestEnv', 'BayBridgeEnv', 'SingleStraightRoad', 'BottleNeckAccelEnv', 'DesiredVelocityEnv', 'PO_TrafficLightGridEnv', 'GreenWaveTestEnv']\n"
     ]
    }
   ],
   "source": [
    "import flow.envs as flowenvs\n",
    "\n",
    "print(flowenvs.__all__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the environment \"WaveAttenuationPOEnv\", which is used to train autonomous vehicles to attenuate the formation and propagation of waves in a partially observable variable density ring road. To create the Gym Environment, the only necessary parameters are the environment name plus the previously defined variables. These are defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.envs import EnergyOptSPDEnv\n",
    "\n",
    "env_name = EnergyOptSPDEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from flow.envs import WaveAttenuationPOEnv\n",
    "\n",
    "# env_name = WaveAttenuationPOEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Setting up Flow Parameters\n",
    "\n",
    "RLlib experiments both generate a `params.json` file for each experiment run. For RLlib experiments, the parameters defining the Flow network and environment must be stored as well. As such, in this section we define the dictionary `flow_params`, which contains the variables required by the utility function `make_create_env`. `make_create_env` is a higher-order function which returns a function `create_env` that initializes a Gym environment corresponding to the Flow network specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating flow_params. Make sure the dictionary keys are as specified. \n",
    "flow_params = dict(\n",
    "    # name of the experiment\n",
    "    exp_tag=name,\n",
    "    # name of the flow environment the experiment is running on\n",
    "    env_name=env_name,\n",
    "    # name of the network class the experiment uses\n",
    "    network=network_name,\n",
    "    # simulator that is used by the experiment\n",
    "    simulator='traci',\n",
    "    # simulation-related parameters\n",
    "    sim=sim_params,\n",
    "    # environment related parameters (see flow.core.params.EnvParams)\n",
    "    env=env_params,\n",
    "    # network-related parameters (see flow.core.params.NetParams and\n",
    "    # the network's documentation or ADDITIONAL_NET_PARAMS component)\n",
    "    net=net_params,\n",
    "    # vehicles to be placed in the network at the start of a rollout \n",
    "    # (see flow.core.vehicles.Vehicles)\n",
    "    veh=vehicles,\n",
    "    # (optional) parameters affecting the positioning of vehicles upon \n",
    "    # initialization/reset (see flow.core.params.InitialConfig)\n",
    "    initial=initial_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Running RL experiments in Ray\n",
    "\n",
    "### 4.1 Import \n",
    "\n",
    "First, we must import modules required to run experiments in Ray. The `json` package is required to store the Flow experiment parameters in the `params.json` file, as is `FlowParamsEncoder`. Ray-related imports are required: the PPO algorithm agent, `ray.tune`'s experiment runner, and environment helper methods `register_env` and `make_create_env`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import ray\n",
    "try:\n",
    "    from ray.rllib.agents.agent import get_agent_class\n",
    "except ImportError:\n",
    "    from ray.rllib.agents.registry import get_agent_class\n",
    "# from ray.rllib.agents.agent import get_agent_class\n",
    "#from ray.rllib.agents.registry import get_agent_class\n",
    "from ray.tune import run_experiments\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "from flow.utils.registry import make_create_env\n",
    "from flow.utils.rllib import FlowParamsEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Initializing Ray\n",
    "Here, we initialize Ray and experiment-based constant variables specifying parallelism in the experiment as well as experiment batch size in terms of number of rollouts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-30 18:03:30,973\tINFO node.py:498 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-07-30_18-03-30_972842_25964/logs.\n",
      "2020-07-30 18:03:31,092\tINFO services.py:409 -- Waiting for redis server at 127.0.0.1:55213 to respond...\n",
      "2020-07-30 18:03:31,235\tINFO services.py:409 -- Waiting for redis server at 127.0.0.1:58697 to respond...\n",
      "2020-07-30 18:03:31,241\tINFO services.py:809 -- Starting Redis shard with 3.3 GB max memory.\n",
      "2020-07-30 18:03:31,298\tINFO node.py:512 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-07-30_18-03-30_972842_25964/logs.\n",
      "2020-07-30 18:03:31,300\tWARNING services.py:1330 -- WARNING: The default object store size of 4.96 GB will use more than 50% of the available memory on this node (7.52 GB). Consider setting the object store memory manually to a smaller size to avoid memory contention with other applications.\n",
      "2020-07-30 18:03:31,301\tINFO services.py:1475 -- Starting the Plasma object store with 4.96 GB memory using /dev/shm.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.100.38',\n",
       " 'redis_address': '192.168.100.38:55213',\n",
       " 'object_store_address': '/tmp/ray/session_2020-07-30_18-03-30_972842_25964/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-07-30_18-03-30_972842_25964/sockets/raylet',\n",
       " 'webui_url': None,\n",
       " 'session_dir': '/tmp/ray/session_2020-07-30_18-03-30_972842_25964'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of parallel workers\n",
    "N_CPUS = 6\n",
    "# number of rollouts per training iteration\n",
    "N_ROLLOUTS = 1\n",
    "#ray.shutdown()\n",
    "ray.init(num_cpus=N_CPUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Configuration and Setup\n",
    "Here, we copy and modify the default configuration for the [PPO algorithm](https://arxiv.org/abs/1707.06347). The agent has the number of parallel workers specified, a batch size corresponding to `N_ROLLOUTS` rollouts (each of which has length `HORIZON` steps), a discount rate $\\gamma$ of 0.999, two hidden layers of size 16, uses Generalized Advantage Estimation, $\\lambda$ of 0.97, and other parameters as set below.\n",
    "\n",
    "Once `config` contains the desired parameters, a JSON string corresponding to the `flow_params` specified in section 3 is generated. The `FlowParamsEncoder` maps objects to string representations so that the experiment can be reproduced later. That string representation is stored within the `env_config` section of the `config` dictionary. Later, `config` is written out to the file `params.json`. \n",
    "\n",
    "Next, we call `make_create_env` and pass in the `flow_params` to return a function we can use to register our Flow environment with Gym. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The algorithm or model to train. This may refer to \"\n",
    "#      \"the name of a built-on algorithm (e.g. RLLib's DQN \"\n",
    "#      \"or PPO), or a user-defined trainable function or \"\n",
    "#      \"class registered in the tune registry.\")\n",
    "alg_run = \"PPO\"\n",
    "\n",
    "agent_cls = get_agent_class(alg_run)\n",
    "config = agent_cls._default_config.copy()\n",
    "config[\"num_workers\"] = N_CPUS - 1  # number of parallel workers\n",
    "config[\"train_batch_size\"] = HORIZON * N_ROLLOUTS  # batch size\n",
    "config[\"gamma\"] = 0.99999  # discount rate\n",
    "config[\"model\"].update({\"fcnet_hiddens\": [16, 16]})  # size of hidden layers in network\n",
    "config[\"use_gae\"] = True  # using generalized advantage estimation\n",
    "config[\"lambda\"] = 0.97  \n",
    "config[\"sgd_minibatch_size\"] = min(16 * 1024, config[\"train_batch_size\"])  # stochastic gradient descent\n",
    "config[\"kl_target\"] = 0.02  # target KL divergence\n",
    "config[\"num_sgd_iter\"] = 10  # number of SGD iterations\n",
    "config[\"horizon\"] = HORIZON  # rollout horizon\n",
    "\n",
    "# save the flow params for replay\n",
    "flow_json = json.dumps(flow_params, cls=FlowParamsEncoder, sort_keys=True,\n",
    "                       indent=4)  # generating a string version of flow_params\n",
    "config['env_config']['flow_params'] = flow_json  # adding the flow_params to config dict\n",
    "config['env_config']['run'] = alg_run\n",
    "\n",
    "# Call the utility function make_create_env to be able to \n",
    "# register the Flow env for this experiment\n",
    "create_env, gym_name = make_create_env(params=flow_params, version=0)\n",
    "\n",
    "# Register as rllib env with Gym\n",
    "register_env(gym_name, create_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Running Experiments\n",
    "\n",
    "Here, we use the `run_experiments` function from `ray.tune`. The function takes a dictionary with one key, a name corresponding to the experiment, and one value, itself a dictionary containing parameters for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-30 18:03:31,610\tINFO trial_runner.py:176 -- Starting a new experiment.\n",
      "2020-07-30 18:03:31,704\tWARNING signature.py:108 -- The function with_updates has a **kwargs argument, which is currently not supported.\n",
      "2020-07-30 18:03:31,726\tWARNING logger.py:227 -- Could not instantiate <class 'ray.tune.logger.TFLogger'> - skipping.\n",
      "2020-07-30 18:03:31,736\tERROR log_sync.py:34 -- Log sync requires cluster to be setup with `ray up`.\n",
      "2020-07-30 18:03:31,814\tWARNING util.py:145 -- The `start_trial` operation took 0.11550617218017578 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 9.1/16.5 GB\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 9.1/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m 2020-07-30 18:03:34,326\tWARNING ppo.py:143 -- FYI: By default, the value function will not share layers with the policy model ('vf_share_layers': False).\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m 2020-07-30 18:03:35,444\tINFO rollout_worker.py:319 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m 2020-07-30 18:03:35.445359: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m 2020-07-30 18:03:35.468962: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 1999965000 Hz\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m 2020-07-30 18:03:35.469598: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc51c000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m 2020-07-30 18:03:35.469631: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m 2020-07-30 18:03:35.471547: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m 2020-07-30 18:03:35.471566: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m 2020-07-30 18:03:35.471582: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (solom-XPS-13-9380): /proc/driver/nvidia/version does not exist\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/models/tf/fcnet_v1.py:48: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m Use keras.layers.Dense instead.\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/models/tf/fcnet_v1.py:48: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m Use keras.layers.Dense instead.\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/tensorflow/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m Please use `layer.__call__` method instead.\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/tensorflow/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m Please use `layer.__call__` method instead.\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/models/tf/tf_action_dist.py:138: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m Use `tf.cast` instead.\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/models/tf/tf_action_dist.py:138: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m Use `tf.cast` instead.\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m 2020-07-30 18:03:35,577\tINFO dynamic_tf_policy.py:324 -- Initializing loss function with dummy input:\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m { 'action_prob': <tf.Tensor 'default_policy/action_prob:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m   'actions': <tf.Tensor 'default_policy/actions:0' shape=(?, 1) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m   'advantages': <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m   'behaviour_logits': <tf.Tensor 'default_policy/behaviour_logits:0' shape=(?, 2) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m   'dones': <tf.Tensor 'default_policy/dones:0' shape=(?,) dtype=bool>,\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m   'new_obs': <tf.Tensor 'default_policy/new_obs:0' shape=(?, 3) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m   'obs': <tf.Tensor 'default_policy/observation:0' shape=(?, 3) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m   'prev_actions': <tf.Tensor 'default_policy/action:0' shape=(?, 1) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m   'prev_rewards': <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m   'rewards': <tf.Tensor 'default_policy/rewards:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m   'value_targets': <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m   'vf_preds': <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>}\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m 2020-07-30 18:03:36,226\tINFO rollout_worker.py:742 -- Built policy map: {'default_policy': <ray.rllib.policy.tf_policy_template.PPOTFPolicy object at 0x7fc5534a1550>}\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m 2020-07-30 18:03:36,226\tINFO rollout_worker.py:743 -- Built preprocessor map: {'default_policy': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7fc55440d050>}\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m 2020-07-30 18:03:36,226\tINFO rollout_worker.py:356 -- Built filter map: {'default_policy': <ray.rllib.utils.filter.NoFilter object at 0x7fc5534a1090>}\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m 2020-07-30 18:03:36,313\tINFO multi_gpu_optimizer.py:93 -- LocalMultiGPUOptimizer devices ['/cpu:0']\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m 2020-07-30 18:03:39,560\tWARNING util.py:47 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/policy/tf_policy.py:570: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/policy/tf_policy.py:570: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m 2020-07-30 18:03:40,571\tINFO rollout_worker.py:319 -- Creating policy evaluation worker 2 on CPU (please ignore any CUDA init errors)\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m 2020-07-30 18:03:40.572980: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m 2020-07-30 18:03:40,586\tINFO rollout_worker.py:319 -- Creating policy evaluation worker 4 on CPU (please ignore any CUDA init errors)\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m 2020-07-30 18:03:40.587869: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m 2020-07-30 18:03:40.594691: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 1999965000 Hz\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m 2020-07-30 18:03:40.594831: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f0c7c000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m 2020-07-30 18:03:40.594873: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m 2020-07-30 18:03:40.596622: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 1999965000 Hz\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m 2020-07-30 18:03:40.596849: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f00f0000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m 2020-07-30 18:03:40.596875: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m 2020-07-30 18:03:40.598859: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m 2020-07-30 18:03:40.598874: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m 2020-07-30 18:03:40.598890: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (solom-XPS-13-9380): /proc/driver/nvidia/version does not exist\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/models/tf/fcnet_v1.py:48: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m Use keras.layers.Dense instead.\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/models/tf/fcnet_v1.py:48: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m Use keras.layers.Dense instead.\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/tensorflow/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m Please use `layer.__call__` method instead.\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/tensorflow/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m Please use `layer.__call__` method instead.\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m 2020-07-30 18:03:40.596278: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m 2020-07-30 18:03:40.596288: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m 2020-07-30 18:03:40.596305: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (solom-XPS-13-9380): /proc/driver/nvidia/version does not exist\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/models/tf/fcnet_v1.py:48: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m Use keras.layers.Dense instead.\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/models/tf/fcnet_v1.py:48: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m Use keras.layers.Dense instead.\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/tensorflow/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m Please use `layer.__call__` method instead.\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/tensorflow/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m Please use `layer.__call__` method instead.\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/models/tf/tf_action_dist.py:138: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m Use `tf.cast` instead.\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/models/tf/tf_action_dist.py:138: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m Use `tf.cast` instead.\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/models/tf/tf_action_dist.py:138: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m Use `tf.cast` instead.\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/models/tf/tf_action_dist.py:138: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m Use `tf.cast` instead.\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m 2020-07-30 18:03:40,738\tINFO rollout_worker.py:319 -- Creating policy evaluation worker 3 on CPU (please ignore any CUDA init errors)\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m 2020-07-30 18:03:40.739903: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m 2020-07-30 18:03:40,743\tINFO rollout_worker.py:319 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m 2020-07-30 18:03:40.745259: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m 2020-07-30 18:03:40.752579: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 1999965000 Hz\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m 2020-07-30 18:03:40.752796: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8f90000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m 2020-07-30 18:03:40.752820: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m 2020-07-30 18:03:40.755318: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m 2020-07-30 18:03:40.755339: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m 2020-07-30 18:03:40.755360: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (solom-XPS-13-9380): /proc/driver/nvidia/version does not exist\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/models/tf/fcnet_v1.py:48: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m Use keras.layers.Dense instead.\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/models/tf/fcnet_v1.py:48: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m Use keras.layers.Dense instead.\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/tensorflow/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m Please use `layer.__call__` method instead.\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/tensorflow/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m Please use `layer.__call__` method instead.\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m 2020-07-30 18:03:40.753467: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 1999965000 Hz\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m 2020-07-30 18:03:40.753679: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc7c8000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m 2020-07-30 18:03:40.753699: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m 2020-07-30 18:03:40.756504: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m 2020-07-30 18:03:40.756531: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m 2020-07-30 18:03:40.756566: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (solom-XPS-13-9380): /proc/driver/nvidia/version does not exist\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/models/tf/fcnet_v1.py:48: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m Use keras.layers.Dense instead.\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/models/tf/fcnet_v1.py:48: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m Use keras.layers.Dense instead.\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/tensorflow/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m Please use `layer.__call__` method instead.\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/tensorflow/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m Please use `layer.__call__` method instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/models/tf/tf_action_dist.py:138: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m Use `tf.cast` instead.\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/models/tf/tf_action_dist.py:138: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m Use `tf.cast` instead.\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/models/tf/tf_action_dist.py:138: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m Use `tf.cast` instead.\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/models/tf/tf_action_dist.py:138: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m Use `tf.cast` instead.\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m 2020-07-30 18:03:40,860\tINFO rollout_worker.py:319 -- Creating policy evaluation worker 5 on CPU (please ignore any CUDA init errors)\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m 2020-07-30 18:03:40.862046: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m 2020-07-30 18:03:40.869928: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 1999965000 Hz\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m 2020-07-30 18:03:40.870138: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7610000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m 2020-07-30 18:03:40.870161: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m 2020-07-30 18:03:40.873107: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m 2020-07-30 18:03:40.873141: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m 2020-07-30 18:03:40.873171: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (solom-XPS-13-9380): /proc/driver/nvidia/version does not exist\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/models/tf/fcnet_v1.py:48: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m Use keras.layers.Dense instead.\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/models/tf/fcnet_v1.py:48: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m Use keras.layers.Dense instead.\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/tensorflow/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m Please use `layer.__call__` method instead.\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/tensorflow/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m Please use `layer.__call__` method instead.\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m 2020-07-30 18:03:40,917\tINFO dynamic_tf_policy.py:324 -- Initializing loss function with dummy input:\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m { 'action_prob': <tf.Tensor 'default_policy/action_prob:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m   'actions': <tf.Tensor 'default_policy/actions:0' shape=(?, 1) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m   'advantages': <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m   'behaviour_logits': <tf.Tensor 'default_policy/behaviour_logits:0' shape=(?, 2) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m   'dones': <tf.Tensor 'default_policy/dones:0' shape=(?,) dtype=bool>,\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m   'new_obs': <tf.Tensor 'default_policy/new_obs:0' shape=(?, 3) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m   'obs': <tf.Tensor 'default_policy/observation:0' shape=(?, 3) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m   'prev_actions': <tf.Tensor 'default_policy/action:0' shape=(?, 1) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m   'prev_rewards': <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m   'rewards': <tf.Tensor 'default_policy/rewards:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m   'value_targets': <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m   'vf_preds': <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>}\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/models/tf/tf_action_dist.py:138: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m Use `tf.cast` instead.\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/models/tf/tf_action_dist.py:138: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m Use `tf.cast` instead.\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/policy/tf_policy.py:570: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/policy/tf_policy.py:570: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/policy/tf_policy.py:570: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/policy/tf_policy.py:570: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/policy/tf_policy.py:570: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/policy/tf_policy.py:570: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m 2020-07-30 18:03:41,874\tINFO rollout_worker.py:451 -- Generating sample batch of size 200\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/policy/tf_policy.py:570: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/policy/tf_policy.py:570: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/policy/tf_policy.py:570: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m WARNING:tensorflow:From /home/solom/anaconda3/lib/python3.7/site-packages/ray/rllib/policy/tf_policy.py:570: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m 2020-07-30 18:03:42,986\tINFO sampler.py:304 -- Raw obs from env: { 0: { 'agent0': np.ndarray((3,), dtype=float64, min=0.0, max=0.0, mean=0.0)}}\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m 2020-07-30 18:03:42,986\tINFO sampler.py:305 -- Info return from env: {0: {'agent0': None}}\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m 2020-07-30 18:03:42,986\tINFO sampler.py:403 -- Preprocessed obs: np.ndarray((3,), dtype=float64, min=0.0, max=0.0, mean=0.0)\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m 2020-07-30 18:03:42,986\tINFO sampler.py:407 -- Filtered obs: np.ndarray((3,), dtype=float64, min=0.0, max=0.0, mean=0.0)\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m 2020-07-30 18:03:42,987\tINFO sampler.py:521 -- Inputs to compute_actions():\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m { 'default_policy': [ { 'data': { 'agent_id': 'agent0',\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m                                   'env_id': 0,\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m                                   'info': None,\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m                                   'obs': np.ndarray((3,), dtype=float64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m                                   'prev_action': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m                                   'prev_reward': 0.0,\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m                                   'rnn_state': []},\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m                         'type': 'PolicyEvalData'}]}\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m 2020-07-30 18:03:42,987\tINFO tf_run_builder.py:92 -- Executing TF run without tracing. To dump TF timeline traces to disk, set the TF_TIMELINE_DIR environment variable.\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m 2020-07-30 18:03:43,023\tINFO sampler.py:548 -- Outputs of compute_actions():\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m { 'default_policy': ( np.ndarray((1, 1), dtype=float32, min=1.1, max=1.1, mean=1.1),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m                       [],\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m                       { 'action_prob': np.ndarray((1,), dtype=float32, min=0.218, max=0.218, mean=0.218),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m                         'behaviour_logits': np.ndarray((1, 2), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m                         'vf_preds': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0)})}\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m 2020-07-30 18:03:43,977\tINFO sample_batch_builder.py:161 -- Trajectory fragment after postprocess_trajectory():\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m { 'agent0': { 'data': { 'action_prob': np.ndarray((200,), dtype=float32, min=0.012, max=0.399, mean=0.286),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m                         'actions': np.ndarray((200, 1), dtype=float32, min=-2.663, max=2.506, mean=-0.049),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m                         'advantages': np.ndarray((200,), dtype=float32, min=0.053, max=2.208, mean=1.724),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m                         'agent_index': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m                         'behaviour_logits': np.ndarray((200, 2), dtype=float32, min=-0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m                         'dones': np.ndarray((200,), dtype=bool, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m                         'eps_id': np.ndarray((200,), dtype=int64, min=1525407891.0, max=1525407891.0, mean=1525407891.0),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m                         'infos': np.ndarray((200,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m                         'new_obs': np.ndarray((200, 3), dtype=float32, min=0.0, max=0.038, mean=0.008),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m                         'obs': np.ndarray((200, 3), dtype=float32, min=0.0, max=0.038, mean=0.008),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m                         'prev_actions': np.ndarray((200, 1), dtype=float32, min=-2.663, max=2.506, mean=-0.056),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m                         'prev_rewards': np.ndarray((200,), dtype=float32, min=0.0, max=0.07, mean=0.059),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m                         'rewards': np.ndarray((200,), dtype=float32, min=0.011, max=0.07, mean=0.059),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m                         't': np.ndarray((200,), dtype=int64, min=0.0, max=199.0, mean=99.5),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m                         'unroll_id': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m                         'value_targets': np.ndarray((200,), dtype=float32, min=0.053, max=2.208, mean=1.724),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m                         'vf_preds': np.ndarray((200,), dtype=float32, min=-0.0, max=0.0, mean=0.0)},\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m               'type': 'SampleBatch'}}\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m 2020-07-30 18:03:43,980\tINFO rollout_worker.py:485 -- Completed sample batch:\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m { 'data': { 'action_prob': np.ndarray((200,), dtype=float32, min=0.012, max=0.399, mean=0.286),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m             'actions': np.ndarray((200, 1), dtype=float32, min=-2.663, max=2.506, mean=-0.049),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m             'advantages': np.ndarray((200,), dtype=float32, min=0.053, max=2.208, mean=1.724),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m             'agent_index': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m             'behaviour_logits': np.ndarray((200, 2), dtype=float32, min=-0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m             'dones': np.ndarray((200,), dtype=bool, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m             'eps_id': np.ndarray((200,), dtype=int64, min=1525407891.0, max=1525407891.0, mean=1525407891.0),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m             'infos': np.ndarray((200,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m             'new_obs': np.ndarray((200, 3), dtype=float32, min=0.0, max=0.038, mean=0.008),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m             'obs': np.ndarray((200, 3), dtype=float32, min=0.0, max=0.038, mean=0.008),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m             'prev_actions': np.ndarray((200, 1), dtype=float32, min=-2.663, max=2.506, mean=-0.056),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m             'prev_rewards': np.ndarray((200,), dtype=float32, min=0.0, max=0.07, mean=0.059),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m             'rewards': np.ndarray((200,), dtype=float32, min=0.011, max=0.07, mean=0.059),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m             't': np.ndarray((200,), dtype=int64, min=0.0, max=199.0, mean=99.5),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m             'unroll_id': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m             'value_targets': np.ndarray((200,), dtype=float32, min=0.053, max=2.208, mean=1.724),\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m             'vf_preds': np.ndarray((200,), dtype=float32, min=-0.0, max=0.0, mean=0.0)},\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m   'type': 'SampleBatch'}\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m 2020-07-30 18:03:45,922\tINFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/default_model/fc1/kernel:0' shape=(3, 16) dtype=float32_ref>\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m 2020-07-30 18:03:45,922\tINFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/default_model/fc1/bias:0' shape=(16,) dtype=float32_ref>\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m 2020-07-30 18:03:45,929\tINFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/default_model/fc2/kernel:0' shape=(16, 16) dtype=float32_ref>\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m 2020-07-30 18:03:45,929\tINFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/default_model/fc2/bias:0' shape=(16,) dtype=float32_ref>\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m 2020-07-30 18:03:45,929\tINFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/default_model/fc_out/kernel:0' shape=(16, 2) dtype=float32_ref>\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m 2020-07-30 18:03:45,929\tINFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/default_model/fc_out/bias:0' shape=(2,) dtype=float32_ref>\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m 2020-07-30 18:03:45,929\tINFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/value_function/fc1/kernel:0' shape=(3, 16) dtype=float32_ref>\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m 2020-07-30 18:03:45,930\tINFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/value_function/fc1/bias:0' shape=(16,) dtype=float32_ref>\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m 2020-07-30 18:03:45,930\tINFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/value_function/fc2/kernel:0' shape=(16, 16) dtype=float32_ref>\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m 2020-07-30 18:03:45,930\tINFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/value_function/fc2/bias:0' shape=(16,) dtype=float32_ref>\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m 2020-07-30 18:03:45,930\tINFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/value_function/fc_out/kernel:0' shape=(16, 1) dtype=float32_ref>\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m 2020-07-30 18:03:45,930\tINFO tf_policy.py:355 -- Optimizing variable <tf.Variable 'default_policy/value_function/fc_out/bias:0' shape=(1,) dtype=float32_ref>\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m 2020-07-30 18:03:45,931\tINFO multi_gpu_impl.py:146 -- Training on concatenated sample batches:\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m { 'inputs': [ np.ndarray((2600, 1), dtype=float32, min=-3.515, max=3.44, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m               np.ndarray((2600,), dtype=float32, min=0.0, max=0.147, mean=0.07),\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m               np.ndarray((2600, 3), dtype=float32, min=0.0, max=0.113, mean=0.018),\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m               np.ndarray((2600, 1), dtype=float32, min=-3.515, max=3.44, mean=0.002),\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m               np.ndarray((2600,), dtype=float32, min=-2.115, max=2.548, mean=-0.0),\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m               np.ndarray((2600, 2), dtype=float32, min=-0.0, max=0.001, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m               np.ndarray((2600,), dtype=float32, min=0.043, max=4.449, mean=2.041),\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m               np.ndarray((2600,), dtype=float32, min=-0.0, max=0.0, mean=0.0)],\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m   'placeholders': [ <tf.Tensor 'default_policy/action:0' shape=(?, 1) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 3) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m                     <tf.Tensor 'default_policy/actions:0' shape=(?, 1) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m                     <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m                     <tf.Tensor 'default_policy/behaviour_logits:0' shape=(?, 2) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m                     <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m                     <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>],\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m   'state_inputs': []}\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m 2020-07-30 18:03:45,931\tINFO multi_gpu_impl.py:191 -- Divided 2600 rollout sequences, each of length 1, among 1 devices.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-03-46\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 322.373\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4187803268432617\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.979278690418141e-07\n",
      "        policy_loss: 3.0692412110511214e-05\n",
      "        total_loss: 5.060368537902832\n",
      "        vf_explained_var: 0.00028771162033081055\n",
      "        vf_loss: 5.060336589813232\n",
      "    load_time_ms: 54.955\n",
      "    num_steps_sampled: 2600\n",
      "    num_steps_trained: 2500\n",
      "    sample_time_ms: 5727.582\n",
      "    update_time_ms: 582.942\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.529999999999994\n",
      "    ram_util_percent: 63.4\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 6.734850645065308\n",
      "  time_this_iter_s: 6.734850645065308\n",
      "  time_total_s: 6.734850645065308\n",
      "  timestamp: 1596121426\n",
      "  timesteps_since_restore: 2600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2600\n",
      "  training_iteration: 1\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 6 s, 1 iter, 2600 ts, nan rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m /home/solom/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m   out=out, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m /home/solom/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "\u001b[2m\u001b[36m(pid=26009)\u001b[0m   ret = ret.dtype.type(ret / rcount)\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-03-52\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 123.053\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.05000000074505806\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4178918600082397\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.0511159871384734e-06\n",
      "        policy_loss: 0.006286472547799349\n",
      "        total_loss: 40.38962936401367\n",
      "        vf_explained_var: 0.0004157423973083496\n",
      "        vf_loss: 40.38334274291992\n",
      "    load_time_ms: 19.127\n",
      "    num_steps_sampled: 7800\n",
      "    num_steps_trained: 7500\n",
      "    sample_time_ms: 3827.421\n",
      "    update_time_ms: 196.889\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.160000000000004\n",
      "    ram_util_percent: 63.6\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 12.559945106506348\n",
      "  time_this_iter_s: 2.9120333194732666\n",
      "  time_total_s: 12.559945106506348\n",
      "  timestamp: 1596121432\n",
      "  timesteps_since_restore: 7800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 7800\n",
      "  training_iteration: 3\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 12 s, 3 iter, 7800 ts, nan rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-03-59\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 606.4036123591301\n",
      "  episode_reward_mean: 487.3138560669742\n",
      "  episode_reward_min: 287.20456899664816\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 5\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 83.137\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.012500000186264515\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4183239936828613\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.103423068750999e-06\n",
      "        policy_loss: 0.003976467996835709\n",
      "        total_loss: 60.482662200927734\n",
      "        vf_explained_var: 0.0014674067497253418\n",
      "        vf_loss: 60.47867965698242\n",
      "    load_time_ms: 11.943\n",
      "    num_steps_sampled: 13000\n",
      "    num_steps_trained: 12500\n",
      "    sample_time_ms: 3685.775\n",
      "    update_time_ms: 119.655\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 43.96666666666667\n",
      "    ram_util_percent: 63.58333333333334\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.182533776013038\n",
      "    mean_inference_ms: 0.8905975968046678\n",
      "    mean_processing_ms: 0.6480592436535639\n",
      "  time_since_restore: 19.588744401931763\n",
      "  time_this_iter_s: 4.002650737762451\n",
      "  time_total_s: 19.588744401931763\n",
      "  timestamp: 1596121439\n",
      "  timesteps_since_restore: 13000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 13000\n",
      "  training_iteration: 5\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 19 s, 5 iter, 13000 ts, 487 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-04-05\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 606.4036123591301\n",
      "  episode_reward_mean: 487.3138560669742\n",
      "  episode_reward_min: 287.20456899664816\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 5\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 66.082\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0031250000465661287\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4184831380844116\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.4156571498679114e-07\n",
      "        policy_loss: -0.0021580515895038843\n",
      "        total_loss: 18.241050720214844\n",
      "        vf_explained_var: 0.001673281192779541\n",
      "        vf_loss: 18.243206024169922\n",
      "    load_time_ms: 8.854\n",
      "    num_steps_sampled: 18200\n",
      "    num_steps_trained: 17500\n",
      "    sample_time_ms: 3512.369\n",
      "    update_time_ms: 87.362\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.95\n",
      "    ram_util_percent: 63.65\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.182533776013038\n",
      "    mean_inference_ms: 0.8905975968046678\n",
      "    mean_processing_ms: 0.6480592436535639\n",
      "  time_since_restore: 25.821800470352173\n",
      "  time_this_iter_s: 3.131666898727417\n",
      "  time_total_s: 25.821800470352173\n",
      "  timestamp: 1596121445\n",
      "  timesteps_since_restore: 18200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 18200\n",
      "  training_iteration: 7\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 25 s, 7 iter, 18200 ts, 487 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-04-12\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 606.4036123591301\n",
      "  episode_reward_mean: 433.86099541364916\n",
      "  episode_reward_min: 166.59669214702404\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 6\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 56.735\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0007812500116415322\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4176993370056152\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.283428154394642e-07\n",
      "        policy_loss: 0.0008164261817000806\n",
      "        total_loss: 29.64784049987793\n",
      "        vf_explained_var: 0.0015592575073242188\n",
      "        vf_loss: 29.647022247314453\n",
      "    load_time_ms: 7.137\n",
      "    num_steps_sampled: 23400\n",
      "    num_steps_trained: 22500\n",
      "    sample_time_ms: 3534.607\n",
      "    update_time_ms: 68.801\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 51.71666666666667\n",
      "    ram_util_percent: 63.616666666666674\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.16126726502411\n",
      "    mean_inference_ms: 0.8927665515431502\n",
      "    mean_processing_ms: 0.6516933547214708\n",
      "  time_since_restore: 33.11888074874878\n",
      "  time_this_iter_s: 4.122771263122559\n",
      "  time_total_s: 33.11888074874878\n",
      "  timestamp: 1596121452\n",
      "  timesteps_since_restore: 23400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 23400\n",
      "  training_iteration: 9\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 33 s, 9 iter, 23400 ts, 434 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-04-19\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 645.844145864241\n",
      "  episode_reward_mean: 408.80159466771477\n",
      "  episode_reward_min: 157.54734207482142\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 10\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 23.871\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.00019531250291038305\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4178593158721924\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.6689299942029834e-10\n",
      "        policy_loss: -0.0034391391091048717\n",
      "        total_loss: 9.208727836608887\n",
      "        vf_explained_var: 0.0025658607482910156\n",
      "        vf_loss: 9.21216869354248\n",
      "    load_time_ms: 1.167\n",
      "    num_steps_sampled: 28600\n",
      "    num_steps_trained: 27500\n",
      "    sample_time_ms: 3312.103\n",
      "    update_time_ms: 4.448\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.824999999999996\n",
      "    ram_util_percent: 63.675\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.135935480592866\n",
      "    mean_inference_ms: 0.9026974181078351\n",
      "    mean_processing_ms: 0.6578540946682371\n",
      "  time_since_restore: 40.23332333564758\n",
      "  time_this_iter_s: 3.000096082687378\n",
      "  time_total_s: 40.23332333564758\n",
      "  timestamp: 1596121459\n",
      "  timesteps_since_restore: 28600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 28600\n",
      "  training_iteration: 11\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 40 s, 11 iter, 28600 ts, 409 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-04-26\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 645.844145864241\n",
      "  episode_reward_mean: 408.80159466771477\n",
      "  episode_reward_min: 157.54734207482142\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 10\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 23.847\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 4.882812572759576e-05\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.417540431022644\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.723071924672695e-07\n",
      "        policy_loss: -0.003725234651938081\n",
      "        total_loss: 46.35298156738281\n",
      "        vf_explained_var: 0.0033150911331176758\n",
      "        vf_loss: 46.35670471191406\n",
      "    load_time_ms: 1.148\n",
      "    num_steps_sampled: 33800\n",
      "    num_steps_trained: 32500\n",
      "    sample_time_ms: 3354.597\n",
      "    update_time_ms: 4.532\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.675\n",
      "    ram_util_percent: 63.625\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.135935480592866\n",
      "    mean_inference_ms: 0.9026974181078351\n",
      "    mean_processing_ms: 0.6578540946682371\n",
      "  time_since_restore: 46.484778881073\n",
      "  time_this_iter_s: 3.1161537170410156\n",
      "  time_total_s: 46.484778881073\n",
      "  timestamp: 1596121466\n",
      "  timesteps_since_restore: 33800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 33800\n",
      "  training_iteration: 13\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 46 s, 13 iter, 33800 ts, 409 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-04-34\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 645.844145864241\n",
      "  episode_reward_mean: 415.16444618551355\n",
      "  episode_reward_min: 157.54734207482142\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 15\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 24.279\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.220703143189894e-05\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4179211854934692\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.8977403897224576e-06\n",
      "        policy_loss: -3.510589522193186e-05\n",
      "        total_loss: 28.503175735473633\n",
      "        vf_explained_var: 0.004620015621185303\n",
      "        vf_loss: 28.50320053100586\n",
      "    load_time_ms: 1.144\n",
      "    num_steps_sampled: 39000\n",
      "    num_steps_trained: 37500\n",
      "    sample_time_ms: 3446.921\n",
      "    update_time_ms: 4.561\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.53333333333333\n",
      "    ram_util_percent: 63.63333333333333\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.1078221412502565\n",
      "    mean_inference_ms: 0.9091995321810926\n",
      "    mean_processing_ms: 0.6619871258945328\n",
      "  time_since_restore: 54.4313702583313\n",
      "  time_this_iter_s: 4.613804817199707\n",
      "  time_total_s: 54.4313702583313\n",
      "  timestamp: 1596121474\n",
      "  timesteps_since_restore: 39000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 39000\n",
      "  training_iteration: 15\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 54 s, 15 iter, 39000 ts, 415 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-04-40\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 645.844145864241\n",
      "  episode_reward_mean: 415.16444618551344\n",
      "  episode_reward_min: 157.54734207482142\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 15\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 24.071\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 3.051757857974735e-06\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.417754888534546\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.8644332300254973e-08\n",
      "        policy_loss: 0.007586339022964239\n",
      "        total_loss: 14.60401725769043\n",
      "        vf_explained_var: 0.002976536750793457\n",
      "        vf_loss: 14.596430778503418\n",
      "    load_time_ms: 1.137\n",
      "    num_steps_sampled: 44200\n",
      "    num_steps_trained: 42500\n",
      "    sample_time_ms: 3430.385\n",
      "    update_time_ms: 4.018\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.0\n",
      "    ram_util_percent: 63.6\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.107822141250257\n",
      "    mean_inference_ms: 0.9091995321810926\n",
      "    mean_processing_ms: 0.661987125894533\n",
      "  time_since_restore: 60.49235272407532\n",
      "  time_this_iter_s: 2.992438554763794\n",
      "  time_total_s: 60.49235272407532\n",
      "  timestamp: 1596121480\n",
      "  timesteps_since_restore: 44200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 44200\n",
      "  training_iteration: 17\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 60 s, 17 iter, 44200 ts, 415 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-04-48\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 645.844145864241\n",
      "  episode_reward_mean: 402.9989756344348\n",
      "  episode_reward_min: 157.54734207482142\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 18\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 23.997\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 7.629394644936838e-07\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4178563356399536\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.3267755321066943e-06\n",
      "        policy_loss: -0.003598263254389167\n",
      "        total_loss: 40.23943328857422\n",
      "        vf_explained_var: 0.0051381587982177734\n",
      "        vf_loss: 40.243038177490234\n",
      "    load_time_ms: 1.139\n",
      "    num_steps_sampled: 49400\n",
      "    num_steps_trained: 47500\n",
      "    sample_time_ms: 3514.755\n",
      "    update_time_ms: 4.092\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 42.449999999999996\n",
      "    ram_util_percent: 63.6\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.091056132550949\n",
      "    mean_inference_ms: 0.9105211523335623\n",
      "    mean_processing_ms: 0.6640695910541033\n",
      "  time_since_restore: 68.63308644294739\n",
      "  time_this_iter_s: 3.994950532913208\n",
      "  time_total_s: 68.63308644294739\n",
      "  timestamp: 1596121488\n",
      "  timesteps_since_restore: 49400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 49400\n",
      "  training_iteration: 19\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 68 s, 19 iter, 49400 ts, 403 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-04-54\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 645.844145864241\n",
      "  episode_reward_mean: 406.60768125442\n",
      "  episode_reward_min: 157.54734207482142\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 20\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 23.966\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.9073486612342094e-07\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4178017377853394\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.0704994224397524e-08\n",
      "        policy_loss: -0.004053878597915173\n",
      "        total_loss: 19.000078201293945\n",
      "        vf_explained_var: 0.005147576332092285\n",
      "        vf_loss: 19.004133224487305\n",
      "    load_time_ms: 1.119\n",
      "    num_steps_sampled: 54600\n",
      "    num_steps_trained: 52500\n",
      "    sample_time_ms: 3407.82\n",
      "    update_time_ms: 4.001\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.62499999999999\n",
      "    ram_util_percent: 63.6\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.085059508018563\n",
      "    mean_inference_ms: 0.9118225692049575\n",
      "    mean_processing_ms: 0.6663368591724245\n",
      "  time_since_restore: 74.6757378578186\n",
      "  time_this_iter_s: 2.996478796005249\n",
      "  time_total_s: 74.6757378578186\n",
      "  timestamp: 1596121494\n",
      "  timesteps_since_restore: 54600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 54600\n",
      "  training_iteration: 21\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 74 s, 21 iter, 54600 ts, 407 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-05-01\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 645.844145864241\n",
      "  episode_reward_mean: 404.34849381681335\n",
      "  episode_reward_min: 157.54734207482142\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 21\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 24.021\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 4.7683716530855236e-08\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.41826331615448\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 9.026527436617471e-07\n",
      "        policy_loss: -0.0032318043522536755\n",
      "        total_loss: 41.616783142089844\n",
      "        vf_explained_var: 0.00841444730758667\n",
      "        vf_loss: 41.62001419067383\n",
      "    load_time_ms: 1.134\n",
      "    num_steps_sampled: 59800\n",
      "    num_steps_trained: 57500\n",
      "    sample_time_ms: 3480.244\n",
      "    update_time_ms: 3.993\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.86\n",
      "    ram_util_percent: 63.620000000000005\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.0789128376775885\n",
      "    mean_inference_ms: 0.9115228589545351\n",
      "    mean_processing_ms: 0.6664269215567309\n",
      "  time_since_restore: 81.6508641242981\n",
      "  time_this_iter_s: 3.9662890434265137\n",
      "  time_total_s: 81.6508641242981\n",
      "  timestamp: 1596121501\n",
      "  timesteps_since_restore: 59800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 59800\n",
      "  training_iteration: 23\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 81 s, 23 iter, 59800 ts, 404 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-05-07\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 645.844145864241\n",
      "  episode_reward_mean: 411.88563695834983\n",
      "  episode_reward_min: 157.54734207482142\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 24\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 23.779\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.1920929132713809e-08\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4185662269592285\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.5267601699852094e-07\n",
      "        policy_loss: 0.0017515139188617468\n",
      "        total_loss: 6.6232194900512695\n",
      "        vf_explained_var: 0.011926651000976562\n",
      "        vf_loss: 6.621469497680664\n",
      "    load_time_ms: 1.12\n",
      "    num_steps_sampled: 65000\n",
      "    num_steps_trained: 62500\n",
      "    sample_time_ms: 3301.329\n",
      "    update_time_ms: 4.076\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.324999999999996\n",
      "    ram_util_percent: 63.6\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.066434394973487\n",
      "    mean_inference_ms: 0.9122117253265491\n",
      "    mean_processing_ms: 0.6675746707937705\n",
      "  time_since_restore: 87.80611944198608\n",
      "  time_this_iter_s: 2.961198091506958\n",
      "  time_total_s: 87.80611944198608\n",
      "  timestamp: 1596121507\n",
      "  timesteps_since_restore: 65000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 65000\n",
      "  training_iteration: 25\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 87 s, 25 iter, 65000 ts, 412 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-05-15\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 645.844145864241\n",
      "  episode_reward_mean: 396.7965996436134\n",
      "  episode_reward_min: 157.54734207482142\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 26\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 23.954\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.9802322831784522e-09\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4193532466888428\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 7.688522600801662e-07\n",
      "        policy_loss: 0.0013940485659986734\n",
      "        total_loss: 14.031665802001953\n",
      "        vf_explained_var: 0.0116194486618042\n",
      "        vf_loss: 14.030275344848633\n",
      "    load_time_ms: 1.152\n",
      "    num_steps_sampled: 70200\n",
      "    num_steps_trained: 67500\n",
      "    sample_time_ms: 3470.459\n",
      "    update_time_ms: 4.035\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 52.23333333333333\n",
      "    ram_util_percent: 63.66666666666668\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.058472704915382\n",
      "    mean_inference_ms: 0.9121699847501629\n",
      "    mean_processing_ms: 0.6684851206775606\n",
      "  time_since_restore: 95.56106185913086\n",
      "  time_this_iter_s: 4.374079465866089\n",
      "  time_total_s: 95.56106185913086\n",
      "  timestamp: 1596121515\n",
      "  timesteps_since_restore: 70200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 70200\n",
      "  training_iteration: 27\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 95 s, 27 iter, 70200 ts, 397 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-05-21\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 645.844145864241\n",
      "  episode_reward_mean: 388.48473516758355\n",
      "  episode_reward_min: 157.54734207482142\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 28\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 23.787\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 7.450580707946131e-10\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4197971820831299\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.3757943406744744e-07\n",
      "        policy_loss: -0.00567496195435524\n",
      "        total_loss: 30.193471908569336\n",
      "        vf_explained_var: 0.011645913124084473\n",
      "        vf_loss: 30.199146270751953\n",
      "    load_time_ms: 1.134\n",
      "    num_steps_sampled: 75400\n",
      "    num_steps_trained: 72500\n",
      "    sample_time_ms: 3274.846\n",
      "    update_time_ms: 4.13\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.81999999999999\n",
      "    ram_util_percent: 63.5\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.052710674379556\n",
      "    mean_inference_ms: 0.912729012194669\n",
      "    mean_processing_ms: 0.6690585159596373\n",
      "  time_since_restore: 101.74477243423462\n",
      "  time_this_iter_s: 3.2256946563720703\n",
      "  time_total_s: 101.74477243423462\n",
      "  timestamp: 1596121521\n",
      "  timesteps_since_restore: 75400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 75400\n",
      "  training_iteration: 29\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 101 s, 29 iter, 75400 ts, 388 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-05-28\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 645.844145864241\n",
      "  episode_reward_mean: 385.99624377055403\n",
      "  episode_reward_min: 157.54734207482142\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 30\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 24.493\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.8626451769865326e-10\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4196174144744873\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.593206372443092e-07\n",
      "        policy_loss: 0.00597383501008153\n",
      "        total_loss: 8.646759033203125\n",
      "        vf_explained_var: 0.011146306991577148\n",
      "        vf_loss: 8.640785217285156\n",
      "    load_time_ms: 1.194\n",
      "    num_steps_sampled: 80600\n",
      "    num_steps_trained: 77500\n",
      "    sample_time_ms: 3409.61\n",
      "    update_time_ms: 4.302\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.54\n",
      "    ram_util_percent: 63.620000000000005\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.0476756089325345\n",
      "    mean_inference_ms: 0.9131829680306042\n",
      "    mean_processing_ms: 0.6702032034022366\n",
      "  time_since_restore: 109.14529705047607\n",
      "  time_this_iter_s: 3.136281728744507\n",
      "  time_total_s: 109.14529705047607\n",
      "  timestamp: 1596121528\n",
      "  timesteps_since_restore: 80600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 80600\n",
      "  training_iteration: 31\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 109 s, 31 iter, 80600 ts, 386 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-05-35\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 645.844145864241\n",
      "  episode_reward_mean: 378.1078199796122\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 31\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 24.42\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 4.6566129424663316e-11\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4204174280166626\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.8325320045041735e-07\n",
      "        policy_loss: -0.0034448641818016768\n",
      "        total_loss: 38.959476470947266\n",
      "        vf_explained_var: 0.007436871528625488\n",
      "        vf_loss: 38.96292495727539\n",
      "    load_time_ms: 1.183\n",
      "    num_steps_sampled: 85800\n",
      "    num_steps_trained: 82500\n",
      "    sample_time_ms: 3336.687\n",
      "    update_time_ms: 4.224\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.875\n",
      "    ram_util_percent: 63.6\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.043654166788068\n",
      "    mean_inference_ms: 0.9129316055225115\n",
      "    mean_processing_ms: 0.6700940626386293\n",
      "  time_since_restore: 115.38990259170532\n",
      "  time_this_iter_s: 2.989079236984253\n",
      "  time_total_s: 115.38990259170532\n",
      "  timestamp: 1596121535\n",
      "  timesteps_since_restore: 85800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 85800\n",
      "  training_iteration: 33\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 115 s, 33 iter, 85800 ts, 378 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-05-42\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 673.6670136115706\n",
      "  episode_reward_mean: 376.13922308914425\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 35\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 24.299\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.1641532356165829e-11\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4208877086639404\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.6138762854752713e-07\n",
      "        policy_loss: -0.008913376368582249\n",
      "        total_loss: 26.873043060302734\n",
      "        vf_explained_var: 0.01360476016998291\n",
      "        vf_loss: 26.881959915161133\n",
      "    load_time_ms: 1.234\n",
      "    num_steps_sampled: 91000\n",
      "    num_steps_trained: 87500\n",
      "    sample_time_ms: 3460.455\n",
      "    update_time_ms: 4.171\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 52.379999999999995\n",
      "    ram_util_percent: 63.6\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.035988306177332\n",
      "    mean_inference_ms: 0.9141854881035548\n",
      "    mean_processing_ms: 0.6711043043131639\n",
      "  time_since_restore: 122.78120255470276\n",
      "  time_this_iter_s: 3.2166013717651367\n",
      "  time_total_s: 122.78120255470276\n",
      "  timestamp: 1596121542\n",
      "  timesteps_since_restore: 91000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 91000\n",
      "  training_iteration: 35\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 122 s, 35 iter, 91000 ts, 376 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-05-48\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 673.6670136115706\n",
      "  episode_reward_mean: 379.47204187462825\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 36\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 24.316\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.9103830890414573e-12\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.422324299812317\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.1569022717594635e-06\n",
      "        policy_loss: 0.006148746237158775\n",
      "        total_loss: 49.077823638916016\n",
      "        vf_explained_var: 0.013901710510253906\n",
      "        vf_loss: 49.0716667175293\n",
      "    load_time_ms: 1.215\n",
      "    num_steps_sampled: 96200\n",
      "    num_steps_trained: 92500\n",
      "    sample_time_ms: 3271.335\n",
      "    update_time_ms: 4.143\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.0\n",
      "    ram_util_percent: 63.574999999999996\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.032830982130447\n",
      "    mean_inference_ms: 0.9139613549303385\n",
      "    mean_processing_ms: 0.6712093800032067\n",
      "  time_since_restore: 128.64311623573303\n",
      "  time_this_iter_s: 2.9581282138824463\n",
      "  time_total_s: 128.64311623573303\n",
      "  timestamp: 1596121548\n",
      "  timesteps_since_restore: 96200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 96200\n",
      "  training_iteration: 37\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 128 s, 37 iter, 96200 ts, 379 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-05-56\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 699.3911588084176\n",
      "  episode_reward_mean: 389.5270796814995\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 38\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 28.571\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 7.275957722603643e-13\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4218708276748657\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.439183147856966e-07\n",
      "        policy_loss: 0.00017581252905074507\n",
      "        total_loss: 46.35760498046875\n",
      "        vf_explained_var: 0.01638948917388916\n",
      "        vf_loss: 46.357425689697266\n",
      "    load_time_ms: 1.351\n",
      "    num_steps_sampled: 101400\n",
      "    num_steps_trained: 97500\n",
      "    sample_time_ms: 3482.534\n",
      "    update_time_ms: 4.036\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.98\n",
      "    ram_util_percent: 63.64\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.029034010127463\n",
      "    mean_inference_ms: 0.9144094144653954\n",
      "    mean_processing_ms: 0.6714568645022209\n",
      "  time_since_restore: 136.99566459655762\n",
      "  time_this_iter_s: 3.9226317405700684\n",
      "  time_total_s: 136.99566459655762\n",
      "  timestamp: 1596121556\n",
      "  timesteps_since_restore: 101400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 101400\n",
      "  training_iteration: 39\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 136 s, 39 iter, 101400 ts, 390 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-06-03\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 699.3911588084176\n",
      "  episode_reward_mean: 394.09942336822934\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 40\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 27.601\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.8189894306509108e-13\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.420275330543518\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.652355182268366e-07\n",
      "        policy_loss: -0.0015470476355403662\n",
      "        total_loss: 24.88664436340332\n",
      "        vf_explained_var: 0.015905678272247314\n",
      "        vf_loss: 24.888193130493164\n",
      "    load_time_ms: 1.311\n",
      "    num_steps_sampled: 106600\n",
      "    num_steps_trained: 102500\n",
      "    sample_time_ms: 3424.535\n",
      "    update_time_ms: 4.948\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.32000000000001\n",
      "    ram_util_percent: 63.6\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.027838487784284\n",
      "    mean_inference_ms: 0.9152771441309863\n",
      "    mean_processing_ms: 0.6720030367899156\n",
      "  time_since_restore: 143.8151228427887\n",
      "  time_this_iter_s: 3.2529873847961426\n",
      "  time_total_s: 143.8151228427887\n",
      "  timestamp: 1596121563\n",
      "  timesteps_since_restore: 106600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 106600\n",
      "  training_iteration: 41\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 143 s, 41 iter, 106600 ts, 394 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-06-11\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 720.5634332736429\n",
      "  episode_reward_mean: 397.34720105856843\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 42\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 28.278\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 4.547473576627277e-14\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.419504165649414\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.481979421048891e-07\n",
      "        policy_loss: 0.0017754174768924713\n",
      "        total_loss: 22.294803619384766\n",
      "        vf_explained_var: 0.010267436504364014\n",
      "        vf_loss: 22.293027877807617\n",
      "    load_time_ms: 1.319\n",
      "    num_steps_sampled: 111800\n",
      "    num_steps_trained: 107500\n",
      "    sample_time_ms: 3547.602\n",
      "    update_time_ms: 5.127\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.160000000000004\n",
      "    ram_util_percent: 63.660000000000004\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.025609360294339\n",
      "    mean_inference_ms: 0.9156389847233568\n",
      "    mean_processing_ms: 0.6722270767149888\n",
      "  time_since_restore: 151.302344083786\n",
      "  time_this_iter_s: 3.4030160903930664\n",
      "  time_total_s: 151.302344083786\n",
      "  timestamp: 1596121571\n",
      "  timesteps_since_restore: 111800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 111800\n",
      "  training_iteration: 43\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 151 s, 43 iter, 111800 ts, 397 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-06-18\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 720.5634332736429\n",
      "  episode_reward_mean: 393.02825550421176\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 45\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 28.309\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.1368683941568192e-14\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4186125993728638\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.33817195546726e-06\n",
      "        policy_loss: -0.0006104545318521559\n",
      "        total_loss: 34.17859649658203\n",
      "        vf_explained_var: 0.021199584007263184\n",
      "        vf_loss: 34.179203033447266\n",
      "    load_time_ms: 1.286\n",
      "    num_steps_sampled: 117000\n",
      "    num_steps_trained: 112500\n",
      "    sample_time_ms: 3536.249\n",
      "    update_time_ms: 5.133\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.599999999999994\n",
      "    ram_util_percent: 63.7\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.023577616803308\n",
      "    mean_inference_ms: 0.9168092176481163\n",
      "    mean_processing_ms: 0.672974227937073\n",
      "  time_since_restore: 158.57837200164795\n",
      "  time_this_iter_s: 3.212062358856201\n",
      "  time_total_s: 158.57837200164795\n",
      "  timestamp: 1596121578\n",
      "  timesteps_since_restore: 117000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 117000\n",
      "  training_iteration: 45\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 158 s, 45 iter, 117000 ts, 393 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-06-25\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 810.6955632493704\n",
      "  episode_reward_mean: 404.22775853648204\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 47\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 28.36\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.842170985392048e-15\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4187268018722534\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.5860796054312232e-07\n",
      "        policy_loss: -0.00322825089097023\n",
      "        total_loss: 37.13375473022461\n",
      "        vf_explained_var: 0.016514062881469727\n",
      "        vf_loss: 37.1369743347168\n",
      "    load_time_ms: 1.264\n",
      "    num_steps_sampled: 122200\n",
      "    num_steps_trained: 117500\n",
      "    sample_time_ms: 3691.635\n",
      "    update_time_ms: 5.134\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 52.199999999999996\n",
      "    ram_util_percent: 63.63333333333335\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.021727771855605\n",
      "    mean_inference_ms: 0.9170779254987451\n",
      "    mean_processing_ms: 0.6732146890986013\n",
      "  time_since_restore: 165.99463939666748\n",
      "  time_this_iter_s: 4.418122291564941\n",
      "  time_total_s: 165.99463939666748\n",
      "  timestamp: 1596121585\n",
      "  timesteps_since_restore: 122200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 122200\n",
      "  training_iteration: 47\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 165 s, 47 iter, 122200 ts, 404 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-06-32\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 810.6955632493704\n",
      "  episode_reward_mean: 402.0604182469674\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 49\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 28.034\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 7.10542746348012e-16\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.418236494064331\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.459764516515861e-07\n",
      "        policy_loss: 0.007801887579262257\n",
      "        total_loss: 31.092300415039062\n",
      "        vf_explained_var: 0.029797732830047607\n",
      "        vf_loss: 31.08450698852539\n",
      "    load_time_ms: 1.224\n",
      "    num_steps_sampled: 127400\n",
      "    num_steps_trained: 122500\n",
      "    sample_time_ms: 3552.66\n",
      "    update_time_ms: 5.069\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.26666666666666\n",
      "    ram_util_percent: 63.65\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.02087361249208\n",
      "    mean_inference_ms: 0.9179268845940702\n",
      "    mean_processing_ms: 0.673716719506185\n",
      "  time_since_restore: 172.95105123519897\n",
      "  time_this_iter_s: 3.7871391773223877\n",
      "  time_total_s: 172.95105123519897\n",
      "  timestamp: 1596121592\n",
      "  timesteps_since_restore: 127400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 127400\n",
      "  training_iteration: 49\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 172 s, 49 iter, 127400 ts, 402 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-06-39\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 810.6955632493704\n",
      "  episode_reward_mean: 401.23056817230025\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 50\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 27.963\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.77635686587003e-16\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4186677932739258\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.3345947397501732e-07\n",
      "        policy_loss: 0.0021034509409219027\n",
      "        total_loss: 20.8459529876709\n",
      "        vf_explained_var: 0.015240073204040527\n",
      "        vf_loss: 20.843847274780273\n",
      "    load_time_ms: 1.216\n",
      "    num_steps_sampled: 132600\n",
      "    num_steps_trained: 127500\n",
      "    sample_time_ms: 3543.797\n",
      "    update_time_ms: 4.767\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.125\n",
      "    ram_util_percent: 63.7\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.0209994590288956\n",
      "    mean_inference_ms: 0.9183523074939796\n",
      "    mean_processing_ms: 0.6739345362060996\n",
      "  time_since_restore: 179.67628049850464\n",
      "  time_this_iter_s: 3.121918201446533\n",
      "  time_total_s: 179.67628049850464\n",
      "  timestamp: 1596121599\n",
      "  timesteps_since_restore: 132600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 132600\n",
      "  training_iteration: 51\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 179 s, 51 iter, 132600 ts, 401 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-06-45\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 810.6955632493704\n",
      "  episode_reward_mean: 398.37933858766814\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 52\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 27.168\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 4.440892164675075e-17\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.418789267539978\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.934072350692986e-08\n",
      "        policy_loss: -0.0002654321724548936\n",
      "        total_loss: 32.24570846557617\n",
      "        vf_explained_var: 0.022646665573120117\n",
      "        vf_loss: 32.245967864990234\n",
      "    load_time_ms: 1.209\n",
      "    num_steps_sampled: 137800\n",
      "    num_steps_trained: 132500\n",
      "    sample_time_ms: 3418.829\n",
      "    update_time_ms: 4.55\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.3\n",
      "    ram_util_percent: 63.7\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.020257576240089\n",
      "    mean_inference_ms: 0.9187631796642026\n",
      "    mean_processing_ms: 0.6740561500245801\n",
      "  time_since_restore: 185.90032148361206\n",
      "  time_this_iter_s: 3.067028284072876\n",
      "  time_total_s: 185.90032148361206\n",
      "  timestamp: 1596121605\n",
      "  timesteps_since_restore: 137800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 137800\n",
      "  training_iteration: 53\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 185 s, 53 iter, 137800 ts, 398 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-06-53\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 810.6955632493704\n",
      "  episode_reward_mean: 399.7739884963056\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 55\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 27.618\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.1102230411687688e-17\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4184958934783936\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.4008999187353766e-06\n",
      "        policy_loss: -5.9476853493833914e-05\n",
      "        total_loss: 34.68757247924805\n",
      "        vf_explained_var: 0.0318794846534729\n",
      "        vf_loss: 34.6876106262207\n",
      "    load_time_ms: 1.256\n",
      "    num_steps_sampled: 143000\n",
      "    num_steps_trained: 137500\n",
      "    sample_time_ms: 3407.767\n",
      "    update_time_ms: 4.518\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.4\n",
      "    ram_util_percent: 63.8\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.0196951811663935\n",
      "    mean_inference_ms: 0.9198435969928307\n",
      "    mean_processing_ms: 0.6747025531862925\n",
      "  time_since_restore: 193.0722532272339\n",
      "  time_this_iter_s: 3.0575037002563477\n",
      "  time_total_s: 193.0722532272339\n",
      "  timestamp: 1596121613\n",
      "  timesteps_since_restore: 143000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 143000\n",
      "  training_iteration: 55\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 193 s, 55 iter, 143000 ts, 400 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-07-01\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 810.6955632493704\n",
      "  episode_reward_mean: 403.4845149153205\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 57\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 28.763\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.775557602921922e-18\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4179662466049194\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.2464990934167872e-07\n",
      "        policy_loss: -0.0013116314075887203\n",
      "        total_loss: 14.349501609802246\n",
      "        vf_explained_var: 0.019754111766815186\n",
      "        vf_loss: 14.350815773010254\n",
      "    load_time_ms: 1.335\n",
      "    num_steps_sampled: 148200\n",
      "    num_steps_trained: 142500\n",
      "    sample_time_ms: 3454.065\n",
      "    update_time_ms: 4.721\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.779999999999994\n",
      "    ram_util_percent: 63.78000000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.018659428583693\n",
      "    mean_inference_ms: 0.9200931380690006\n",
      "    mean_processing_ms: 0.6748689762336135\n",
      "  time_since_restore: 200.97237348556519\n",
      "  time_this_iter_s: 3.737623691558838\n",
      "  time_total_s: 200.97237348556519\n",
      "  timestamp: 1596121621\n",
      "  timesteps_since_restore: 148200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 148200\n",
      "  training_iteration: 57\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.6/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 200 s, 57 iter, 148200 ts, 403 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-07-09\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 810.6955632493704\n",
      "  episode_reward_mean: 398.8415661528124\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 59\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 24.95\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 6.938894007304805e-19\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4171556234359741\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.1002293237870617e-07\n",
      "        policy_loss: 0.007204736117273569\n",
      "        total_loss: 26.221275329589844\n",
      "        vf_explained_var: 0.024741709232330322\n",
      "        vf_loss: 26.214065551757812\n",
      "    load_time_ms: 1.273\n",
      "    num_steps_sampled: 153400\n",
      "    num_steps_trained: 147500\n",
      "    sample_time_ms: 3567.294\n",
      "    update_time_ms: 5.205\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.9\n",
      "    ram_util_percent: 63.72500000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.01911668725667\n",
      "    mean_inference_ms: 0.9209342409377157\n",
      "    mean_processing_ms: 0.6753474786293551\n",
      "  time_since_restore: 209.0158085823059\n",
      "  time_this_iter_s: 3.2989072799682617\n",
      "  time_total_s: 209.0158085823059\n",
      "  timestamp: 1596121629\n",
      "  timesteps_since_restore: 153400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 153400\n",
      "  training_iteration: 59\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 209 s, 59 iter, 153400 ts, 399 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-07-16\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 810.6955632493704\n",
      "  episode_reward_mean: 403.37554175366625\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 62\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 25.144\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.7347235018262012e-19\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.418345332145691\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.713847152335802e-06\n",
      "        policy_loss: -0.0034273536875844\n",
      "        total_loss: 33.76877212524414\n",
      "        vf_explained_var: 0.03632885217666626\n",
      "        vf_loss: 33.77220153808594\n",
      "    load_time_ms: 1.292\n",
      "    num_steps_sampled: 158600\n",
      "    num_steps_trained: 152500\n",
      "    sample_time_ms: 3657.121\n",
      "    update_time_ms: 4.477\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.51666666666666\n",
      "    ram_util_percent: 63.78333333333333\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.019665876023908\n",
      "    mean_inference_ms: 0.9217275785630514\n",
      "    mean_processing_ms: 0.6756489861415537\n",
      "  time_since_restore: 216.63418173789978\n",
      "  time_this_iter_s: 4.357519626617432\n",
      "  time_total_s: 216.63418173789978\n",
      "  timestamp: 1596121636\n",
      "  timesteps_since_restore: 158600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 158600\n",
      "  training_iteration: 61\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 216 s, 61 iter, 158600 ts, 403 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-07-23\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 810.6955632493704\n",
      "  episode_reward_mean: 403.4355889650046\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 63\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 25.31\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 4.336808754565503e-20\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4181619882583618\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 9.371041898020849e-08\n",
      "        policy_loss: 0.000359170458978042\n",
      "        total_loss: 18.883867263793945\n",
      "        vf_explained_var: 0.02501577138900757\n",
      "        vf_loss: 18.883508682250977\n",
      "    load_time_ms: 1.298\n",
      "    num_steps_sampled: 163800\n",
      "    num_steps_trained: 157500\n",
      "    sample_time_ms: 3674.626\n",
      "    update_time_ms: 4.554\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.275000000000006\n",
      "    ram_util_percent: 63.72500000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.0198550155936665\n",
      "    mean_inference_ms: 0.9221446020008791\n",
      "    mean_processing_ms: 0.6758248648800993\n",
      "  time_since_restore: 223.03661251068115\n",
      "  time_this_iter_s: 3.1388003826141357\n",
      "  time_total_s: 223.03661251068115\n",
      "  timestamp: 1596121643\n",
      "  timesteps_since_restore: 163800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 163800\n",
      "  training_iteration: 63\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 223 s, 63 iter, 163800 ts, 403 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-07-29\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 810.6955632493704\n",
      "  episode_reward_mean: 399.21722428795874\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 65\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 25.14\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.0842021886413758e-20\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.418475866317749\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.6974210836906423e-07\n",
      "        policy_loss: 0.0012597679160535336\n",
      "        total_loss: 38.60623550415039\n",
      "        vf_explained_var: 0.024953007698059082\n",
      "        vf_loss: 38.60496139526367\n",
      "    load_time_ms: 1.245\n",
      "    num_steps_sampled: 169000\n",
      "    num_steps_trained: 162500\n",
      "    sample_time_ms: 3588.633\n",
      "    update_time_ms: 4.556\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.175\n",
      "    ram_util_percent: 63.8\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.020219392410099\n",
      "    mean_inference_ms: 0.9227686955151858\n",
      "    mean_processing_ms: 0.6761254196909549\n",
      "  time_since_restore: 229.34623312950134\n",
      "  time_this_iter_s: 3.2340662479400635\n",
      "  time_total_s: 229.34623312950134\n",
      "  timestamp: 1596121649\n",
      "  timesteps_since_restore: 169000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 169000\n",
      "  training_iteration: 65\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 229 s, 65 iter, 169000 ts, 399 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-07-35\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 810.6955632493704\n",
      "  episode_reward_mean: 397.275806984015\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 67\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 23.727\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.7105054716034394e-21\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4185304641723633\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.4375447676684416e-07\n",
      "        policy_loss: -0.0003138768661301583\n",
      "        total_loss: 39.06398391723633\n",
      "        vf_explained_var: 0.04008793830871582\n",
      "        vf_loss: 39.06428909301758\n",
      "    load_time_ms: 1.184\n",
      "    num_steps_sampled: 174200\n",
      "    num_steps_trained: 167500\n",
      "    sample_time_ms: 3413.543\n",
      "    update_time_ms: 4.549\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.2\n",
      "    ram_util_percent: 63.7\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.020208767677187\n",
      "    mean_inference_ms: 0.9231289924974425\n",
      "    mean_processing_ms: 0.676290247782382\n",
      "  time_since_restore: 235.47413063049316\n",
      "  time_this_iter_s: 3.0225181579589844\n",
      "  time_total_s: 235.47413063049316\n",
      "  timestamp: 1596121655\n",
      "  timesteps_since_restore: 174200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 174200\n",
      "  training_iteration: 67\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 235 s, 67 iter, 174200 ts, 397 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-07-42\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 844.6505203111441\n",
      "  episode_reward_mean: 404.1741325553573\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 69\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 23.768\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 6.776263679008599e-22\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4189083576202393\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.1296013958126423e-07\n",
      "        policy_loss: -0.004913543350994587\n",
      "        total_loss: 35.1002082824707\n",
      "        vf_explained_var: 0.03727281093597412\n",
      "        vf_loss: 35.105125427246094\n",
      "    load_time_ms: 1.185\n",
      "    num_steps_sampled: 179400\n",
      "    num_steps_trained: 172500\n",
      "    sample_time_ms: 3310.12\n",
      "    update_time_ms: 4.091\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.46\n",
      "    ram_util_percent: 63.71999999999999\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.0204655328056225\n",
      "    mean_inference_ms: 0.9237775752171647\n",
      "    mean_processing_ms: 0.6766548446753557\n",
      "  time_since_restore: 242.47892117500305\n",
      "  time_this_iter_s: 3.74021053314209\n",
      "  time_total_s: 242.47892117500305\n",
      "  timestamp: 1596121662\n",
      "  timesteps_since_restore: 179400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 179400\n",
      "  training_iteration: 69\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 242 s, 69 iter, 179400 ts, 404 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-07-49\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 844.6505203111441\n",
      "  episode_reward_mean: 403.2893078226134\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 72\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 23.785\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.6940659197521496e-22\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4188319444656372\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.560781536293689e-08\n",
      "        policy_loss: 0.0036544932518154383\n",
      "        total_loss: 12.504073143005371\n",
      "        vf_explained_var: 0.03178894519805908\n",
      "        vf_loss: 12.50041675567627\n",
      "    load_time_ms: 1.158\n",
      "    num_steps_sampled: 184600\n",
      "    num_steps_trained: 177500\n",
      "    sample_time_ms: 3257.582\n",
      "    update_time_ms: 4.099\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.075\n",
      "    ram_util_percent: 63.7\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.020485947335928\n",
      "    mean_inference_ms: 0.9243221692836142\n",
      "    mean_processing_ms: 0.676939359320561\n",
      "  time_since_restore: 249.57316136360168\n",
      "  time_this_iter_s: 2.883904457092285\n",
      "  time_total_s: 249.57316136360168\n",
      "  timestamp: 1596121669\n",
      "  timesteps_since_restore: 184600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 184600\n",
      "  training_iteration: 71\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 249 s, 71 iter, 184600 ts, 403 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-07-56\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 844.6505203111441\n",
      "  episode_reward_mean: 402.02783271417786\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 73\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 26.062\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 4.235164799380374e-23\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4191551208496094\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.993511299427155e-09\n",
      "        policy_loss: 0.003869878826662898\n",
      "        total_loss: 28.761343002319336\n",
      "        vf_explained_var: 0.03168320655822754\n",
      "        vf_loss: 28.757471084594727\n",
      "    load_time_ms: 1.15\n",
      "    num_steps_sampled: 189800\n",
      "    num_steps_trained: 182500\n",
      "    sample_time_ms: 3316.791\n",
      "    update_time_ms: 4.439\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.3\n",
      "    ram_util_percent: 63.7\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.0206210765508885\n",
      "    mean_inference_ms: 0.9246459649328069\n",
      "    mean_processing_ms: 0.6770735628722874\n",
      "  time_since_restore: 256.5979223251343\n",
      "  time_this_iter_s: 4.051400899887085\n",
      "  time_total_s: 256.5979223251343\n",
      "  timestamp: 1596121676\n",
      "  timesteps_since_restore: 189800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 189800\n",
      "  training_iteration: 73\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 256 s, 73 iter, 189800 ts, 402 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-08-04\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 844.6505203111441\n",
      "  episode_reward_mean: 400.9171700379917\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 77\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 27.288\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.0587911998450935e-23\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4198049306869507\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 9.194135941470449e-07\n",
      "        policy_loss: 0.0007448667893186212\n",
      "        total_loss: 22.29955291748047\n",
      "        vf_explained_var: 0.04797285795211792\n",
      "        vf_loss: 22.29880714416504\n",
      "    load_time_ms: 1.154\n",
      "    num_steps_sampled: 195000\n",
      "    num_steps_trained: 187500\n",
      "    sample_time_ms: 3448.429\n",
      "    update_time_ms: 4.425\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.46\n",
      "    ram_util_percent: 63.739999999999995\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.021139820357732\n",
      "    mean_inference_ms: 0.9254355193448308\n",
      "    mean_processing_ms: 0.677432686475693\n",
      "  time_since_restore: 264.239084482193\n",
      "  time_this_iter_s: 3.557898759841919\n",
      "  time_total_s: 264.239084482193\n",
      "  timestamp: 1596121684\n",
      "  timesteps_since_restore: 195000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 195000\n",
      "  training_iteration: 75\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 264 s, 75 iter, 195000 ts, 401 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-08-10\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 844.6505203111441\n",
      "  episode_reward_mean: 400.91717003799175\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 77\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 28.257\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.646977999612734e-24\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4200907945632935\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 7.096529230921078e-08\n",
      "        policy_loss: -0.0019334886455908418\n",
      "        total_loss: 27.310014724731445\n",
      "        vf_explained_var: 0.03141891956329346\n",
      "        vf_loss: 27.311952590942383\n",
      "    load_time_ms: 1.178\n",
      "    num_steps_sampled: 200200\n",
      "    num_steps_trained: 192500\n",
      "    sample_time_ms: 3458.802\n",
      "    update_time_ms: 4.543\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 65.675\n",
      "    ram_util_percent: 63.75\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.021139820357731\n",
      "    mean_inference_ms: 0.9254355193448308\n",
      "    mean_processing_ms: 0.6774326864756931\n",
      "  time_since_restore: 270.482625246048\n",
      "  time_this_iter_s: 3.1256721019744873\n",
      "  time_total_s: 270.482625246048\n",
      "  timestamp: 1596121690\n",
      "  timesteps_since_restore: 200200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 200200\n",
      "  training_iteration: 77\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 270 s, 77 iter, 200200 ts, 401 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-08-17\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 844.6505203111441\n",
      "  episode_reward_mean: 400.16640871829264\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 80\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 28.312\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 6.617444999031835e-25\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4206606149673462\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.335092509994865e-07\n",
      "        policy_loss: 0.00225042924284935\n",
      "        total_loss: 44.630157470703125\n",
      "        vf_explained_var: 0.0465162992477417\n",
      "        vf_loss: 44.62791061401367\n",
      "    load_time_ms: 1.202\n",
      "    num_steps_sampled: 205400\n",
      "    num_steps_trained: 197500\n",
      "    sample_time_ms: 3469.088\n",
      "    update_time_ms: 4.562\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 52.94\n",
      "    ram_util_percent: 63.7\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.0213142384387925\n",
      "    mean_inference_ms: 0.9261352445311992\n",
      "    mean_processing_ms: 0.6778221702733292\n",
      "  time_since_restore: 277.5919623374939\n",
      "  time_this_iter_s: 4.126014471054077\n",
      "  time_total_s: 277.5919623374939\n",
      "  timestamp: 1596121697\n",
      "  timesteps_since_restore: 205400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 205400\n",
      "  training_iteration: 79\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 277 s, 79 iter, 205400 ts, 400 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-08-24\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 844.6505203111441\n",
      "  episode_reward_mean: 400.9345396430285\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 82\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 30.835\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.6543612497579586e-25\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4201650619506836\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 7.462263056368101e-07\n",
      "        policy_loss: -0.005568448919802904\n",
      "        total_loss: 26.137001037597656\n",
      "        vf_explained_var: 0.037645041942596436\n",
      "        vf_loss: 26.142574310302734\n",
      "    load_time_ms: 1.25\n",
      "    num_steps_sampled: 210600\n",
      "    num_steps_trained: 202500\n",
      "    sample_time_ms: 3388.424\n",
      "    update_time_ms: 4.619\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.625\n",
      "    ram_util_percent: 63.775000000000006\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.021191546598803\n",
      "    mean_inference_ms: 0.9263382524812709\n",
      "    mean_processing_ms: 0.6778489804782107\n",
      "  time_since_restore: 283.90949416160583\n",
      "  time_this_iter_s: 3.063117265701294\n",
      "  time_total_s: 283.90949416160583\n",
      "  timestamp: 1596121704\n",
      "  timesteps_since_restore: 210600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 210600\n",
      "  training_iteration: 81\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.6/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 283 s, 81 iter, 210600 ts, 401 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-08-30\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 844.6505203111441\n",
      "  episode_reward_mean: 401.19944949458005\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 83\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 28.508\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 4.1359031243948966e-26\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4222992658615112\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.3354500550995e-07\n",
      "        policy_loss: 0.004603066947311163\n",
      "        total_loss: 60.075618743896484\n",
      "        vf_explained_var: 0.036517977714538574\n",
      "        vf_loss: 60.071006774902344\n",
      "    load_time_ms: 1.249\n",
      "    num_steps_sampled: 215800\n",
      "    num_steps_trained: 207500\n",
      "    sample_time_ms: 3350.983\n",
      "    update_time_ms: 5.034\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.24000000000001\n",
      "    ram_util_percent: 63.9\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.021089729050378\n",
      "    mean_inference_ms: 0.9265644133458211\n",
      "    mean_processing_ms: 0.6779519827415391\n",
      "  time_since_restore: 290.5357942581177\n",
      "  time_this_iter_s: 3.293146848678589\n",
      "  time_total_s: 290.5357942581177\n",
      "  timestamp: 1596121710\n",
      "  timesteps_since_restore: 215800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 215800\n",
      "  training_iteration: 83\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.6/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 290 s, 83 iter, 215800 ts, 401 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-08-38\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 844.6505203111441\n",
      "  episode_reward_mean: 404.42362379192116\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 87\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 28.619\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.0339757810987241e-26\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.420021653175354\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.1774301356126671e-07\n",
      "        policy_loss: 0.005598624236881733\n",
      "        total_loss: 10.773856163024902\n",
      "        vf_explained_var: 0.03124326467514038\n",
      "        vf_loss: 10.768260955810547\n",
      "    load_time_ms: 1.308\n",
      "    num_steps_sampled: 221000\n",
      "    num_steps_trained: 212500\n",
      "    sample_time_ms: 3334.319\n",
      "    update_time_ms: 5.185\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.660000000000004\n",
      "    ram_util_percent: 63.9\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.021068983619609\n",
      "    mean_inference_ms: 0.9271297447723265\n",
      "    mean_processing_ms: 0.6782796623159653\n",
      "  time_since_restore: 298.0180039405823\n",
      "  time_this_iter_s: 3.2288734912872314\n",
      "  time_total_s: 298.0180039405823\n",
      "  timestamp: 1596121718\n",
      "  timesteps_since_restore: 221000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 221000\n",
      "  training_iteration: 85\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.6/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 298 s, 85 iter, 221000 ts, 404 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-08-45\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 844.6505203111441\n",
      "  episode_reward_mean: 404.42362379192116\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 87\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 28.672\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.5849394527468104e-27\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4206889867782593\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.154848281563318e-07\n",
      "        policy_loss: 0.0033390684984624386\n",
      "        total_loss: 62.36117935180664\n",
      "        vf_explained_var: 0.023956716060638428\n",
      "        vf_loss: 62.35783767700195\n",
      "    load_time_ms: 1.297\n",
      "    num_steps_sampled: 226200\n",
      "    num_steps_trained: 217500\n",
      "    sample_time_ms: 3397.836\n",
      "    update_time_ms: 4.996\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.580000000000005\n",
      "    ram_util_percent: 63.9\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.021068983619609\n",
      "    mean_inference_ms: 0.9271297447723265\n",
      "    mean_processing_ms: 0.6782796623159653\n",
      "  time_since_restore: 304.89907932281494\n",
      "  time_this_iter_s: 3.6048989295959473\n",
      "  time_total_s: 304.89907932281494\n",
      "  timestamp: 1596121725\n",
      "  timesteps_since_restore: 226200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 226200\n",
      "  training_iteration: 87\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 304 s, 87 iter, 226200 ts, 404 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-08-52\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 844.6505203111441\n",
      "  episode_reward_mean: 412.2671528748354\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 92\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 28.718\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 6.462348631867026e-28\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4209314584732056\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.528113539796323e-07\n",
      "        policy_loss: -0.0019639129750430584\n",
      "        total_loss: 49.25442123413086\n",
      "        vf_explained_var: 0.06591367721557617\n",
      "        vf_loss: 49.256370544433594\n",
      "    load_time_ms: 1.261\n",
      "    num_steps_sampled: 231400\n",
      "    num_steps_trained: 222500\n",
      "    sample_time_ms: 3439.068\n",
      "    update_time_ms: 5.152\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.51666666666667\n",
      "    ram_util_percent: 63.76666666666666\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.021497454732242\n",
      "    mean_inference_ms: 0.9279910666364772\n",
      "    mean_processing_ms: 0.678559616017277\n",
      "  time_since_restore: 312.4213516712189\n",
      "  time_this_iter_s: 4.298074007034302\n",
      "  time_total_s: 312.4213516712189\n",
      "  timestamp: 1596121732\n",
      "  timesteps_since_restore: 231400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 231400\n",
      "  training_iteration: 89\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 312 s, 89 iter, 231400 ts, 412 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-08-59\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 844.6505203111441\n",
      "  episode_reward_mean: 412.26715287483546\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 92\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 25.832\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.6155871579667565e-28\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4202324151992798\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.4245509660781863e-08\n",
      "        policy_loss: 0.00016689501353539526\n",
      "        total_loss: 21.25550079345703\n",
      "        vf_explained_var: 0.04505598545074463\n",
      "        vf_loss: 21.25533103942871\n",
      "    load_time_ms: 1.235\n",
      "    num_steps_sampled: 236600\n",
      "    num_steps_trained: 227500\n",
      "    sample_time_ms: 3441.703\n",
      "    update_time_ms: 5.068\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.525\n",
      "    ram_util_percent: 63.9\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.021497454732242\n",
      "    mean_inference_ms: 0.9279910666364771\n",
      "    mean_processing_ms: 0.678559616017277\n",
      "  time_since_restore: 318.73003363609314\n",
      "  time_this_iter_s: 3.1548941135406494\n",
      "  time_total_s: 318.73003363609314\n",
      "  timestamp: 1596121739\n",
      "  timesteps_since_restore: 236600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 236600\n",
      "  training_iteration: 91\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 318 s, 91 iter, 236600 ts, 412 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-09-07\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 844.6505203111441\n",
      "  episode_reward_mean: 409.0048487518166\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 94\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 26.884\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 4.038967894916891e-29\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4211459159851074\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.437633169933179e-08\n",
      "        policy_loss: 0.003448577132076025\n",
      "        total_loss: 39.757164001464844\n",
      "        vf_explained_var: 0.06629133224487305\n",
      "        vf_loss: 39.75371551513672\n",
      "    load_time_ms: 1.237\n",
      "    num_steps_sampled: 241800\n",
      "    num_steps_trained: 232500\n",
      "    sample_time_ms: 3570.669\n",
      "    update_time_ms: 4.295\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.94285714285714\n",
      "    ram_util_percent: 65.3\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.021716998393163\n",
      "    mean_inference_ms: 0.9283204218129522\n",
      "    mean_processing_ms: 0.6786883674815113\n",
      "  time_since_restore: 326.6514220237732\n",
      "  time_this_iter_s: 4.727821111679077\n",
      "  time_total_s: 326.6514220237732\n",
      "  timestamp: 1596121747\n",
      "  timesteps_since_restore: 241800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 241800\n",
      "  training_iteration: 93\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 326 s, 93 iter, 241800 ts, 409 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-09-14\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 844.6505203111441\n",
      "  episode_reward_mean: 411.4094007191923\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 97\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 26.035\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.0097419737292228e-29\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4207082986831665\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.991956974568893e-07\n",
      "        policy_loss: 0.008532200939953327\n",
      "        total_loss: 47.050071716308594\n",
      "        vf_explained_var: 0.03921705484390259\n",
      "        vf_loss: 47.041534423828125\n",
      "    load_time_ms: 1.197\n",
      "    num_steps_sampled: 247000\n",
      "    num_steps_trained: 237500\n",
      "    sample_time_ms: 3616.294\n",
      "    update_time_ms: 4.146\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.98\n",
      "    ram_util_percent: 66.42\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.022256342964905\n",
      "    mean_inference_ms: 0.9288613904442453\n",
      "    mean_processing_ms: 0.6788908902297066\n",
      "  time_since_restore: 334.5737326145172\n",
      "  time_this_iter_s: 3.671395778656006\n",
      "  time_total_s: 334.5737326145172\n",
      "  timestamp: 1596121754\n",
      "  timesteps_since_restore: 247000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 247000\n",
      "  training_iteration: 95\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 11.0/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 334 s, 95 iter, 247000 ts, 411 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-09-23\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 844.6505203111441\n",
      "  episode_reward_mean: 411.4094007191923\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 97\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 26.875\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.524354934323057e-30\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4264366626739502\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.8186082090542186e-06\n",
      "        policy_loss: 0.002745038131251931\n",
      "        total_loss: 130.25436401367188\n",
      "        vf_explained_var: 0.020709216594696045\n",
      "        vf_loss: 130.25161743164062\n",
      "    load_time_ms: 1.226\n",
      "    num_steps_sampled: 252200\n",
      "    num_steps_trained: 242500\n",
      "    sample_time_ms: 3729.164\n",
      "    update_time_ms: 4.249\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.26\n",
      "    ram_util_percent: 66.4\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.022256342964905\n",
      "    mean_inference_ms: 0.9288613904442453\n",
      "    mean_processing_ms: 0.6788908902297066\n",
      "  time_since_restore: 342.5927972793579\n",
      "  time_this_iter_s: 3.8867104053497314\n",
      "  time_total_s: 342.5927972793579\n",
      "  timestamp: 1596121763\n",
      "  timesteps_since_restore: 252200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 252200\n",
      "  training_iteration: 97\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 11.0/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 342 s, 97 iter, 252200 ts, 411 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-09-28\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 944.7236355929094\n",
      "  episode_reward_mean: 420.49549677329867\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 100\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 27.784\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.2621774671615285e-30\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4291573762893677\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.1847114365082234e-05\n",
      "        policy_loss: 0.003130868077278137\n",
      "        total_loss: 132.6818389892578\n",
      "        vf_explained_var: 0.051780521869659424\n",
      "        vf_loss: 132.67874145507812\n",
      "    load_time_ms: 1.242\n",
      "    num_steps_sampled: 254800\n",
      "    num_steps_trained: 245000\n",
      "    sample_time_ms: 3913.201\n",
      "    update_time_ms: 4.195\n",
      "  iterations_since_restore: 98\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.224999999999994\n",
      "    ram_util_percent: 66.3625\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.023760041954226\n",
      "    mean_inference_ms: 0.9295288016877385\n",
      "    mean_processing_ms: 0.6791028403979098\n",
      "  time_since_restore: 347.6706085205078\n",
      "  time_this_iter_s: 5.077811241149902\n",
      "  time_total_s: 347.6706085205078\n",
      "  timestamp: 1596121768\n",
      "  timesteps_since_restore: 254800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 254800\n",
      "  training_iteration: 98\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 11.0/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 347 s, 98 iter, 254800 ts, 420 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-09-35\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 944.7236355929094\n",
      "  episode_reward_mean: 429.01331861446766\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 102\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 28.204\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 3.1554436679038213e-31\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4232120513916016\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.104210009041708e-06\n",
      "        policy_loss: 0.002437660936266184\n",
      "        total_loss: 16.136734008789062\n",
      "        vf_explained_var: 0.03792613744735718\n",
      "        vf_loss: 16.134294509887695\n",
      "    load_time_ms: 1.232\n",
      "    num_steps_sampled: 260000\n",
      "    num_steps_trained: 250000\n",
      "    sample_time_ms: 3890.144\n",
      "    update_time_ms: 4.404\n",
      "  iterations_since_restore: 100\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 69.72\n",
      "    ram_util_percent: 65.86000000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.022218530330693\n",
      "    mean_inference_ms: 0.9309265300859283\n",
      "    mean_processing_ms: 0.6798972280475689\n",
      "  time_since_restore: 354.9005329608917\n",
      "  time_this_iter_s: 3.4367659091949463\n",
      "  time_total_s: 354.9005329608917\n",
      "  timestamp: 1596121775\n",
      "  timesteps_since_restore: 260000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 260000\n",
      "  training_iteration: 100\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.6/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 354 s, 100 iter, 260000 ts, 429 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-09-42\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 944.7236355929094\n",
      "  episode_reward_mean: 426.0379764522781\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 103\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 28.665\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 7.888609169759553e-32\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4279640913009644\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 7.419109238071542e-07\n",
      "        policy_loss: -0.0017240002052858472\n",
      "        total_loss: 27.453222274780273\n",
      "        vf_explained_var: 0.01685577630996704\n",
      "        vf_loss: 27.4549503326416\n",
      "    load_time_ms: 1.241\n",
      "    num_steps_sampled: 265200\n",
      "    num_steps_trained: 255000\n",
      "    sample_time_ms: 3992.045\n",
      "    update_time_ms: 4.462\n",
      "  iterations_since_restore: 102\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.333333333333336\n",
      "    ram_util_percent: 63.949999999999996\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.02130242656948\n",
      "    mean_inference_ms: 0.9314863390066176\n",
      "    mean_processing_ms: 0.6802471809669153\n",
      "  time_since_restore: 362.2754125595093\n",
      "  time_this_iter_s: 4.370930910110474\n",
      "  time_total_s: 362.2754125595093\n",
      "  timestamp: 1596121782\n",
      "  timesteps_since_restore: 265200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 265200\n",
      "  training_iteration: 102\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 362 s, 102 iter, 265200 ts, 426 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-09-51\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 944.7236355929094\n",
      "  episode_reward_mean: 427.08630874149196\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 107\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 33.655\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.9721522924398883e-32\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4243226051330566\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.478003580108634e-07\n",
      "        policy_loss: -0.0014085721923038363\n",
      "        total_loss: 18.95341682434082\n",
      "        vf_explained_var: 0.06323528289794922\n",
      "        vf_loss: 18.954832077026367\n",
      "    load_time_ms: 1.349\n",
      "    num_steps_sampled: 270400\n",
      "    num_steps_trained: 260000\n",
      "    sample_time_ms: 3945.434\n",
      "    update_time_ms: 4.665\n",
      "  iterations_since_restore: 104\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.642857142857146\n",
      "    ram_util_percent: 63.71428571428571\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.0192810237669105\n",
      "    mean_inference_ms: 0.9338635904747218\n",
      "    mean_processing_ms: 0.6815874829885078\n",
      "  time_since_restore: 370.85590624809265\n",
      "  time_this_iter_s: 4.756823301315308\n",
      "  time_total_s: 370.85590624809265\n",
      "  timestamp: 1596121791\n",
      "  timesteps_since_restore: 270400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 270400\n",
      "  training_iteration: 104\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 370 s, 104 iter, 270400 ts, 427 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-09-58\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 944.7236355929094\n",
      "  episode_reward_mean: 427.08630874149196\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 107\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 32.412\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 4.930380731099721e-33\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.425351619720459\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.6336679209416616e-06\n",
      "        policy_loss: -0.0012822147691622376\n",
      "        total_loss: 43.12633514404297\n",
      "        vf_explained_var: 0.050767481327056885\n",
      "        vf_loss: 43.127620697021484\n",
      "    load_time_ms: 1.345\n",
      "    num_steps_sampled: 275600\n",
      "    num_steps_trained: 265000\n",
      "    sample_time_ms: 3881.019\n",
      "    update_time_ms: 4.964\n",
      "  iterations_since_restore: 106\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.260000000000005\n",
      "    ram_util_percent: 63.78000000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.0192810237669105\n",
      "    mean_inference_ms: 0.9338635904747218\n",
      "    mean_processing_ms: 0.6815874829885078\n",
      "  time_since_restore: 378.003653049469\n",
      "  time_this_iter_s: 3.336398124694824\n",
      "  time_total_s: 378.003653049469\n",
      "  timestamp: 1596121798\n",
      "  timesteps_since_restore: 275600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 275600\n",
      "  training_iteration: 106\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 378 s, 106 iter, 275600 ts, 427 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-10-06\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 944.7236355929094\n",
      "  episode_reward_mean: 428.7567069952519\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 112\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 31.051\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.2325951827749302e-33\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4272841215133667\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.9073485846288207e-10\n",
      "        policy_loss: -0.003809311194345355\n",
      "        total_loss: 53.53873062133789\n",
      "        vf_explained_var: 0.07013928890228271\n",
      "        vf_loss: 53.542545318603516\n",
      "    load_time_ms: 1.331\n",
      "    num_steps_sampled: 280800\n",
      "    num_steps_trained: 270000\n",
      "    sample_time_ms: 3770.598\n",
      "    update_time_ms: 4.784\n",
      "  iterations_since_restore: 108\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 52.40000000000001\n",
      "    ram_util_percent: 63.77142857142858\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.020991144558485\n",
      "    mean_inference_ms: 0.9361042083414786\n",
      "    mean_processing_ms: 0.6827216314420476\n",
      "  time_since_restore: 385.8435022830963\n",
      "  time_this_iter_s: 4.763235569000244\n",
      "  time_total_s: 385.8435022830963\n",
      "  timestamp: 1596121806\n",
      "  timesteps_since_restore: 280800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 280800\n",
      "  training_iteration: 108\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 385 s, 108 iter, 280800 ts, 429 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-10-12\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 944.7236355929094\n",
      "  episode_reward_mean: 428.7567069952519\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 112\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 30.982\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 3.0814879569373254e-34\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.422744631767273\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.1827945911591087e-07\n",
      "        policy_loss: 0.0025664898566901684\n",
      "        total_loss: 14.281580924987793\n",
      "        vf_explained_var: 0.042426228523254395\n",
      "        vf_loss: 14.279012680053711\n",
      "    load_time_ms: 1.341\n",
      "    num_steps_sampled: 286000\n",
      "    num_steps_trained: 275000\n",
      "    sample_time_ms: 3677.879\n",
      "    update_time_ms: 4.651\n",
      "  iterations_since_restore: 110\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.125\n",
      "    ram_util_percent: 63.6\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.020991144558484\n",
      "    mean_inference_ms: 0.9361042083414784\n",
      "    mean_processing_ms: 0.6827216314420476\n",
      "  time_since_restore: 392.14234685897827\n",
      "  time_this_iter_s: 3.0475776195526123\n",
      "  time_total_s: 392.14234685897827\n",
      "  timestamp: 1596121812\n",
      "  timesteps_since_restore: 286000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 286000\n",
      "  training_iteration: 110\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 392 s, 110 iter, 286000 ts, 429 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-10-20\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 944.7236355929094\n",
      "  episode_reward_mean: 430.1586340049557\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 113\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 34.995\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 7.703719892343314e-35\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4259274005889893\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.385543934086854e-08\n",
      "        policy_loss: -0.002658007200807333\n",
      "        total_loss: 26.185544967651367\n",
      "        vf_explained_var: 0.05540728569030762\n",
      "        vf_loss: 26.188203811645508\n",
      "    load_time_ms: 1.453\n",
      "    num_steps_sampled: 291200\n",
      "    num_steps_trained: 280000\n",
      "    sample_time_ms: 3690.677\n",
      "    update_time_ms: 4.643\n",
      "  iterations_since_restore: 112\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.228571428571435\n",
      "    ram_util_percent: 63.64285714285715\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.021107753945821\n",
      "    mean_inference_ms: 0.9363028796082492\n",
      "    mean_processing_ms: 0.6827643254075138\n",
      "  time_since_restore: 399.6980662345886\n",
      "  time_this_iter_s: 4.543072938919067\n",
      "  time_total_s: 399.6980662345886\n",
      "  timestamp: 1596121820\n",
      "  timesteps_since_restore: 291200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 291200\n",
      "  training_iteration: 112\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 399 s, 112 iter, 291200 ts, 430 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-10-27\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 944.7236355929094\n",
      "  episode_reward_mean: 427.94495763922845\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 117\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 29.257\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.9259299730858284e-35\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.421599268913269\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.035400363340159e-07\n",
      "        policy_loss: 0.0007703776936978102\n",
      "        total_loss: 2.8203303813934326\n",
      "        vf_explained_var: 0.1137879490852356\n",
      "        vf_loss: 2.8195600509643555\n",
      "    load_time_ms: 1.353\n",
      "    num_steps_sampled: 296400\n",
      "    num_steps_trained: 285000\n",
      "    sample_time_ms: 3602.233\n",
      "    update_time_ms: 5.192\n",
      "  iterations_since_restore: 114\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.349999999999994\n",
      "    ram_util_percent: 63.7\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.0243051784575\n",
      "    mean_inference_ms: 0.9380960815813272\n",
      "    mean_processing_ms: 0.6836604811609699\n",
      "  time_since_restore: 407.3257656097412\n",
      "  time_this_iter_s: 3.0370218753814697\n",
      "  time_total_s: 407.3257656097412\n",
      "  timestamp: 1596121827\n",
      "  timesteps_since_restore: 296400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 296400\n",
      "  training_iteration: 114\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 407 s, 114 iter, 296400 ts, 428 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-10-33\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 944.7236355929094\n",
      "  episode_reward_mean: 427.94495763922845\n",
      "  episode_reward_min: 141.4551062513581\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 117\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 28.951\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 4.814824932714571e-36\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4247443675994873\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.053540909713774e-07\n",
      "        policy_loss: -0.007453788071870804\n",
      "        total_loss: 24.202680587768555\n",
      "        vf_explained_var: 0.07652616500854492\n",
      "        vf_loss: 24.210134506225586\n",
      "    load_time_ms: 1.337\n",
      "    num_steps_sampled: 301600\n",
      "    num_steps_trained: 290000\n",
      "    sample_time_ms: 3488.43\n",
      "    update_time_ms: 4.847\n",
      "  iterations_since_restore: 116\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.45\n",
      "    ram_util_percent: 63.75\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.0243051784575\n",
      "    mean_inference_ms: 0.9380960815813272\n",
      "    mean_processing_ms: 0.6836604811609699\n",
      "  time_since_restore: 413.32776856422424\n",
      "  time_this_iter_s: 2.987490177154541\n",
      "  time_total_s: 413.32776856422424\n",
      "  timestamp: 1596121833\n",
      "  timesteps_since_restore: 301600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 301600\n",
      "  training_iteration: 116\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 413 s, 116 iter, 301600 ts, 428 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-10-40\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 944.7236355929094\n",
      "  episode_reward_mean: 421.59691756358944\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 122\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 28.872\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.2037062331786428e-36\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4224516153335571\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.487825495085417e-07\n",
      "        policy_loss: 0.002750476123765111\n",
      "        total_loss: 11.84224796295166\n",
      "        vf_explained_var: 0.09787416458129883\n",
      "        vf_loss: 11.839495658874512\n",
      "    load_time_ms: 1.293\n",
      "    num_steps_sampled: 306800\n",
      "    num_steps_trained: 295000\n",
      "    sample_time_ms: 3377.206\n",
      "    update_time_ms: 4.838\n",
      "  iterations_since_restore: 118\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 52.879999999999995\n",
      "    ram_util_percent: 63.7\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.028961133956625\n",
      "    mean_inference_ms: 0.9401666993828001\n",
      "    mean_processing_ms: 0.6842795063246279\n",
      "  time_since_restore: 420.054203748703\n",
      "  time_this_iter_s: 3.5242085456848145\n",
      "  time_total_s: 420.054203748703\n",
      "  timestamp: 1596121840\n",
      "  timesteps_since_restore: 306800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 306800\n",
      "  training_iteration: 118\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 420 s, 118 iter, 306800 ts, 422 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-10-46\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 944.7236355929094\n",
      "  episode_reward_mean: 421.59691756358944\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 122\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 28.262\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 3.009265582946607e-37\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4235337972640991\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.1503696129011587e-07\n",
      "        policy_loss: 0.0037824944593012333\n",
      "        total_loss: 37.507999420166016\n",
      "        vf_explained_var: 0.056506216526031494\n",
      "        vf_loss: 37.50421142578125\n",
      "    load_time_ms: 1.26\n",
      "    num_steps_sampled: 312000\n",
      "    num_steps_trained: 300000\n",
      "    sample_time_ms: 3326.868\n",
      "    update_time_ms: 4.755\n",
      "  iterations_since_restore: 120\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.125\n",
      "    ram_util_percent: 63.6\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.028961133956626\n",
      "    mean_inference_ms: 0.9401666993828002\n",
      "    mean_processing_ms: 0.6842795063246279\n",
      "  time_since_restore: 425.841956615448\n",
      "  time_this_iter_s: 2.910623550415039\n",
      "  time_total_s: 425.841956615448\n",
      "  timestamp: 1596121846\n",
      "  timesteps_since_restore: 312000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 312000\n",
      "  training_iteration: 120\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 425 s, 120 iter, 312000 ts, 422 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-10-53\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 944.7236355929094\n",
      "  episode_reward_mean: 426.22557320727424\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 125\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 24.182\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 7.523163957366517e-38\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.428405523300171\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.358291789685609e-06\n",
      "        policy_loss: 0.0033415996003896\n",
      "        total_loss: 63.01348114013672\n",
      "        vf_explained_var: 0.07423293590545654\n",
      "        vf_loss: 63.0101318359375\n",
      "    load_time_ms: 1.119\n",
      "    num_steps_sampled: 317200\n",
      "    num_steps_trained: 305000\n",
      "    sample_time_ms: 3311.991\n",
      "    update_time_ms: 4.838\n",
      "  iterations_since_restore: 122\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.78333333333333\n",
      "    ram_util_percent: 63.699999999999996\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.031829679927326\n",
      "    mean_inference_ms: 0.9413188510090442\n",
      "    mean_processing_ms: 0.6845462099741966\n",
      "  time_since_restore: 433.1946792602539\n",
      "  time_this_iter_s: 4.2896575927734375\n",
      "  time_total_s: 433.1946792602539\n",
      "  timestamp: 1596121853\n",
      "  timesteps_since_restore: 317200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 317200\n",
      "  training_iteration: 122\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 433 s, 122 iter, 317200 ts, 426 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-11-00\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 944.7236355929094\n",
      "  episode_reward_mean: 429.4022141348924\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 127\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 24.149\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.8807909893416293e-38\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.422001838684082\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.136178853921592e-07\n",
      "        policy_loss: 0.008283122442662716\n",
      "        total_loss: 16.397138595581055\n",
      "        vf_explained_var: 0.08160996437072754\n",
      "        vf_loss: 16.388856887817383\n",
      "    load_time_ms: 1.09\n",
      "    num_steps_sampled: 322400\n",
      "    num_steps_trained: 310000\n",
      "    sample_time_ms: 3206.355\n",
      "    update_time_ms: 4.072\n",
      "  iterations_since_restore: 124\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.725\n",
      "    ram_util_percent: 63.72500000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.034578973141965\n",
      "    mean_inference_ms: 0.942221551145889\n",
      "    mean_processing_ms: 0.6848589617581443\n",
      "  time_since_restore: 439.7576913833618\n",
      "  time_this_iter_s: 3.318199634552002\n",
      "  time_total_s: 439.7576913833618\n",
      "  timestamp: 1596121860\n",
      "  timesteps_since_restore: 322400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 322400\n",
      "  training_iteration: 124\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 439 s, 124 iter, 322400 ts, 429 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-11-06\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 944.7236355929094\n",
      "  episode_reward_mean: 429.4022141348924\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 127\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 24.379\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4260435104370117\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.306482080413844e-07\n",
      "        policy_loss: -0.0010064917150884867\n",
      "        total_loss: 67.55641174316406\n",
      "        vf_explained_var: 0.06218200922012329\n",
      "        vf_loss: 67.55741119384766\n",
      "    load_time_ms: 1.084\n",
      "    num_steps_sampled: 327600\n",
      "    num_steps_trained: 315000\n",
      "    sample_time_ms: 3239.574\n",
      "    update_time_ms: 4.147\n",
      "  iterations_since_restore: 126\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.525000000000006\n",
      "    ram_util_percent: 63.724999999999994\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.034578973141965\n",
      "    mean_inference_ms: 0.942221551145889\n",
      "    mean_processing_ms: 0.6848589617581443\n",
      "  time_since_restore: 446.09398770332336\n",
      "  time_this_iter_s: 3.1612207889556885\n",
      "  time_total_s: 446.09398770332336\n",
      "  timestamp: 1596121866\n",
      "  timesteps_since_restore: 327600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 327600\n",
      "  training_iteration: 126\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 446 s, 126 iter, 327600 ts, 429 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-11-14\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 944.7236355929094\n",
      "  episode_reward_mean: 433.36520981974127\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 132\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 24.248\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4214050769805908\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.106998403585749e-07\n",
      "        policy_loss: -0.0017039201920852065\n",
      "        total_loss: 19.8147029876709\n",
      "        vf_explained_var: 0.0778314471244812\n",
      "        vf_loss: 19.816410064697266\n",
      "    load_time_ms: 1.121\n",
      "    num_steps_sampled: 332800\n",
      "    num_steps_trained: 320000\n",
      "    sample_time_ms: 3341.34\n",
      "    update_time_ms: 4.178\n",
      "  iterations_since_restore: 128\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.35\n",
      "    ram_util_percent: 63.7\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.040439714000472\n",
      "    mean_inference_ms: 0.9441842477109226\n",
      "    mean_processing_ms: 0.6854433609309707\n",
      "  time_since_restore: 453.8369810581207\n",
      "  time_this_iter_s: 3.316683053970337\n",
      "  time_total_s: 453.8369810581207\n",
      "  timestamp: 1596121874\n",
      "  timesteps_since_restore: 332800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 332800\n",
      "  training_iteration: 128\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 453 s, 128 iter, 332800 ts, 433 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-11-20\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 944.7236355929094\n",
      "  episode_reward_mean: 433.36520981974127\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 132\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 24.608\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4254320859909058\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.45956776629464e-07\n",
      "        policy_loss: 0.0007130921585485339\n",
      "        total_loss: 53.54905700683594\n",
      "        vf_explained_var: 0.07540011405944824\n",
      "        vf_loss: 53.548336029052734\n",
      "    load_time_ms: 1.133\n",
      "    num_steps_sampled: 338000\n",
      "    num_steps_trained: 325000\n",
      "    sample_time_ms: 3390.471\n",
      "    update_time_ms: 4.233\n",
      "  iterations_since_restore: 130\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.55\n",
      "    ram_util_percent: 63.7\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.040439714000473\n",
      "    mean_inference_ms: 0.9441842477109228\n",
      "    mean_processing_ms: 0.6854433609309706\n",
      "  time_since_restore: 460.12140703201294\n",
      "  time_this_iter_s: 3.0800864696502686\n",
      "  time_total_s: 460.12140703201294\n",
      "  timestamp: 1596121880\n",
      "  timesteps_since_restore: 338000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 338000\n",
      "  training_iteration: 130\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 460 s, 130 iter, 338000 ts, 433 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-11-28\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 944.7236355929094\n",
      "  episode_reward_mean: 443.4119913919666\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 135\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 25.124\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4267412424087524\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.354742039438861e-06\n",
      "        policy_loss: -0.0011755697196349502\n",
      "        total_loss: 45.39120864868164\n",
      "        vf_explained_var: 0.0870751142501831\n",
      "        vf_loss: 45.39238739013672\n",
      "    load_time_ms: 1.19\n",
      "    num_steps_sampled: 343200\n",
      "    num_steps_trained: 330000\n",
      "    sample_time_ms: 3390.342\n",
      "    update_time_ms: 4.265\n",
      "  iterations_since_restore: 132\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 51.879999999999995\n",
      "    ram_util_percent: 63.760000000000005\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.0436338076926015\n",
      "    mean_inference_ms: 0.9451542615484718\n",
      "    mean_processing_ms: 0.6857082294327621\n",
      "  time_since_restore: 467.48156476020813\n",
      "  time_this_iter_s: 3.2287991046905518\n",
      "  time_total_s: 467.48156476020813\n",
      "  timestamp: 1596121888\n",
      "  timesteps_since_restore: 343200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 343200\n",
      "  training_iteration: 132\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 467 s, 132 iter, 343200 ts, 443 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-11-34\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 944.7236355929094\n",
      "  episode_reward_mean: 439.4272459587028\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 137\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 25.921\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4246853590011597\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.4818180577312887e-07\n",
      "        policy_loss: -0.004985530860722065\n",
      "        total_loss: 37.63795852661133\n",
      "        vf_explained_var: 0.09321898221969604\n",
      "        vf_loss: 37.642948150634766\n",
      "    load_time_ms: 1.263\n",
      "    num_steps_sampled: 348400\n",
      "    num_steps_trained: 335000\n",
      "    sample_time_ms: 3389.413\n",
      "    update_time_ms: 4.504\n",
      "  iterations_since_restore: 134\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.57499999999999\n",
      "    ram_util_percent: 63.7\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.0463571444871596\n",
      "    mean_inference_ms: 0.9460675434861375\n",
      "    mean_processing_ms: 0.6859852351472274\n",
      "  time_since_restore: 474.0468888282776\n",
      "  time_this_iter_s: 3.2631947994232178\n",
      "  time_total_s: 474.0468888282776\n",
      "  timestamp: 1596121894\n",
      "  timesteps_since_restore: 348400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 348400\n",
      "  training_iteration: 134\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 474 s, 134 iter, 348400 ts, 439 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-11-42\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 944.7236355929094\n",
      "  episode_reward_mean: 439.47240116150846\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 140\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 30.229\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.427425503730774\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.217195510136662e-06\n",
      "        policy_loss: -0.0035542678087949753\n",
      "        total_loss: 31.047285079956055\n",
      "        vf_explained_var: 0.07926392555236816\n",
      "        vf_loss: 31.05083656311035\n",
      "    load_time_ms: 1.42\n",
      "    num_steps_sampled: 353600\n",
      "    num_steps_trained: 340000\n",
      "    sample_time_ms: 3518.981\n",
      "    update_time_ms: 4.353\n",
      "  iterations_since_restore: 136\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 52.01666666666667\n",
      "    ram_util_percent: 63.81666666666666\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.049048948257472\n",
      "    mean_inference_ms: 0.9468101541084463\n",
      "    mean_processing_ms: 0.6862496535029533\n",
      "  time_since_restore: 481.7339894771576\n",
      "  time_this_iter_s: 4.307881116867065\n",
      "  time_total_s: 481.7339894771576\n",
      "  timestamp: 1596121902\n",
      "  timesteps_since_restore: 353600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 353600\n",
      "  training_iteration: 136\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.6/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 481 s, 136 iter, 353600 ts, 439 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-11-49\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 944.7236355929094\n",
      "  episode_reward_mean: 439.6415818222563\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 142\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 32.567\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4293246269226074\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.255818450677907e-06\n",
      "        policy_loss: -0.0004182329575996846\n",
      "        total_loss: 35.21284103393555\n",
      "        vf_explained_var: 0.10129326581954956\n",
      "        vf_loss: 35.21326446533203\n",
      "    load_time_ms: 1.506\n",
      "    num_steps_sampled: 358800\n",
      "    num_steps_trained: 345000\n",
      "    sample_time_ms: 3431.827\n",
      "    update_time_ms: 4.725\n",
      "  iterations_since_restore: 138\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.82000000000001\n",
      "    ram_util_percent: 63.86\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.0510800584169955\n",
      "    mean_inference_ms: 0.9475408935505212\n",
      "    mean_processing_ms: 0.6865720291564072\n",
      "  time_since_restore: 488.6405415534973\n",
      "  time_this_iter_s: 3.6206698417663574\n",
      "  time_total_s: 488.6405415534973\n",
      "  timestamp: 1596121909\n",
      "  timesteps_since_restore: 358800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 358800\n",
      "  training_iteration: 138\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.6/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 488 s, 138 iter, 358800 ts, 440 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-11-57\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 944.7236355929094\n",
      "  episode_reward_mean: 439.24379242242486\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 143\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 32.211\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4324780702590942\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.145332230924396e-07\n",
      "        policy_loss: -0.0013091875007376075\n",
      "        total_loss: 62.73654556274414\n",
      "        vf_explained_var: 0.06785261631011963\n",
      "        vf_loss: 62.73786163330078\n",
      "    load_time_ms: 1.498\n",
      "    num_steps_sampled: 364000\n",
      "    num_steps_trained: 350000\n",
      "    sample_time_ms: 3560.888\n",
      "    update_time_ms: 5.189\n",
      "  iterations_since_restore: 140\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.51666666666666\n",
      "    ram_util_percent: 63.75\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.052051073121842\n",
      "    mean_inference_ms: 0.9477250545160139\n",
      "    mean_processing_ms: 0.6866412168137941\n",
      "  time_since_restore: 496.2157678604126\n",
      "  time_this_iter_s: 4.504465818405151\n",
      "  time_total_s: 496.2157678604126\n",
      "  timestamp: 1596121917\n",
      "  timesteps_since_restore: 364000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 364000\n",
      "  training_iteration: 140\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 496 s, 140 iter, 364000 ts, 439 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-12-04\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 944.7236355929094\n",
      "  episode_reward_mean: 441.460389408594\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 145\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 32.21\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.427485466003418\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.070015610428527e-06\n",
      "        policy_loss: 0.001718774437904358\n",
      "        total_loss: 42.72014236450195\n",
      "        vf_explained_var: 0.09097862243652344\n",
      "        vf_loss: 42.71841812133789\n",
      "    load_time_ms: 1.546\n",
      "    num_steps_sampled: 369200\n",
      "    num_steps_trained: 355000\n",
      "    sample_time_ms: 3569.475\n",
      "    update_time_ms: 5.123\n",
      "  iterations_since_restore: 142\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.459999999999994\n",
      "    ram_util_percent: 63.8\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.053710422401861\n",
      "    mean_inference_ms: 0.9482334976130017\n",
      "    mean_processing_ms: 0.6867458471699065\n",
      "  time_since_restore: 503.658390045166\n",
      "  time_this_iter_s: 3.228039026260376\n",
      "  time_total_s: 503.658390045166\n",
      "  timestamp: 1596121924\n",
      "  timesteps_since_restore: 369200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 369200\n",
      "  training_iteration: 142\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 503 s, 142 iter, 369200 ts, 441 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-12-11\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 944.7236355929094\n",
      "  episode_reward_mean: 441.6490813382301\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 147\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 31.554\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4250637292861938\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.615451819565351e-07\n",
      "        policy_loss: -0.006610901094973087\n",
      "        total_loss: 17.79652976989746\n",
      "        vf_explained_var: 0.09533894062042236\n",
      "        vf_loss: 17.803138732910156\n",
      "    load_time_ms: 1.468\n",
      "    num_steps_sampled: 374400\n",
      "    num_steps_trained: 360000\n",
      "    sample_time_ms: 3630.934\n",
      "    update_time_ms: 4.877\n",
      "  iterations_since_restore: 144\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.050000000000004\n",
      "    ram_util_percent: 63.77499999999999\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.05579631985597\n",
      "    mean_inference_ms: 0.9489680432613283\n",
      "    mean_processing_ms: 0.6870146275953859\n",
      "  time_since_restore: 510.82701778411865\n",
      "  time_this_iter_s: 2.9775643348693848\n",
      "  time_total_s: 510.82701778411865\n",
      "  timestamp: 1596121931\n",
      "  timesteps_since_restore: 374400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 374400\n",
      "  training_iteration: 144\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 510 s, 144 iter, 374400 ts, 442 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-12-17\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 944.7236355929094\n",
      "  episode_reward_mean: 440.83000124573596\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 150\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 27.506\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.427506923675537\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.192829123894626e-07\n",
      "        policy_loss: 0.003917815629392862\n",
      "        total_loss: 50.17027282714844\n",
      "        vf_explained_var: 0.07911545038223267\n",
      "        vf_loss: 50.166358947753906\n",
      "    load_time_ms: 1.299\n",
      "    num_steps_sampled: 379600\n",
      "    num_steps_trained: 365000\n",
      "    sample_time_ms: 3489.938\n",
      "    update_time_ms: 4.925\n",
      "  iterations_since_restore: 146\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.839999999999996\n",
      "    ram_util_percent: 63.78000000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.057857437801601\n",
      "    mean_inference_ms: 0.9494806949975956\n",
      "    mean_processing_ms: 0.6871178215304787\n",
      "  time_since_restore: 517.0522577762604\n",
      "  time_this_iter_s: 3.138786792755127\n",
      "  time_total_s: 517.0522577762604\n",
      "  timestamp: 1596121937\n",
      "  timesteps_since_restore: 379600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 379600\n",
      "  training_iteration: 146\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 517 s, 146 iter, 379600 ts, 441 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-12-25\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 944.7236355929094\n",
      "  episode_reward_mean: 444.5404677039529\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 152\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 27.457\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4274694919586182\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.8954158349515637e-06\n",
      "        policy_loss: 0.00326723325997591\n",
      "        total_loss: 63.566139221191406\n",
      "        vf_explained_var: 0.08374065160751343\n",
      "        vf_loss: 63.56287384033203\n",
      "    load_time_ms: 1.356\n",
      "    num_steps_sampled: 384800\n",
      "    num_steps_trained: 370000\n",
      "    sample_time_ms: 3607.448\n",
      "    update_time_ms: 4.509\n",
      "  iterations_since_restore: 148\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.52\n",
      "    ram_util_percent: 64.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.059370432363479\n",
      "    mean_inference_ms: 0.9500648766983766\n",
      "    mean_processing_ms: 0.6874183547615798\n",
      "  time_since_restore: 525.1238658428192\n",
      "  time_this_iter_s: 3.8967912197113037\n",
      "  time_total_s: 525.1238658428192\n",
      "  timestamp: 1596121945\n",
      "  timesteps_since_restore: 384800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 384800\n",
      "  training_iteration: 148\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.6/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 525 s, 148 iter, 384800 ts, 445 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-12-35\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 454.8046076393239\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 154\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 29.891\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4308576583862305\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.0684370863600634e-06\n",
      "        policy_loss: -0.0018266307888552547\n",
      "        total_loss: 76.30021667480469\n",
      "        vf_explained_var: 0.08711361885070801\n",
      "        vf_loss: 76.30204772949219\n",
      "    load_time_ms: 1.379\n",
      "    num_steps_sampled: 390000\n",
      "    num_steps_trained: 375000\n",
      "    sample_time_ms: 3761.679\n",
      "    update_time_ms: 4.081\n",
      "  iterations_since_restore: 150\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.6875\n",
      "    ram_util_percent: 64.85\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.060986416178878\n",
      "    mean_inference_ms: 0.9504051358966809\n",
      "    mean_processing_ms: 0.6874580713848267\n",
      "  time_since_restore: 534.2660901546478\n",
      "  time_this_iter_s: 5.62632155418396\n",
      "  time_total_s: 534.2660901546478\n",
      "  timestamp: 1596121955\n",
      "  timesteps_since_restore: 390000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 390000\n",
      "  training_iteration: 150\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 534 s, 150 iter, 390000 ts, 455 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-12-43\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 450.6808989764182\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 156\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 37.19\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4268112182617188\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.9496203549351776e-06\n",
      "        policy_loss: 0.005153419449925423\n",
      "        total_loss: 33.10601806640625\n",
      "        vf_explained_var: 0.07522368431091309\n",
      "        vf_loss: 33.10087585449219\n",
      "    load_time_ms: 1.634\n",
      "    num_steps_sampled: 395200\n",
      "    num_steps_trained: 380000\n",
      "    sample_time_ms: 3884.809\n",
      "    update_time_ms: 5.114\n",
      "  iterations_since_restore: 152\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 68.41666666666667\n",
      "    ram_util_percent: 66.86666666666666\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.06336525623472\n",
      "    mean_inference_ms: 0.9512267970200174\n",
      "    mean_processing_ms: 0.6877103513320728\n",
      "  time_since_restore: 543.0497832298279\n",
      "  time_this_iter_s: 3.9368350505828857\n",
      "  time_total_s: 543.0497832298279\n",
      "  timestamp: 1596121963\n",
      "  timesteps_since_restore: 395200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 395200\n",
      "  training_iteration: 152\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 11.1/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 543 s, 152 iter, 395200 ts, 451 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-12-53\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 451.5371616076646\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 158\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 39.76\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4269191026687622\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.074283641690272e-07\n",
      "        policy_loss: -0.005646892357617617\n",
      "        total_loss: 40.33176040649414\n",
      "        vf_explained_var: 0.12165409326553345\n",
      "        vf_loss: 40.33740234375\n",
      "    load_time_ms: 1.675\n",
      "    num_steps_sampled: 400400\n",
      "    num_steps_trained: 385000\n",
      "    sample_time_ms: 4115.929\n",
      "    update_time_ms: 5.743\n",
      "  iterations_since_restore: 154\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.77777777777777\n",
      "    ram_util_percent: 65.6\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.065478193946966\n",
      "    mean_inference_ms: 0.9517366778127058\n",
      "    mean_processing_ms: 0.6878648090372124\n",
      "  time_since_restore: 552.5719017982483\n",
      "  time_this_iter_s: 5.74648118019104\n",
      "  time_total_s: 552.5719017982483\n",
      "  timestamp: 1596121973\n",
      "  timesteps_since_restore: 400400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 400400\n",
      "  training_iteration: 154\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 552 s, 154 iter, 400400 ts, 452 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-13-01\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 453.5901942410755\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 159\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 39.764\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.427770733833313\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.2865543794760015e-06\n",
      "        policy_loss: -0.0010819084709510207\n",
      "        total_loss: 38.318092346191406\n",
      "        vf_explained_var: 0.08388018608093262\n",
      "        vf_loss: 38.31917190551758\n",
      "    load_time_ms: 1.688\n",
      "    num_steps_sampled: 405600\n",
      "    num_steps_trained: 390000\n",
      "    sample_time_ms: 4273.049\n",
      "    update_time_ms: 6.218\n",
      "  iterations_since_restore: 156\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.64000000000001\n",
      "    ram_util_percent: 65.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.066360045662982\n",
      "    mean_inference_ms: 0.951990547052008\n",
      "    mean_processing_ms: 0.6878824556779753\n",
      "  time_since_restore: 560.3733103275299\n",
      "  time_this_iter_s: 3.2428154945373535\n",
      "  time_total_s: 560.3733103275299\n",
      "  timestamp: 1596121981\n",
      "  timesteps_since_restore: 405600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 405600\n",
      "  training_iteration: 156\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 560 s, 156 iter, 405600 ts, 454 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-13-09\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 453.13231499560027\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 163\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 39.34\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4263527393341064\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.6007423653263686e-07\n",
      "        policy_loss: -0.001982427202165127\n",
      "        total_loss: 25.60803985595703\n",
      "        vf_explained_var: 0.12370520830154419\n",
      "        vf_loss: 25.610021591186523\n",
      "    load_time_ms: 1.745\n",
      "    num_steps_sampled: 410800\n",
      "    num_steps_trained: 395000\n",
      "    sample_time_ms: 4319.735\n",
      "    update_time_ms: 6.361\n",
      "  iterations_since_restore: 158\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.48571428571428\n",
      "    ram_util_percent: 65.25714285714285\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.070807100029682\n",
      "    mean_inference_ms: 0.9533591760255711\n",
      "    mean_processing_ms: 0.6883667673823166\n",
      "  time_since_restore: 568.9117014408112\n",
      "  time_this_iter_s: 5.135701656341553\n",
      "  time_total_s: 568.9117014408112\n",
      "  timestamp: 1596121989\n",
      "  timesteps_since_restore: 410800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 410800\n",
      "  training_iteration: 158\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 568 s, 158 iter, 410800 ts, 453 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-13-17\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 455.0471220293254\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 164\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 37.944\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4245350360870361\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.97749039646078e-07\n",
      "        policy_loss: -0.0009983980562537909\n",
      "        total_loss: 15.455641746520996\n",
      "        vf_explained_var: 0.06123560667037964\n",
      "        vf_loss: 15.456639289855957\n",
      "    load_time_ms: 1.751\n",
      "    num_steps_sampled: 416000\n",
      "    num_steps_trained: 400000\n",
      "    sample_time_ms: 4173.305\n",
      "    update_time_ms: 6.388\n",
      "  iterations_since_restore: 160\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.21999999999999\n",
      "    ram_util_percent: 65.26\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.071813034329533\n",
      "    mean_inference_ms: 0.953633351329429\n",
      "    mean_processing_ms: 0.6883976601338042\n",
      "  time_since_restore: 576.575204372406\n",
      "  time_this_iter_s: 3.3995001316070557\n",
      "  time_total_s: 576.575204372406\n",
      "  timestamp: 1596121997\n",
      "  timesteps_since_restore: 416000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 416000\n",
      "  training_iteration: 160\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 576 s, 160 iter, 416000 ts, 455 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-13-24\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 454.32646816501796\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 166\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 29.4\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4252082109451294\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.913475043442304e-07\n",
      "        policy_loss: -0.0020974529907107353\n",
      "        total_loss: 9.884057998657227\n",
      "        vf_explained_var: 0.10253632068634033\n",
      "        vf_loss: 9.886154174804688\n",
      "    load_time_ms: 1.41\n",
      "    num_steps_sampled: 421200\n",
      "    num_steps_trained: 405000\n",
      "    sample_time_ms: 3957.819\n",
      "    update_time_ms: 5.254\n",
      "  iterations_since_restore: 162\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.56\n",
      "    ram_util_percent: 65.28\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.074790410805942\n",
      "    mean_inference_ms: 0.9545926497832293\n",
      "    mean_processing_ms: 0.6887086592281151\n",
      "  time_since_restore: 583.079311132431\n",
      "  time_this_iter_s: 3.323431968688965\n",
      "  time_total_s: 583.079311132431\n",
      "  timestamp: 1596122004\n",
      "  timesteps_since_restore: 421200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 421200\n",
      "  training_iteration: 162\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 583 s, 162 iter, 421200 ts, 454 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-13-31\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 448.17410517371536\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 168\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 27.459\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.427364468574524\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.383180561897461e-07\n",
      "        policy_loss: -0.0049950783140957355\n",
      "        total_loss: 39.153541564941406\n",
      "        vf_explained_var: 0.07828748226165771\n",
      "        vf_loss: 39.158538818359375\n",
      "    load_time_ms: 1.386\n",
      "    num_steps_sampled: 426400\n",
      "    num_steps_trained: 410000\n",
      "    sample_time_ms: 3734.087\n",
      "    update_time_ms: 4.639\n",
      "  iterations_since_restore: 164\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.919999999999995\n",
      "    ram_util_percent: 65.34\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.07708655122515\n",
      "    mean_inference_ms: 0.9551618410623487\n",
      "    mean_processing_ms: 0.6888751258329235\n",
      "  time_since_restore: 590.3286356925964\n",
      "  time_this_iter_s: 3.103874921798706\n",
      "  time_total_s: 590.3286356925964\n",
      "  timestamp: 1596122011\n",
      "  timesteps_since_restore: 426400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 426400\n",
      "  training_iteration: 164\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 590 s, 164 iter, 426400 ts, 448 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-13-38\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 452.2245886445762\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 170\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 27.898\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4330227375030518\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.7483453070308315e-06\n",
      "        policy_loss: 0.0013869869289919734\n",
      "        total_loss: 57.62596130371094\n",
      "        vf_explained_var: 0.07869774103164673\n",
      "        vf_loss: 57.624568939208984\n",
      "    load_time_ms: 1.399\n",
      "    num_steps_sampled: 431600\n",
      "    num_steps_trained: 415000\n",
      "    sample_time_ms: 3658.079\n",
      "    update_time_ms: 4.222\n",
      "  iterations_since_restore: 166\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.39999999999999\n",
      "    ram_util_percent: 65.38\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.079806253989802\n",
      "    mean_inference_ms: 0.9559642650811524\n",
      "    mean_processing_ms: 0.6890525539299521\n",
      "  time_since_restore: 597.3771200180054\n",
      "  time_this_iter_s: 3.571082592010498\n",
      "  time_total_s: 597.3771200180054\n",
      "  timestamp: 1596122018\n",
      "  timesteps_since_restore: 431600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 431600\n",
      "  training_iteration: 166\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 597 s, 166 iter, 431600 ts, 452 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-13-46\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 455.8553208354314\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 173\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 27.722\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4304158687591553\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.0178565617025015e-06\n",
      "        policy_loss: -0.002286521252244711\n",
      "        total_loss: 29.918746948242188\n",
      "        vf_explained_var: 0.1204337477684021\n",
      "        vf_loss: 29.921031951904297\n",
      "    load_time_ms: 1.272\n",
      "    num_steps_sampled: 436800\n",
      "    num_steps_trained: 420000\n",
      "    sample_time_ms: 3600.571\n",
      "    update_time_ms: 4.195\n",
      "  iterations_since_restore: 168\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.35999999999999\n",
      "    ram_util_percent: 65.3\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.083461120352279\n",
      "    mean_inference_ms: 0.9569640186234821\n",
      "    mean_processing_ms: 0.6893757671900711\n",
      "  time_since_restore: 605.3377304077148\n",
      "  time_this_iter_s: 3.5793731212615967\n",
      "  time_total_s: 605.3377304077148\n",
      "  timestamp: 1596122026\n",
      "  timesteps_since_restore: 436800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 436800\n",
      "  training_iteration: 168\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 605 s, 168 iter, 436800 ts, 456 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-13-53\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 457.61717147975753\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 174\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 26.827\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4291632175445557\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.1794558051624335e-06\n",
      "        policy_loss: 0.005138026084750891\n",
      "        total_loss: 16.067228317260742\n",
      "        vf_explained_var: 0.0634424090385437\n",
      "        vf_loss: 16.062089920043945\n",
      "    load_time_ms: 1.236\n",
      "    num_steps_sampled: 442000\n",
      "    num_steps_trained: 425000\n",
      "    sample_time_ms: 3520.143\n",
      "    update_time_ms: 4.428\n",
      "  iterations_since_restore: 170\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.8\n",
      "    ram_util_percent: 65.35999999999999\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.084460795310926\n",
      "    mean_inference_ms: 0.9572422277885654\n",
      "    mean_processing_ms: 0.6894255732211988\n",
      "  time_since_restore: 612.186113357544\n",
      "  time_this_iter_s: 3.207848310470581\n",
      "  time_total_s: 612.186113357544\n",
      "  timestamp: 1596122033\n",
      "  timesteps_since_restore: 442000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 442000\n",
      "  training_iteration: 170\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 612 s, 170 iter, 442000 ts, 458 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-14-00\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 454.31469178813137\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 176\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 26.925\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4348416328430176\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.9349326524652497e-08\n",
      "        policy_loss: 0.0011745344381779432\n",
      "        total_loss: 36.33571243286133\n",
      "        vf_explained_var: 0.11619734764099121\n",
      "        vf_loss: 36.334537506103516\n",
      "    load_time_ms: 1.24\n",
      "    num_steps_sampled: 447200\n",
      "    num_steps_trained: 430000\n",
      "    sample_time_ms: 3539.889\n",
      "    update_time_ms: 4.621\n",
      "  iterations_since_restore: 172\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.474999999999994\n",
      "    ram_util_percent: 65.3\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.087224326942263\n",
      "    mean_inference_ms: 0.9581115819163578\n",
      "    mean_processing_ms: 0.6897202322527426\n",
      "  time_since_restore: 618.8987646102905\n",
      "  time_this_iter_s: 3.215226650238037\n",
      "  time_total_s: 618.8987646102905\n",
      "  timestamp: 1596122040\n",
      "  timesteps_since_restore: 447200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 447200\n",
      "  training_iteration: 172\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 618 s, 172 iter, 447200 ts, 454 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-14-06\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 456.2492788077439\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 179\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 26.15\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4322360754013062\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.51605501944141e-06\n",
      "        policy_loss: 0.006577926687896252\n",
      "        total_loss: 32.21383285522461\n",
      "        vf_explained_var: 0.1114230751991272\n",
      "        vf_loss: 32.20724868774414\n",
      "    load_time_ms: 1.226\n",
      "    num_steps_sampled: 452400\n",
      "    num_steps_trained: 435000\n",
      "    sample_time_ms: 3477.915\n",
      "    update_time_ms: 4.776\n",
      "  iterations_since_restore: 174\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.080000000000005\n",
      "    ram_util_percent: 65.3\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.090968485559523\n",
      "    mean_inference_ms: 0.959105772694492\n",
      "    mean_processing_ms: 0.6899742996439109\n",
      "  time_since_restore: 625.5224778652191\n",
      "  time_this_iter_s: 3.2616398334503174\n",
      "  time_total_s: 625.5224778652191\n",
      "  timestamp: 1596122046\n",
      "  timesteps_since_restore: 452400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 452400\n",
      "  training_iteration: 174\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 625 s, 174 iter, 452400 ts, 456 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-14-14\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 457.3949958463992\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 180\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 26.019\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.432767391204834\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.1447191354818642e-06\n",
      "        policy_loss: 0.0007305109174922109\n",
      "        total_loss: 28.37211799621582\n",
      "        vf_explained_var: 0.09784317016601562\n",
      "        vf_loss: 28.37139320373535\n",
      "    load_time_ms: 1.244\n",
      "    num_steps_sampled: 457600\n",
      "    num_steps_trained: 440000\n",
      "    sample_time_ms: 3562.592\n",
      "    update_time_ms: 4.739\n",
      "  iterations_since_restore: 176\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.50000000000001\n",
      "    ram_util_percent: 65.27499999999999\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.092455406736886\n",
      "    mean_inference_ms: 0.9595170922721371\n",
      "    mean_processing_ms: 0.6900751865201106\n",
      "  time_since_restore: 633.410346031189\n",
      "  time_this_iter_s: 3.1409335136413574\n",
      "  time_total_s: 633.410346031189\n",
      "  timestamp: 1596122054\n",
      "  timesteps_since_restore: 457600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 457600\n",
      "  training_iteration: 176\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 633 s, 176 iter, 457600 ts, 457 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-14-21\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 458.1619013410246\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 183\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 24.516\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4317899942398071\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.991412083654723e-07\n",
      "        policy_loss: 0.0073443143628537655\n",
      "        total_loss: 22.423614501953125\n",
      "        vf_explained_var: 0.1438853144645691\n",
      "        vf_loss: 22.416271209716797\n",
      "    load_time_ms: 1.171\n",
      "    num_steps_sampled: 462800\n",
      "    num_steps_trained: 445000\n",
      "    sample_time_ms: 3491.035\n",
      "    update_time_ms: 4.694\n",
      "  iterations_since_restore: 178\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.175\n",
      "    ram_util_percent: 65.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.096609971930326\n",
      "    mean_inference_ms: 0.9607107711162673\n",
      "    mean_processing_ms: 0.6905211791739423\n",
      "  time_since_restore: 640.6377854347229\n",
      "  time_this_iter_s: 3.157792091369629\n",
      "  time_total_s: 640.6377854347229\n",
      "  timestamp: 1596122061\n",
      "  timesteps_since_restore: 462800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 462800\n",
      "  training_iteration: 178\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 640 s, 178 iter, 462800 ts, 458 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-14-28\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 456.94280451297396\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 185\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 26.086\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4305768013000488\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.885196744908171e-07\n",
      "        policy_loss: 0.0017626503249630332\n",
      "        total_loss: 17.955121994018555\n",
      "        vf_explained_var: 0.12492966651916504\n",
      "        vf_loss: 17.95335578918457\n",
      "    load_time_ms: 1.257\n",
      "    num_steps_sampled: 468000\n",
      "    num_steps_trained: 450000\n",
      "    sample_time_ms: 3476.583\n",
      "    update_time_ms: 4.464\n",
      "  iterations_since_restore: 180\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.339999999999996\n",
      "    ram_util_percent: 65.12\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.099292895515385\n",
      "    mean_inference_ms: 0.9614991473468953\n",
      "    mean_processing_ms: 0.690717530180948\n",
      "  time_since_restore: 647.3612387180328\n",
      "  time_this_iter_s: 3.2941784858703613\n",
      "  time_total_s: 647.3612387180328\n",
      "  timestamp: 1596122068\n",
      "  timesteps_since_restore: 468000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 468000\n",
      "  training_iteration: 180\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 647 s, 180 iter, 468000 ts, 457 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-14-35\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 455.24448737725675\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 187\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 28.113\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.434934377670288\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.7707098979590228e-06\n",
      "        policy_loss: 0.002027243608608842\n",
      "        total_loss: 26.879230499267578\n",
      "        vf_explained_var: 0.12597423791885376\n",
      "        vf_loss: 26.877206802368164\n",
      "    load_time_ms: 1.391\n",
      "    num_steps_sampled: 473200\n",
      "    num_steps_trained: 455000\n",
      "    sample_time_ms: 3506.37\n",
      "    update_time_ms: 4.648\n",
      "  iterations_since_restore: 182\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.779999999999994\n",
      "    ram_util_percent: 65.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.101963802092563\n",
      "    mean_inference_ms: 0.9622049152581214\n",
      "    mean_processing_ms: 0.690917281494093\n",
      "  time_since_restore: 654.3928709030151\n",
      "  time_this_iter_s: 3.6481363773345947\n",
      "  time_total_s: 654.3928709030151\n",
      "  timestamp: 1596122075\n",
      "  timesteps_since_restore: 473200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 473200\n",
      "  training_iteration: 182\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 654 s, 182 iter, 473200 ts, 455 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-14-44\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 445.40238721496587\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 190\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 32.871\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4330857992172241\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.342677134947735e-06\n",
      "        policy_loss: -0.0022932400461286306\n",
      "        total_loss: 17.6711368560791\n",
      "        vf_explained_var: 0.11995428800582886\n",
      "        vf_loss: 17.67342758178711\n",
      "    load_time_ms: 1.514\n",
      "    num_steps_sampled: 478400\n",
      "    num_steps_trained: 460000\n",
      "    sample_time_ms: 3754.444\n",
      "    update_time_ms: 5.307\n",
      "  iterations_since_restore: 184\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.285714285714285\n",
      "    ram_util_percent: 65.15714285714286\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.106096948029258\n",
      "    mean_inference_ms: 0.9633687392589652\n",
      "    mean_processing_ms: 0.691314805730036\n",
      "  time_since_restore: 663.5692341327667\n",
      "  time_this_iter_s: 5.01344108581543\n",
      "  time_total_s: 663.5692341327667\n",
      "  timestamp: 1596122084\n",
      "  timesteps_since_restore: 478400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 478400\n",
      "  training_iteration: 184\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 663 s, 184 iter, 478400 ts, 445 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-14-51\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 446.94971234690297\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 191\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 32.809\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.439555287361145\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.1645079212030396e-06\n",
      "        policy_loss: 0.0009344653808511794\n",
      "        total_loss: 58.6474494934082\n",
      "        vf_explained_var: 0.07628566026687622\n",
      "        vf_loss: 58.646507263183594\n",
      "    load_time_ms: 1.551\n",
      "    num_steps_sampled: 483600\n",
      "    num_steps_trained: 465000\n",
      "    sample_time_ms: 3661.593\n",
      "    update_time_ms: 5.441\n",
      "  iterations_since_restore: 186\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.1\n",
      "    ram_util_percent: 65.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.107497062845626\n",
      "    mean_inference_ms: 0.9637664592537495\n",
      "    mean_processing_ms: 0.6914652285147149\n",
      "  time_since_restore: 670.5327541828156\n",
      "  time_this_iter_s: 3.401219606399536\n",
      "  time_total_s: 670.5327541828156\n",
      "  timestamp: 1596122091\n",
      "  timesteps_since_restore: 483600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 483600\n",
      "  training_iteration: 186\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 670 s, 186 iter, 483600 ts, 447 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-14-59\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 445.3255938596175\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 193\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 32.884\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4408358335494995\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.013658442796441e-06\n",
      "        policy_loss: 0.00915924645960331\n",
      "        total_loss: 64.02420806884766\n",
      "        vf_explained_var: 0.08676183223724365\n",
      "        vf_loss: 64.0150375366211\n",
      "    load_time_ms: 1.538\n",
      "    num_steps_sampled: 488800\n",
      "    num_steps_trained: 470000\n",
      "    sample_time_ms: 3731.02\n",
      "    update_time_ms: 5.417\n",
      "  iterations_since_restore: 188\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.1\n",
      "    ram_util_percent: 65.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.110340097512134\n",
      "    mean_inference_ms: 0.9645659601343028\n",
      "    mean_processing_ms: 0.6917436413179793\n",
      "  time_since_restore: 678.4534499645233\n",
      "  time_this_iter_s: 3.4024596214294434\n",
      "  time_total_s: 678.4534499645233\n",
      "  timestamp: 1596122099\n",
      "  timesteps_since_restore: 488800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 488800\n",
      "  training_iteration: 188\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 678 s, 188 iter, 488800 ts, 445 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-15-06\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 450.182873119833\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 195\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 32.2\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.432444453239441\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.3535718557686778e-06\n",
      "        policy_loss: -0.005063268821686506\n",
      "        total_loss: 27.148212432861328\n",
      "        vf_explained_var: 0.13257819414138794\n",
      "        vf_loss: 27.153268814086914\n",
      "    load_time_ms: 1.507\n",
      "    num_steps_sampled: 494000\n",
      "    num_steps_trained: 475000\n",
      "    sample_time_ms: 3757.405\n",
      "    update_time_ms: 5.472\n",
      "  iterations_since_restore: 190\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.8\n",
      "    ram_util_percent: 65.0\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.1131686131488605\n",
      "    mean_inference_ms: 0.9652725003934697\n",
      "    mean_processing_ms: 0.6919676731659871\n",
      "  time_since_restore: 685.4319317340851\n",
      "  time_this_iter_s: 3.475738763809204\n",
      "  time_total_s: 685.4319317340851\n",
      "  timestamp: 1596122106\n",
      "  timesteps_since_restore: 494000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 494000\n",
      "  training_iteration: 190\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 685 s, 190 iter, 494000 ts, 450 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-15-13\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 448.45902002785306\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 197\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 30.881\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4329769611358643\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.1086464013487785e-07\n",
      "        policy_loss: -0.0027601660694926977\n",
      "        total_loss: 25.31639289855957\n",
      "        vf_explained_var: 0.12941348552703857\n",
      "        vf_loss: 25.31915855407715\n",
      "    load_time_ms: 1.367\n",
      "    num_steps_sampled: 499200\n",
      "    num_steps_trained: 480000\n",
      "    sample_time_ms: 3756.868\n",
      "    update_time_ms: 5.194\n",
      "  iterations_since_restore: 192\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.739999999999995\n",
      "    ram_util_percent: 65.16\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.115737453740746\n",
      "    mean_inference_ms: 0.9659769070399943\n",
      "    mean_processing_ms: 0.6922022398463592\n",
      "  time_since_restore: 692.4390587806702\n",
      "  time_this_iter_s: 3.4905083179473877\n",
      "  time_total_s: 692.4390587806702\n",
      "  timestamp: 1596122113\n",
      "  timesteps_since_restore: 499200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 499200\n",
      "  training_iteration: 192\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 692 s, 192 iter, 499200 ts, 448 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-15-21\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 439.11446708840543\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 200\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 28.372\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4302815198898315\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.5213728374874336e-06\n",
      "        policy_loss: 0.0008908522431738675\n",
      "        total_loss: 19.786741256713867\n",
      "        vf_explained_var: 0.1294531226158142\n",
      "        vf_loss: 19.785852432250977\n",
      "    load_time_ms: 1.277\n",
      "    num_steps_sampled: 504400\n",
      "    num_steps_trained: 485000\n",
      "    sample_time_ms: 3645.456\n",
      "    update_time_ms: 4.436\n",
      "  iterations_since_restore: 194\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.28\n",
      "    ram_util_percent: 65.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.118895607621114\n",
      "    mean_inference_ms: 0.9670166204488585\n",
      "    mean_processing_ms: 0.6925636979896597\n",
      "  time_since_restore: 700.4660289287567\n",
      "  time_this_iter_s: 3.669276714324951\n",
      "  time_total_s: 700.4660289287567\n",
      "  timestamp: 1596122121\n",
      "  timesteps_since_restore: 504400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 504400\n",
      "  training_iteration: 194\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 700 s, 194 iter, 504400 ts, 439 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-15-30\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 434.1594547802643\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 201\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 29.075\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4400768280029297\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.948377636537771e-07\n",
      "        policy_loss: -0.00527851702645421\n",
      "        total_loss: 56.30837631225586\n",
      "        vf_explained_var: 0.06448686122894287\n",
      "        vf_loss: 56.313655853271484\n",
      "    load_time_ms: 1.238\n",
      "    num_steps_sampled: 509600\n",
      "    num_steps_trained: 490000\n",
      "    sample_time_ms: 3820.165\n",
      "    update_time_ms: 5.61\n",
      "  iterations_since_restore: 196\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.333333333333336\n",
      "    ram_util_percent: 65.23333333333333\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.119925307613565\n",
      "    mean_inference_ms: 0.9672595083670388\n",
      "    mean_processing_ms: 0.6926356907455979\n",
      "  time_since_restore: 709.195723772049\n",
      "  time_this_iter_s: 4.811862945556641\n",
      "  time_total_s: 709.195723772049\n",
      "  timestamp: 1596122130\n",
      "  timesteps_since_restore: 509600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 509600\n",
      "  training_iteration: 196\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 709 s, 196 iter, 509600 ts, 434 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-15-38\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 434.20474432201905\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 204\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 29.644\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4298783540725708\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 9.793043176387073e-08\n",
      "        policy_loss: -0.004243450704962015\n",
      "        total_loss: 15.513343811035156\n",
      "        vf_explained_var: 0.15419870615005493\n",
      "        vf_loss: 15.51758861541748\n",
      "    load_time_ms: 1.312\n",
      "    num_steps_sampled: 514800\n",
      "    num_steps_trained: 495000\n",
      "    sample_time_ms: 3870.015\n",
      "    update_time_ms: 5.531\n",
      "  iterations_since_restore: 198\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.199999999999996\n",
      "    ram_util_percent: 65.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.122511502008964\n",
      "    mean_inference_ms: 0.96810087570132\n",
      "    mean_processing_ms: 0.6929127702392686\n",
      "  time_since_restore: 717.6206629276276\n",
      "  time_this_iter_s: 4.238795518875122\n",
      "  time_total_s: 717.6206629276276\n",
      "  timestamp: 1596122138\n",
      "  timesteps_since_restore: 514800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 514800\n",
      "  training_iteration: 198\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 717 s, 198 iter, 514800 ts, 434 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-15-48\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 435.66959386294496\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 205\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 32.043\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.434146523475647\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.862236207576643e-07\n",
      "        policy_loss: -0.0010466730454936624\n",
      "        total_loss: 32.2055549621582\n",
      "        vf_explained_var: 0.08178472518920898\n",
      "        vf_loss: 32.20658874511719\n",
      "    load_time_ms: 1.334\n",
      "    num_steps_sampled: 520000\n",
      "    num_steps_trained: 500000\n",
      "    sample_time_ms: 4086.635\n",
      "    update_time_ms: 5.74\n",
      "  iterations_since_restore: 200\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.04285714285713\n",
      "    ram_util_percent: 65.0\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.123771861719089\n",
      "    mean_inference_ms: 0.9684452306956505\n",
      "    mean_processing_ms: 0.6930376310440962\n",
      "  time_since_restore: 726.8085465431213\n",
      "  time_this_iter_s: 4.391071796417236\n",
      "  time_total_s: 726.8085465431213\n",
      "  timestamp: 1596122148\n",
      "  timesteps_since_restore: 520000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 520000\n",
      "  training_iteration: 200\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 726 s, 200 iter, 520000 ts, 436 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-15-58\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 433.5737036759402\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 209\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 32.71\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4409486055374146\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.1907219459317275e-06\n",
      "        policy_loss: 0.004694175906479359\n",
      "        total_loss: 60.60983657836914\n",
      "        vf_explained_var: 0.09943807125091553\n",
      "        vf_loss: 60.60514450073242\n",
      "    load_time_ms: 1.351\n",
      "    num_steps_sampled: 525200\n",
      "    num_steps_trained: 505000\n",
      "    sample_time_ms: 4364.607\n",
      "    update_time_ms: 6.967\n",
      "  iterations_since_restore: 202\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.35\n",
      "    ram_util_percent: 65.0\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.1280000521004165\n",
      "    mean_inference_ms: 0.9695677463991558\n",
      "    mean_processing_ms: 0.6933051142589903\n",
      "  time_since_restore: 736.6158671379089\n",
      "  time_this_iter_s: 5.553792953491211\n",
      "  time_total_s: 736.6158671379089\n",
      "  timestamp: 1596122158\n",
      "  timesteps_since_restore: 525200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 525200\n",
      "  training_iteration: 202\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 736 s, 202 iter, 525200 ts, 434 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-16-07\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 436.73948428322734\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 210\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 33.295\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.43611741065979\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.6513079610122077e-07\n",
      "        policy_loss: 0.0028753243386745453\n",
      "        total_loss: 66.68521881103516\n",
      "        vf_explained_var: 0.08581662178039551\n",
      "        vf_loss: 66.68234252929688\n",
      "    load_time_ms: 1.332\n",
      "    num_steps_sampled: 530400\n",
      "    num_steps_trained: 510000\n",
      "    sample_time_ms: 4464.647\n",
      "    update_time_ms: 8.826\n",
      "  iterations_since_restore: 204\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.88571428571429\n",
      "    ram_util_percent: 65.08571428571429\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.129538679214989\n",
      "    mean_inference_ms: 0.9700483758860992\n",
      "    mean_processing_ms: 0.6934858733755666\n",
      "  time_since_restore: 745.6720368862152\n",
      "  time_this_iter_s: 4.481048107147217\n",
      "  time_total_s: 745.6720368862152\n",
      "  timestamp: 1596122167\n",
      "  timesteps_since_restore: 530400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 530400\n",
      "  training_iteration: 204\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 745 s, 204 iter, 530400 ts, 437 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-16-17\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 436.6896239091527\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 211\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 33.212\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4448716640472412\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.119896857446292e-06\n",
      "        policy_loss: 0.0005484436405822635\n",
      "        total_loss: 73.89622497558594\n",
      "        vf_explained_var: 0.06156158447265625\n",
      "        vf_loss: 73.89568328857422\n",
      "    load_time_ms: 1.377\n",
      "    num_steps_sampled: 535600\n",
      "    num_steps_trained: 515000\n",
      "    sample_time_ms: 4598.212\n",
      "    update_time_ms: 7.746\n",
      "  iterations_since_restore: 206\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.237500000000004\n",
      "    ram_util_percent: 65.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.130853363346912\n",
      "    mean_inference_ms: 0.9704035227341116\n",
      "    mean_processing_ms: 0.6935837954121602\n",
      "  time_since_restore: 755.7273986339569\n",
      "  time_this_iter_s: 5.576751947402954\n",
      "  time_total_s: 755.7273986339569\n",
      "  timestamp: 1596122177\n",
      "  timesteps_since_restore: 535600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 535600\n",
      "  training_iteration: 206\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 755 s, 206 iter, 535600 ts, 437 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-16-22\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 441.23081008772397\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 214\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 34.283\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.437221646308899\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.8243064775779203e-07\n",
      "        policy_loss: -0.0037908763624727726\n",
      "        total_loss: 43.76601791381836\n",
      "        vf_explained_var: 0.11043733358383179\n",
      "        vf_loss: 43.76980972290039\n",
      "    load_time_ms: 1.378\n",
      "    num_steps_sampled: 538200\n",
      "    num_steps_trained: 517500\n",
      "    sample_time_ms: 4693.775\n",
      "    update_time_ms: 7.899\n",
      "  iterations_since_restore: 207\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.71428571428572\n",
      "    ram_util_percent: 65.10000000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.135371017607764\n",
      "    mean_inference_ms: 0.9717613421103265\n",
      "    mean_processing_ms: 0.6940376047984038\n",
      "  time_since_restore: 760.8841428756714\n",
      "  time_this_iter_s: 5.1567442417144775\n",
      "  time_total_s: 760.8841428756714\n",
      "  timestamp: 1596122182\n",
      "  timesteps_since_restore: 538200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 538200\n",
      "  training_iteration: 207\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 760 s, 207 iter, 538200 ts, 441 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-16-27\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 442.6676049866574\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 215\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 33.921\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4294134378433228\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 9.799003919397364e-08\n",
      "        policy_loss: -0.0033871338237076998\n",
      "        total_loss: 14.90156364440918\n",
      "        vf_explained_var: 0.12306433916091919\n",
      "        vf_loss: 14.904948234558105\n",
      "    load_time_ms: 1.351\n",
      "    num_steps_sampled: 540800\n",
      "    num_steps_trained: 520000\n",
      "    sample_time_ms: 4813.559\n",
      "    update_time_ms: 7.999\n",
      "  iterations_since_restore: 208\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.6625\n",
      "    ram_util_percent: 65.0375\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.136898004960027\n",
      "    mean_inference_ms: 0.9721724660634483\n",
      "    mean_processing_ms: 0.6941505853721874\n",
      "  time_since_restore: 766.3183765411377\n",
      "  time_this_iter_s: 5.434233665466309\n",
      "  time_total_s: 766.3183765411377\n",
      "  timestamp: 1596122187\n",
      "  timesteps_since_restore: 540800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 540800\n",
      "  training_iteration: 208\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 766 s, 208 iter, 540800 ts, 443 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-16-36\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 442.66760498665747\n",
      "  episode_reward_min: 137.5418868105293\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 215\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 36.033\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4351906776428223\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.1430016658996465e-06\n",
      "        policy_loss: -0.0012970810057595372\n",
      "        total_loss: 35.55009841918945\n",
      "        vf_explained_var: 0.053647518157958984\n",
      "        vf_loss: 35.551395416259766\n",
      "    load_time_ms: 1.341\n",
      "    num_steps_sampled: 546000\n",
      "    num_steps_trained: 525000\n",
      "    sample_time_ms: 4804.009\n",
      "    update_time_ms: 8.056\n",
      "  iterations_since_restore: 210\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 67.99999999999999\n",
      "    ram_util_percent: 65.10000000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.136898004960026\n",
      "    mean_inference_ms: 0.9721724660634483\n",
      "    mean_processing_ms: 0.6941505853721874\n",
      "  time_since_restore: 775.4378232955933\n",
      "  time_this_iter_s: 4.684732913970947\n",
      "  time_total_s: 775.4378232955933\n",
      "  timestamp: 1596122196\n",
      "  timesteps_since_restore: 546000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 546000\n",
      "  training_iteration: 210\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 775 s, 210 iter, 546000 ts, 443 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-16-47\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 447.08614795214197\n",
      "  episode_reward_min: 182.48059621587115\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 220\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 36.275\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4339816570281982\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.5954712984676007e-07\n",
      "        policy_loss: -0.001590013038367033\n",
      "        total_loss: 20.1749210357666\n",
      "        vf_explained_var: 0.10320854187011719\n",
      "        vf_loss: 20.176511764526367\n",
      "    load_time_ms: 1.333\n",
      "    num_steps_sampled: 551200\n",
      "    num_steps_trained: 530000\n",
      "    sample_time_ms: 4878.472\n",
      "    update_time_ms: 8.02\n",
      "  iterations_since_restore: 212\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.6625\n",
      "    ram_util_percent: 65.0\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.146158170114217\n",
      "    mean_inference_ms: 0.974791507970004\n",
      "    mean_processing_ms: 0.6949363047695559\n",
      "  time_since_restore: 785.9954569339752\n",
      "  time_this_iter_s: 5.895404577255249\n",
      "  time_total_s: 785.9954569339752\n",
      "  timestamp: 1596122207\n",
      "  timesteps_since_restore: 551200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 551200\n",
      "  training_iteration: 212\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 785 s, 212 iter, 551200 ts, 447 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-16-56\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 447.086147952142\n",
      "  episode_reward_min: 182.48059621587115\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 220\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 39.177\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4323540925979614\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 7.525682690356916e-07\n",
      "        policy_loss: -0.0026543999556452036\n",
      "        total_loss: 23.405513763427734\n",
      "        vf_explained_var: 0.050208091735839844\n",
      "        vf_loss: 23.408172607421875\n",
      "    load_time_ms: 1.425\n",
      "    num_steps_sampled: 556400\n",
      "    num_steps_trained: 535000\n",
      "    sample_time_ms: 4859.271\n",
      "    update_time_ms: 7.074\n",
      "  iterations_since_restore: 214\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.98571428571428\n",
      "    ram_util_percent: 65.0\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.146158170114217\n",
      "    mean_inference_ms: 0.9747915079700037\n",
      "    mean_processing_ms: 0.694936304769556\n",
      "  time_since_restore: 794.8760178089142\n",
      "  time_this_iter_s: 4.569137334823608\n",
      "  time_total_s: 794.8760178089142\n",
      "  timestamp: 1596122216\n",
      "  timesteps_since_restore: 556400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 556400\n",
      "  training_iteration: 214\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 794 s, 214 iter, 556400 ts, 447 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-17-06\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 449.0716838989887\n",
      "  episode_reward_min: 182.48059621587115\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 222\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 39.376\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4416929483413696\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.6768187189627497e-07\n",
      "        policy_loss: -0.0017437301576137543\n",
      "        total_loss: 49.780792236328125\n",
      "        vf_explained_var: 0.08613759279251099\n",
      "        vf_loss: 49.78253936767578\n",
      "    load_time_ms: 1.416\n",
      "    num_steps_sampled: 561600\n",
      "    num_steps_trained: 540000\n",
      "    sample_time_ms: 4848.091\n",
      "    update_time_ms: 6.946\n",
      "  iterations_since_restore: 216\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.8\n",
      "    ram_util_percent: 64.92500000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.1501836129979965\n",
      "    mean_inference_ms: 0.9758960492770058\n",
      "    mean_processing_ms: 0.695282003771504\n",
      "  time_since_restore: 804.8199191093445\n",
      "  time_this_iter_s: 5.426161527633667\n",
      "  time_total_s: 804.8199191093445\n",
      "  timestamp: 1596122226\n",
      "  timesteps_since_restore: 561600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 561600\n",
      "  training_iteration: 216\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 804 s, 216 iter, 561600 ts, 449 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-17-12\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 448.1447918964934\n",
      "  episode_reward_min: 182.48059621587115\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 225\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 39.404\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4357675313949585\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.8769979988064733e-06\n",
      "        policy_loss: -0.007792849093675613\n",
      "        total_loss: 29.051544189453125\n",
      "        vf_explained_var: 0.126181960105896\n",
      "        vf_loss: 29.0593318939209\n",
      "    load_time_ms: 1.462\n",
      "    num_steps_sampled: 564200\n",
      "    num_steps_trained: 542500\n",
      "    sample_time_ms: 4888.023\n",
      "    update_time_ms: 6.929\n",
      "  iterations_since_restore: 217\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.5125\n",
      "    ram_util_percent: 64.975\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.157559068519712\n",
      "    mean_inference_ms: 0.9779920753645441\n",
      "    mean_processing_ms: 0.6959025380811784\n",
      "  time_since_restore: 810.3768789768219\n",
      "  time_this_iter_s: 5.556959867477417\n",
      "  time_total_s: 810.3768789768219\n",
      "  timestamp: 1596122232\n",
      "  timesteps_since_restore: 564200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 564200\n",
      "  training_iteration: 217\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 810 s, 217 iter, 564200 ts, 448 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-17-19\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 448.1447918964935\n",
      "  episode_reward_min: 182.48059621587115\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 225\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 38.559\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4320157766342163\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.671905339317163e-07\n",
      "        policy_loss: -0.0026025797706097364\n",
      "        total_loss: 24.949283599853516\n",
      "        vf_explained_var: 0.09023141860961914\n",
      "        vf_loss: 24.951887130737305\n",
      "    load_time_ms: 1.418\n",
      "    num_steps_sampled: 569400\n",
      "    num_steps_trained: 547500\n",
      "    sample_time_ms: 4659.703\n",
      "    update_time_ms: 6.807\n",
      "  iterations_since_restore: 219\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.67999999999999\n",
      "    ram_util_percent: 65.0\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.157559068519712\n",
      "    mean_inference_ms: 0.9779920753645444\n",
      "    mean_processing_ms: 0.6959025380811782\n",
      "  time_since_restore: 817.9511518478394\n",
      "  time_this_iter_s: 3.453054904937744\n",
      "  time_total_s: 817.9511518478394\n",
      "  timestamp: 1596122239\n",
      "  timesteps_since_restore: 569400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 569400\n",
      "  training_iteration: 219\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 817 s, 219 iter, 569400 ts, 448 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-17-27\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 443.5294797852762\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 228\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 32.826\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.438786506652832\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.263711161911488e-06\n",
      "        policy_loss: 0.0032230690121650696\n",
      "        total_loss: 51.38916015625\n",
      "        vf_explained_var: 0.07463568449020386\n",
      "        vf_loss: 51.38593673706055\n",
      "    load_time_ms: 1.418\n",
      "    num_steps_sampled: 574600\n",
      "    num_steps_trained: 552500\n",
      "    sample_time_ms: 4548.138\n",
      "    update_time_ms: 5.816\n",
      "  iterations_since_restore: 221\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.12857142857143\n",
      "    ram_util_percent: 65.0\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.164439732071997\n",
      "    mean_inference_ms: 0.9798433293194758\n",
      "    mean_processing_ms: 0.6964025556627401\n",
      "  time_since_restore: 826.090012550354\n",
      "  time_this_iter_s: 4.672429323196411\n",
      "  time_total_s: 826.090012550354\n",
      "  timestamp: 1596122247\n",
      "  timesteps_since_restore: 574600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 574600\n",
      "  training_iteration: 221\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 826 s, 221 iter, 574600 ts, 444 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-17-34\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 447.8110617294465\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 230\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 27.417\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4419913291931152\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.596399432761245e-07\n",
      "        policy_loss: 0.0024775161873549223\n",
      "        total_loss: 79.39578247070312\n",
      "        vf_explained_var: 0.08257734775543213\n",
      "        vf_loss: 79.3932876586914\n",
      "    load_time_ms: 1.335\n",
      "    num_steps_sampled: 579800\n",
      "    num_steps_trained: 557500\n",
      "    sample_time_ms: 4233.948\n",
      "    update_time_ms: 5.439\n",
      "  iterations_since_restore: 223\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.220000000000006\n",
      "    ram_util_percent: 65.0\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.169192110935811\n",
      "    mean_inference_ms: 0.981292569121579\n",
      "    mean_processing_ms: 0.6968185099523214\n",
      "  time_since_restore: 833.0813436508179\n",
      "  time_this_iter_s: 3.475459098815918\n",
      "  time_total_s: 833.0813436508179\n",
      "  timestamp: 1596122254\n",
      "  timesteps_since_restore: 579800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 579800\n",
      "  training_iteration: 223\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 833 s, 223 iter, 579800 ts, 448 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-17-42\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 454.9802258302281\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 232\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 26.307\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4448268413543701\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.121684924029978e-06\n",
      "        policy_loss: -0.00038003583904355764\n",
      "        total_loss: 77.51576232910156\n",
      "        vf_explained_var: 0.08452057838439941\n",
      "        vf_loss: 77.5161361694336\n",
      "    load_time_ms: 1.285\n",
      "    num_steps_sampled: 585000\n",
      "    num_steps_trained: 562500\n",
      "    sample_time_ms: 4124.041\n",
      "    update_time_ms: 4.479\n",
      "  iterations_since_restore: 225\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.028571428571425\n",
      "    ram_util_percent: 65.0\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.173682737405541\n",
      "    mean_inference_ms: 0.9825677537461627\n",
      "    mean_processing_ms: 0.6972035843868417\n",
      "  time_since_restore: 841.0431935787201\n",
      "  time_this_iter_s: 4.964106559753418\n",
      "  time_total_s: 841.0431935787201\n",
      "  timestamp: 1596122262\n",
      "  timesteps_since_restore: 585000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 585000\n",
      "  training_iteration: 225\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 841 s, 225 iter, 585000 ts, 455 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-17-51\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 448.80890517634924\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 235\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 24.125\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4340577125549316\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.023816136897949e-07\n",
      "        policy_loss: 0.00236348039470613\n",
      "        total_loss: 14.40646743774414\n",
      "        vf_explained_var: 0.1344340443611145\n",
      "        vf_loss: 14.404106140136719\n",
      "    load_time_ms: 1.162\n",
      "    num_steps_sampled: 590200\n",
      "    num_steps_trained: 567500\n",
      "    sample_time_ms: 3867.758\n",
      "    update_time_ms: 4.438\n",
      "  iterations_since_restore: 227\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.614285714285714\n",
      "    ram_util_percent: 65.04285714285713\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.181138371526825\n",
      "    mean_inference_ms: 0.9848055387862155\n",
      "    mean_processing_ms: 0.6978769935377771\n",
      "  time_since_restore: 849.4325816631317\n",
      "  time_this_iter_s: 4.945955514907837\n",
      "  time_total_s: 849.4325816631317\n",
      "  timestamp: 1596122271\n",
      "  timesteps_since_restore: 590200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 590200\n",
      "  training_iteration: 227\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 849 s, 227 iter, 590200 ts, 449 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-17-58\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 448.80890517634924\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 235\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 24.435\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4340417385101318\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.5485287008232262e-07\n",
      "        policy_loss: 0.0017892224714159966\n",
      "        total_loss: 17.0643310546875\n",
      "        vf_explained_var: 0.07920634746551514\n",
      "        vf_loss: 17.062541961669922\n",
      "    load_time_ms: 1.271\n",
      "    num_steps_sampled: 595400\n",
      "    num_steps_trained: 572500\n",
      "    sample_time_ms: 3806.484\n",
      "    update_time_ms: 4.347\n",
      "  iterations_since_restore: 229\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.32000000000001\n",
      "    ram_util_percent: 65.0\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.181138371526824\n",
      "    mean_inference_ms: 0.9848055387862157\n",
      "    mean_processing_ms: 0.6978769935377772\n",
      "  time_since_restore: 856.4002387523651\n",
      "  time_this_iter_s: 3.5465087890625\n",
      "  time_total_s: 856.4002387523651\n",
      "  timestamp: 1596122278\n",
      "  timesteps_since_restore: 595400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 595400\n",
      "  training_iteration: 229\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 856 s, 229 iter, 595400 ts, 449 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-18-05\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 446.36181399867974\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 237\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 24.855\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4379266500473022\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.16414615958638e-07\n",
      "        policy_loss: 0.0024324681144207716\n",
      "        total_loss: 44.84489822387695\n",
      "        vf_explained_var: 0.07108700275421143\n",
      "        vf_loss: 44.84246826171875\n",
      "    load_time_ms: 1.287\n",
      "    num_steps_sampled: 600600\n",
      "    num_steps_trained: 577500\n",
      "    sample_time_ms: 3724.058\n",
      "    update_time_ms: 4.149\n",
      "  iterations_since_restore: 231\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 68.64000000000001\n",
      "    ram_util_percent: 65.0\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.185831599006347\n",
      "    mean_inference_ms: 0.9860931868365959\n",
      "    mean_processing_ms: 0.6982616151119551\n",
      "  time_since_restore: 863.7156341075897\n",
      "  time_this_iter_s: 3.4753005504608154\n",
      "  time_total_s: 863.7156341075897\n",
      "  timestamp: 1596122285\n",
      "  timesteps_since_restore: 600600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 600600\n",
      "  training_iteration: 231\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 863 s, 231 iter, 600600 ts, 446 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-18-12\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 443.5853596878657\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 240\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 24.651\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4353253841400146\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.031824343859626e-07\n",
      "        policy_loss: 0.00030038339900784194\n",
      "        total_loss: 48.94948959350586\n",
      "        vf_explained_var: 0.0923452377319336\n",
      "        vf_loss: 48.949180603027344\n",
      "    load_time_ms: 1.289\n",
      "    num_steps_sampled: 605800\n",
      "    num_steps_trained: 582500\n",
      "    sample_time_ms: 3753.35\n",
      "    update_time_ms: 4.075\n",
      "  iterations_since_restore: 233\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.160000000000004\n",
      "    ram_util_percent: 65.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.193409795546595\n",
      "    mean_inference_ms: 0.9883934623985198\n",
      "    mean_processing_ms: 0.6989378625522642\n",
      "  time_since_restore: 870.9937918186188\n",
      "  time_this_iter_s: 3.27498197555542\n",
      "  time_total_s: 870.9937918186188\n",
      "  timestamp: 1596122292\n",
      "  timesteps_since_restore: 605800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 605800\n",
      "  training_iteration: 233\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 870 s, 233 iter, 605800 ts, 444 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-18-20\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 450.0266470210052\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 242\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 24.969\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4358115196228027\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.3895034101096826e-07\n",
      "        policy_loss: -0.0005665569333359599\n",
      "        total_loss: 31.682109832763672\n",
      "        vf_explained_var: 0.09420794248580933\n",
      "        vf_loss: 31.682668685913086\n",
      "    load_time_ms: 1.366\n",
      "    num_steps_sampled: 611000\n",
      "    num_steps_trained: 587500\n",
      "    sample_time_ms: 3700.732\n",
      "    update_time_ms: 4.014\n",
      "  iterations_since_restore: 235\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.379999999999995\n",
      "    ram_util_percent: 65.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.198005965964592\n",
      "    mean_inference_ms: 0.9896703582202323\n",
      "    mean_processing_ms: 0.6992633585996003\n",
      "  time_since_restore: 878.4368488788605\n",
      "  time_this_iter_s: 3.683408260345459\n",
      "  time_total_s: 878.4368488788605\n",
      "  timestamp: 1596122300\n",
      "  timesteps_since_restore: 611000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 611000\n",
      "  training_iteration: 235\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 878 s, 235 iter, 611000 ts, 450 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-18-28\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 448.2423284345486\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 245\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 28.277\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4334627389907837\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.007389982987661e-06\n",
      "        policy_loss: -0.003108648583292961\n",
      "        total_loss: 26.711288452148438\n",
      "        vf_explained_var: 0.11789822578430176\n",
      "        vf_loss: 26.714397430419922\n",
      "    load_time_ms: 1.45\n",
      "    num_steps_sampled: 616200\n",
      "    num_steps_trained: 592500\n",
      "    sample_time_ms: 3646.832\n",
      "    update_time_ms: 4.017\n",
      "  iterations_since_restore: 237\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 66.43333333333334\n",
      "    ram_util_percent: 65.13333333333334\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.205688587490871\n",
      "    mean_inference_ms: 0.9919990352304072\n",
      "    mean_processing_ms: 0.6999637187234308\n",
      "  time_since_restore: 886.3357656002045\n",
      "  time_this_iter_s: 3.9039852619171143\n",
      "  time_total_s: 886.3357656002045\n",
      "  timestamp: 1596122308\n",
      "  timesteps_since_restore: 616200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 616200\n",
      "  training_iteration: 237\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 886 s, 237 iter, 616200 ts, 448 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-18-35\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 448.24232843454854\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 245\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 26.967\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.440307378768921\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.4233797780179884e-07\n",
      "        policy_loss: -0.0019460605690255761\n",
      "        total_loss: 55.54745101928711\n",
      "        vf_explained_var: 0.0669550895690918\n",
      "        vf_loss: 55.549400329589844\n",
      "    load_time_ms: 1.313\n",
      "    num_steps_sampled: 621400\n",
      "    num_steps_trained: 597500\n",
      "    sample_time_ms: 3689.421\n",
      "    update_time_ms: 4.221\n",
      "  iterations_since_restore: 239\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 66.78\n",
      "    ram_util_percent: 65.17999999999999\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.205688587490871\n",
      "    mean_inference_ms: 0.991999035230407\n",
      "    mean_processing_ms: 0.6999637187234304\n",
      "  time_since_restore: 893.7110140323639\n",
      "  time_this_iter_s: 3.515191078186035\n",
      "  time_total_s: 893.7110140323639\n",
      "  timestamp: 1596122315\n",
      "  timesteps_since_restore: 621400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 621400\n",
      "  training_iteration: 239\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 893 s, 239 iter, 621400 ts, 448 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-18-42\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 448.5912408157715\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 249\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 25.405\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4352055788040161\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 7.323145609916537e-07\n",
      "        policy_loss: -0.00756416330114007\n",
      "        total_loss: 20.329395294189453\n",
      "        vf_explained_var: 0.10851508378982544\n",
      "        vf_loss: 20.336952209472656\n",
      "    load_time_ms: 1.255\n",
      "    num_steps_sampled: 626600\n",
      "    num_steps_trained: 602500\n",
      "    sample_time_ms: 3666.707\n",
      "    update_time_ms: 4.069\n",
      "  iterations_since_restore: 241\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.0\n",
      "    ram_util_percent: 65.28\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.2154729358038905\n",
      "    mean_inference_ms: 0.9948426178604391\n",
      "    mean_processing_ms: 0.7007751797079615\n",
      "  time_since_restore: 900.7770457267761\n",
      "  time_this_iter_s: 4.025390148162842\n",
      "  time_total_s: 900.7770457267761\n",
      "  timestamp: 1596122322\n",
      "  timesteps_since_restore: 626600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 626600\n",
      "  training_iteration: 241\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 900 s, 241 iter, 626600 ts, 449 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-18-48\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 446.72056736355245\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 250\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 25.51\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4352449178695679\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.247762722618063e-06\n",
      "        policy_loss: 0.0009319057571701705\n",
      "        total_loss: 38.0618782043457\n",
      "        vf_explained_var: 0.11474984884262085\n",
      "        vf_loss: 38.060943603515625\n",
      "    load_time_ms: 1.263\n",
      "    num_steps_sampled: 631800\n",
      "    num_steps_trained: 607500\n",
      "    sample_time_ms: 3511.701\n",
      "    update_time_ms: 4.062\n",
      "  iterations_since_restore: 243\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.9\n",
      "    ram_util_percent: 65.38\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.218131305198047\n",
      "    mean_inference_ms: 0.995680670667727\n",
      "    mean_processing_ms: 0.7010307125821827\n",
      "  time_since_restore: 906.50883436203\n",
      "  time_this_iter_s: 3.0526580810546875\n",
      "  time_total_s: 906.50883436203\n",
      "  timestamp: 1596122328\n",
      "  timesteps_since_restore: 631800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 631800\n",
      "  training_iteration: 243\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 906 s, 243 iter, 631800 ts, 447 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-18-55\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1006.7023529932075\n",
      "  episode_reward_mean: 446.66333123377\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 252\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 23.924\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4314594268798828\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.365756017752574e-06\n",
      "        policy_loss: -0.000920503051020205\n",
      "        total_loss: 32.222869873046875\n",
      "        vf_explained_var: 0.07495981454849243\n",
      "        vf_loss: 32.223785400390625\n",
      "    load_time_ms: 1.162\n",
      "    num_steps_sampled: 637000\n",
      "    num_steps_trained: 612500\n",
      "    sample_time_ms: 3468.575\n",
      "    update_time_ms: 3.876\n",
      "  iterations_since_restore: 245\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.375\n",
      "    ram_util_percent: 65.375\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.222764340575443\n",
      "    mean_inference_ms: 0.9969870444393689\n",
      "    mean_processing_ms: 0.7013818429942948\n",
      "  time_since_restore: 913.4955925941467\n",
      "  time_this_iter_s: 2.81660532951355\n",
      "  time_total_s: 913.4955925941467\n",
      "  timestamp: 1596122335\n",
      "  timesteps_since_restore: 637000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 637000\n",
      "  training_iteration: 245\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 913 s, 245 iter, 637000 ts, 447 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-19-01\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 440.8373064491555\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 255\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.579\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4321584701538086\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.947351269242063e-07\n",
      "        policy_loss: -0.005593237467110157\n",
      "        total_loss: 29.900928497314453\n",
      "        vf_explained_var: 0.08625388145446777\n",
      "        vf_loss: 29.906518936157227\n",
      "    load_time_ms: 1.059\n",
      "    num_steps_sampled: 642200\n",
      "    num_steps_trained: 617500\n",
      "    sample_time_ms: 3279.833\n",
      "    update_time_ms: 3.518\n",
      "  iterations_since_restore: 247\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 51.125\n",
      "    ram_util_percent: 65.25\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.229580932361531\n",
      "    mean_inference_ms: 0.9990754500925805\n",
      "    mean_processing_ms: 0.7019935749648043\n",
      "  time_since_restore: 919.4413042068481\n",
      "  time_this_iter_s: 2.865326166152954\n",
      "  time_total_s: 919.4413042068481\n",
      "  timestamp: 1596122341\n",
      "  timesteps_since_restore: 642200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 642200\n",
      "  training_iteration: 247\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 919 s, 247 iter, 642200 ts, 441 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-19-07\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 441.31465430932144\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 257\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.281\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4323369264602661\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.38699532373721e-07\n",
      "        policy_loss: 0.0033702885266393423\n",
      "        total_loss: 39.72025680541992\n",
      "        vf_explained_var: 0.09475290775299072\n",
      "        vf_loss: 39.71687698364258\n",
      "    load_time_ms: 1.049\n",
      "    num_steps_sampled: 647400\n",
      "    num_steps_trained: 622500\n",
      "    sample_time_ms: 3118.134\n",
      "    update_time_ms: 3.175\n",
      "  iterations_since_restore: 249\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.599999999999994\n",
      "    ram_util_percent: 65.05\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.233036182846197\n",
      "    mean_inference_ms: 1.0001125729758402\n",
      "    mean_processing_ms: 0.7022787593898966\n",
      "  time_since_restore: 925.1927013397217\n",
      "  time_this_iter_s: 3.0153355598449707\n",
      "  time_total_s: 925.1927013397217\n",
      "  timestamp: 1596122347\n",
      "  timesteps_since_restore: 647400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 647400\n",
      "  training_iteration: 249\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 925 s, 249 iter, 647400 ts, 441 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-19-12\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 442.1147590487932\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 258\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.217\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.437475562095642\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.847718232918851e-07\n",
      "        policy_loss: 0.002506369026377797\n",
      "        total_loss: 50.35266876220703\n",
      "        vf_explained_var: 0.08364588022232056\n",
      "        vf_loss: 50.35016632080078\n",
      "    load_time_ms: 1.047\n",
      "    num_steps_sampled: 652600\n",
      "    num_steps_trained: 627500\n",
      "    sample_time_ms: 2987.068\n",
      "    update_time_ms: 3.231\n",
      "  iterations_since_restore: 251\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.625\n",
      "    ram_util_percent: 65.0\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.23482510297531\n",
      "    mean_inference_ms: 1.0007092233556063\n",
      "    mean_processing_ms: 0.7024661342200735\n",
      "  time_since_restore: 930.9473083019257\n",
      "  time_this_iter_s: 2.9203689098358154\n",
      "  time_total_s: 930.9473083019257\n",
      "  timestamp: 1596122352\n",
      "  timesteps_since_restore: 652600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 652600\n",
      "  training_iteration: 251\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 930 s, 251 iter, 652600 ts, 442 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-19-19\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 443.6450554947971\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 262\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.9\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.434161901473999\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.4720678791491082e-06\n",
      "        policy_loss: 0.011018725112080574\n",
      "        total_loss: 39.8316764831543\n",
      "        vf_explained_var: 0.10204583406448364\n",
      "        vf_loss: 39.82066345214844\n",
      "    load_time_ms: 1.019\n",
      "    num_steps_sampled: 657800\n",
      "    num_steps_trained: 632500\n",
      "    sample_time_ms: 3089.451\n",
      "    update_time_ms: 3.172\n",
      "  iterations_since_restore: 253\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.760000000000005\n",
      "    ram_util_percent: 65.0\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.241014167584564\n",
      "    mean_inference_ms: 1.0026708894583627\n",
      "    mean_processing_ms: 0.7030622633366282\n",
      "  time_since_restore: 937.6837821006775\n",
      "  time_this_iter_s: 3.8414292335510254\n",
      "  time_total_s: 937.6837821006775\n",
      "  timestamp: 1596122359\n",
      "  timesteps_since_restore: 657800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 657800\n",
      "  training_iteration: 253\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 937 s, 253 iter, 657800 ts, 444 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-19-24\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 443.6450554947971\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 262\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.909\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.431943655014038\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 7.284641014848603e-07\n",
      "        policy_loss: -0.006236220244318247\n",
      "        total_loss: 29.699405670166016\n",
      "        vf_explained_var: 0.10915189981460571\n",
      "        vf_loss: 29.705644607543945\n",
      "    load_time_ms: 1.038\n",
      "    num_steps_sampled: 663000\n",
      "    num_steps_trained: 637500\n",
      "    sample_time_ms: 2913.482\n",
      "    update_time_ms: 3.115\n",
      "  iterations_since_restore: 255\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.2\n",
      "    ram_util_percent: 65.0\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.241014167584563\n",
      "    mean_inference_ms: 1.0026708894583627\n",
      "    mean_processing_ms: 0.7030622633366284\n",
      "  time_since_restore: 942.9095978736877\n",
      "  time_this_iter_s: 2.809018135070801\n",
      "  time_total_s: 942.9095978736877\n",
      "  timestamp: 1596122364\n",
      "  timesteps_since_restore: 663000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 663000\n",
      "  training_iteration: 255\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 942 s, 255 iter, 663000 ts, 444 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-19-31\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 443.9631210035145\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 265\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.036\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4326270818710327\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.091687959677074e-07\n",
      "        policy_loss: -0.001353614847175777\n",
      "        total_loss: 22.1771240234375\n",
      "        vf_explained_var: 0.14619451761245728\n",
      "        vf_loss: 22.178476333618164\n",
      "    load_time_ms: 1.045\n",
      "    num_steps_sampled: 668200\n",
      "    num_steps_trained: 642500\n",
      "    sample_time_ms: 2977.572\n",
      "    update_time_ms: 3.124\n",
      "  iterations_since_restore: 257\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.375\n",
      "    ram_util_percent: 65.0\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.245338970683755\n",
      "    mean_inference_ms: 1.0040553382235426\n",
      "    mean_processing_ms: 0.7034933541412246\n",
      "  time_since_restore: 949.4980771541595\n",
      "  time_this_iter_s: 2.7339682579040527\n",
      "  time_total_s: 949.4980771541595\n",
      "  timestamp: 1596122371\n",
      "  timesteps_since_restore: 668200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 668200\n",
      "  training_iteration: 257\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 949 s, 257 iter, 668200 ts, 444 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-19-37\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 446.07714150154214\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 267\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.716\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4271776676177979\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 7.934570334100499e-08\n",
      "        policy_loss: -0.002215499524027109\n",
      "        total_loss: 7.638368129730225\n",
      "        vf_explained_var: 0.06959474086761475\n",
      "        vf_loss: 7.640583038330078\n",
      "    load_time_ms: 1.039\n",
      "    num_steps_sampled: 673400\n",
      "    num_steps_trained: 647500\n",
      "    sample_time_ms: 2980.253\n",
      "    update_time_ms: 3.115\n",
      "  iterations_since_restore: 259\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.425000000000004\n",
      "    ram_util_percent: 65.125\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.247415957739366\n",
      "    mean_inference_ms: 1.0047893217095207\n",
      "    mean_processing_ms: 0.7037445446660442\n",
      "  time_since_restore: 955.2721524238586\n",
      "  time_this_iter_s: 2.776453733444214\n",
      "  time_total_s: 955.2721524238586\n",
      "  timestamp: 1596122377\n",
      "  timesteps_since_restore: 673400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 673400\n",
      "  training_iteration: 259\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 955 s, 259 iter, 673400 ts, 446 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-19-44\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 440.6532893495581\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 270\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.916\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4342257976531982\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.9041300447497633e-07\n",
      "        policy_loss: 0.0015784864081069827\n",
      "        total_loss: 22.300729751586914\n",
      "        vf_explained_var: 0.11023557186126709\n",
      "        vf_loss: 22.299148559570312\n",
      "    load_time_ms: 1.042\n",
      "    num_steps_sampled: 678600\n",
      "    num_steps_trained: 652500\n",
      "    sample_time_ms: 3124.893\n",
      "    update_time_ms: 3.162\n",
      "  iterations_since_restore: 261\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 52.0\n",
      "    ram_util_percent: 65.14999999999999\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.251156246654213\n",
      "    mean_inference_ms: 1.0060937460550792\n",
      "    mean_processing_ms: 0.7041408761058979\n",
      "  time_since_restore: 962.4765651226044\n",
      "  time_this_iter_s: 4.096670150756836\n",
      "  time_total_s: 962.4765651226044\n",
      "  timestamp: 1596122384\n",
      "  timesteps_since_restore: 678600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 678600\n",
      "  training_iteration: 261\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 962 s, 261 iter, 678600 ts, 441 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-19-51\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 436.9879948028311\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 272\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.703\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.434037685394287\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.363630404848664e-07\n",
      "        policy_loss: 0.002632789546623826\n",
      "        total_loss: 46.81947326660156\n",
      "        vf_explained_var: 0.0936589241027832\n",
      "        vf_loss: 46.816837310791016\n",
      "    load_time_ms: 1.111\n",
      "    num_steps_sampled: 683800\n",
      "    num_steps_trained: 657500\n",
      "    sample_time_ms: 3154.481\n",
      "    update_time_ms: 3.43\n",
      "  iterations_since_restore: 263\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.73333333333333\n",
      "    ram_util_percent: 65.10000000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.253203516998963\n",
      "    mean_inference_ms: 1.0067070299873309\n",
      "    mean_processing_ms: 0.7043108372939746\n",
      "  time_since_restore: 969.5367929935455\n",
      "  time_this_iter_s: 3.786710500717163\n",
      "  time_total_s: 969.5367929935455\n",
      "  timestamp: 1596122391\n",
      "  timesteps_since_restore: 683800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 683800\n",
      "  training_iteration: 263\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 969 s, 263 iter, 683800 ts, 437 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-20-00\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 436.03209183750437\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 273\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 21.932\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4328689575195312\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.9263735541462665e-06\n",
      "        policy_loss: -0.0003630738356150687\n",
      "        total_loss: 43.03842544555664\n",
      "        vf_explained_var: 0.08594357967376709\n",
      "        vf_loss: 43.03878402709961\n",
      "    load_time_ms: 1.191\n",
      "    num_steps_sampled: 689000\n",
      "    num_steps_trained: 662500\n",
      "    sample_time_ms: 3522.447\n",
      "    update_time_ms: 3.741\n",
      "  iterations_since_restore: 265\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.357142857142854\n",
      "    ram_util_percent: 65.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.254595302021638\n",
      "    mean_inference_ms: 1.0072790183088203\n",
      "    mean_processing_ms: 0.7044852031179051\n",
      "  time_since_restore: 978.4721105098724\n",
      "  time_this_iter_s: 4.891399621963501\n",
      "  time_total_s: 978.4721105098724\n",
      "  timestamp: 1596122400\n",
      "  timesteps_since_restore: 689000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 689000\n",
      "  training_iteration: 265\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 978 s, 265 iter, 689000 ts, 436 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-20-07\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 440.73363976955267\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 275\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 23.898\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4287890195846558\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.042314796810388e-07\n",
      "        policy_loss: 0.0033692698925733566\n",
      "        total_loss: 17.211088180541992\n",
      "        vf_explained_var: 0.10517513751983643\n",
      "        vf_loss: 17.207717895507812\n",
      "    load_time_ms: 1.244\n",
      "    num_steps_sampled: 694200\n",
      "    num_steps_trained: 667500\n",
      "    sample_time_ms: 3601.672\n",
      "    update_time_ms: 4.29\n",
      "  iterations_since_restore: 267\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 65.28\n",
      "    ram_util_percent: 65.08\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.2571628379391315\n",
      "    mean_inference_ms: 1.0081471953827073\n",
      "    mean_processing_ms: 0.7047556919579214\n",
      "  time_since_restore: 985.884194612503\n",
      "  time_this_iter_s: 3.6178009510040283\n",
      "  time_total_s: 985.884194612503\n",
      "  timestamp: 1596122407\n",
      "  timesteps_since_restore: 694200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 694200\n",
      "  training_iteration: 267\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 985 s, 267 iter, 694200 ts, 441 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-20-15\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 439.85642930054894\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 277\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 25.263\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4302641153335571\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 9.344577733827464e-07\n",
      "        policy_loss: 0.0035372532438486814\n",
      "        total_loss: 57.81832504272461\n",
      "        vf_explained_var: 0.04743242263793945\n",
      "        vf_loss: 57.814788818359375\n",
      "    load_time_ms: 1.305\n",
      "    num_steps_sampled: 699400\n",
      "    num_steps_trained: 672500\n",
      "    sample_time_ms: 3788.837\n",
      "    update_time_ms: 4.696\n",
      "  iterations_since_restore: 269\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 65.36\n",
      "    ram_util_percent: 65.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.259313737924631\n",
      "    mean_inference_ms: 1.0088018115570172\n",
      "    mean_processing_ms: 0.7049528057457647\n",
      "  time_since_restore: 993.5546898841858\n",
      "  time_this_iter_s: 3.6579389572143555\n",
      "  time_total_s: 993.5546898841858\n",
      "  timestamp: 1596122415\n",
      "  timesteps_since_restore: 699400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 699400\n",
      "  training_iteration: 269\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 993 s, 269 iter, 699400 ts, 440 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-20-22\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 438.8835936868134\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 278\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 25.648\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4339382648468018\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.698159278224921e-06\n",
      "        policy_loss: -0.007844336330890656\n",
      "        total_loss: 83.42747497558594\n",
      "        vf_explained_var: 0.06518673896789551\n",
      "        vf_loss: 83.435302734375\n",
      "    load_time_ms: 1.328\n",
      "    num_steps_sampled: 704600\n",
      "    num_steps_trained: 677500\n",
      "    sample_time_ms: 3750.671\n",
      "    update_time_ms: 4.819\n",
      "  iterations_since_restore: 271\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.46000000000001\n",
      "    ram_util_percent: 65.16000000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.2607268570326955\n",
      "    mean_inference_ms: 1.0093942959169444\n",
      "    mean_processing_ms: 0.7051257051445322\n",
      "  time_since_restore: 1000.3828806877136\n",
      "  time_this_iter_s: 3.2547638416290283\n",
      "  time_total_s: 1000.3828806877136\n",
      "  timestamp: 1596122422\n",
      "  timesteps_since_restore: 704600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 704600\n",
      "  training_iteration: 271\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1000 s, 271 iter, 704600 ts, 439 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-20-29\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 445.26044326410624\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 282\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 23.983\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.426027774810791\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.81095502430162e-08\n",
      "        policy_loss: -0.0013801452005282044\n",
      "        total_loss: 23.10186767578125\n",
      "        vf_explained_var: 0.13496798276901245\n",
      "        vf_loss: 23.10325050354004\n",
      "    load_time_ms: 1.264\n",
      "    num_steps_sampled: 709800\n",
      "    num_steps_trained: 682500\n",
      "    sample_time_ms: 3733.992\n",
      "    update_time_ms: 4.626\n",
      "  iterations_since_restore: 273\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.025000000000006\n",
      "    ram_util_percent: 65.125\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.265743122368509\n",
      "    mean_inference_ms: 1.0111283123449568\n",
      "    mean_processing_ms: 0.7056579315766629\n",
      "  time_since_restore: 1007.2503395080566\n",
      "  time_this_iter_s: 2.8022284507751465\n",
      "  time_total_s: 1007.2503395080566\n",
      "  timestamp: 1596122429\n",
      "  timesteps_since_restore: 709800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 709800\n",
      "  training_iteration: 273\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1007 s, 273 iter, 709800 ts, 445 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-20-35\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 447.0417405379155\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 283\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 22.587\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4256709814071655\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.280515544356604e-07\n",
      "        policy_loss: -0.001514254603534937\n",
      "        total_loss: 13.226146697998047\n",
      "        vf_explained_var: 0.13434362411499023\n",
      "        vf_loss: 13.227659225463867\n",
      "    load_time_ms: 1.178\n",
      "    num_steps_sampled: 715000\n",
      "    num_steps_trained: 687500\n",
      "    sample_time_ms: 3447.289\n",
      "    update_time_ms: 4.393\n",
      "  iterations_since_restore: 275\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.625\n",
      "    ram_util_percent: 65.175\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.266964455878096\n",
      "    mean_inference_ms: 1.0115597886113132\n",
      "    mean_processing_ms: 0.7057769722462415\n",
      "  time_since_restore: 1013.2999942302704\n",
      "  time_this_iter_s: 2.9689178466796875\n",
      "  time_total_s: 1013.2999942302704\n",
      "  timestamp: 1596122435\n",
      "  timesteps_since_restore: 715000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 715000\n",
      "  training_iteration: 275\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1013 s, 275 iter, 715000 ts, 447 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-20-42\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 444.2331397366043\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 287\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.315\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.42668879032135\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.797008508219733e-06\n",
      "        policy_loss: -0.000884232809767127\n",
      "        total_loss: 22.646440505981445\n",
      "        vf_explained_var: 0.12747269868850708\n",
      "        vf_loss: 22.647327423095703\n",
      "    load_time_ms: 1.085\n",
      "    num_steps_sampled: 720200\n",
      "    num_steps_trained: 692500\n",
      "    sample_time_ms: 3449.044\n",
      "    update_time_ms: 3.904\n",
      "  iterations_since_restore: 277\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.21666666666667\n",
      "    ram_util_percent: 65.3\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.271670043181187\n",
      "    mean_inference_ms: 1.0132199082957414\n",
      "    mean_processing_ms: 0.706306557283641\n",
      "  time_since_restore: 1020.6961660385132\n",
      "  time_this_iter_s: 4.160804510116577\n",
      "  time_total_s: 1020.6961660385132\n",
      "  timestamp: 1596122442\n",
      "  timesteps_since_restore: 720200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 720200\n",
      "  training_iteration: 277\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1020 s, 277 iter, 720200 ts, 444 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-20-49\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 442.589158819814\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 288\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.473\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4255633354187012\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.0824203400261467e-07\n",
      "        policy_loss: -2.033481541729998e-05\n",
      "        total_loss: 26.561656951904297\n",
      "        vf_explained_var: 0.07548320293426514\n",
      "        vf_loss: 26.561681747436523\n",
      "    load_time_ms: 1.033\n",
      "    num_steps_sampled: 725400\n",
      "    num_steps_trained: 697500\n",
      "    sample_time_ms: 3332.061\n",
      "    update_time_ms: 3.867\n",
      "  iterations_since_restore: 279\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.2\n",
      "    ram_util_percent: 65.3\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.272741311611271\n",
      "    mean_inference_ms: 1.0136159260732456\n",
      "    mean_processing_ms: 0.7064126734895811\n",
      "  time_since_restore: 1027.180031299591\n",
      "  time_this_iter_s: 3.273061513900757\n",
      "  time_total_s: 1027.180031299591\n",
      "  timestamp: 1596122449\n",
      "  timesteps_since_restore: 725400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 725400\n",
      "  training_iteration: 279\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1027 s, 279 iter, 725400 ts, 443 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-20-56\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 444.1605500690208\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 290\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.081\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4294127225875854\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.5914439543962544e-08\n",
      "        policy_loss: 0.001801436417736113\n",
      "        total_loss: 40.239498138427734\n",
      "        vf_explained_var: 0.054727017879486084\n",
      "        vf_loss: 40.23768997192383\n",
      "    load_time_ms: 1.016\n",
      "    num_steps_sampled: 730600\n",
      "    num_steps_trained: 702500\n",
      "    sample_time_ms: 3368.49\n",
      "    update_time_ms: 3.682\n",
      "  iterations_since_restore: 281\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.03333333333334\n",
      "    ram_util_percent: 65.0\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.274534752694798\n",
      "    mean_inference_ms: 1.0143498326635203\n",
      "    mean_processing_ms: 0.7066289315620683\n",
      "  time_since_restore: 1034.3679122924805\n",
      "  time_this_iter_s: 4.356724739074707\n",
      "  time_total_s: 1034.3679122924805\n",
      "  timestamp: 1596122456\n",
      "  timesteps_since_restore: 730600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 730600\n",
      "  training_iteration: 281\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1034 s, 281 iter, 730600 ts, 444 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-21-02\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 445.8081756130255\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 292\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.297\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4254230260849\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.575682683276682e-07\n",
      "        policy_loss: 0.003739939769729972\n",
      "        total_loss: 29.60196304321289\n",
      "        vf_explained_var: 0.09383440017700195\n",
      "        vf_loss: 29.598215103149414\n",
      "    load_time_ms: 1.016\n",
      "    num_steps_sampled: 735800\n",
      "    num_steps_trained: 707500\n",
      "    sample_time_ms: 3249.635\n",
      "    update_time_ms: 3.576\n",
      "  iterations_since_restore: 283\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.574999999999996\n",
      "    ram_util_percent: 64.95\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.276681574905794\n",
      "    mean_inference_ms: 1.0151201898089077\n",
      "    mean_processing_ms: 0.7068660441889508\n",
      "  time_since_restore: 1040.0486915111542\n",
      "  time_this_iter_s: 2.896939754486084\n",
      "  time_total_s: 1040.0486915111542\n",
      "  timestamp: 1596122462\n",
      "  timesteps_since_restore: 735800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 735800\n",
      "  training_iteration: 283\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1040 s, 283 iter, 735800 ts, 446 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-21-09\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 445.75286322784393\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 294\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.976\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4282559156417847\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.12020514267897e-08\n",
      "        policy_loss: -0.0027464861050248146\n",
      "        total_loss: 38.886627197265625\n",
      "        vf_explained_var: 0.06879359483718872\n",
      "        vf_loss: 38.889373779296875\n",
      "    load_time_ms: 1.101\n",
      "    num_steps_sampled: 741000\n",
      "    num_steps_trained: 712500\n",
      "    sample_time_ms: 3358.513\n",
      "    update_time_ms: 3.705\n",
      "  iterations_since_restore: 285\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.98333333333334\n",
      "    ram_util_percent: 64.89999999999999\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.27829798628118\n",
      "    mean_inference_ms: 1.0158014797277466\n",
      "    mean_processing_ms: 0.7070603156703872\n",
      "  time_since_restore: 1047.1854639053345\n",
      "  time_this_iter_s: 3.912097454071045\n",
      "  time_total_s: 1047.1854639053345\n",
      "  timestamp: 1596122469\n",
      "  timesteps_since_restore: 741000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 741000\n",
      "  training_iteration: 285\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1047 s, 285 iter, 741000 ts, 446 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-21-15\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 445.6867131871451\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 296\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.472\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4283058643341064\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.224015188152407e-07\n",
      "        policy_loss: 0.003842500038444996\n",
      "        total_loss: 37.928226470947266\n",
      "        vf_explained_var: 0.0892571210861206\n",
      "        vf_loss: 37.924381256103516\n",
      "    load_time_ms: 1.152\n",
      "    num_steps_sampled: 746200\n",
      "    num_steps_trained: 717500\n",
      "    sample_time_ms: 3202.539\n",
      "    update_time_ms: 3.619\n",
      "  iterations_since_restore: 287\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.025\n",
      "    ram_util_percent: 64.9\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.280057935600038\n",
      "    mean_inference_ms: 1.0164967528567725\n",
      "    mean_processing_ms: 0.7072843709164066\n",
      "  time_since_restore: 1053.0264501571655\n",
      "  time_this_iter_s: 3.05163311958313\n",
      "  time_total_s: 1053.0264501571655\n",
      "  timestamp: 1596122475\n",
      "  timesteps_since_restore: 746200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 746200\n",
      "  training_iteration: 287\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1053 s, 287 iter, 746200 ts, 446 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-21-20\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 448.56184249741904\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 298\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.502\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4278026819229126\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.8237828669498413e-07\n",
      "        policy_loss: -0.0062295859679579735\n",
      "        total_loss: 36.15300750732422\n",
      "        vf_explained_var: 0.09638220071792603\n",
      "        vf_loss: 36.159236907958984\n",
      "    load_time_ms: 1.162\n",
      "    num_steps_sampled: 751400\n",
      "    num_steps_trained: 722500\n",
      "    sample_time_ms: 3136.039\n",
      "    update_time_ms: 3.332\n",
      "  iterations_since_restore: 289\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.45\n",
      "    ram_util_percent: 64.9\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.281609171346528\n",
      "    mean_inference_ms: 1.0171289505362298\n",
      "    mean_processing_ms: 0.7074736727168682\n",
      "  time_since_restore: 1058.8433425426483\n",
      "  time_this_iter_s: 2.8934576511383057\n",
      "  time_total_s: 1058.8433425426483\n",
      "  timestamp: 1596122480\n",
      "  timesteps_since_restore: 751400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 751400\n",
      "  training_iteration: 289\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1058 s, 289 iter, 751400 ts, 449 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-21-28\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 451.2705312006814\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 300\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.818\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4260743856430054\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.7591665597888095e-09\n",
      "        policy_loss: 0.0038705940824002028\n",
      "        total_loss: 25.182580947875977\n",
      "        vf_explained_var: 0.11783349514007568\n",
      "        vf_loss: 25.178714752197266\n",
      "    load_time_ms: 1.199\n",
      "    num_steps_sampled: 756600\n",
      "    num_steps_trained: 727500\n",
      "    sample_time_ms: 3127.149\n",
      "    update_time_ms: 3.296\n",
      "  iterations_since_restore: 291\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.775\n",
      "    ram_util_percent: 64.975\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.282789794597697\n",
      "    mean_inference_ms: 1.017697687247578\n",
      "    mean_processing_ms: 0.7076646417431993\n",
      "  time_since_restore: 1065.94389295578\n",
      "  time_this_iter_s: 2.887763023376465\n",
      "  time_total_s: 1065.94389295578\n",
      "  timestamp: 1596122488\n",
      "  timesteps_since_restore: 756600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 756600\n",
      "  training_iteration: 291\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1065 s, 291 iter, 756600 ts, 451 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-21-35\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 453.74429895344326\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 302\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 21.857\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.428588628768921\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 9.990692433348158e-07\n",
      "        policy_loss: -0.0005307972896844149\n",
      "        total_loss: 48.019142150878906\n",
      "        vf_explained_var: 0.06423360109329224\n",
      "        vf_loss: 48.01968002319336\n",
      "    load_time_ms: 1.3\n",
      "    num_steps_sampled: 761800\n",
      "    num_steps_trained: 732500\n",
      "    sample_time_ms: 3314.259\n",
      "    update_time_ms: 3.622\n",
      "  iterations_since_restore: 293\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.50000000000001\n",
      "    ram_util_percent: 64.94000000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.2842131709325875\n",
      "    mean_inference_ms: 1.0181763766569576\n",
      "    mean_processing_ms: 0.7078162629567635\n",
      "  time_since_restore: 1073.5306386947632\n",
      "  time_this_iter_s: 3.8399057388305664\n",
      "  time_total_s: 1073.5306386947632\n",
      "  timestamp: 1596122495\n",
      "  timesteps_since_restore: 761800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 761800\n",
      "  training_iteration: 293\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1073 s, 293 iter, 761800 ts, 454 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-21-43\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 452.32966619952253\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 305\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 23.248\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4271200895309448\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.01875797201501e-07\n",
      "        policy_loss: 0.0026979073882102966\n",
      "        total_loss: 49.75016784667969\n",
      "        vf_explained_var: 0.07985162734985352\n",
      "        vf_loss: 49.74747085571289\n",
      "    load_time_ms: 1.263\n",
      "    num_steps_sampled: 767000\n",
      "    num_steps_trained: 737500\n",
      "    sample_time_ms: 3360.952\n",
      "    update_time_ms: 3.736\n",
      "  iterations_since_restore: 295\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.339999999999996\n",
      "    ram_util_percent: 65.0\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.285989472912534\n",
      "    mean_inference_ms: 1.0191506652623064\n",
      "    mean_processing_ms: 0.7081011080721022\n",
      "  time_since_restore: 1081.1545507907867\n",
      "  time_this_iter_s: 3.693208694458008\n",
      "  time_total_s: 1081.1545507907867\n",
      "  timestamp: 1596122503\n",
      "  timesteps_since_restore: 767000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 767000\n",
      "  training_iteration: 295\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1081 s, 295 iter, 767000 ts, 452 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-21-51\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 451.9208004041276\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 307\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 24.622\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4290269613265991\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.173566826968454e-06\n",
      "        policy_loss: 0.007682485971599817\n",
      "        total_loss: 71.91838836669922\n",
      "        vf_explained_var: 0.051405131816864014\n",
      "        vf_loss: 71.91069030761719\n",
      "    load_time_ms: 1.274\n",
      "    num_steps_sampled: 772200\n",
      "    num_steps_trained: 742500\n",
      "    sample_time_ms: 3603.27\n",
      "    update_time_ms: 4.233\n",
      "  iterations_since_restore: 297\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.32857142857143\n",
      "    ram_util_percent: 64.95714285714287\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.286922918740173\n",
      "    mean_inference_ms: 1.019552100324262\n",
      "    mean_processing_ms: 0.7082491044165521\n",
      "  time_since_restore: 1089.441586971283\n",
      "  time_this_iter_s: 4.59212851524353\n",
      "  time_total_s: 1089.441586971283\n",
      "  timestamp: 1596122511\n",
      "  timesteps_since_restore: 772200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 772200\n",
      "  training_iteration: 297\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1089 s, 297 iter, 772200 ts, 452 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-22-00\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 456.55017402946845\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 308\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 24.77\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4294986724853516\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.7145853184483713e-06\n",
      "        policy_loss: -0.007051204796880484\n",
      "        total_loss: 91.3125228881836\n",
      "        vf_explained_var: 0.07404255867004395\n",
      "        vf_loss: 91.31956481933594\n",
      "    load_time_ms: 1.327\n",
      "    num_steps_sampled: 777400\n",
      "    num_steps_trained: 747500\n",
      "    sample_time_ms: 3865.907\n",
      "    update_time_ms: 4.331\n",
      "  iterations_since_restore: 299\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.42857142857143\n",
      "    ram_util_percent: 65.08571428571429\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.2871372902966565\n",
      "    mean_inference_ms: 1.019743164966858\n",
      "    mean_processing_ms: 0.7083481318030733\n",
      "  time_since_restore: 1097.8902740478516\n",
      "  time_this_iter_s: 4.85151743888855\n",
      "  time_total_s: 1097.8902740478516\n",
      "  timestamp: 1596122520\n",
      "  timesteps_since_restore: 777400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 777400\n",
      "  training_iteration: 299\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1097 s, 299 iter, 777400 ts, 457 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-22-08\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 462.58711124775306\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 311\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 26.463\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.422452688217163\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.1751652095881582e-07\n",
      "        policy_loss: 0.006804007571190596\n",
      "        total_loss: 24.70220947265625\n",
      "        vf_explained_var: 0.03606462478637695\n",
      "        vf_loss: 24.695405960083008\n",
      "    load_time_ms: 1.403\n",
      "    num_steps_sampled: 782600\n",
      "    num_steps_trained: 752500\n",
      "    sample_time_ms: 3995.332\n",
      "    update_time_ms: 4.472\n",
      "  iterations_since_restore: 301\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.971428571428575\n",
      "    ram_util_percent: 65.07142857142857\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.288271098226359\n",
      "    mean_inference_ms: 1.0205567180572703\n",
      "    mean_processing_ms: 0.7085730659271607\n",
      "  time_since_restore: 1106.3109622001648\n",
      "  time_this_iter_s: 5.0007970333099365\n",
      "  time_total_s: 1106.3109622001648\n",
      "  timestamp: 1596122528\n",
      "  timesteps_since_restore: 782600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 782600\n",
      "  training_iteration: 301\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1106 s, 301 iter, 782600 ts, 463 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-22-15\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 457.4994216745803\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 312\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 25.899\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4247570037841797\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.8313169221073622e-06\n",
      "        policy_loss: -0.0005754355224780738\n",
      "        total_loss: 34.138160705566406\n",
      "        vf_explained_var: 0.09518390893936157\n",
      "        vf_loss: 34.138755798339844\n",
      "    load_time_ms: 1.352\n",
      "    num_steps_sampled: 787800\n",
      "    num_steps_trained: 757500\n",
      "    sample_time_ms: 3973.375\n",
      "    update_time_ms: 4.766\n",
      "  iterations_since_restore: 303\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.58333333333334\n",
      "    ram_util_percent: 65.06666666666666\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.288259533934884\n",
      "    mean_inference_ms: 1.0205616094540477\n",
      "    mean_processing_ms: 0.7085764616298514\n",
      "  time_since_restore: 1113.6709558963776\n",
      "  time_this_iter_s: 3.70491886138916\n",
      "  time_total_s: 1113.6709558963776\n",
      "  timestamp: 1596122535\n",
      "  timesteps_since_restore: 787800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 787800\n",
      "  training_iteration: 303\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1113 s, 303 iter, 787800 ts, 457 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-22-23\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 454.6362203735602\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 315\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 24.705\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4255874156951904\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.4204463140195e-08\n",
      "        policy_loss: 0.0021176470909267664\n",
      "        total_loss: 40.43158721923828\n",
      "        vf_explained_var: 0.10023725032806396\n",
      "        vf_loss: 40.429466247558594\n",
      "    load_time_ms: 1.335\n",
      "    num_steps_sampled: 793000\n",
      "    num_steps_trained: 762500\n",
      "    sample_time_ms: 4003.797\n",
      "    update_time_ms: 4.929\n",
      "  iterations_since_restore: 305\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.324999999999996\n",
      "    ram_util_percent: 65.175\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.288464824725512\n",
      "    mean_inference_ms: 1.0211330457186356\n",
      "    mean_processing_ms: 0.7087419937100233\n",
      "  time_since_restore: 1121.5879561901093\n",
      "  time_this_iter_s: 2.9947257041931152\n",
      "  time_total_s: 1121.5879561901093\n",
      "  timestamp: 1596122543\n",
      "  timesteps_since_restore: 793000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 793000\n",
      "  training_iteration: 305\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1121 s, 305 iter, 793000 ts, 455 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-22-29\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 460.3281323754639\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 317\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 23.689\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.424487590789795\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.1598825722103356e-06\n",
      "        policy_loss: -0.0013403447810560465\n",
      "        total_loss: 51.62173080444336\n",
      "        vf_explained_var: 0.09317612648010254\n",
      "        vf_loss: 51.62306594848633\n",
      "    load_time_ms: 1.323\n",
      "    num_steps_sampled: 798200\n",
      "    num_steps_trained: 767500\n",
      "    sample_time_ms: 3763.673\n",
      "    update_time_ms: 4.544\n",
      "  iterations_since_restore: 307\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.05\n",
      "    ram_util_percent: 65.17500000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.288126052491126\n",
      "    mean_inference_ms: 1.0212294393247392\n",
      "    mean_processing_ms: 0.708789709069027\n",
      "  time_since_restore: 1127.455664396286\n",
      "  time_this_iter_s: 2.871664047241211\n",
      "  time_total_s: 1127.455664396286\n",
      "  timestamp: 1596122549\n",
      "  timesteps_since_restore: 798200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 798200\n",
      "  training_iteration: 307\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1127 s, 307 iter, 798200 ts, 460 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-22-36\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 461.81903864794435\n",
      "  episode_reward_min: 176.89235923777426\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 319\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 22.536\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4247205257415771\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.6718139451986644e-06\n",
      "        policy_loss: -0.010387009009718895\n",
      "        total_loss: 61.787330627441406\n",
      "        vf_explained_var: 0.084522545337677\n",
      "        vf_loss: 61.7977180480957\n",
      "    load_time_ms: 1.242\n",
      "    num_steps_sampled: 803400\n",
      "    num_steps_trained: 772500\n",
      "    sample_time_ms: 3607.209\n",
      "    update_time_ms: 4.321\n",
      "  iterations_since_restore: 309\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.3\n",
      "    ram_util_percent: 65.25\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.287078510795915\n",
      "    mean_inference_ms: 1.0212780138202564\n",
      "    mean_processing_ms: 0.7087988569738993\n",
      "  time_since_restore: 1134.3223388195038\n",
      "  time_this_iter_s: 2.7156872749328613\n",
      "  time_total_s: 1134.3223388195038\n",
      "  timestamp: 1596122556\n",
      "  timesteps_since_restore: 803400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 803400\n",
      "  training_iteration: 309\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1134 s, 309 iter, 803400 ts, 462 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-22-43\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 466.4134353379875\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 322\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.728\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4247125387191772\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 7.916092954474152e-07\n",
      "        policy_loss: -0.001038160058669746\n",
      "        total_loss: 52.26405715942383\n",
      "        vf_explained_var: 0.08557909727096558\n",
      "        vf_loss: 52.265106201171875\n",
      "    load_time_ms: 1.114\n",
      "    num_steps_sampled: 808600\n",
      "    num_steps_trained: 777500\n",
      "    sample_time_ms: 3495.061\n",
      "    update_time_ms: 4.184\n",
      "  iterations_since_restore: 311\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.71666666666666\n",
      "    ram_util_percent: 65.16666666666666\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.286275314995421\n",
      "    mean_inference_ms: 1.021495714026989\n",
      "    mean_processing_ms: 0.7088734406339101\n",
      "  time_since_restore: 1141.5940444469452\n",
      "  time_this_iter_s: 4.151473045349121\n",
      "  time_total_s: 1141.5940444469452\n",
      "  timestamp: 1596122563\n",
      "  timesteps_since_restore: 808600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 808600\n",
      "  training_iteration: 311\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1141 s, 311 iter, 808600 ts, 466 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-22-50\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 467.0280924208571\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 323\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.444\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4251224994659424\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.1327018657757435e-06\n",
      "        policy_loss: -0.010623968206346035\n",
      "        total_loss: 40.82345962524414\n",
      "        vf_explained_var: 0.06516510248184204\n",
      "        vf_loss: 40.834083557128906\n",
      "    load_time_ms: 1.087\n",
      "    num_steps_sampled: 813800\n",
      "    num_steps_trained: 782500\n",
      "    sample_time_ms: 3373.22\n",
      "    update_time_ms: 3.627\n",
      "  iterations_since_restore: 313\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.75000000000001\n",
      "    ram_util_percent: 65.225\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.2852485197780625\n",
      "    mean_inference_ms: 1.0213100498155736\n",
      "    mean_processing_ms: 0.7088396036392488\n",
      "  time_since_restore: 1147.726113319397\n",
      "  time_this_iter_s: 3.225245237350464\n",
      "  time_total_s: 1147.726113319397\n",
      "  timestamp: 1596122570\n",
      "  timesteps_since_restore: 813800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 813800\n",
      "  training_iteration: 313\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1147 s, 313 iter, 813800 ts, 467 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-22-57\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 463.8897250257186\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 325\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 21.816\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4261313676834106\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 9.538173344481038e-07\n",
      "        policy_loss: -0.005155469290912151\n",
      "        total_loss: 51.48374557495117\n",
      "        vf_explained_var: 0.0989764928817749\n",
      "        vf_loss: 51.48888397216797\n",
      "    load_time_ms: 1.123\n",
      "    num_steps_sampled: 819000\n",
      "    num_steps_trained: 787500\n",
      "    sample_time_ms: 3319.551\n",
      "    update_time_ms: 3.346\n",
      "  iterations_since_restore: 315\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 67.68333333333334\n",
      "    ram_util_percent: 65.23333333333333\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.283850356012272\n",
      "    mean_inference_ms: 1.02132622019273\n",
      "    mean_processing_ms: 0.7088139007206721\n",
      "  time_since_restore: 1155.11763048172\n",
      "  time_this_iter_s: 3.865879774093628\n",
      "  time_total_s: 1155.11763048172\n",
      "  timestamp: 1596122577\n",
      "  timesteps_since_restore: 819000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 819000\n",
      "  training_iteration: 315\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1155 s, 315 iter, 819000 ts, 464 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-23-03\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 471.2861951843066\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 327\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 21.403\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4239568710327148\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.218671728674963e-07\n",
      "        policy_loss: 0.00014238452422432601\n",
      "        total_loss: 33.0750617980957\n",
      "        vf_explained_var: 0.06402432918548584\n",
      "        vf_loss: 33.074920654296875\n",
      "    load_time_ms: 1.102\n",
      "    num_steps_sampled: 824200\n",
      "    num_steps_trained: 792500\n",
      "    sample_time_ms: 3354.304\n",
      "    update_time_ms: 3.511\n",
      "  iterations_since_restore: 317\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.175\n",
      "    ram_util_percent: 65.15\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.282479212131892\n",
      "    mean_inference_ms: 1.0211862407554435\n",
      "    mean_processing_ms: 0.7088050522843787\n",
      "  time_since_restore: 1161.3299639225006\n",
      "  time_this_iter_s: 2.7405738830566406\n",
      "  time_total_s: 1161.3299639225006\n",
      "  timestamp: 1596122583\n",
      "  timesteps_since_restore: 824200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 824200\n",
      "  training_iteration: 317\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1161 s, 317 iter, 824200 ts, 471 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-23-10\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 467.92885048826844\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 330\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 21.447\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4271280765533447\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.617264729247836e-06\n",
      "        policy_loss: 0.004933179821819067\n",
      "        total_loss: 63.05693054199219\n",
      "        vf_explained_var: 0.08929526805877686\n",
      "        vf_loss: 63.051998138427734\n",
      "    load_time_ms: 1.108\n",
      "    num_steps_sampled: 829400\n",
      "    num_steps_trained: 797500\n",
      "    sample_time_ms: 3323.751\n",
      "    update_time_ms: 3.546\n",
      "  iterations_since_restore: 319\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.78\n",
      "    ram_util_percent: 65.12\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.280083869758553\n",
      "    mean_inference_ms: 1.0209685752195938\n",
      "    mean_processing_ms: 0.708754182203815\n",
      "  time_since_restore: 1167.8915536403656\n",
      "  time_this_iter_s: 3.7142019271850586\n",
      "  time_total_s: 1167.8915536403656\n",
      "  timestamp: 1596122590\n",
      "  timesteps_since_restore: 829400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 829400\n",
      "  training_iteration: 319\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1167 s, 319 iter, 829400 ts, 468 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-23-16\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 463.47235244806774\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 332\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.778\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4240283966064453\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.916025264061318e-07\n",
      "        policy_loss: -0.003948788624256849\n",
      "        total_loss: 30.04289436340332\n",
      "        vf_explained_var: 0.08753859996795654\n",
      "        vf_loss: 30.046836853027344\n",
      "    load_time_ms: 1.124\n",
      "    num_steps_sampled: 834600\n",
      "    num_steps_trained: 802500\n",
      "    sample_time_ms: 3246.616\n",
      "    update_time_ms: 3.421\n",
      "  iterations_since_restore: 321\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.099999999999994\n",
      "    ram_util_percent: 65.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.278901090371901\n",
      "    mean_inference_ms: 1.0208283300020176\n",
      "    mean_processing_ms: 0.7087401579075767\n",
      "  time_since_restore: 1174.383090019226\n",
      "  time_this_iter_s: 2.8271989822387695\n",
      "  time_total_s: 1174.383090019226\n",
      "  timestamp: 1596122596\n",
      "  timesteps_since_restore: 834600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 834600\n",
      "  training_iteration: 321\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1174 s, 321 iter, 834600 ts, 463 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-23-22\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 464.5383629836932\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 333\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.375\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4248886108398438\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.905104447061603e-07\n",
      "        policy_loss: -0.0013802825706079602\n",
      "        total_loss: 37.84493637084961\n",
      "        vf_explained_var: 0.06888598203659058\n",
      "        vf_loss: 37.8463249206543\n",
      "    load_time_ms: 1.102\n",
      "    num_steps_sampled: 839800\n",
      "    num_steps_trained: 807500\n",
      "    sample_time_ms: 3192.362\n",
      "    update_time_ms: 3.369\n",
      "  iterations_since_restore: 323\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.14999999999999\n",
      "    ram_util_percent: 65.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.277646989911682\n",
      "    mean_inference_ms: 1.020555972588766\n",
      "    mean_processing_ms: 0.7086814207046315\n",
      "  time_since_restore: 1179.9520478248596\n",
      "  time_this_iter_s: 2.918989419937134\n",
      "  time_total_s: 1179.9520478248596\n",
      "  timestamp: 1596122602\n",
      "  timesteps_since_restore: 839800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 839800\n",
      "  training_iteration: 323\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1179 s, 323 iter, 839800 ts, 465 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-23-28\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 463.87192595160116\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 336\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.492\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4238860607147217\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 9.415865065420803e-07\n",
      "        policy_loss: 0.0016616977518424392\n",
      "        total_loss: 36.39514923095703\n",
      "        vf_explained_var: 0.09791481494903564\n",
      "        vf_loss: 36.39347839355469\n",
      "    load_time_ms: 1.028\n",
      "    num_steps_sampled: 845000\n",
      "    num_steps_trained: 812500\n",
      "    sample_time_ms: 3081.137\n",
      "    update_time_ms: 3.141\n",
      "  iterations_since_restore: 325\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.349999999999994\n",
      "    ram_util_percent: 65.325\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.274722839521419\n",
      "    mean_inference_ms: 1.0201935690611845\n",
      "    mean_processing_ms: 0.7085787278188352\n",
      "  time_since_restore: 1186.203866481781\n",
      "  time_this_iter_s: 2.9944729804992676\n",
      "  time_total_s: 1186.203866481781\n",
      "  timestamp: 1596122608\n",
      "  timesteps_since_restore: 845000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 845000\n",
      "  training_iteration: 325\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1186 s, 325 iter, 845000 ts, 464 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-23-35\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 469.6722383007896\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 338\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.921\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4237544536590576\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.523464600784791e-09\n",
      "        policy_loss: -0.0003581228374969214\n",
      "        total_loss: 22.943065643310547\n",
      "        vf_explained_var: 0.09436160326004028\n",
      "        vf_loss: 22.943424224853516\n",
      "    load_time_ms: 1.033\n",
      "    num_steps_sampled: 850200\n",
      "    num_steps_trained: 817500\n",
      "    sample_time_ms: 3161.837\n",
      "    update_time_ms: 2.971\n",
      "  iterations_since_restore: 327\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.28333333333334\n",
      "    ram_util_percent: 65.3\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.272858962058825\n",
      "    mean_inference_ms: 1.0198210883056456\n",
      "    mean_processing_ms: 0.7085038852241681\n",
      "  time_since_restore: 1193.226854801178\n",
      "  time_this_iter_s: 4.11354923248291\n",
      "  time_total_s: 1193.226854801178\n",
      "  timestamp: 1596122615\n",
      "  timesteps_since_restore: 850200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 850200\n",
      "  training_iteration: 327\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1193 s, 327 iter, 850200 ts, 470 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-23-41\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 941.9759148877148\n",
      "  episode_reward_mean: 469.4476885786836\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 340\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.004\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.426660180091858\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.0956993296294968e-07\n",
      "        policy_loss: 0.0039072344079613686\n",
      "        total_loss: 56.358192443847656\n",
      "        vf_explained_var: 0.058300137519836426\n",
      "        vf_loss: 56.35427474975586\n",
      "    load_time_ms: 1.054\n",
      "    num_steps_sampled: 855400\n",
      "    num_steps_trained: 822500\n",
      "    sample_time_ms: 3107.466\n",
      "    update_time_ms: 2.996\n",
      "  iterations_since_restore: 329\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.480000000000004\n",
      "    ram_util_percent: 65.24\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.2707058005204015\n",
      "    mean_inference_ms: 1.0195757251479884\n",
      "    mean_processing_ms: 0.7084059101601844\n",
      "  time_since_restore: 1199.2630591392517\n",
      "  time_this_iter_s: 3.352592945098877\n",
      "  time_total_s: 1199.2630591392517\n",
      "  timestamp: 1596122621\n",
      "  timesteps_since_restore: 855400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 855400\n",
      "  training_iteration: 329\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1199 s, 329 iter, 855400 ts, 469 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-23-47\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 938.1085166386691\n",
      "  episode_reward_mean: 464.0617453512867\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 342\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.017\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4264637231826782\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.4944911299608066e-06\n",
      "        policy_loss: -8.37731859064661e-05\n",
      "        total_loss: 55.8150634765625\n",
      "        vf_explained_var: 0.07394343614578247\n",
      "        vf_loss: 55.81513595581055\n",
      "    load_time_ms: 1.087\n",
      "    num_steps_sampled: 860600\n",
      "    num_steps_trained: 827500\n",
      "    sample_time_ms: 3080.436\n",
      "    update_time_ms: 3.456\n",
      "  iterations_since_restore: 331\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.25\n",
      "    ram_util_percent: 65.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.2690587616054065\n",
      "    mean_inference_ms: 1.0192853654042526\n",
      "    mean_processing_ms: 0.7083535918445172\n",
      "  time_since_restore: 1205.5019023418427\n",
      "  time_this_iter_s: 3.0100951194763184\n",
      "  time_total_s: 1205.5019023418427\n",
      "  timestamp: 1596122627\n",
      "  timesteps_since_restore: 860600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 860600\n",
      "  training_iteration: 331\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1205 s, 331 iter, 860600 ts, 464 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-23-54\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 938.1085166386691\n",
      "  episode_reward_mean: 466.4260262789077\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 343\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.886\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4237358570098877\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.9528866346263385e-07\n",
      "        policy_loss: 0.004837001208215952\n",
      "        total_loss: 22.46617317199707\n",
      "        vf_explained_var: 0.11602914333343506\n",
      "        vf_loss: 22.461332321166992\n",
      "    load_time_ms: 1.106\n",
      "    num_steps_sampled: 865800\n",
      "    num_steps_trained: 832500\n",
      "    sample_time_ms: 3144.444\n",
      "    update_time_ms: 3.579\n",
      "  iterations_since_restore: 333\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.08\n",
      "    ram_util_percent: 65.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.267783370207518\n",
      "    mean_inference_ms: 1.0190454379529863\n",
      "    mean_processing_ms: 0.7083061820286438\n",
      "  time_since_restore: 1211.7228093147278\n",
      "  time_this_iter_s: 3.108473777770996\n",
      "  time_total_s: 1211.7228093147278\n",
      "  timestamp: 1596122634\n",
      "  timesteps_since_restore: 865800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 865800\n",
      "  training_iteration: 333\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1211 s, 333 iter, 865800 ts, 466 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-24-00\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 938.1085166386691\n",
      "  episode_reward_mean: 465.3938723756616\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 346\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 21.905\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4242112636566162\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.54015838865962e-07\n",
      "        policy_loss: 0.0015467259800061584\n",
      "        total_loss: 19.85649299621582\n",
      "        vf_explained_var: 0.11624592542648315\n",
      "        vf_loss: 19.854948043823242\n",
      "    load_time_ms: 1.219\n",
      "    num_steps_sampled: 871000\n",
      "    num_steps_trained: 837500\n",
      "    sample_time_ms: 3155.427\n",
      "    update_time_ms: 3.683\n",
      "  iterations_since_restore: 335\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.760000000000005\n",
      "    ram_util_percent: 65.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.264065636707456\n",
      "    mean_inference_ms: 1.0183893480468236\n",
      "    mean_processing_ms: 0.7080978998917571\n",
      "  time_since_restore: 1218.1003255844116\n",
      "  time_this_iter_s: 3.098193407058716\n",
      "  time_total_s: 1218.1003255844116\n",
      "  timestamp: 1596122640\n",
      "  timesteps_since_restore: 871000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 871000\n",
      "  training_iteration: 335\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1218 s, 335 iter, 871000 ts, 465 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-24-07\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 938.1085166386691\n",
      "  episode_reward_mean: 464.75158211042276\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 348\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 22.575\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4236832857131958\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.0493278068679501e-06\n",
      "        policy_loss: -0.0027577830478549004\n",
      "        total_loss: 17.923646926879883\n",
      "        vf_explained_var: 0.10503792762756348\n",
      "        vf_loss: 17.92640495300293\n",
      "    load_time_ms: 1.248\n",
      "    num_steps_sampled: 876200\n",
      "    num_steps_trained: 842500\n",
      "    sample_time_ms: 3150.446\n",
      "    update_time_ms: 3.787\n",
      "  iterations_since_restore: 337\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.775\n",
      "    ram_util_percent: 65.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.261807952178907\n",
      "    mean_inference_ms: 1.0179505312664947\n",
      "    mean_processing_ms: 0.7080005816172981\n",
      "  time_since_restore: 1225.080506324768\n",
      "  time_this_iter_s: 2.778813600540161\n",
      "  time_total_s: 1225.080506324768\n",
      "  timestamp: 1596122647\n",
      "  timesteps_since_restore: 876200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 876200\n",
      "  training_iteration: 337\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1225 s, 337 iter, 876200 ts, 465 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-24-14\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 938.1085166386691\n",
      "  episode_reward_mean: 463.93814057869014\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 351\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 21.969\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4300729036331177\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.652406578818045e-07\n",
      "        policy_loss: -0.003335548099130392\n",
      "        total_loss: 57.177738189697266\n",
      "        vf_explained_var: 0.06922686100006104\n",
      "        vf_loss: 57.18107604980469\n",
      "    load_time_ms: 1.226\n",
      "    num_steps_sampled: 881400\n",
      "    num_steps_trained: 847500\n",
      "    sample_time_ms: 3258.8\n",
      "    update_time_ms: 3.859\n",
      "  iterations_since_restore: 339\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.29999999999999\n",
      "    ram_util_percent: 65.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.25834164095341\n",
      "    mean_inference_ms: 1.0173441433527195\n",
      "    mean_processing_ms: 0.7078239328809172\n",
      "  time_since_restore: 1232.1896069049835\n",
      "  time_this_iter_s: 4.079188823699951\n",
      "  time_total_s: 1232.1896069049835\n",
      "  timestamp: 1596122654\n",
      "  timesteps_since_restore: 881400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 881400\n",
      "  training_iteration: 339\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1232 s, 339 iter, 881400 ts, 464 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-24-20\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 938.1085166386691\n",
      "  episode_reward_mean: 466.0481030337503\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 353\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 21.815\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4247266054153442\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.313090365329117e-07\n",
      "        policy_loss: 0.0018207002431154251\n",
      "        total_loss: 23.244247436523438\n",
      "        vf_explained_var: 0.07015424966812134\n",
      "        vf_loss: 23.242431640625\n",
      "    load_time_ms: 1.203\n",
      "    num_steps_sampled: 886600\n",
      "    num_steps_trained: 852500\n",
      "    sample_time_ms: 3241.261\n",
      "    update_time_ms: 3.508\n",
      "  iterations_since_restore: 341\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.35999999999999\n",
      "    ram_util_percent: 65.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.256334640291716\n",
      "    mean_inference_ms: 1.0169649254989195\n",
      "    mean_processing_ms: 0.7077352421764884\n",
      "  time_since_restore: 1238.247376203537\n",
      "  time_this_iter_s: 3.2871477603912354\n",
      "  time_total_s: 1238.247376203537\n",
      "  timestamp: 1596122660\n",
      "  timesteps_since_restore: 886600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 886600\n",
      "  training_iteration: 341\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1238 s, 341 iter, 886600 ts, 466 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-24-26\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 938.1085166386691\n",
      "  episode_reward_mean: 466.04810303375035\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 353\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 22.471\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4261316061019897\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.8605461466213455e-07\n",
      "        policy_loss: -0.0013358767610043287\n",
      "        total_loss: 17.87902069091797\n",
      "        vf_explained_var: 0.09792089462280273\n",
      "        vf_loss: 17.88035011291504\n",
      "    load_time_ms: 1.192\n",
      "    num_steps_sampled: 891800\n",
      "    num_steps_trained: 857500\n",
      "    sample_time_ms: 3238.141\n",
      "    update_time_ms: 3.532\n",
      "  iterations_since_restore: 343\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.14000000000001\n",
      "    ram_util_percent: 65.3\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.256334640291717\n",
      "    mean_inference_ms: 1.0169649254989193\n",
      "    mean_processing_ms: 0.7077352421764884\n",
      "  time_since_restore: 1244.4497277736664\n",
      "  time_this_iter_s: 3.2343201637268066\n",
      "  time_total_s: 1244.4497277736664\n",
      "  timestamp: 1596122666\n",
      "  timesteps_since_restore: 891800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 891800\n",
      "  training_iteration: 343\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1244 s, 343 iter, 891800 ts, 466 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-24-34\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 938.1085166386691\n",
      "  episode_reward_mean: 456.4333514909291\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 358\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.728\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4253153800964355\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 9.234667004420771e-07\n",
      "        policy_loss: 0.0024735298939049244\n",
      "        total_loss: 19.80040740966797\n",
      "        vf_explained_var: 0.07957923412322998\n",
      "        vf_loss: 19.79793357849121\n",
      "    load_time_ms: 1.062\n",
      "    num_steps_sampled: 897000\n",
      "    num_steps_trained: 862500\n",
      "    sample_time_ms: 3392.523\n",
      "    update_time_ms: 3.476\n",
      "  iterations_since_restore: 345\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.1\n",
      "    ram_util_percent: 65.31666666666668\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.25119481453673\n",
      "    mean_inference_ms: 1.0160649242450484\n",
      "    mean_processing_ms: 0.707521087553528\n",
      "  time_since_restore: 1252.3471629619598\n",
      "  time_this_iter_s: 4.035714864730835\n",
      "  time_total_s: 1252.3471629619598\n",
      "  timestamp: 1596122674\n",
      "  timesteps_since_restore: 897000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 897000\n",
      "  training_iteration: 345\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1252 s, 345 iter, 897000 ts, 456 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-24-40\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 938.1085166386691\n",
      "  episode_reward_mean: 456.4333514909292\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 358\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.904\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.428841233253479\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.802201255595719e-07\n",
      "        policy_loss: 0.003003246383741498\n",
      "        total_loss: 59.91112518310547\n",
      "        vf_explained_var: 0.04809695482254028\n",
      "        vf_loss: 59.90812683105469\n",
      "    load_time_ms: 1.057\n",
      "    num_steps_sampled: 902200\n",
      "    num_steps_trained: 867500\n",
      "    sample_time_ms: 3263.461\n",
      "    update_time_ms: 3.317\n",
      "  iterations_since_restore: 347\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.95\n",
      "    ram_util_percent: 65.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.25119481453673\n",
      "    mean_inference_ms: 1.0160649242450486\n",
      "    mean_processing_ms: 0.7075210875535279\n",
      "  time_since_restore: 1258.0266954898834\n",
      "  time_this_iter_s: 2.93813157081604\n",
      "  time_total_s: 1258.0266954898834\n",
      "  timestamp: 1596122680\n",
      "  timesteps_since_restore: 902200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 902200\n",
      "  training_iteration: 347\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1258 s, 347 iter, 902200 ts, 456 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-24-46\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 938.1085166386691\n",
      "  episode_reward_mean: 460.02104734576494\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 361\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.007\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4320948123931885\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.5009384191653226e-06\n",
      "        policy_loss: 0.002034165896475315\n",
      "        total_loss: 56.62983703613281\n",
      "        vf_explained_var: 0.06751161813735962\n",
      "        vf_loss: 56.62779998779297\n",
      "    load_time_ms: 1.052\n",
      "    num_steps_sampled: 907400\n",
      "    num_steps_trained: 872500\n",
      "    sample_time_ms: 3177.096\n",
      "    update_time_ms: 3.311\n",
      "  iterations_since_restore: 349\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 52.720000000000006\n",
      "    ram_util_percent: 65.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.248019878040458\n",
      "    mean_inference_ms: 1.0155387793412545\n",
      "    mean_processing_ms: 0.7073621696139688\n",
      "  time_since_restore: 1264.2713906764984\n",
      "  time_this_iter_s: 3.465681791305542\n",
      "  time_total_s: 1264.2713906764984\n",
      "  timestamp: 1596122686\n",
      "  timesteps_since_restore: 907400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 907400\n",
      "  training_iteration: 349\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1264 s, 349 iter, 907400 ts, 460 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-24-52\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 938.1085166386691\n",
      "  episode_reward_mean: 460.13610159409234\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 363\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.805\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4247663021087646\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.322720658616163e-07\n",
      "        policy_loss: 0.0024975428823381662\n",
      "        total_loss: 26.758968353271484\n",
      "        vf_explained_var: 0.0837520956993103\n",
      "        vf_loss: 26.7564754486084\n",
      "    load_time_ms: 1.058\n",
      "    num_steps_sampled: 912600\n",
      "    num_steps_trained: 877500\n",
      "    sample_time_ms: 3175.912\n",
      "    update_time_ms: 3.304\n",
      "  iterations_since_restore: 351\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.075\n",
      "    ram_util_percent: 65.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.246280945767646\n",
      "    mean_inference_ms: 1.0151687784101648\n",
      "    mean_processing_ms: 0.7072765898971016\n",
      "  time_since_restore: 1270.3148124217987\n",
      "  time_this_iter_s: 2.9285271167755127\n",
      "  time_total_s: 1270.3148124217987\n",
      "  timestamp: 1596122692\n",
      "  timesteps_since_restore: 912600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 912600\n",
      "  training_iteration: 351\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1270 s, 351 iter, 912600 ts, 460 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-24-59\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 938.1085166386691\n",
      "  episode_reward_mean: 460.13610159409234\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 363\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.946\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4314146041870117\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.8622149983448253e-08\n",
      "        policy_loss: 0.0019422225886955857\n",
      "        total_loss: 65.07785034179688\n",
      "        vf_explained_var: 0.051002323627471924\n",
      "        vf_loss: 65.07592010498047\n",
      "    load_time_ms: 1.045\n",
      "    num_steps_sampled: 917800\n",
      "    num_steps_trained: 882500\n",
      "    sample_time_ms: 3180.574\n",
      "    update_time_ms: 3.248\n",
      "  iterations_since_restore: 353\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.825\n",
      "    ram_util_percent: 65.175\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.246280945767646\n",
      "    mean_inference_ms: 1.0151687784101648\n",
      "    mean_processing_ms: 0.7072765898971016\n",
      "  time_since_restore: 1276.5477578639984\n",
      "  time_this_iter_s: 3.0607831478118896\n",
      "  time_total_s: 1276.5477578639984\n",
      "  timestamp: 1596122699\n",
      "  timesteps_since_restore: 917800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 917800\n",
      "  training_iteration: 353\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1276 s, 353 iter, 917800 ts, 460 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-25-06\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 938.1085166386691\n",
      "  episode_reward_mean: 467.68544290518497\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 368\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.88\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4230284690856934\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.4958381200358417e-07\n",
      "        policy_loss: -0.003525493899360299\n",
      "        total_loss: 15.300806045532227\n",
      "        vf_explained_var: 0.0911855697631836\n",
      "        vf_loss: 15.304332733154297\n",
      "    load_time_ms: 1.123\n",
      "    num_steps_sampled: 923000\n",
      "    num_steps_trained: 887500\n",
      "    sample_time_ms: 3082.779\n",
      "    update_time_ms: 3.563\n",
      "  iterations_since_restore: 355\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.45\n",
      "    ram_util_percent: 65.175\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.2420749761777925\n",
      "    mean_inference_ms: 1.0145092159101514\n",
      "    mean_processing_ms: 0.7071026492160939\n",
      "  time_since_restore: 1283.4993827342987\n",
      "  time_this_iter_s: 2.8297080993652344\n",
      "  time_total_s: 1283.4993827342987\n",
      "  timestamp: 1596122706\n",
      "  timesteps_since_restore: 923000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 923000\n",
      "  training_iteration: 355\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1283 s, 355 iter, 923000 ts, 468 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-25-12\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 938.1085166386691\n",
      "  episode_reward_mean: 467.68544290518497\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 368\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 22.361\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4281625747680664\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.5011300408550596e-07\n",
      "        policy_loss: 0.006285396404564381\n",
      "        total_loss: 61.55594253540039\n",
      "        vf_explained_var: 0.03614509105682373\n",
      "        vf_loss: 61.54967498779297\n",
      "    load_time_ms: 1.252\n",
      "    num_steps_sampled: 928200\n",
      "    num_steps_trained: 892500\n",
      "    sample_time_ms: 3137.449\n",
      "    update_time_ms: 3.814\n",
      "  iterations_since_restore: 357\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 65.75\n",
      "    ram_util_percent: 65.125\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.242074976177792\n",
      "    mean_inference_ms: 1.0145092159101514\n",
      "    mean_processing_ms: 0.7071026492160938\n",
      "  time_since_restore: 1289.7464773654938\n",
      "  time_this_iter_s: 3.0582499504089355\n",
      "  time_total_s: 1289.7464773654938\n",
      "  timestamp: 1596122712\n",
      "  timesteps_since_restore: 928200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 928200\n",
      "  training_iteration: 357\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1289 s, 357 iter, 928200 ts, 468 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-25-19\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 938.1085166386691\n",
      "  episode_reward_mean: 479.06734391953484\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 373\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 22.103\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4325203895568848\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.8949380066478625e-06\n",
      "        policy_loss: 0.0012217732146382332\n",
      "        total_loss: 74.61113739013672\n",
      "        vf_explained_var: 0.06391096115112305\n",
      "        vf_loss: 74.60990905761719\n",
      "    load_time_ms: 1.271\n",
      "    num_steps_sampled: 933400\n",
      "    num_steps_trained: 897500\n",
      "    sample_time_ms: 3208.104\n",
      "    update_time_ms: 3.73\n",
      "  iterations_since_restore: 359\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.44\n",
      "    ram_util_percent: 65.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.237847979158473\n",
      "    mean_inference_ms: 1.013822509690532\n",
      "    mean_processing_ms: 0.7068952957352724\n",
      "  time_since_restore: 1296.6943657398224\n",
      "  time_this_iter_s: 3.8712267875671387\n",
      "  time_total_s: 1296.6943657398224\n",
      "  timestamp: 1596122719\n",
      "  timesteps_since_restore: 933400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 933400\n",
      "  training_iteration: 359\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1296 s, 359 iter, 933400 ts, 479 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-25-25\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 938.1085166386691\n",
      "  episode_reward_mean: 479.0673439195348\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 373\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 22.078\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4271302223205566\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.895759448369063e-08\n",
      "        policy_loss: 0.0026920721866190434\n",
      "        total_loss: 55.538211822509766\n",
      "        vf_explained_var: 0.05350297689437866\n",
      "        vf_loss: 55.535518646240234\n",
      "    load_time_ms: 1.258\n",
      "    num_steps_sampled: 938600\n",
      "    num_steps_trained: 902500\n",
      "    sample_time_ms: 3219.274\n",
      "    update_time_ms: 3.661\n",
      "  iterations_since_restore: 361\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.9\n",
      "    ram_util_percent: 65.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.237847979158474\n",
      "    mean_inference_ms: 1.0138225096905322\n",
      "    mean_processing_ms: 0.7068952957352727\n",
      "  time_since_restore: 1302.847751379013\n",
      "  time_this_iter_s: 3.2340176105499268\n",
      "  time_total_s: 1302.847751379013\n",
      "  timestamp: 1596122725\n",
      "  timesteps_since_restore: 938600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 938600\n",
      "  training_iteration: 361\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1302 s, 361 iter, 938600 ts, 479 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-25-31\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 938.1085166386691\n",
      "  episode_reward_mean: 477.63166144770804\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 375\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 24.758\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4346339702606201\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 9.953976132237585e-07\n",
      "        policy_loss: -0.0056851934641599655\n",
      "        total_loss: 83.38895416259766\n",
      "        vf_explained_var: 0.0219041109085083\n",
      "        vf_loss: 83.39464569091797\n",
      "    load_time_ms: 1.374\n",
      "    num_steps_sampled: 943800\n",
      "    num_steps_trained: 907500\n",
      "    sample_time_ms: 3229.516\n",
      "    update_time_ms: 3.783\n",
      "  iterations_since_restore: 363\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.64\n",
      "    ram_util_percent: 65.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.235457149901348\n",
      "    mean_inference_ms: 1.0134042644820347\n",
      "    mean_processing_ms: 0.7067729074022482\n",
      "  time_since_restore: 1309.228734254837\n",
      "  time_this_iter_s: 3.3761889934539795\n",
      "  time_total_s: 1309.228734254837\n",
      "  timestamp: 1596122731\n",
      "  timesteps_since_restore: 943800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 943800\n",
      "  training_iteration: 363\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1309 s, 363 iter, 943800 ts, 478 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-25-38\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 938.1085166386691\n",
      "  episode_reward_mean: 485.3435772520638\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 378\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 22.946\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4226845502853394\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.4232873581931926e-06\n",
      "        policy_loss: -0.0027262659277766943\n",
      "        total_loss: 23.54082679748535\n",
      "        vf_explained_var: 0.08774060010910034\n",
      "        vf_loss: 23.543556213378906\n",
      "    load_time_ms: 1.309\n",
      "    num_steps_sampled: 949000\n",
      "    num_steps_trained: 912500\n",
      "    sample_time_ms: 3219.935\n",
      "    update_time_ms: 4.212\n",
      "  iterations_since_restore: 365\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.325\n",
      "    ram_util_percent: 65.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.232987159747514\n",
      "    mean_inference_ms: 1.0129228058829514\n",
      "    mean_processing_ms: 0.7066612191588382\n",
      "  time_since_restore: 1316.0608596801758\n",
      "  time_this_iter_s: 2.935206651687622\n",
      "  time_total_s: 1316.0608596801758\n",
      "  timestamp: 1596122738\n",
      "  timesteps_since_restore: 949000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 949000\n",
      "  training_iteration: 365\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1316 s, 365 iter, 949000 ts, 485 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-25-45\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 938.1085166386691\n",
      "  episode_reward_mean: 485.3435772520638\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 378\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 22.4\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4286208152770996\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.084442105702692e-08\n",
      "        policy_loss: 0.0017577571561560035\n",
      "        total_loss: 51.591285705566406\n",
      "        vf_explained_var: 0.046179115772247314\n",
      "        vf_loss: 51.589515686035156\n",
      "    load_time_ms: 1.191\n",
      "    num_steps_sampled: 954200\n",
      "    num_steps_trained: 917500\n",
      "    sample_time_ms: 3221.175\n",
      "    update_time_ms: 4.143\n",
      "  iterations_since_restore: 367\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.620000000000005\n",
      "    ram_util_percent: 65.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.232987159747514\n",
      "    mean_inference_ms: 1.0129228058829514\n",
      "    mean_processing_ms: 0.7066612191588382\n",
      "  time_since_restore: 1322.3169720172882\n",
      "  time_this_iter_s: 3.0748441219329834\n",
      "  time_total_s: 1322.3169720172882\n",
      "  timestamp: 1596122745\n",
      "  timesteps_since_restore: 954200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 954200\n",
      "  training_iteration: 367\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1322 s, 367 iter, 954200 ts, 485 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-25-51\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 887.7077352087381\n",
      "  episode_reward_mean: 478.8530143966663\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 382\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 23.569\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.424025297164917\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.097653404893208e-07\n",
      "        policy_loss: 0.0019205276621505618\n",
      "        total_loss: 17.008007049560547\n",
      "        vf_explained_var: 0.09843045473098755\n",
      "        vf_loss: 17.00609016418457\n",
      "    load_time_ms: 1.184\n",
      "    num_steps_sampled: 959400\n",
      "    num_steps_trained: 922500\n",
      "    sample_time_ms: 3212.024\n",
      "    update_time_ms: 4.336\n",
      "  iterations_since_restore: 369\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.75\n",
      "    ram_util_percent: 65.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.228748556573115\n",
      "    mean_inference_ms: 1.012102753489231\n",
      "    mean_processing_ms: 0.7064392863075741\n",
      "  time_since_restore: 1329.1917052268982\n",
      "  time_this_iter_s: 2.718991279602051\n",
      "  time_total_s: 1329.1917052268982\n",
      "  timestamp: 1596122751\n",
      "  timesteps_since_restore: 959400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 959400\n",
      "  training_iteration: 369\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1329 s, 369 iter, 959400 ts, 479 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-25-58\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 887.7077352087381\n",
      "  episode_reward_mean: 476.1758951182877\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 383\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 24.229\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4276773929595947\n",
      "        entropy_coeff: 0.0\n",
      "        kl: -7.033348348173263e-10\n",
      "        policy_loss: -0.0004917595651932061\n",
      "        total_loss: 44.484317779541016\n",
      "        vf_explained_var: 0.043603599071502686\n",
      "        vf_loss: 44.48481369018555\n",
      "    load_time_ms: 1.221\n",
      "    num_steps_sampled: 964600\n",
      "    num_steps_trained: 927500\n",
      "    sample_time_ms: 3219.922\n",
      "    update_time_ms: 4.753\n",
      "  iterations_since_restore: 371\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.5\n",
      "    ram_util_percent: 65.14\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.227820749844594\n",
      "    mean_inference_ms: 1.0119258541635778\n",
      "    mean_processing_ms: 0.7063836396205895\n",
      "  time_since_restore: 1335.441386938095\n",
      "  time_this_iter_s: 3.032322406768799\n",
      "  time_total_s: 1335.441386938095\n",
      "  timestamp: 1596122758\n",
      "  timesteps_since_restore: 964600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 964600\n",
      "  training_iteration: 371\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1335 s, 371 iter, 964600 ts, 476 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-26-05\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 887.7077352087381\n",
      "  episode_reward_mean: 481.38462729496007\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 386\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 21.002\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4300633668899536\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.674502396388561e-07\n",
      "        policy_loss: 0.000835708633530885\n",
      "        total_loss: 53.67200469970703\n",
      "        vf_explained_var: 0.07468527555465698\n",
      "        vf_loss: 53.67116165161133\n",
      "    load_time_ms: 1.126\n",
      "    num_steps_sampled: 969800\n",
      "    num_steps_trained: 932500\n",
      "    sample_time_ms: 3361.292\n",
      "    update_time_ms: 4.695\n",
      "  iterations_since_restore: 373\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 43.46666666666667\n",
      "    ram_util_percent: 65.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.224270307967508\n",
      "    mean_inference_ms: 1.011247609988757\n",
      "    mean_processing_ms: 0.7061974024450796\n",
      "  time_since_restore: 1343.1863508224487\n",
      "  time_this_iter_s: 3.69256329536438\n",
      "  time_total_s: 1343.1863508224487\n",
      "  timestamp: 1596122765\n",
      "  timesteps_since_restore: 969800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 969800\n",
      "  training_iteration: 373\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1343 s, 373 iter, 969800 ts, 481 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-26-11\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 887.7077352087381\n",
      "  episode_reward_mean: 486.70336319630877\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 388\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 22.224\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.425201654434204\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.0895013247136376e-06\n",
      "        policy_loss: 0.010164809413254261\n",
      "        total_loss: 36.71503829956055\n",
      "        vf_explained_var: 0.05281156301498413\n",
      "        vf_loss: 36.70487594604492\n",
      "    load_time_ms: 1.144\n",
      "    num_steps_sampled: 975000\n",
      "    num_steps_trained: 937500\n",
      "    sample_time_ms: 3276.437\n",
      "    update_time_ms: 3.927\n",
      "  iterations_since_restore: 375\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.4\n",
      "    ram_util_percent: 65.22500000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.222734930727189\n",
      "    mean_inference_ms: 1.0109496788460646\n",
      "    mean_processing_ms: 0.7061118584764658\n",
      "  time_since_restore: 1349.1791791915894\n",
      "  time_this_iter_s: 3.1057491302490234\n",
      "  time_total_s: 1349.1791791915894\n",
      "  timestamp: 1596122771\n",
      "  timesteps_since_restore: 975000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 975000\n",
      "  training_iteration: 375\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1349 s, 375 iter, 975000 ts, 487 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-26-18\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 887.7077352087381\n",
      "  episode_reward_mean: 488.0499704607501\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 389\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 21.854\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4308849573135376\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.259267378372897e-06\n",
      "        policy_loss: 0.0021985627245157957\n",
      "        total_loss: 68.75960540771484\n",
      "        vf_explained_var: 0.04306221008300781\n",
      "        vf_loss: 68.75740051269531\n",
      "    load_time_ms: 1.161\n",
      "    num_steps_sampled: 980200\n",
      "    num_steps_trained: 942500\n",
      "    sample_time_ms: 3260.418\n",
      "    update_time_ms: 3.946\n",
      "  iterations_since_restore: 377\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.08\n",
      "    ram_util_percent: 65.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.221422166335372\n",
      "    mean_inference_ms: 1.0106557772899927\n",
      "    mean_processing_ms: 0.7060669705439588\n",
      "  time_since_restore: 1355.2675092220306\n",
      "  time_this_iter_s: 3.11841082572937\n",
      "  time_total_s: 1355.2675092220306\n",
      "  timestamp: 1596122778\n",
      "  timesteps_since_restore: 980200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 980200\n",
      "  training_iteration: 377\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1355 s, 377 iter, 980200 ts, 488 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-26-25\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 887.7077352087381\n",
      "  episode_reward_mean: 490.843589314739\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 392\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.641\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.423966407775879\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.7013759285619017e-07\n",
      "        policy_loss: 0.0010823312913998961\n",
      "        total_loss: 45.29119110107422\n",
      "        vf_explained_var: 0.06033557653427124\n",
      "        vf_loss: 45.29010772705078\n",
      "    load_time_ms: 1.165\n",
      "    num_steps_sampled: 985400\n",
      "    num_steps_trained: 947500\n",
      "    sample_time_ms: 3279.707\n",
      "    update_time_ms: 3.747\n",
      "  iterations_since_restore: 379\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.949999999999996\n",
      "    ram_util_percent: 65.30000000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.21861652344934\n",
      "    mean_inference_ms: 1.0101419394986368\n",
      "    mean_processing_ms: 0.7058845133976397\n",
      "  time_since_restore: 1362.316740512848\n",
      "  time_this_iter_s: 2.9287168979644775\n",
      "  time_total_s: 1362.316740512848\n",
      "  timestamp: 1596122785\n",
      "  timesteps_since_restore: 985400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 985400\n",
      "  training_iteration: 379\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1362 s, 379 iter, 985400 ts, 491 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-26-31\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 887.7077352087381\n",
      "  episode_reward_mean: 492.09291068904474\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 393\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.576\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.42753267288208\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.676296162462677e-06\n",
      "        policy_loss: -0.0034210665617138147\n",
      "        total_loss: 46.505210876464844\n",
      "        vf_explained_var: 0.04785865545272827\n",
      "        vf_loss: 46.50862503051758\n",
      "    load_time_ms: 1.117\n",
      "    num_steps_sampled: 990600\n",
      "    num_steps_trained: 952500\n",
      "    sample_time_ms: 3339.316\n",
      "    update_time_ms: 3.383\n",
      "  iterations_since_restore: 381\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.925\n",
      "    ram_util_percent: 65.3\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.217717452822699\n",
      "    mean_inference_ms: 1.0099686367105942\n",
      "    mean_processing_ms: 0.7058323323641315\n",
      "  time_since_restore: 1369.1402428150177\n",
      "  time_this_iter_s: 2.903451681137085\n",
      "  time_total_s: 1369.1402428150177\n",
      "  timestamp: 1596122791\n",
      "  timesteps_since_restore: 990600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 990600\n",
      "  training_iteration: 381\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1369 s, 381 iter, 990600 ts, 492 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-26-39\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 887.7077352087381\n",
      "  episode_reward_mean: 496.59263261480226\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 397\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.347\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4253326654434204\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.8896800447218993e-07\n",
      "        policy_loss: 0.009285705164074898\n",
      "        total_loss: 29.234996795654297\n",
      "        vf_explained_var: 0.09029161930084229\n",
      "        vf_loss: 29.225719451904297\n",
      "    load_time_ms: 1.123\n",
      "    num_steps_sampled: 995800\n",
      "    num_steps_trained: 957500\n",
      "    sample_time_ms: 3294.755\n",
      "    update_time_ms: 3.519\n",
      "  iterations_since_restore: 383\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.8\n",
      "    ram_util_percent: 65.25\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.213866440669007\n",
      "    mean_inference_ms: 1.009233130781723\n",
      "    mean_processing_ms: 0.7056314292009196\n",
      "  time_since_restore: 1376.4515841007233\n",
      "  time_this_iter_s: 2.9803764820098877\n",
      "  time_total_s: 1376.4515841007233\n",
      "  timestamp: 1596122799\n",
      "  timesteps_since_restore: 995800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 995800\n",
      "  training_iteration: 383\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1376 s, 383 iter, 995800 ts, 497 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-26-45\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 887.7077352087381\n",
      "  episode_reward_mean: 497.21015445959057\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 398\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.667\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4267243146896362\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.809882175824896e-07\n",
      "        policy_loss: 0.0030615401919931173\n",
      "        total_loss: 32.685272216796875\n",
      "        vf_explained_var: 0.06090962886810303\n",
      "        vf_loss: 32.68220901489258\n",
      "    load_time_ms: 1.093\n",
      "    num_steps_sampled: 1001000\n",
      "    num_steps_trained: 962500\n",
      "    sample_time_ms: 3341.292\n",
      "    update_time_ms: 3.948\n",
      "  iterations_since_restore: 385\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.325\n",
      "    ram_util_percent: 65.3\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.213052904446874\n",
      "    mean_inference_ms: 1.0090804720427384\n",
      "    mean_processing_ms: 0.7055918488279923\n",
      "  time_since_restore: 1382.9031064510345\n",
      "  time_this_iter_s: 3.2633039951324463\n",
      "  time_total_s: 1382.9031064510345\n",
      "  timestamp: 1596122805\n",
      "  timesteps_since_restore: 1001000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1001000\n",
      "  training_iteration: 385\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1382 s, 385 iter, 1001000 ts, 497 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-26-52\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 887.7077352087381\n",
      "  episode_reward_mean: 491.3064663299179\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 402\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.854\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.429089903831482\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.24795348913176e-06\n",
      "        policy_loss: -0.0014293615240603685\n",
      "        total_loss: 45.85730743408203\n",
      "        vf_explained_var: 0.049176156520843506\n",
      "        vf_loss: 45.858734130859375\n",
      "    load_time_ms: 1.032\n",
      "    num_steps_sampled: 1006200\n",
      "    num_steps_trained: 967500\n",
      "    sample_time_ms: 3455.695\n",
      "    update_time_ms: 3.857\n",
      "  iterations_since_restore: 387\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.166666666666664\n",
      "    ram_util_percent: 65.36666666666666\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.209352048396673\n",
      "    mean_inference_ms: 1.0083794051326682\n",
      "    mean_processing_ms: 0.7053915782869354\n",
      "  time_since_restore: 1390.123596906662\n",
      "  time_this_iter_s: 4.1532299518585205\n",
      "  time_total_s: 1390.123596906662\n",
      "  timestamp: 1596122812\n",
      "  timesteps_since_restore: 1006200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1006200\n",
      "  training_iteration: 387\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1390 s, 387 iter, 1006200 ts, 491 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-26-58\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 887.7077352087381\n",
      "  episode_reward_mean: 491.30646632991795\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 402\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.317\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4252004623413086\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.3252497410576325e-07\n",
      "        policy_loss: 0.00018208782421424985\n",
      "        total_loss: 47.992950439453125\n",
      "        vf_explained_var: 0.06497371196746826\n",
      "        vf_loss: 47.99277877807617\n",
      "    load_time_ms: 1.065\n",
      "    num_steps_sampled: 1011400\n",
      "    num_steps_trained: 972500\n",
      "    sample_time_ms: 3308.739\n",
      "    update_time_ms: 3.79\n",
      "  iterations_since_restore: 389\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.7\n",
      "    ram_util_percent: 65.3\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.209352048396672\n",
      "    mean_inference_ms: 1.0083794051326682\n",
      "    mean_processing_ms: 0.7053915782869354\n",
      "  time_since_restore: 1395.720366716385\n",
      "  time_this_iter_s: 2.89011549949646\n",
      "  time_total_s: 1395.720366716385\n",
      "  timestamp: 1596122818\n",
      "  timesteps_since_restore: 1011400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1011400\n",
      "  training_iteration: 389\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1395 s, 389 iter, 1011400 ts, 491 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-27-05\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 887.7077352087381\n",
      "  episode_reward_mean: 494.0662850493387\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 404\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.325\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4310632944107056\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.2421607742396645e-08\n",
      "        policy_loss: 0.004275768995285034\n",
      "        total_loss: 64.103515625\n",
      "        vf_explained_var: 0.055791616439819336\n",
      "        vf_loss: 64.09921264648438\n",
      "    load_time_ms: 1.066\n",
      "    num_steps_sampled: 1016600\n",
      "    num_steps_trained: 977500\n",
      "    sample_time_ms: 3291.718\n",
      "    update_time_ms: 4.045\n",
      "  iterations_since_restore: 391\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.160000000000004\n",
      "    ram_util_percent: 65.12\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.207218287209773\n",
      "    mean_inference_ms: 1.007901243292163\n",
      "    mean_processing_ms: 0.7053081361079214\n",
      "  time_since_restore: 1402.3770489692688\n",
      "  time_this_iter_s: 3.8276960849761963\n",
      "  time_total_s: 1402.3770489692688\n",
      "  timestamp: 1596122825\n",
      "  timesteps_since_restore: 1016600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1016600\n",
      "  training_iteration: 391\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1402 s, 391 iter, 1016600 ts, 494 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-27-11\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 887.7077352087381\n",
      "  episode_reward_mean: 490.4230603867751\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 407\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.302\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4230332374572754\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.203983270504978e-08\n",
      "        policy_loss: 1.852929563028738e-05\n",
      "        total_loss: 32.9780387878418\n",
      "        vf_explained_var: 0.0651707649230957\n",
      "        vf_loss: 32.978023529052734\n",
      "    load_time_ms: 1.022\n",
      "    num_steps_sampled: 1021800\n",
      "    num_steps_trained: 982500\n",
      "    sample_time_ms: 3170.642\n",
      "    update_time_ms: 3.742\n",
      "  iterations_since_restore: 393\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.375\n",
      "    ram_util_percent: 65.175\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.204215025616066\n",
      "    mean_inference_ms: 1.007327174220725\n",
      "    mean_processing_ms: 0.7050973591681173\n",
      "  time_since_restore: 1408.4587116241455\n",
      "  time_this_iter_s: 2.7515246868133545\n",
      "  time_total_s: 1408.4587116241455\n",
      "  timestamp: 1596122831\n",
      "  timesteps_since_restore: 1021800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1021800\n",
      "  training_iteration: 393\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1408 s, 393 iter, 1021800 ts, 490 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-27-17\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 887.7077352087381\n",
      "  episode_reward_mean: 490.4230603867751\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 407\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.161\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4322706460952759\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.3437032748697675e-06\n",
      "        policy_loss: -0.003456120379269123\n",
      "        total_loss: 89.44086456298828\n",
      "        vf_explained_var: 0.027785181999206543\n",
      "        vf_loss: 89.44432830810547\n",
      "    load_time_ms: 1.04\n",
      "    num_steps_sampled: 1027000\n",
      "    num_steps_trained: 987500\n",
      "    sample_time_ms: 3100.3\n",
      "    update_time_ms: 3.332\n",
      "  iterations_since_restore: 395\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.075\n",
      "    ram_util_percent: 65.14999999999999\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.204215025616066\n",
      "    mean_inference_ms: 1.007327174220725\n",
      "    mean_processing_ms: 0.7050973591681173\n",
      "  time_since_restore: 1414.2016713619232\n",
      "  time_this_iter_s: 2.975714683532715\n",
      "  time_total_s: 1414.2016713619232\n",
      "  timestamp: 1596122837\n",
      "  timesteps_since_restore: 1027000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1027000\n",
      "  training_iteration: 395\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1414 s, 395 iter, 1027000 ts, 490 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-27-25\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 887.7077352087381\n",
      "  episode_reward_mean: 494.5726892127974\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 412\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 21.095\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4257333278656006\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.2191056839583325e-06\n",
      "        policy_loss: 0.0003738364321179688\n",
      "        total_loss: 34.7426643371582\n",
      "        vf_explained_var: 0.07286334037780762\n",
      "        vf_loss: 34.7422981262207\n",
      "    load_time_ms: 1.086\n",
      "    num_steps_sampled: 1032200\n",
      "    num_steps_trained: 992500\n",
      "    sample_time_ms: 3169.074\n",
      "    update_time_ms: 3.376\n",
      "  iterations_since_restore: 397\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 66.24000000000001\n",
      "    ram_util_percent: 65.64\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.198544514952162\n",
      "    mean_inference_ms: 1.0060952267108234\n",
      "    mean_processing_ms: 0.7047559557026751\n",
      "  time_since_restore: 1422.1352353096008\n",
      "  time_this_iter_s: 3.674732208251953\n",
      "  time_total_s: 1422.1352353096008\n",
      "  timestamp: 1596122845\n",
      "  timesteps_since_restore: 1032200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1032200\n",
      "  training_iteration: 397\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1422 s, 397 iter, 1032200 ts, 495 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-27-30\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 887.7077352087381\n",
      "  episode_reward_mean: 494.5726892127974\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 412\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.96\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4261369705200195\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.5955906696472084e-07\n",
      "        policy_loss: -0.007565625011920929\n",
      "        total_loss: 32.25499725341797\n",
      "        vf_explained_var: 0.05679202079772949\n",
      "        vf_loss: 32.26255798339844\n",
      "    load_time_ms: 1.047\n",
      "    num_steps_sampled: 1037400\n",
      "    num_steps_trained: 997500\n",
      "    sample_time_ms: 3197.723\n",
      "    update_time_ms: 3.526\n",
      "  iterations_since_restore: 399\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.775000000000006\n",
      "    ram_util_percent: 65.4\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.198544514952162\n",
      "    mean_inference_ms: 1.0060952267108232\n",
      "    mean_processing_ms: 0.7047559557026751\n",
      "  time_since_restore: 1428.0051848888397\n",
      "  time_this_iter_s: 3.007312297821045\n",
      "  time_total_s: 1428.0051848888397\n",
      "  timestamp: 1596122850\n",
      "  timesteps_since_restore: 1037400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1037400\n",
      "  training_iteration: 399\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1428 s, 399 iter, 1037400 ts, 495 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-27-37\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 887.7077352087381\n",
      "  episode_reward_mean: 493.6356464341683\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 415\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.721\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4291467666625977\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 7.42602367154177e-07\n",
      "        policy_loss: -0.006919307634234428\n",
      "        total_loss: 34.997493743896484\n",
      "        vf_explained_var: 0.07066917419433594\n",
      "        vf_loss: 35.004417419433594\n",
      "    load_time_ms: 1.054\n",
      "    num_steps_sampled: 1042600\n",
      "    num_steps_trained: 1002500\n",
      "    sample_time_ms: 3222.519\n",
      "    update_time_ms: 3.425\n",
      "  iterations_since_restore: 401\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.42\n",
      "    ram_util_percent: 65.53999999999999\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.194935462999883\n",
      "    mean_inference_ms: 1.005083670046684\n",
      "    mean_processing_ms: 0.7045086928635977\n",
      "  time_since_restore: 1434.9188573360443\n",
      "  time_this_iter_s: 3.6650571823120117\n",
      "  time_total_s: 1434.9188573360443\n",
      "  timestamp: 1596122857\n",
      "  timesteps_since_restore: 1042600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1042600\n",
      "  training_iteration: 401\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1434 s, 401 iter, 1042600 ts, 494 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-27-44\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 887.7077352087381\n",
      "  episode_reward_mean: 490.4138279247384\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 417\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 21.455\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4239153861999512\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.5354156346347736e-07\n",
      "        policy_loss: 0.004935336299240589\n",
      "        total_loss: 18.24910545349121\n",
      "        vf_explained_var: 0.09472006559371948\n",
      "        vf_loss: 18.244171142578125\n",
      "    load_time_ms: 1.083\n",
      "    num_steps_sampled: 1047800\n",
      "    num_steps_trained: 1007500\n",
      "    sample_time_ms: 3243.645\n",
      "    update_time_ms: 3.496\n",
      "  iterations_since_restore: 403\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.875\n",
      "    ram_util_percent: 65.7\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.1925630766190904\n",
      "    mean_inference_ms: 1.0047485808813033\n",
      "    mean_processing_ms: 0.7043716975321641\n",
      "  time_since_restore: 1441.2216475009918\n",
      "  time_this_iter_s: 2.9216196537017822\n",
      "  time_total_s: 1441.2216475009918\n",
      "  timestamp: 1596122864\n",
      "  timesteps_since_restore: 1047800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1047800\n",
      "  training_iteration: 403\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1441 s, 403 iter, 1047800 ts, 490 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-27-51\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 887.7077352087381\n",
      "  episode_reward_mean: 488.03823982416475\n",
      "  episode_reward_min: 120.10138577388487\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 418\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 21.523\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4284358024597168\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.8232803944993066e-07\n",
      "        policy_loss: 0.003887576749548316\n",
      "        total_loss: 42.6652946472168\n",
      "        vf_explained_var: 0.04603421688079834\n",
      "        vf_loss: 42.66141128540039\n",
      "    load_time_ms: 1.075\n",
      "    num_steps_sampled: 1053000\n",
      "    num_steps_trained: 1012500\n",
      "    sample_time_ms: 3435.548\n",
      "    update_time_ms: 3.557\n",
      "  iterations_since_restore: 405\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.78571428571429\n",
      "    ram_util_percent: 65.85714285714285\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.191398052572794\n",
      "    mean_inference_ms: 1.0044756262742787\n",
      "    mean_processing_ms: 0.7042948393865918\n",
      "  time_since_restore: 1448.8844244480133\n",
      "  time_this_iter_s: 4.432564735412598\n",
      "  time_total_s: 1448.8844244480133\n",
      "  timestamp: 1596122871\n",
      "  timesteps_since_restore: 1053000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1053000\n",
      "  training_iteration: 405\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1448 s, 405 iter, 1053000 ts, 488 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-27-58\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 887.7077352087381\n",
      "  episode_reward_mean: 484.16447194502075\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 422\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.36\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4257375001907349\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.4238586320279865e-06\n",
      "        policy_loss: 0.0007540038786828518\n",
      "        total_loss: 20.07799530029297\n",
      "        vf_explained_var: 0.09077143669128418\n",
      "        vf_loss: 20.07724380493164\n",
      "    load_time_ms: 1.039\n",
      "    num_steps_sampled: 1058200\n",
      "    num_steps_trained: 1017500\n",
      "    sample_time_ms: 3291.347\n",
      "    update_time_ms: 3.403\n",
      "  iterations_since_restore: 407\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.8\n",
      "    ram_util_percent: 65.82000000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.187016878342022\n",
      "    mean_inference_ms: 1.003509255445907\n",
      "    mean_processing_ms: 0.7040190731487479\n",
      "  time_since_restore: 1455.3598275184631\n",
      "  time_this_iter_s: 3.21877384185791\n",
      "  time_total_s: 1455.3598275184631\n",
      "  timestamp: 1596122878\n",
      "  timesteps_since_restore: 1058200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1058200\n",
      "  training_iteration: 407\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1455 s, 407 iter, 1058200 ts, 484 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-28-04\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 887.7077352087381\n",
      "  episode_reward_mean: 484.16447194502075\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 422\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.425\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.429409146308899\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 9.603262469681795e-07\n",
      "        policy_loss: 0.0016690663760527968\n",
      "        total_loss: 34.319801330566406\n",
      "        vf_explained_var: 0.04803234338760376\n",
      "        vf_loss: 34.318138122558594\n",
      "    load_time_ms: 1.044\n",
      "    num_steps_sampled: 1063400\n",
      "    num_steps_trained: 1022500\n",
      "    sample_time_ms: 3316.022\n",
      "    update_time_ms: 3.465\n",
      "  iterations_since_restore: 409\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.67999999999999\n",
      "    ram_util_percent: 65.78\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.187016878342022\n",
      "    mean_inference_ms: 1.003509255445907\n",
      "    mean_processing_ms: 0.7040190731487479\n",
      "  time_since_restore: 1461.4801044464111\n",
      "  time_this_iter_s: 3.0364861488342285\n",
      "  time_total_s: 1461.4801044464111\n",
      "  timestamp: 1596122884\n",
      "  timesteps_since_restore: 1063400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1063400\n",
      "  training_iteration: 409\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1461 s, 409 iter, 1063400 ts, 484 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-28-11\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 887.7077352087381\n",
      "  episode_reward_mean: 483.2564055985359\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 426\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.899\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4310730695724487\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.5035628848636406e-06\n",
      "        policy_loss: 0.005417629145085812\n",
      "        total_loss: 48.02573013305664\n",
      "        vf_explained_var: 0.07007288932800293\n",
      "        vf_loss: 48.02030944824219\n",
      "    load_time_ms: 1.027\n",
      "    num_steps_sampled: 1068600\n",
      "    num_steps_trained: 1027500\n",
      "    sample_time_ms: 3351.83\n",
      "    update_time_ms: 3.283\n",
      "  iterations_since_restore: 411\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.925000000000004\n",
      "    ram_util_percent: 65.8\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.182397778044659\n",
      "    mean_inference_ms: 1.0023387893158417\n",
      "    mean_processing_ms: 0.7037082269189555\n",
      "  time_since_restore: 1468.745887041092\n",
      "  time_this_iter_s: 3.179913282394409\n",
      "  time_total_s: 1468.745887041092\n",
      "  timestamp: 1596122891\n",
      "  timesteps_since_restore: 1068600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1068600\n",
      "  training_iteration: 411\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1468 s, 411 iter, 1068600 ts, 483 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-28-17\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 887.7077352087381\n",
      "  episode_reward_mean: 482.1151931016437\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 427\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.762\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.426820158958435\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.4256706865344313e-07\n",
      "        policy_loss: -0.0035062015522271395\n",
      "        total_loss: 23.24089241027832\n",
      "        vf_explained_var: 0.06976455450057983\n",
      "        vf_loss: 23.244396209716797\n",
      "    load_time_ms: 1.031\n",
      "    num_steps_sampled: 1073800\n",
      "    num_steps_trained: 1032500\n",
      "    sample_time_ms: 3335.275\n",
      "    update_time_ms: 3.264\n",
      "  iterations_since_restore: 413\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.55\n",
      "    ram_util_percent: 65.85000000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.181501877353063\n",
      "    mean_inference_ms: 1.002271783659534\n",
      "    mean_processing_ms: 0.703682348059496\n",
      "  time_since_restore: 1474.8817863464355\n",
      "  time_this_iter_s: 3.0004634857177734\n",
      "  time_total_s: 1474.8817863464355\n",
      "  timestamp: 1596122897\n",
      "  timesteps_since_restore: 1073800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1073800\n",
      "  training_iteration: 413\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1474 s, 413 iter, 1073800 ts, 482 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-28-25\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 887.7077352087381\n",
      "  episode_reward_mean: 481.5875849155883\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 429\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.557\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4375299215316772\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 9.952664186130278e-07\n",
      "        policy_loss: 0.00017399883654434234\n",
      "        total_loss: 73.58647155761719\n",
      "        vf_explained_var: 0.028459906578063965\n",
      "        vf_loss: 73.5862808227539\n",
      "    load_time_ms: 1.098\n",
      "    num_steps_sampled: 1079000\n",
      "    num_steps_trained: 1037500\n",
      "    sample_time_ms: 3281.13\n",
      "    update_time_ms: 3.405\n",
      "  iterations_since_restore: 415\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 52.9\n",
      "    ram_util_percent: 65.83333333333333\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.179358785890357\n",
      "    mean_inference_ms: 1.001690242533675\n",
      "    mean_processing_ms: 0.7035459054791001\n",
      "  time_since_restore: 1482.0174598693848\n",
      "  time_this_iter_s: 4.0328049659729\n",
      "  time_total_s: 1482.0174598693848\n",
      "  timestamp: 1596122905\n",
      "  timesteps_since_restore: 1079000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1079000\n",
      "  training_iteration: 415\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1482 s, 415 iter, 1079000 ts, 482 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-28-31\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 887.7077352087381\n",
      "  episode_reward_mean: 481.97718656525393\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 432\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.698\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4254472255706787\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.3436546925381663e-08\n",
      "        policy_loss: 0.0060208081267774105\n",
      "        total_loss: 24.772563934326172\n",
      "        vf_explained_var: 0.06099981069564819\n",
      "        vf_loss: 24.76654815673828\n",
      "    load_time_ms: 1.08\n",
      "    num_steps_sampled: 1084200\n",
      "    num_steps_trained: 1042500\n",
      "    sample_time_ms: 3323.102\n",
      "    update_time_ms: 3.433\n",
      "  iterations_since_restore: 417\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.375\n",
      "    ram_util_percent: 66.0\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.176171882791011\n",
      "    mean_inference_ms: 1.0010846049746236\n",
      "    mean_processing_ms: 0.7033547935868922\n",
      "  time_since_restore: 1488.9010927677155\n",
      "  time_this_iter_s: 2.8091182708740234\n",
      "  time_total_s: 1488.9010927677155\n",
      "  timestamp: 1596122911\n",
      "  timesteps_since_restore: 1084200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1084200\n",
      "  training_iteration: 417\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1488 s, 417 iter, 1084200 ts, 482 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-28-39\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 887.7077352087381\n",
      "  episode_reward_mean: 481.23833705577323\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 433\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.482\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4348286390304565\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.5333853197225835e-06\n",
      "        policy_loss: 0.004597162827849388\n",
      "        total_loss: 53.990604400634766\n",
      "        vf_explained_var: 0.03004544973373413\n",
      "        vf_loss: 53.986019134521484\n",
      "    load_time_ms: 1.077\n",
      "    num_steps_sampled: 1089400\n",
      "    num_steps_trained: 1047500\n",
      "    sample_time_ms: 3443.379\n",
      "    update_time_ms: 3.299\n",
      "  iterations_since_restore: 419\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.94\n",
      "    ram_util_percent: 66.0\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.175134608423028\n",
      "    mean_inference_ms: 1.0008481880704887\n",
      "    mean_processing_ms: 0.7032914993729306\n",
      "  time_since_restore: 1496.2194547653198\n",
      "  time_this_iter_s: 4.084214925765991\n",
      "  time_total_s: 1496.2194547653198\n",
      "  timestamp: 1596122919\n",
      "  timesteps_since_restore: 1089400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1089400\n",
      "  training_iteration: 419\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1496 s, 419 iter, 1089400 ts, 481 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-28-45\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 887.7077352087381\n",
      "  episode_reward_mean: 487.21526015161623\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 437\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.464\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4360655546188354\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.168365302983148e-07\n",
      "        policy_loss: 0.006043345667421818\n",
      "        total_loss: 51.731651306152344\n",
      "        vf_explained_var: 0.053675830364227295\n",
      "        vf_loss: 51.725616455078125\n",
      "    load_time_ms: 1.085\n",
      "    num_steps_sampled: 1094600\n",
      "    num_steps_trained: 1052500\n",
      "    sample_time_ms: 3361.324\n",
      "    update_time_ms: 3.353\n",
      "  iterations_since_restore: 421\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.050000000000004\n",
      "    ram_util_percent: 66.0\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.171232335009638\n",
      "    mean_inference_ms: 1.0000059200296827\n",
      "    mean_processing_ms: 0.7030431972361778\n",
      "  time_since_restore: 1502.6619634628296\n",
      "  time_this_iter_s: 3.572915554046631\n",
      "  time_total_s: 1502.6619634628296\n",
      "  timestamp: 1596122925\n",
      "  timesteps_since_restore: 1094600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1094600\n",
      "  training_iteration: 421\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1502 s, 421 iter, 1094600 ts, 487 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-28-52\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 887.7077352087381\n",
      "  episode_reward_mean: 487.2152601516162\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 437\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.403\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.434415578842163\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.5981673868736834e-06\n",
      "        policy_loss: -0.0024782856926321983\n",
      "        total_loss: 45.8005485534668\n",
      "        vf_explained_var: 0.0587310791015625\n",
      "        vf_loss: 45.80303192138672\n",
      "    load_time_ms: 1.184\n",
      "    num_steps_sampled: 1099800\n",
      "    num_steps_trained: 1057500\n",
      "    sample_time_ms: 3442.531\n",
      "    update_time_ms: 3.918\n",
      "  iterations_since_restore: 423\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.76666666666667\n",
      "    ram_util_percent: 66.11666666666666\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.171232335009638\n",
      "    mean_inference_ms: 1.0000059200296831\n",
      "    mean_processing_ms: 0.7030431972361777\n",
      "  time_since_restore: 1509.6280834674835\n",
      "  time_this_iter_s: 3.8900396823883057\n",
      "  time_total_s: 1509.6280834674835\n",
      "  timestamp: 1596122932\n",
      "  timesteps_since_restore: 1099800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1099800\n",
      "  training_iteration: 423\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1509 s, 423 iter, 1099800 ts, 487 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-28-59\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 887.7077352087381\n",
      "  episode_reward_mean: 487.85040961687844\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 439\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.378\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4369088411331177\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.4183401617628988e-06\n",
      "        policy_loss: 0.0016122210072353482\n",
      "        total_loss: 38.549713134765625\n",
      "        vf_explained_var: 0.049938082695007324\n",
      "        vf_loss: 38.548095703125\n",
      "    load_time_ms: 1.132\n",
      "    num_steps_sampled: 1105000\n",
      "    num_steps_trained: 1062500\n",
      "    sample_time_ms: 3372.283\n",
      "    update_time_ms: 3.754\n",
      "  iterations_since_restore: 425\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.760000000000005\n",
      "    ram_util_percent: 66.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.169386547018175\n",
      "    mean_inference_ms: 0.9995006321204332\n",
      "    mean_processing_ms: 0.7029255413446215\n",
      "  time_since_restore: 1516.0600652694702\n",
      "  time_this_iter_s: 3.3003265857696533\n",
      "  time_total_s: 1516.0600652694702\n",
      "  timestamp: 1596122939\n",
      "  timesteps_since_restore: 1105000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1105000\n",
      "  training_iteration: 425\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1516 s, 425 iter, 1105000 ts, 488 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-29-05\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 887.7077352087381\n",
      "  episode_reward_mean: 487.2737178554975\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 442\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 21.025\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4326759576797485\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 9.579181323715602e-07\n",
      "        policy_loss: -0.0036071320064365864\n",
      "        total_loss: 31.372215270996094\n",
      "        vf_explained_var: 0.057880520820617676\n",
      "        vf_loss: 31.375818252563477\n",
      "    load_time_ms: 1.271\n",
      "    num_steps_sampled: 1110200\n",
      "    num_steps_trained: 1067500\n",
      "    sample_time_ms: 3340.277\n",
      "    update_time_ms: 4.017\n",
      "  iterations_since_restore: 427\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.77499999999999\n",
      "    ram_util_percent: 66.3\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.166610723782998\n",
      "    mean_inference_ms: 0.9989932629420377\n",
      "    mean_processing_ms: 0.7027513684920718\n",
      "  time_since_restore: 1522.6380698680878\n",
      "  time_this_iter_s: 3.0879201889038086\n",
      "  time_total_s: 1522.6380698680878\n",
      "  timestamp: 1596122945\n",
      "  timesteps_since_restore: 1110200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1110200\n",
      "  training_iteration: 427\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 11.0/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1522 s, 427 iter, 1110200 ts, 487 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-29-12\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 887.7077352087381\n",
      "  episode_reward_mean: 485.10934634522835\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 443\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.743\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4493145942687988\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.8808831302740145e-06\n",
      "        policy_loss: -0.0004802923067472875\n",
      "        total_loss: 98.69927215576172\n",
      "        vf_explained_var: 0.011673986911773682\n",
      "        vf_loss: 98.69975280761719\n",
      "    load_time_ms: 1.264\n",
      "    num_steps_sampled: 1115400\n",
      "    num_steps_trained: 1072500\n",
      "    sample_time_ms: 3267.7\n",
      "    update_time_ms: 3.964\n",
      "  iterations_since_restore: 429\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.099999999999994\n",
      "    ram_util_percent: 66.13333333333333\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.165663594728351\n",
      "    mean_inference_ms: 0.9987787569365638\n",
      "    mean_processing_ms: 0.7026937559610197\n",
      "  time_since_restore: 1529.226410150528\n",
      "  time_this_iter_s: 3.536198377609253\n",
      "  time_total_s: 1529.226410150528\n",
      "  timestamp: 1596122952\n",
      "  timesteps_since_restore: 1115400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1115400\n",
      "  training_iteration: 429\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1529 s, 429 iter, 1115400 ts, 485 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-29-19\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 916.2031883288246\n",
      "  episode_reward_mean: 493.9002677404431\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 447\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.76\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4327702522277832\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.8843878681072965e-06\n",
      "        policy_loss: 0.006455085705965757\n",
      "        total_loss: 36.794700622558594\n",
      "        vf_explained_var: 0.060227811336517334\n",
      "        vf_loss: 36.788246154785156\n",
      "    load_time_ms: 1.272\n",
      "    num_steps_sampled: 1120600\n",
      "    num_steps_trained: 1077500\n",
      "    sample_time_ms: 3320.113\n",
      "    update_time_ms: 3.876\n",
      "  iterations_since_restore: 431\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.45\n",
      "    ram_util_percent: 66.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.162099706122809\n",
      "    mean_inference_ms: 0.9980046076829758\n",
      "    mean_processing_ms: 0.7024779111086855\n",
      "  time_since_restore: 1536.1931841373444\n",
      "  time_this_iter_s: 2.970679759979248\n",
      "  time_total_s: 1536.1931841373444\n",
      "  timestamp: 1596122959\n",
      "  timesteps_since_restore: 1120600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1120600\n",
      "  training_iteration: 431\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1536 s, 431 iter, 1120600 ts, 494 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-29-25\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 916.2031883288246\n",
      "  episode_reward_mean: 493.90026774044304\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 447\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.7\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.440413475036621\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.6710978292830987e-06\n",
      "        policy_loss: 0.004087100736796856\n",
      "        total_loss: 87.20063781738281\n",
      "        vf_explained_var: 0.028852760791778564\n",
      "        vf_loss: 87.19656372070312\n",
      "    load_time_ms: 1.181\n",
      "    num_steps_sampled: 1125800\n",
      "    num_steps_trained: 1082500\n",
      "    sample_time_ms: 3248.557\n",
      "    update_time_ms: 3.735\n",
      "  iterations_since_restore: 433\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 65.975\n",
      "    ram_util_percent: 66.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.162099706122808\n",
      "    mean_inference_ms: 0.9980046076829759\n",
      "    mean_processing_ms: 0.7024779111086856\n",
      "  time_since_restore: 1542.44189119339\n",
      "  time_this_iter_s: 3.1965548992156982\n",
      "  time_total_s: 1542.44189119339\n",
      "  timestamp: 1596122965\n",
      "  timesteps_since_restore: 1125800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1125800\n",
      "  training_iteration: 433\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1542 s, 433 iter, 1125800 ts, 494 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-29-32\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 916.2031883288246\n",
      "  episode_reward_mean: 505.90097004164323\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 451\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.098\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4321019649505615\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.209969342307886e-06\n",
      "        policy_loss: -0.002186710247769952\n",
      "        total_loss: 43.12139129638672\n",
      "        vf_explained_var: 0.04397547245025635\n",
      "        vf_loss: 43.123573303222656\n",
      "    load_time_ms: 1.17\n",
      "    num_steps_sampled: 1131000\n",
      "    num_steps_trained: 1087500\n",
      "    sample_time_ms: 3325.211\n",
      "    update_time_ms: 3.836\n",
      "  iterations_since_restore: 435\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.88333333333333\n",
      "    ram_util_percent: 66.10000000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.158589760425854\n",
      "    mean_inference_ms: 0.9971551146157297\n",
      "    mean_processing_ms: 0.7022436178273003\n",
      "  time_since_restore: 1549.6322646141052\n",
      "  time_this_iter_s: 4.077640056610107\n",
      "  time_total_s: 1549.6322646141052\n",
      "  timestamp: 1596122972\n",
      "  timesteps_since_restore: 1131000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1131000\n",
      "  training_iteration: 435\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1549 s, 435 iter, 1131000 ts, 506 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-29-38\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 916.2031883288246\n",
      "  episode_reward_mean: 501.93821518632626\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 452\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.236\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4284179210662842\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.776094210181327e-07\n",
      "        policy_loss: 0.005109558347612619\n",
      "        total_loss: 33.850311279296875\n",
      "        vf_explained_var: 0.0673142671585083\n",
      "        vf_loss: 33.8452033996582\n",
      "    load_time_ms: 1.053\n",
      "    num_steps_sampled: 1136200\n",
      "    num_steps_trained: 1092500\n",
      "    sample_time_ms: 3246.629\n",
      "    update_time_ms: 3.539\n",
      "  iterations_since_restore: 437\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.55\n",
      "    ram_util_percent: 66.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.157706012290959\n",
      "    mean_inference_ms: 0.9970393833611637\n",
      "    mean_processing_ms: 0.7021992332577978\n",
      "  time_since_restore: 1555.4185945987701\n",
      "  time_this_iter_s: 3.039187431335449\n",
      "  time_total_s: 1555.4185945987701\n",
      "  timestamp: 1596122978\n",
      "  timesteps_since_restore: 1136200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1136200\n",
      "  training_iteration: 437\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1555 s, 437 iter, 1136200 ts, 502 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-29-45\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 916.2031883288246\n",
      "  episode_reward_mean: 511.3104816367416\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 455\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.026\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.432273030281067\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.215815586874669e-06\n",
      "        policy_loss: 0.004547293297946453\n",
      "        total_loss: 46.218326568603516\n",
      "        vf_explained_var: 0.04093921184539795\n",
      "        vf_loss: 46.213775634765625\n",
      "    load_time_ms: 1.047\n",
      "    num_steps_sampled: 1141400\n",
      "    num_steps_trained: 1097500\n",
      "    sample_time_ms: 3305.632\n",
      "    update_time_ms: 3.727\n",
      "  iterations_since_restore: 439\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.48333333333333\n",
      "    ram_util_percent: 66.0\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.15516015273861\n",
      "    mean_inference_ms: 0.9965069256885084\n",
      "    mean_processing_ms: 0.7020439481802856\n",
      "  time_since_restore: 1562.596051454544\n",
      "  time_this_iter_s: 3.9957330226898193\n",
      "  time_total_s: 1562.596051454544\n",
      "  timestamp: 1596122985\n",
      "  timesteps_since_restore: 1141400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1141400\n",
      "  training_iteration: 439\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1562 s, 439 iter, 1141400 ts, 511 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-29-51\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 916.2031883288246\n",
      "  episode_reward_mean: 510.9176021820589\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 456\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.172\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.429500699043274\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.4461746761517134e-07\n",
      "        policy_loss: -0.0035251679364591837\n",
      "        total_loss: 61.60481262207031\n",
      "        vf_explained_var: 0.04718106985092163\n",
      "        vf_loss: 61.60833740234375\n",
      "    load_time_ms: 1.044\n",
      "    num_steps_sampled: 1146600\n",
      "    num_steps_trained: 1102500\n",
      "    sample_time_ms: 3211.664\n",
      "    update_time_ms: 3.744\n",
      "  iterations_since_restore: 441\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.1\n",
      "    ram_util_percent: 66.03999999999999\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.154304236477552\n",
      "    mean_inference_ms: 0.996212368362493\n",
      "    mean_processing_ms: 0.7019880364040273\n",
      "  time_since_restore: 1568.6243572235107\n",
      "  time_this_iter_s: 3.0140480995178223\n",
      "  time_total_s: 1568.6243572235107\n",
      "  timestamp: 1596122991\n",
      "  timesteps_since_restore: 1146600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1146600\n",
      "  training_iteration: 441\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1568 s, 441 iter, 1146600 ts, 511 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-29-58\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 916.2031883288246\n",
      "  episode_reward_mean: 512.095512002254\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 457\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.768\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4357457160949707\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 9.845495441140883e-08\n",
      "        policy_loss: -0.004830297082662582\n",
      "        total_loss: 88.9481201171875\n",
      "        vf_explained_var: 0.035809338092803955\n",
      "        vf_loss: 88.95294189453125\n",
      "    load_time_ms: 1.09\n",
      "    num_steps_sampled: 1151800\n",
      "    num_steps_trained: 1107500\n",
      "    sample_time_ms: 3213.054\n",
      "    update_time_ms: 3.466\n",
      "  iterations_since_restore: 443\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.4\n",
      "    ram_util_percent: 66.0\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.153468968249659\n",
      "    mean_inference_ms: 0.9961079482907123\n",
      "    mean_processing_ms: 0.7019440664480243\n",
      "  time_since_restore: 1574.8919417858124\n",
      "  time_this_iter_s: 3.0329840183258057\n",
      "  time_total_s: 1574.8919417858124\n",
      "  timestamp: 1596122998\n",
      "  timesteps_since_restore: 1151800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1151800\n",
      "  training_iteration: 443\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1574 s, 443 iter, 1151800 ts, 512 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-30-04\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1041.0804019138245\n",
      "  episode_reward_mean: 519.0718806644009\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 461\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 21.555\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4265838861465454\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.86247438150167e-07\n",
      "        policy_loss: -0.00025873060803860426\n",
      "        total_loss: 32.122276306152344\n",
      "        vf_explained_var: 0.06751573085784912\n",
      "        vf_loss: 32.12253952026367\n",
      "    load_time_ms: 1.103\n",
      "    num_steps_sampled: 1157000\n",
      "    num_steps_trained: 1112500\n",
      "    sample_time_ms: 3171.172\n",
      "    update_time_ms: 3.454\n",
      "  iterations_since_restore: 445\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.13333333333333\n",
      "    ram_util_percent: 66.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.150224521673889\n",
      "    mean_inference_ms: 0.995325332444205\n",
      "    mean_processing_ms: 0.7017336927592314\n",
      "  time_since_restore: 1581.6724841594696\n",
      "  time_this_iter_s: 2.6589794158935547\n",
      "  time_total_s: 1581.6724841594696\n",
      "  timestamp: 1596123004\n",
      "  timesteps_since_restore: 1157000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1157000\n",
      "  training_iteration: 445\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1581 s, 445 iter, 1157000 ts, 519 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-30-11\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1041.0804019138245\n",
      "  episode_reward_mean: 518.727246731502\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 462\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.812\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4346015453338623\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.550410383468261e-07\n",
      "        policy_loss: 0.0027987996581941843\n",
      "        total_loss: 62.65366744995117\n",
      "        vf_explained_var: 0.011856496334075928\n",
      "        vf_loss: 62.6508674621582\n",
      "    load_time_ms: 1.095\n",
      "    num_steps_sampled: 1162200\n",
      "    num_steps_trained: 1117500\n",
      "    sample_time_ms: 3245.84\n",
      "    update_time_ms: 3.563\n",
      "  iterations_since_restore: 447\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.2\n",
      "    ram_util_percent: 66.05999999999999\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.149429740243937\n",
      "    mean_inference_ms: 0.9952314945569158\n",
      "    mean_processing_ms: 0.7016922336612396\n",
      "  time_since_restore: 1588.1979620456696\n",
      "  time_this_iter_s: 3.4153692722320557\n",
      "  time_total_s: 1588.1979620456696\n",
      "  timestamp: 1596123011\n",
      "  timesteps_since_restore: 1162200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1162200\n",
      "  training_iteration: 447\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1588 s, 447 iter, 1162200 ts, 519 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-30-18\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1041.0804019138245\n",
      "  episode_reward_mean: 521.0029288833633\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 465\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 21.028\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4282758235931396\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.347656267280399e-07\n",
      "        policy_loss: 0.0002872980257961899\n",
      "        total_loss: 27.427513122558594\n",
      "        vf_explained_var: 0.07663601636886597\n",
      "        vf_loss: 27.427221298217773\n",
      "    load_time_ms: 1.102\n",
      "    num_steps_sampled: 1167400\n",
      "    num_steps_trained: 1122500\n",
      "    sample_time_ms: 3231.376\n",
      "    update_time_ms: 3.334\n",
      "  iterations_since_restore: 449\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.25\n",
      "    ram_util_percent: 66.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.14692335247539\n",
      "    mean_inference_ms: 0.9946774569344224\n",
      "    mean_processing_ms: 0.7015176902671274\n",
      "  time_since_restore: 1595.2310037612915\n",
      "  time_this_iter_s: 2.90407657623291\n",
      "  time_total_s: 1595.2310037612915\n",
      "  timestamp: 1596123018\n",
      "  timesteps_since_restore: 1167400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1167400\n",
      "  training_iteration: 449\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1595 s, 449 iter, 1167400 ts, 521 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-30-25\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1041.0804019138245\n",
      "  episode_reward_mean: 521.0752750239835\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 466\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 21.704\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4303947687149048\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.5948027604936215e-07\n",
      "        policy_loss: -0.00048512229113839567\n",
      "        total_loss: 41.32110595703125\n",
      "        vf_explained_var: 0.0533100962638855\n",
      "        vf_loss: 41.321590423583984\n",
      "    load_time_ms: 1.167\n",
      "    num_steps_sampled: 1172600\n",
      "    num_steps_trained: 1127500\n",
      "    sample_time_ms: 3288.136\n",
      "    update_time_ms: 3.74\n",
      "  iterations_since_restore: 451\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 69.175\n",
      "    ram_util_percent: 65.7\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.146270894191865\n",
      "    mean_inference_ms: 0.9944713145766199\n",
      "    mean_processing_ms: 0.7015019834885632\n",
      "  time_since_restore: 1601.843534708023\n",
      "  time_this_iter_s: 3.274984121322632\n",
      "  time_total_s: 1601.843534708023\n",
      "  timestamp: 1596123025\n",
      "  timesteps_since_restore: 1172600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1172600\n",
      "  training_iteration: 451\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1601 s, 451 iter, 1172600 ts, 521 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-30-31\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1041.0804019138245\n",
      "  episode_reward_mean: 516.3273215557368\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 469\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.847\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4335817098617554\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.162788513895066e-07\n",
      "        policy_loss: -0.0009042262099683285\n",
      "        total_loss: 57.82152557373047\n",
      "        vf_explained_var: 0.0520402193069458\n",
      "        vf_loss: 57.822418212890625\n",
      "    load_time_ms: 1.132\n",
      "    num_steps_sampled: 1177800\n",
      "    num_steps_trained: 1132500\n",
      "    sample_time_ms: 3308.625\n",
      "    update_time_ms: 3.741\n",
      "  iterations_since_restore: 453\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.82000000000001\n",
      "    ram_util_percent: 65.7\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.143782747801047\n",
      "    mean_inference_ms: 0.994000010160611\n",
      "    mean_processing_ms: 0.7013290327472107\n",
      "  time_since_restore: 1608.3057079315186\n",
      "  time_this_iter_s: 3.2393624782562256\n",
      "  time_total_s: 1608.3057079315186\n",
      "  timestamp: 1596123031\n",
      "  timesteps_since_restore: 1177800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1177800\n",
      "  training_iteration: 453\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1608 s, 453 iter, 1177800 ts, 516 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-30-38\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1041.0804019138245\n",
      "  episode_reward_mean: 516.7881742043733\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 471\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.55\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.429844617843628\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.6709309370053234e-07\n",
      "        policy_loss: 0.0034066273365169764\n",
      "        total_loss: 41.31282424926758\n",
      "        vf_explained_var: 0.06145453453063965\n",
      "        vf_loss: 41.309425354003906\n",
      "    load_time_ms: 1.201\n",
      "    num_steps_sampled: 1183000\n",
      "    num_steps_trained: 1137500\n",
      "    sample_time_ms: 3332.726\n",
      "    update_time_ms: 3.729\n",
      "  iterations_since_restore: 455\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.125\n",
      "    ram_util_percent: 65.8\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.142239000570758\n",
      "    mean_inference_ms: 0.9936740074280705\n",
      "    mean_processing_ms: 0.7012267318089939\n",
      "  time_since_restore: 1615.3222408294678\n",
      "  time_this_iter_s: 2.7555525302886963\n",
      "  time_total_s: 1615.3222408294678\n",
      "  timestamp: 1596123038\n",
      "  timesteps_since_restore: 1183000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1183000\n",
      "  training_iteration: 455\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1615 s, 455 iter, 1183000 ts, 517 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-30-45\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1041.0804019138245\n",
      "  episode_reward_mean: 522.2503074702138\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 474\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.436\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4371898174285889\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.062247171532363e-06\n",
      "        policy_loss: -0.0005674300482496619\n",
      "        total_loss: 53.99492645263672\n",
      "        vf_explained_var: 0.03458482027053833\n",
      "        vf_loss: 53.995487213134766\n",
      "    load_time_ms: 1.207\n",
      "    num_steps_sampled: 1188200\n",
      "    num_steps_trained: 1142500\n",
      "    sample_time_ms: 3402.205\n",
      "    update_time_ms: 3.737\n",
      "  iterations_since_restore: 457\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.68333333333334\n",
      "    ram_util_percent: 65.84999999999998\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.140190090319314\n",
      "    mean_inference_ms: 0.9932598928026881\n",
      "    mean_processing_ms: 0.7011551778295333\n",
      "  time_since_restore: 1622.5419936180115\n",
      "  time_this_iter_s: 4.146392107009888\n",
      "  time_total_s: 1622.5419936180115\n",
      "  timestamp: 1596123045\n",
      "  timesteps_since_restore: 1188200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1188200\n",
      "  training_iteration: 457\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1622 s, 457 iter, 1188200 ts, 522 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-30-52\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1041.0804019138245\n",
      "  episode_reward_mean: 517.3703364887816\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 476\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.273\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4305789470672607\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.8392542478504765e-07\n",
      "        policy_loss: -0.0023762150667607784\n",
      "        total_loss: 18.32463836669922\n",
      "        vf_explained_var: 0.06080871820449829\n",
      "        vf_loss: 18.327014923095703\n",
      "    load_time_ms: 1.21\n",
      "    num_steps_sampled: 1193400\n",
      "    num_steps_trained: 1147500\n",
      "    sample_time_ms: 3359.431\n",
      "    update_time_ms: 3.829\n",
      "  iterations_since_restore: 459\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 52.42\n",
      "    ram_util_percent: 65.9\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.1389221761417305\n",
      "    mean_inference_ms: 0.9928503237199184\n",
      "    mean_processing_ms: 0.7010369159356681\n",
      "  time_since_restore: 1629.145975112915\n",
      "  time_this_iter_s: 3.9394052028656006\n",
      "  time_total_s: 1629.145975112915\n",
      "  timestamp: 1596123052\n",
      "  timesteps_since_restore: 1193400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1193400\n",
      "  training_iteration: 459\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1629 s, 459 iter, 1193400 ts, 517 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-30-58\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1041.0804019138245\n",
      "  episode_reward_mean: 517.3703364887816\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 476\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.71\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4323277473449707\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.373477733883192e-07\n",
      "        policy_loss: -0.006173980887979269\n",
      "        total_loss: 35.0867919921875\n",
      "        vf_explained_var: 0.015174448490142822\n",
      "        vf_loss: 35.09296417236328\n",
      "    load_time_ms: 1.155\n",
      "    num_steps_sampled: 1198600\n",
      "    num_steps_trained: 1152500\n",
      "    sample_time_ms: 3309.24\n",
      "    update_time_ms: 3.44\n",
      "  iterations_since_restore: 461\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.8\n",
      "    ram_util_percent: 65.8\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.1389221761417305\n",
      "    mean_inference_ms: 0.9928503237199183\n",
      "    mean_processing_ms: 0.7010369159356682\n",
      "  time_since_restore: 1635.2423212528229\n",
      "  time_this_iter_s: 3.124232053756714\n",
      "  time_total_s: 1635.2423212528229\n",
      "  timestamp: 1596123058\n",
      "  timesteps_since_restore: 1198600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1198600\n",
      "  training_iteration: 461\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1635 s, 461 iter, 1198600 ts, 517 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-31-06\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1041.0804019138245\n",
      "  episode_reward_mean: 507.73784549237985\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 480\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.678\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4320244789123535\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.418518079139176e-07\n",
      "        policy_loss: 0.0042881108820438385\n",
      "        total_loss: 36.563114166259766\n",
      "        vf_explained_var: 0.05828136205673218\n",
      "        vf_loss: 36.558834075927734\n",
      "    load_time_ms: 1.118\n",
      "    num_steps_sampled: 1203800\n",
      "    num_steps_trained: 1157500\n",
      "    sample_time_ms: 3480.024\n",
      "    update_time_ms: 3.257\n",
      "  iterations_since_restore: 463\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.63333333333333\n",
      "    ram_util_percent: 65.8\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.1358627501703715\n",
      "    mean_inference_ms: 0.9923877934802041\n",
      "    mean_processing_ms: 0.7009131037043415\n",
      "  time_since_restore: 1643.3962576389313\n",
      "  time_this_iter_s: 4.006792783737183\n",
      "  time_total_s: 1643.3962576389313\n",
      "  timestamp: 1596123066\n",
      "  timesteps_since_restore: 1203800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1203800\n",
      "  training_iteration: 463\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1643 s, 463 iter, 1203800 ts, 508 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-31-12\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1041.0804019138245\n",
      "  episode_reward_mean: 510.27107275134125\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 481\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.414\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4307706356048584\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.465103131678916e-07\n",
      "        policy_loss: -0.0002189710648963228\n",
      "        total_loss: 36.817203521728516\n",
      "        vf_explained_var: 0.05492669343948364\n",
      "        vf_loss: 36.81742858886719\n",
      "    load_time_ms: 1.077\n",
      "    num_steps_sampled: 1209000\n",
      "    num_steps_trained: 1162500\n",
      "    sample_time_ms: 3380.911\n",
      "    update_time_ms: 3.272\n",
      "  iterations_since_restore: 465\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.625\n",
      "    ram_util_percent: 65.7\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.135374669242839\n",
      "    mean_inference_ms: 0.9922357420399317\n",
      "    mean_processing_ms: 0.7008522942694989\n",
      "  time_since_restore: 1649.419103384018\n",
      "  time_this_iter_s: 3.0555312633514404\n",
      "  time_total_s: 1649.419103384018\n",
      "  timestamp: 1596123072\n",
      "  timesteps_since_restore: 1209000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1209000\n",
      "  training_iteration: 465\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1649 s, 465 iter, 1209000 ts, 510 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-31-20\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1041.0804019138245\n",
      "  episode_reward_mean: 512.4778181848292\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 484\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.438\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4387837648391724\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.778748082870152e-05\n",
      "        policy_loss: -0.0030668287072330713\n",
      "        total_loss: 80.25440216064453\n",
      "        vf_explained_var: 0.03026902675628662\n",
      "        vf_loss: 80.25746154785156\n",
      "    load_time_ms: 1.079\n",
      "    num_steps_sampled: 1214200\n",
      "    num_steps_trained: 1167500\n",
      "    sample_time_ms: 3403.429\n",
      "    update_time_ms: 3.204\n",
      "  iterations_since_restore: 467\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.616666666666674\n",
      "    ram_util_percent: 65.8\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.13305960340075\n",
      "    mean_inference_ms: 0.9918068060843042\n",
      "    mean_processing_ms: 0.7006908305932049\n",
      "  time_since_restore: 1656.8634445667267\n",
      "  time_this_iter_s: 4.317154169082642\n",
      "  time_total_s: 1656.8634445667267\n",
      "  timestamp: 1596123080\n",
      "  timesteps_since_restore: 1214200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1214200\n",
      "  training_iteration: 467\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1656 s, 467 iter, 1214200 ts, 512 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-31-26\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1041.0804019138245\n",
      "  episode_reward_mean: 515.2055178053968\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 486\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.651\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4252684116363525\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.2394657150925923e-07\n",
      "        policy_loss: 0.0007853957358747721\n",
      "        total_loss: 17.968029022216797\n",
      "        vf_explained_var: 0.06799435615539551\n",
      "        vf_loss: 17.967243194580078\n",
      "    load_time_ms: 1.081\n",
      "    num_steps_sampled: 1219400\n",
      "    num_steps_trained: 1172500\n",
      "    sample_time_ms: 3374.083\n",
      "    update_time_ms: 3.143\n",
      "  iterations_since_restore: 469\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.44\n",
      "    ram_util_percent: 65.8\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.131786397437025\n",
      "    mean_inference_ms: 0.9914752320953311\n",
      "    mean_processing_ms: 0.7006323507693744\n",
      "  time_since_restore: 1663.1762051582336\n",
      "  time_this_iter_s: 3.3602194786071777\n",
      "  time_total_s: 1663.1762051582336\n",
      "  timestamp: 1596123086\n",
      "  timesteps_since_restore: 1219400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1219400\n",
      "  training_iteration: 469\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1663 s, 469 iter, 1219400 ts, 515 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-31-32\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1041.0804019138245\n",
      "  episode_reward_mean: 515.2055178053968\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 486\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.905\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.431091070175171\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.8726329876226373e-07\n",
      "        policy_loss: 0.0034921085461974144\n",
      "        total_loss: 39.48427963256836\n",
      "        vf_explained_var: 0.01826411485671997\n",
      "        vf_loss: 39.48079299926758\n",
      "    load_time_ms: 1.094\n",
      "    num_steps_sampled: 1224600\n",
      "    num_steps_trained: 1177500\n",
      "    sample_time_ms: 3361.13\n",
      "    update_time_ms: 3.184\n",
      "  iterations_since_restore: 471\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.675000000000004\n",
      "    ram_util_percent: 65.775\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.131786397437024\n",
      "    mean_inference_ms: 0.9914752320953311\n",
      "    mean_processing_ms: 0.7006323507693744\n",
      "  time_since_restore: 1669.1458954811096\n",
      "  time_this_iter_s: 2.946864366531372\n",
      "  time_total_s: 1669.1458954811096\n",
      "  timestamp: 1596123092\n",
      "  timesteps_since_restore: 1224600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1224600\n",
      "  training_iteration: 471\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1669 s, 471 iter, 1224600 ts, 515 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-31-39\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1041.0804019138245\n",
      "  episode_reward_mean: 512.3162945059663\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 491\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 21.448\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4306401014328003\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 7.519483347095957e-07\n",
      "        policy_loss: -0.0063019804656505585\n",
      "        total_loss: 43.89281463623047\n",
      "        vf_explained_var: 0.05241519212722778\n",
      "        vf_loss: 43.89912033081055\n",
      "    load_time_ms: 1.176\n",
      "    num_steps_sampled: 1229800\n",
      "    num_steps_trained: 1182500\n",
      "    sample_time_ms: 3238.424\n",
      "    update_time_ms: 3.196\n",
      "  iterations_since_restore: 473\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.75\n",
      "    ram_util_percent: 65.7\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.128133657765224\n",
      "    mean_inference_ms: 0.9907764600445905\n",
      "    mean_processing_ms: 0.7003912464634813\n",
      "  time_since_restore: 1676.1058614253998\n",
      "  time_this_iter_s: 3.329158306121826\n",
      "  time_total_s: 1676.1058614253998\n",
      "  timestamp: 1596123099\n",
      "  timesteps_since_restore: 1229800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1229800\n",
      "  training_iteration: 473\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1676 s, 473 iter, 1229800 ts, 512 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-31-45\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1041.0804019138245\n",
      "  episode_reward_mean: 512.3162945059663\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 491\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 21.444\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4291239976882935\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.0076503776399477e-07\n",
      "        policy_loss: 0.0040915054269135\n",
      "        total_loss: 40.92748260498047\n",
      "        vf_explained_var: 0.032634198665618896\n",
      "        vf_loss: 40.923397064208984\n",
      "    load_time_ms: 1.151\n",
      "    num_steps_sampled: 1235000\n",
      "    num_steps_trained: 1187500\n",
      "    sample_time_ms: 3236.332\n",
      "    update_time_ms: 3.673\n",
      "  iterations_since_restore: 475\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.325\n",
      "    ram_util_percent: 65.7\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.128133657765224\n",
      "    mean_inference_ms: 0.9907764600445904\n",
      "    mean_processing_ms: 0.7003912464634813\n",
      "  time_since_restore: 1682.114507675171\n",
      "  time_this_iter_s: 3.0224039554595947\n",
      "  time_total_s: 1682.114507675171\n",
      "  timestamp: 1596123105\n",
      "  timesteps_since_restore: 1235000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1235000\n",
      "  training_iteration: 475\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1682 s, 475 iter, 1235000 ts, 512 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-31-53\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1041.0804019138245\n",
      "  episode_reward_mean: 505.77788404535016\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 494\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 21.616\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4396840333938599\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.222486490514711e-07\n",
      "        policy_loss: 0.00399069394916296\n",
      "        total_loss: 87.12476348876953\n",
      "        vf_explained_var: 0.03663414716720581\n",
      "        vf_loss: 87.12077331542969\n",
      "    load_time_ms: 1.158\n",
      "    num_steps_sampled: 1240200\n",
      "    num_steps_trained: 1192500\n",
      "    sample_time_ms: 3278.862\n",
      "    update_time_ms: 3.652\n",
      "  iterations_since_restore: 477\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.08\n",
      "    ram_util_percent: 65.82000000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.125914192535792\n",
      "    mean_inference_ms: 0.9902279542934237\n",
      "    mean_processing_ms: 0.7002961190606217\n",
      "  time_since_restore: 1689.9863638877869\n",
      "  time_this_iter_s: 3.7088873386383057\n",
      "  time_total_s: 1689.9863638877869\n",
      "  timestamp: 1596123113\n",
      "  timesteps_since_restore: 1240200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1240200\n",
      "  training_iteration: 477\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1689 s, 477 iter, 1240200 ts, 506 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-31-59\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1041.0804019138245\n",
      "  episode_reward_mean: 509.17345309164523\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 496\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 22.18\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.425751805305481\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.2862425314306165e-07\n",
      "        policy_loss: 0.001478748396039009\n",
      "        total_loss: 25.45656967163086\n",
      "        vf_explained_var: 0.03148704767227173\n",
      "        vf_loss: 25.455093383789062\n",
      "    load_time_ms: 1.265\n",
      "    num_steps_sampled: 1245400\n",
      "    num_steps_trained: 1197500\n",
      "    sample_time_ms: 3273.52\n",
      "    update_time_ms: 3.74\n",
      "  iterations_since_restore: 479\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.35\n",
      "    ram_util_percent: 65.9\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.124763502746308\n",
      "    mean_inference_ms: 0.9899402223437392\n",
      "    mean_processing_ms: 0.7001844749039422\n",
      "  time_since_restore: 1696.2551584243774\n",
      "  time_this_iter_s: 3.125919818878174\n",
      "  time_total_s: 1696.2551584243774\n",
      "  timestamp: 1596123119\n",
      "  timesteps_since_restore: 1245400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1245400\n",
      "  training_iteration: 479\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1696 s, 479 iter, 1245400 ts, 509 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-32-05\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1041.0804019138245\n",
      "  episode_reward_mean: 509.17345309164523\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 496\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 21.987\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4372938871383667\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.0757922837001388e-06\n",
      "        policy_loss: 0.004735284019261599\n",
      "        total_loss: 53.98818588256836\n",
      "        vf_explained_var: 0.01119321584701538\n",
      "        vf_loss: 53.983463287353516\n",
      "    load_time_ms: 1.247\n",
      "    num_steps_sampled: 1250600\n",
      "    num_steps_trained: 1202500\n",
      "    sample_time_ms: 3259.53\n",
      "    update_time_ms: 3.8\n",
      "  iterations_since_restore: 481\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.379999999999995\n",
      "    ram_util_percent: 65.84\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.124763502746308\n",
      "    mean_inference_ms: 0.9899402223437392\n",
      "    mean_processing_ms: 0.7001844749039422\n",
      "  time_since_restore: 1702.0828840732574\n",
      "  time_this_iter_s: 2.8918545246124268\n",
      "  time_total_s: 1702.0828840732574\n",
      "  timestamp: 1596123125\n",
      "  timesteps_since_restore: 1250600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1250600\n",
      "  training_iteration: 481\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1702 s, 481 iter, 1250600 ts, 509 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-32-12\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1041.0804019138245\n",
      "  episode_reward_mean: 508.81192740342755\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 501\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.292\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4234384298324585\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 7.510423642997921e-07\n",
      "        policy_loss: -0.0040715825743973255\n",
      "        total_loss: 7.285261154174805\n",
      "        vf_explained_var: 0.06297540664672852\n",
      "        vf_loss: 7.289332866668701\n",
      "    load_time_ms: 1.216\n",
      "    num_steps_sampled: 1255800\n",
      "    num_steps_trained: 1207500\n",
      "    sample_time_ms: 3270.879\n",
      "    update_time_ms: 3.799\n",
      "  iterations_since_restore: 483\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.64\n",
      "    ram_util_percent: 65.88\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.121198702212178\n",
      "    mean_inference_ms: 0.9892330674580794\n",
      "    mean_processing_ms: 0.6999939046955\n",
      "  time_since_restore: 1709.1325409412384\n",
      "  time_this_iter_s: 2.950988531112671\n",
      "  time_total_s: 1709.1325409412384\n",
      "  timestamp: 1596123132\n",
      "  timesteps_since_restore: 1255800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1255800\n",
      "  training_iteration: 483\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1709 s, 483 iter, 1255800 ts, 509 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-32-18\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1041.0804019138245\n",
      "  episode_reward_mean: 508.81192740342755\n",
      "  episode_reward_min: 143.86014310313982\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 501\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.027\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.434259295463562\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.1985301284767047e-07\n",
      "        policy_loss: -0.003753701690584421\n",
      "        total_loss: 38.06419372558594\n",
      "        vf_explained_var: 0.015060961246490479\n",
      "        vf_loss: 38.06795120239258\n",
      "    load_time_ms: 1.212\n",
      "    num_steps_sampled: 1261000\n",
      "    num_steps_trained: 1212500\n",
      "    sample_time_ms: 3259.029\n",
      "    update_time_ms: 3.251\n",
      "  iterations_since_restore: 485\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.425\n",
      "    ram_util_percent: 65.95\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.121198702212178\n",
      "    mean_inference_ms: 0.9892330674580794\n",
      "    mean_processing_ms: 0.6999939046955\n",
      "  time_since_restore: 1715.011962890625\n",
      "  time_this_iter_s: 2.896536111831665\n",
      "  time_total_s: 1715.011962890625\n",
      "  timestamp: 1596123138\n",
      "  timesteps_since_restore: 1261000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1261000\n",
      "  training_iteration: 485\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1715 s, 485 iter, 1261000 ts, 509 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-32-24\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1041.0804019138245\n",
      "  episode_reward_mean: 506.0254094426237\n",
      "  episode_reward_min: 180.00220783926667\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 506\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.962\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4330731630325317\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.044983820174821e-07\n",
      "        policy_loss: -0.001496205572038889\n",
      "        total_loss: 30.210086822509766\n",
      "        vf_explained_var: 0.05787694454193115\n",
      "        vf_loss: 30.21158218383789\n",
      "    load_time_ms: 1.205\n",
      "    num_steps_sampled: 1266200\n",
      "    num_steps_trained: 1217500\n",
      "    sample_time_ms: 3106.143\n",
      "    update_time_ms: 3.264\n",
      "  iterations_since_restore: 487\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.8\n",
      "    ram_util_percent: 65.9\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.118217520401896\n",
      "    mean_inference_ms: 0.988687252050624\n",
      "    mean_processing_ms: 0.6997598421890245\n",
      "  time_since_restore: 1721.3541147708893\n",
      "  time_this_iter_s: 3.602428674697876\n",
      "  time_total_s: 1721.3541147708893\n",
      "  timestamp: 1596123144\n",
      "  timesteps_since_restore: 1266200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1266200\n",
      "  training_iteration: 487\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1721 s, 487 iter, 1266200 ts, 506 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-32-30\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1041.0804019138245\n",
      "  episode_reward_mean: 506.02540944262364\n",
      "  episode_reward_min: 180.00220783926667\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 506\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.069\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4315464496612549\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.2949466281497735e-06\n",
      "        policy_loss: 0.0018332034815102816\n",
      "        total_loss: 41.12474822998047\n",
      "        vf_explained_var: 0.028237342834472656\n",
      "        vf_loss: 41.12290573120117\n",
      "    load_time_ms: 1.148\n",
      "    num_steps_sampled: 1271400\n",
      "    num_steps_trained: 1222500\n",
      "    sample_time_ms: 3035.494\n",
      "    update_time_ms: 3.187\n",
      "  iterations_since_restore: 489\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.349999999999994\n",
      "    ram_util_percent: 65.82499999999999\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.118217520401896\n",
      "    mean_inference_ms: 0.9886872520506244\n",
      "    mean_processing_ms: 0.6997598421890244\n",
      "  time_since_restore: 1726.914332151413\n",
      "  time_this_iter_s: 2.891456127166748\n",
      "  time_total_s: 1726.914332151413\n",
      "  timestamp: 1596123150\n",
      "  timesteps_since_restore: 1271400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1271400\n",
      "  training_iteration: 489\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1726 s, 489 iter, 1271400 ts, 506 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-32-37\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1041.0804019138245\n",
      "  episode_reward_mean: 513.980066570402\n",
      "  episode_reward_min: 194.0640247316132\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 508\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.758\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4459328651428223\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.0725608464999823e-06\n",
      "        policy_loss: 0.0015242703957483172\n",
      "        total_loss: 78.97840118408203\n",
      "        vf_explained_var: 0.015807151794433594\n",
      "        vf_loss: 78.97688293457031\n",
      "    load_time_ms: 1.14\n",
      "    num_steps_sampled: 1276600\n",
      "    num_steps_trained: 1227500\n",
      "    sample_time_ms: 3160.916\n",
      "    update_time_ms: 3.192\n",
      "  iterations_since_restore: 491\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.33333333333334\n",
      "    ram_util_percent: 66.0\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.116848357705815\n",
      "    mean_inference_ms: 0.988390577142941\n",
      "    mean_processing_ms: 0.699671277716571\n",
      "  time_since_restore: 1733.9922947883606\n",
      "  time_this_iter_s: 4.002268552780151\n",
      "  time_total_s: 1733.9922947883606\n",
      "  timestamp: 1596123157\n",
      "  timesteps_since_restore: 1276600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1276600\n",
      "  training_iteration: 491\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1733 s, 491 iter, 1276600 ts, 514 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-32-44\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1041.0804019138245\n",
      "  episode_reward_mean: 508.72140427406043\n",
      "  episode_reward_min: 194.0640247316132\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 511\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.696\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4289970397949219\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.1682202335287e-08\n",
      "        policy_loss: 0.00526754604652524\n",
      "        total_loss: 53.27235794067383\n",
      "        vf_explained_var: 0.03955554962158203\n",
      "        vf_loss: 53.26707458496094\n",
      "    load_time_ms: 1.071\n",
      "    num_steps_sampled: 1281800\n",
      "    num_steps_trained: 1232500\n",
      "    sample_time_ms: 3128.939\n",
      "    update_time_ms: 3.147\n",
      "  iterations_since_restore: 493\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.5\n",
      "    ram_util_percent: 66.025\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.115137567776651\n",
      "    mean_inference_ms: 0.988042287578038\n",
      "    mean_processing_ms: 0.6995582860465797\n",
      "  time_since_restore: 1740.709030866623\n",
      "  time_this_iter_s: 2.5747909545898438\n",
      "  time_total_s: 1740.709030866623\n",
      "  timestamp: 1596123164\n",
      "  timesteps_since_restore: 1281800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1281800\n",
      "  training_iteration: 493\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1740 s, 493 iter, 1281800 ts, 509 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-32-51\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1041.0804019138245\n",
      "  episode_reward_mean: 504.9593507036851\n",
      "  episode_reward_min: 194.0640247316132\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 512\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.556\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4402899742126465\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.2711029689380666e-06\n",
      "        policy_loss: -0.005037432070821524\n",
      "        total_loss: 67.39149475097656\n",
      "        vf_explained_var: 0.021406471729278564\n",
      "        vf_loss: 67.39653778076172\n",
      "    load_time_ms: 1.076\n",
      "    num_steps_sampled: 1287000\n",
      "    num_steps_trained: 1237500\n",
      "    sample_time_ms: 3231.724\n",
      "    update_time_ms: 3.138\n",
      "  iterations_since_restore: 495\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 43.03333333333333\n",
      "    ram_util_percent: 66.0\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.114432671585008\n",
      "    mean_inference_ms: 0.9878838872838374\n",
      "    mean_processing_ms: 0.6995107798528507\n",
      "  time_since_restore: 1747.6147663593292\n",
      "  time_this_iter_s: 3.804988384246826\n",
      "  time_total_s: 1747.6147663593292\n",
      "  timestamp: 1596123171\n",
      "  timesteps_since_restore: 1287000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1287000\n",
      "  training_iteration: 495\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1747 s, 495 iter, 1287000 ts, 505 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-32-57\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 510.54663672902444\n",
      "  episode_reward_min: 194.0640247316132\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 515\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.321\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4299802780151367\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.653764579780727e-08\n",
      "        policy_loss: 0.0009779413230717182\n",
      "        total_loss: 19.90959930419922\n",
      "        vf_explained_var: 0.048623085021972656\n",
      "        vf_loss: 19.90862464904785\n",
      "    load_time_ms: 1.068\n",
      "    num_steps_sampled: 1292200\n",
      "    num_steps_trained: 1242500\n",
      "    sample_time_ms: 3228.678\n",
      "    update_time_ms: 3.047\n",
      "  iterations_since_restore: 497\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.825\n",
      "    ram_util_percent: 65.9\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.112940793780601\n",
      "    mean_inference_ms: 0.9876621161861382\n",
      "    mean_processing_ms: 0.6994165564751126\n",
      "  time_since_restore: 1753.9230444431305\n",
      "  time_this_iter_s: 2.7597994804382324\n",
      "  time_total_s: 1753.9230444431305\n",
      "  timestamp: 1596123177\n",
      "  timesteps_since_restore: 1292200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1292200\n",
      "  training_iteration: 497\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1753 s, 497 iter, 1292200 ts, 511 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-33-02\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 509.31077265497413\n",
      "  episode_reward_min: 194.0640247316132\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 516\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.957\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4336843490600586\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.7989635807680315e-06\n",
      "        policy_loss: 0.0042733559384942055\n",
      "        total_loss: 38.30527877807617\n",
      "        vf_explained_var: 0.030615925788879395\n",
      "        vf_loss: 38.3010139465332\n",
      "    load_time_ms: 1.031\n",
      "    num_steps_sampled: 1297400\n",
      "    num_steps_trained: 1247500\n",
      "    sample_time_ms: 3222.726\n",
      "    update_time_ms: 3.081\n",
      "  iterations_since_restore: 499\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.86666666666667\n",
      "    ram_util_percent: 65.9\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.1118901894174975\n",
      "    mean_inference_ms: 0.9873504843632354\n",
      "    mean_processing_ms: 0.6993490366903045\n",
      "  time_since_restore: 1759.4216737747192\n",
      "  time_this_iter_s: 2.725078582763672\n",
      "  time_total_s: 1759.4216737747192\n",
      "  timestamp: 1596123182\n",
      "  timesteps_since_restore: 1297400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1297400\n",
      "  training_iteration: 499\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1759 s, 499 iter, 1297400 ts, 509 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-33-09\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 512.1591667245526\n",
      "  episode_reward_min: 194.0640247316132\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 520\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.122\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4433612823486328\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.101657850696938e-06\n",
      "        policy_loss: 0.0005002975813113153\n",
      "        total_loss: 73.37432098388672\n",
      "        vf_explained_var: 0.04248321056365967\n",
      "        vf_loss: 73.37380981445312\n",
      "    load_time_ms: 1.053\n",
      "    num_steps_sampled: 1302600\n",
      "    num_steps_trained: 1252500\n",
      "    sample_time_ms: 3206.728\n",
      "    update_time_ms: 3.109\n",
      "  iterations_since_restore: 501\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.416666666666664\n",
      "    ram_util_percent: 65.91666666666667\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.109523745568973\n",
      "    mean_inference_ms: 0.9869190765955935\n",
      "    mean_processing_ms: 0.6991975877526261\n",
      "  time_since_restore: 1766.34321475029\n",
      "  time_this_iter_s: 4.111251592636108\n",
      "  time_total_s: 1766.34321475029\n",
      "  timestamp: 1596123189\n",
      "  timesteps_since_restore: 1302600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1302600\n",
      "  training_iteration: 501\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1766 s, 501 iter, 1302600 ts, 512 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-33-15\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 516.7510089169347\n",
      "  episode_reward_min: 194.0640247316132\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 521\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.89\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.436963677406311\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.6219854614973883e-06\n",
      "        policy_loss: 0.0014495926443487406\n",
      "        total_loss: 74.6962661743164\n",
      "        vf_explained_var: 0.022747039794921875\n",
      "        vf_loss: 74.6948471069336\n",
      "    load_time_ms: 1.096\n",
      "    num_steps_sampled: 1307800\n",
      "    num_steps_trained: 1257500\n",
      "    sample_time_ms: 3123.594\n",
      "    update_time_ms: 3.33\n",
      "  iterations_since_restore: 503\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.779999999999994\n",
      "    ram_util_percent: 65.9\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.108437649312955\n",
      "    mean_inference_ms: 0.9865982970076966\n",
      "    mean_processing_ms: 0.6991254571885257\n",
      "  time_since_restore: 1772.2412178516388\n",
      "  time_this_iter_s: 3.2299318313598633\n",
      "  time_total_s: 1772.2412178516388\n",
      "  timestamp: 1596123195\n",
      "  timesteps_since_restore: 1307800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1307800\n",
      "  training_iteration: 503\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1772 s, 503 iter, 1307800 ts, 517 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-33-22\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 515.8923910202702\n",
      "  episode_reward_min: 194.0640247316132\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 522\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.872\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4407578706741333\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.9480934244929813e-06\n",
      "        policy_loss: 0.007628896273672581\n",
      "        total_loss: 102.1352767944336\n",
      "        vf_explained_var: 0.017285048961639404\n",
      "        vf_loss: 102.12763977050781\n",
      "    load_time_ms: 1.094\n",
      "    num_steps_sampled: 1313000\n",
      "    num_steps_trained: 1262500\n",
      "    sample_time_ms: 3112.329\n",
      "    update_time_ms: 3.389\n",
      "  iterations_since_restore: 505\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.06666666666666\n",
      "    ram_util_percent: 65.9\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.107670262579819\n",
      "    mean_inference_ms: 0.9864240018476028\n",
      "    mean_processing_ms: 0.6990750912710406\n",
      "  time_since_restore: 1779.0344915390015\n",
      "  time_this_iter_s: 2.6866323947906494\n",
      "  time_total_s: 1779.0344915390015\n",
      "  timestamp: 1596123202\n",
      "  timesteps_since_restore: 1313000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1313000\n",
      "  training_iteration: 505\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1779 s, 505 iter, 1313000 ts, 516 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-33-29\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 526.3326125076933\n",
      "  episode_reward_min: 194.0640247316132\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 525\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.008\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4298591613769531\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.3528081050681067e-07\n",
      "        policy_loss: -0.0016382610192522407\n",
      "        total_loss: 52.95453643798828\n",
      "        vf_explained_var: 0.04206639528274536\n",
      "        vf_loss: 52.956180572509766\n",
      "    load_time_ms: 1.086\n",
      "    num_steps_sampled: 1318200\n",
      "    num_steps_trained: 1267500\n",
      "    sample_time_ms: 3195.864\n",
      "    update_time_ms: 3.475\n",
      "  iterations_since_restore: 507\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.55\n",
      "    ram_util_percent: 66.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.106035259661802\n",
      "    mean_inference_ms: 0.9861586418438312\n",
      "    mean_processing_ms: 0.6989673531796303\n",
      "  time_since_restore: 1786.1798958778381\n",
      "  time_this_iter_s: 2.766308546066284\n",
      "  time_total_s: 1786.1798958778381\n",
      "  timestamp: 1596123209\n",
      "  timesteps_since_restore: 1318200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1318200\n",
      "  training_iteration: 507\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1786 s, 507 iter, 1318200 ts, 526 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-33-36\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 532.5655666915121\n",
      "  episode_reward_min: 194.0640247316132\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 527\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.585\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4347350597381592\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.350610869456432e-08\n",
      "        policy_loss: 0.005312837194651365\n",
      "        total_loss: 58.5316047668457\n",
      "        vf_explained_var: 0.02995985746383667\n",
      "        vf_loss: 58.52630615234375\n",
      "    load_time_ms: 1.08\n",
      "    num_steps_sampled: 1323400\n",
      "    num_steps_trained: 1272500\n",
      "    sample_time_ms: 3277.783\n",
      "    update_time_ms: 3.448\n",
      "  iterations_since_restore: 509\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.85999999999999\n",
      "    ram_util_percent: 66.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.104206689640335\n",
      "    mean_inference_ms: 0.9856686600847533\n",
      "    mean_processing_ms: 0.6988420176062506\n",
      "  time_since_restore: 1792.4910311698914\n",
      "  time_this_iter_s: 3.0861685276031494\n",
      "  time_total_s: 1792.4910311698914\n",
      "  timestamp: 1596123216\n",
      "  timesteps_since_restore: 1323400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1323400\n",
      "  training_iteration: 509\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1792 s, 509 iter, 1323400 ts, 533 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-33-42\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 529.7341234603049\n",
      "  episode_reward_min: 194.0640247316132\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 530\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.387\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4350109100341797\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.673408622897114e-07\n",
      "        policy_loss: 0.008869390934705734\n",
      "        total_loss: 48.4118537902832\n",
      "        vf_explained_var: 0.034417808055877686\n",
      "        vf_loss: 48.402976989746094\n",
      "    load_time_ms: 1.075\n",
      "    num_steps_sampled: 1328600\n",
      "    num_steps_trained: 1277500\n",
      "    sample_time_ms: 3246.085\n",
      "    update_time_ms: 3.393\n",
      "  iterations_since_restore: 511\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.09999999999999\n",
      "    ram_util_percent: 66.03999999999999\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.102368694583\n",
      "    mean_inference_ms: 0.9852209534381322\n",
      "    mean_processing_ms: 0.6986820077758851\n",
      "  time_since_restore: 1799.0914905071259\n",
      "  time_this_iter_s: 3.6721792221069336\n",
      "  time_total_s: 1799.0914905071259\n",
      "  timestamp: 1596123222\n",
      "  timesteps_since_restore: 1328600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1328600\n",
      "  training_iteration: 511\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1799 s, 511 iter, 1328600 ts, 530 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-33-49\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 531.4859324013677\n",
      "  episode_reward_min: 194.0640247316132\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 532\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.925\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4312843084335327\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.3279914412578364e-07\n",
      "        policy_loss: 0.004883762914687395\n",
      "        total_loss: 38.58729553222656\n",
      "        vf_explained_var: 0.04288172721862793\n",
      "        vf_loss: 38.5824089050293\n",
      "    load_time_ms: 1.056\n",
      "    num_steps_sampled: 1333800\n",
      "    num_steps_trained: 1282500\n",
      "    sample_time_ms: 3365.126\n",
      "    update_time_ms: 3.204\n",
      "  iterations_since_restore: 513\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.35\n",
      "    ram_util_percent: 66.0\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.100776158010937\n",
      "    mean_inference_ms: 0.9849126808553642\n",
      "    mean_processing_ms: 0.6986057414922361\n",
      "  time_since_restore: 1806.1721153259277\n",
      "  time_this_iter_s: 4.157638788223267\n",
      "  time_total_s: 1806.1721153259277\n",
      "  timestamp: 1596123229\n",
      "  timesteps_since_restore: 1333800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1333800\n",
      "  training_iteration: 513\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1806 s, 513 iter, 1333800 ts, 531 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-33-55\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 531.4859324013678\n",
      "  episode_reward_min: 194.0640247316132\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 532\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.083\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4375861883163452\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.8603802232064481e-07\n",
      "        policy_loss: 0.0021777355577796698\n",
      "        total_loss: 72.26071166992188\n",
      "        vf_explained_var: 0.025710344314575195\n",
      "        vf_loss: 72.25852966308594\n",
      "    load_time_ms: 1.054\n",
      "    num_steps_sampled: 1339000\n",
      "    num_steps_trained: 1287500\n",
      "    sample_time_ms: 3272.697\n",
      "    update_time_ms: 3.086\n",
      "  iterations_since_restore: 515\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.96\n",
      "    ram_util_percent: 65.9\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.100776158010937\n",
      "    mean_inference_ms: 0.9849126808553639\n",
      "    mean_processing_ms: 0.698605741492236\n",
      "  time_since_restore: 1812.0416734218597\n",
      "  time_this_iter_s: 3.1275296211242676\n",
      "  time_total_s: 1812.0416734218597\n",
      "  timestamp: 1596123235\n",
      "  timesteps_since_restore: 1339000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1339000\n",
      "  training_iteration: 515\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1812 s, 515 iter, 1339000 ts, 531 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-34-03\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 531.3597693990722\n",
      "  episode_reward_min: 183.50029495949883\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 536\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.281\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4293211698532104\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.11873146124708e-06\n",
      "        policy_loss: 0.0032013384625315666\n",
      "        total_loss: 33.582088470458984\n",
      "        vf_explained_var: 0.05630713701248169\n",
      "        vf_loss: 33.578895568847656\n",
      "    load_time_ms: 1.072\n",
      "    num_steps_sampled: 1344200\n",
      "    num_steps_trained: 1292500\n",
      "    sample_time_ms: 3364.721\n",
      "    update_time_ms: 3.142\n",
      "  iterations_since_restore: 517\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.019999999999996\n",
      "    ram_util_percent: 65.9\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.0981722592111876\n",
      "    mean_inference_ms: 0.9843430954793285\n",
      "    mean_processing_ms: 0.6984402257806716\n",
      "  time_since_restore: 1820.114776134491\n",
      "  time_this_iter_s: 3.905952215194702\n",
      "  time_total_s: 1820.114776134491\n",
      "  timestamp: 1596123243\n",
      "  timesteps_since_restore: 1344200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1344200\n",
      "  training_iteration: 517\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1820 s, 517 iter, 1344200 ts, 531 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-34-09\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 529.8886798685228\n",
      "  episode_reward_min: 183.50029495949883\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 537\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.059\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4289207458496094\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.265018323072582e-07\n",
      "        policy_loss: -0.0007517538615502417\n",
      "        total_loss: 38.24610137939453\n",
      "        vf_explained_var: 0.04119175672531128\n",
      "        vf_loss: 38.24686050415039\n",
      "    load_time_ms: 1.085\n",
      "    num_steps_sampled: 1349400\n",
      "    num_steps_trained: 1297500\n",
      "    sample_time_ms: 3333.581\n",
      "    update_time_ms: 3.225\n",
      "  iterations_since_restore: 519\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.06\n",
      "    ram_util_percent: 65.88000000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.097414464340092\n",
      "    mean_inference_ms: 0.9841704462269237\n",
      "    mean_processing_ms: 0.6983801954477239\n",
      "  time_since_restore: 1826.1254954338074\n",
      "  time_this_iter_s: 3.2317311763763428\n",
      "  time_total_s: 1826.1254954338074\n",
      "  timestamp: 1596123249\n",
      "  timesteps_since_restore: 1349400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1349400\n",
      "  training_iteration: 519\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1826 s, 519 iter, 1349400 ts, 530 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-34-16\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 533.702626836875\n",
      "  episode_reward_min: 183.50029495949883\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 540\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.833\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4367841482162476\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.278205091803102e-06\n",
      "        policy_loss: 0.0016790729714557528\n",
      "        total_loss: 78.1500473022461\n",
      "        vf_explained_var: 0.028058648109436035\n",
      "        vf_loss: 78.14835357666016\n",
      "    load_time_ms: 1.046\n",
      "    num_steps_sampled: 1354600\n",
      "    num_steps_trained: 1302500\n",
      "    sample_time_ms: 3352.821\n",
      "    update_time_ms: 3.255\n",
      "  iterations_since_restore: 521\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.74000000000001\n",
      "    ram_util_percent: 65.9\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.095551515831633\n",
      "    mean_inference_ms: 0.9837182946911858\n",
      "    mean_processing_ms: 0.6982164425246797\n",
      "  time_since_restore: 1832.9152855873108\n",
      "  time_this_iter_s: 3.800447702407837\n",
      "  time_total_s: 1832.9152855873108\n",
      "  timestamp: 1596123256\n",
      "  timesteps_since_restore: 1354600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1354600\n",
      "  training_iteration: 521\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1832 s, 521 iter, 1354600 ts, 534 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-34-22\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 531.9102129337679\n",
      "  episode_reward_min: 183.50029495949883\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 542\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.493\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.425682783126831\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.0132790162487026e-09\n",
      "        policy_loss: -0.0036532836966216564\n",
      "        total_loss: 37.55965805053711\n",
      "        vf_explained_var: 0.03426015377044678\n",
      "        vf_loss: 37.563316345214844\n",
      "    load_time_ms: 1.073\n",
      "    num_steps_sampled: 1359800\n",
      "    num_steps_trained: 1307500\n",
      "    sample_time_ms: 3249.51\n",
      "    update_time_ms: 3.282\n",
      "  iterations_since_restore: 523\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.525000000000006\n",
      "    ram_util_percent: 65.875\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.093937864910612\n",
      "    mean_inference_ms: 0.9834070140835323\n",
      "    mean_processing_ms: 0.69814479818024\n",
      "  time_since_restore: 1838.9717271327972\n",
      "  time_this_iter_s: 3.0774037837982178\n",
      "  time_total_s: 1838.9717271327972\n",
      "  timestamp: 1596123262\n",
      "  timesteps_since_restore: 1359800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1359800\n",
      "  training_iteration: 523\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1838 s, 523 iter, 1359800 ts, 532 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-34-30\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 532.4798515835613\n",
      "  episode_reward_min: 183.50029495949883\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 543\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.268\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.433532953262329\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.574063276166271e-06\n",
      "        policy_loss: 0.006345752160996199\n",
      "        total_loss: 72.91104125976562\n",
      "        vf_explained_var: 0.013590455055236816\n",
      "        vf_loss: 72.90470886230469\n",
      "    load_time_ms: 1.07\n",
      "    num_steps_sampled: 1365000\n",
      "    num_steps_trained: 1312500\n",
      "    sample_time_ms: 3419.623\n",
      "    update_time_ms: 3.395\n",
      "  iterations_since_restore: 525\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.78333333333333\n",
      "    ram_util_percent: 65.7\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.093726018062045\n",
      "    mean_inference_ms: 0.9834426457428367\n",
      "    mean_processing_ms: 0.6981296072027557\n",
      "  time_since_restore: 1846.5406694412231\n",
      "  time_this_iter_s: 4.154292821884155\n",
      "  time_total_s: 1846.5406694412231\n",
      "  timestamp: 1596123270\n",
      "  timesteps_since_restore: 1365000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1365000\n",
      "  training_iteration: 525\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1846 s, 525 iter, 1365000 ts, 532 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-34-36\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 531.7313385049073\n",
      "  episode_reward_min: 183.50029495949883\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 546\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.116\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4296832084655762\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.6400456388510065e-06\n",
      "        policy_loss: 0.0004101406957488507\n",
      "        total_loss: 54.0960578918457\n",
      "        vf_explained_var: 0.03735470771789551\n",
      "        vf_loss: 54.095638275146484\n",
      "    load_time_ms: 1.166\n",
      "    num_steps_sampled: 1370200\n",
      "    num_steps_trained: 1317500\n",
      "    sample_time_ms: 3236.097\n",
      "    update_time_ms: 3.287\n",
      "  iterations_since_restore: 527\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.68000000000001\n",
      "    ram_util_percent: 65.78\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.091532935609618\n",
      "    mean_inference_ms: 0.9829020935013894\n",
      "    mean_processing_ms: 0.6980043465229021\n",
      "  time_since_restore: 1852.785190820694\n",
      "  time_this_iter_s: 3.2164337635040283\n",
      "  time_total_s: 1852.785190820694\n",
      "  timestamp: 1596123276\n",
      "  timesteps_since_restore: 1370200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1370200\n",
      "  training_iteration: 527\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1852 s, 527 iter, 1370200 ts, 532 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-34-42\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 531.5168372092753\n",
      "  episode_reward_min: 183.50029495949883\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 547\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.865\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4308663606643677\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.502058916637907e-06\n",
      "        policy_loss: -0.000989581341855228\n",
      "        total_loss: 67.43890380859375\n",
      "        vf_explained_var: 0.03660547733306885\n",
      "        vf_loss: 67.43988800048828\n",
      "    load_time_ms: 1.154\n",
      "    num_steps_sampled: 1375400\n",
      "    num_steps_trained: 1322500\n",
      "    sample_time_ms: 3265.096\n",
      "    update_time_ms: 3.39\n",
      "  iterations_since_restore: 529\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 65.02000000000001\n",
      "    ram_util_percent: 65.8\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.09054702915143\n",
      "    mean_inference_ms: 0.9826698564887231\n",
      "    mean_processing_ms: 0.6979114929878126\n",
      "  time_since_restore: 1859.0854094028473\n",
      "  time_this_iter_s: 3.0833616256713867\n",
      "  time_total_s: 1859.0854094028473\n",
      "  timestamp: 1596123282\n",
      "  timesteps_since_restore: 1375400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1375400\n",
      "  training_iteration: 529\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1859 s, 529 iter, 1375400 ts, 532 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-34-49\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 526.6880748456272\n",
      "  episode_reward_min: 183.50029495949883\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 550\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.489\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4291940927505493\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.3495445045919041e-06\n",
      "        policy_loss: -0.0032921733800321817\n",
      "        total_loss: 55.59319305419922\n",
      "        vf_explained_var: 0.04303169250488281\n",
      "        vf_loss: 55.59648132324219\n",
      "    load_time_ms: 1.196\n",
      "    num_steps_sampled: 1380600\n",
      "    num_steps_trained: 1327500\n",
      "    sample_time_ms: 3220.463\n",
      "    update_time_ms: 3.356\n",
      "  iterations_since_restore: 531\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.475\n",
      "    ram_util_percent: 66.0\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.089015489088474\n",
      "    mean_inference_ms: 0.9824278847179886\n",
      "    mean_processing_ms: 0.6978059648809058\n",
      "  time_since_restore: 1865.4376292228699\n",
      "  time_this_iter_s: 3.0646469593048096\n",
      "  time_total_s: 1865.4376292228699\n",
      "  timestamp: 1596123289\n",
      "  timesteps_since_restore: 1380600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1380600\n",
      "  training_iteration: 531\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1865 s, 531 iter, 1380600 ts, 527 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-34-56\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 532.1263697668717\n",
      "  episode_reward_min: 183.50029495949883\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 552\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.682\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4240005016326904\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.580378458740597e-07\n",
      "        policy_loss: 0.005997353699058294\n",
      "        total_loss: 27.74484634399414\n",
      "        vf_explained_var: 0.05540001392364502\n",
      "        vf_loss: 27.738853454589844\n",
      "    load_time_ms: 1.18\n",
      "    num_steps_sampled: 1385800\n",
      "    num_steps_trained: 1332500\n",
      "    sample_time_ms: 3317.098\n",
      "    update_time_ms: 3.445\n",
      "  iterations_since_restore: 533\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 67.45\n",
      "    ram_util_percent: 66.0\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.087280689483735\n",
      "    mean_inference_ms: 0.9819639110060079\n",
      "    mean_processing_ms: 0.6976894466479352\n",
      "  time_since_restore: 1872.4506599903107\n",
      "  time_this_iter_s: 2.9953951835632324\n",
      "  time_total_s: 1872.4506599903107\n",
      "  timestamp: 1596123296\n",
      "  timesteps_since_restore: 1385800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1385800\n",
      "  training_iteration: 533\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1872 s, 533 iter, 1385800 ts, 532 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-35-02\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 530.3624597027434\n",
      "  episode_reward_min: 183.50029495949883\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 554\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.561\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4344326257705688\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.7987966884902562e-06\n",
      "        policy_loss: 0.001271666493266821\n",
      "        total_loss: 64.06340789794922\n",
      "        vf_explained_var: 0.0128670334815979\n",
      "        vf_loss: 64.0621337890625\n",
      "    load_time_ms: 1.156\n",
      "    num_steps_sampled: 1391000\n",
      "    num_steps_trained: 1337500\n",
      "    sample_time_ms: 3239.263\n",
      "    update_time_ms: 3.309\n",
      "  iterations_since_restore: 535\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.31666666666666\n",
      "    ram_util_percent: 66.06666666666666\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.086101742159978\n",
      "    mean_inference_ms: 0.9816795441341002\n",
      "    mean_processing_ms: 0.6976159434166632\n",
      "  time_since_restore: 1879.2387480735779\n",
      "  time_this_iter_s: 3.9308419227600098\n",
      "  time_total_s: 1879.2387480735779\n",
      "  timestamp: 1596123302\n",
      "  timesteps_since_restore: 1391000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1391000\n",
      "  training_iteration: 535\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1879 s, 535 iter, 1391000 ts, 530 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-35-09\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 532.52835036048\n",
      "  episode_reward_min: 183.50029495949883\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 557\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.078\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4231187105178833\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.3342112121536047e-07\n",
      "        policy_loss: 0.0035719878505915403\n",
      "        total_loss: 22.53959083557129\n",
      "        vf_explained_var: 0.06296926736831665\n",
      "        vf_loss: 22.53601837158203\n",
      "    load_time_ms: 1.048\n",
      "    num_steps_sampled: 1396200\n",
      "    num_steps_trained: 1342500\n",
      "    sample_time_ms: 3293.393\n",
      "    update_time_ms: 3.309\n",
      "  iterations_since_restore: 537\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.2\n",
      "    ram_util_percent: 66.0\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.084034747829094\n",
      "    mean_inference_ms: 0.9812574573613052\n",
      "    mean_processing_ms: 0.6974685596255433\n",
      "  time_since_restore: 1886.0161621570587\n",
      "  time_this_iter_s: 2.912562847137451\n",
      "  time_total_s: 1886.0161621570587\n",
      "  timestamp: 1596123309\n",
      "  timesteps_since_restore: 1396200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1396200\n",
      "  training_iteration: 537\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1886 s, 537 iter, 1396200 ts, 533 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-35-15\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 532.52835036048\n",
      "  episode_reward_min: 183.50029495949883\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 557\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.212\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4278900623321533\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.437778665713267e-07\n",
      "        policy_loss: 0.0003887115453835577\n",
      "        total_loss: 42.14212417602539\n",
      "        vf_explained_var: 0.017431437969207764\n",
      "        vf_loss: 42.14173889160156\n",
      "    load_time_ms: 1.054\n",
      "    num_steps_sampled: 1401400\n",
      "    num_steps_trained: 1347500\n",
      "    sample_time_ms: 3269.502\n",
      "    update_time_ms: 3.203\n",
      "  iterations_since_restore: 539\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.75\n",
      "    ram_util_percent: 65.975\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.084034747829094\n",
      "    mean_inference_ms: 0.9812574573613052\n",
      "    mean_processing_ms: 0.6974685596255433\n",
      "  time_since_restore: 1892.075413942337\n",
      "  time_this_iter_s: 3.0396363735198975\n",
      "  time_total_s: 1892.075413942337\n",
      "  timestamp: 1596123315\n",
      "  timesteps_since_restore: 1401400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1401400\n",
      "  training_iteration: 539\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1892 s, 539 iter, 1401400 ts, 533 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-35-23\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 523.889319667694\n",
      "  episode_reward_min: 183.50029495949883\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 561\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.293\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4234203100204468\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.7234325468962197e-06\n",
      "        policy_loss: 0.0008419735240750015\n",
      "        total_loss: 34.596893310546875\n",
      "        vf_explained_var: 0.04479855298995972\n",
      "        vf_loss: 34.5960578918457\n",
      "    load_time_ms: 1.078\n",
      "    num_steps_sampled: 1406600\n",
      "    num_steps_trained: 1352500\n",
      "    sample_time_ms: 3365.038\n",
      "    update_time_ms: 3.397\n",
      "  iterations_since_restore: 541\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.525000000000006\n",
      "    ram_util_percent: 66.05\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.081786333670137\n",
      "    mean_inference_ms: 0.9807869637711926\n",
      "    mean_processing_ms: 0.6973401669124066\n",
      "  time_since_restore: 1899.3979089260101\n",
      "  time_this_iter_s: 3.0603861808776855\n",
      "  time_total_s: 1899.3979089260101\n",
      "  timestamp: 1596123323\n",
      "  timesteps_since_restore: 1406600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1406600\n",
      "  training_iteration: 541\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1899 s, 541 iter, 1406600 ts, 524 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-35-29\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 523.2303175341065\n",
      "  episode_reward_min: 183.50029495949883\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 562\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 21.174\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.427008032798767\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.017114747512096e-07\n",
      "        policy_loss: -0.0032131553161889315\n",
      "        total_loss: 70.5501708984375\n",
      "        vf_explained_var: 0.028998494148254395\n",
      "        vf_loss: 70.55337524414062\n",
      "    load_time_ms: 1.103\n",
      "    num_steps_sampled: 1411800\n",
      "    num_steps_trained: 1357500\n",
      "    sample_time_ms: 3330.228\n",
      "    update_time_ms: 3.396\n",
      "  iterations_since_restore: 543\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 65.10000000000001\n",
      "    ram_util_percent: 66.08\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.080805207824741\n",
      "    mean_inference_ms: 0.9805551083241767\n",
      "    mean_processing_ms: 0.6972444123222897\n",
      "  time_since_restore: 1906.0739424228668\n",
      "  time_this_iter_s: 3.369903326034546\n",
      "  time_total_s: 1906.0739424228668\n",
      "  timestamp: 1596123329\n",
      "  timesteps_since_restore: 1411800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1411800\n",
      "  training_iteration: 543\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1906 s, 543 iter, 1411800 ts, 523 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-35-36\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 529.0973833533654\n",
      "  episode_reward_min: 183.50029495949883\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 566\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 22.258\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4378740787506104\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.8986453344259644e-06\n",
      "        policy_loss: -0.0023695756681263447\n",
      "        total_loss: 97.1353530883789\n",
      "        vf_explained_var: 0.01627892255783081\n",
      "        vf_loss: 97.13772583007812\n",
      "    load_time_ms: 1.124\n",
      "    num_steps_sampled: 1417000\n",
      "    num_steps_trained: 1362500\n",
      "    sample_time_ms: 3358.286\n",
      "    update_time_ms: 3.772\n",
      "  iterations_since_restore: 545\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.099999999999994\n",
      "    ram_util_percent: 66.06666666666666\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.078644070027334\n",
      "    mean_inference_ms: 0.9801019542481285\n",
      "    mean_processing_ms: 0.6971223144741061\n",
      "  time_since_restore: 1913.1587538719177\n",
      "  time_this_iter_s: 4.037676095962524\n",
      "  time_total_s: 1913.1587538719177\n",
      "  timestamp: 1596123336\n",
      "  timesteps_since_restore: 1417000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1417000\n",
      "  training_iteration: 545\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1913 s, 545 iter, 1417000 ts, 529 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-35-43\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 531.0496826765346\n",
      "  episode_reward_min: 183.50029495949883\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 567\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 22.921\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4285610914230347\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.934000000706874e-06\n",
      "        policy_loss: -0.0040888190269470215\n",
      "        total_loss: 51.567047119140625\n",
      "        vf_explained_var: 0.022284209728240967\n",
      "        vf_loss: 51.57113265991211\n",
      "    load_time_ms: 1.139\n",
      "    num_steps_sampled: 1422200\n",
      "    num_steps_trained: 1367500\n",
      "    sample_time_ms: 3327.016\n",
      "    update_time_ms: 3.921\n",
      "  iterations_since_restore: 547\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.875\n",
      "    ram_util_percent: 65.975\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.0776760306267334\n",
      "    mean_inference_ms: 0.9798671635840425\n",
      "    mean_processing_ms: 0.697024754843178\n",
      "  time_since_restore: 1919.634861946106\n",
      "  time_this_iter_s: 3.2020139694213867\n",
      "  time_total_s: 1919.634861946106\n",
      "  timestamp: 1596123343\n",
      "  timesteps_since_restore: 1422200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1422200\n",
      "  training_iteration: 547\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1919 s, 547 iter, 1422200 ts, 531 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-35-50\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 534.2565385151291\n",
      "  episode_reward_min: 183.50029495949883\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 568\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 22.6\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4373960494995117\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.0489940223123995e-06\n",
      "        policy_loss: -0.0006176370661705732\n",
      "        total_loss: 79.52926635742188\n",
      "        vf_explained_var: 0.008176267147064209\n",
      "        vf_loss: 79.5298843383789\n",
      "    load_time_ms: 1.137\n",
      "    num_steps_sampled: 1427400\n",
      "    num_steps_trained: 1372500\n",
      "    sample_time_ms: 3416.996\n",
      "    update_time_ms: 3.839\n",
      "  iterations_since_restore: 549\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 51.620000000000005\n",
      "    ram_util_percent: 66.0\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.077084436232609\n",
      "    mean_inference_ms: 0.9796228080001345\n",
      "    mean_processing_ms: 0.696988212606875\n",
      "  time_since_restore: 1926.5897903442383\n",
      "  time_this_iter_s: 4.0232017040252686\n",
      "  time_total_s: 1926.5897903442383\n",
      "  timestamp: 1596123350\n",
      "  timesteps_since_restore: 1427400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1427400\n",
      "  training_iteration: 549\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1926 s, 549 iter, 1427400 ts, 534 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-35-58\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 534.5759243958535\n",
      "  episode_reward_min: 183.50029495949883\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 572\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 23.754\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4285523891448975\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.473473443842522e-07\n",
      "        policy_loss: -0.0013615168863907456\n",
      "        total_loss: 44.5455436706543\n",
      "        vf_explained_var: 0.03259092569351196\n",
      "        vf_loss: 44.54690933227539\n",
      "    load_time_ms: 1.217\n",
      "    num_steps_sampled: 1432600\n",
      "    num_steps_trained: 1377500\n",
      "    sample_time_ms: 3488.406\n",
      "    update_time_ms: 3.789\n",
      "  iterations_since_restore: 551\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 51.76666666666666\n",
      "    ram_util_percent: 66.03333333333332\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.074519462033155\n",
      "    mean_inference_ms: 0.9791685552362843\n",
      "    mean_processing_ms: 0.6968066201205855\n",
      "  time_since_restore: 1934.6456825733185\n",
      "  time_this_iter_s: 4.150131702423096\n",
      "  time_total_s: 1934.6456825733185\n",
      "  timestamp: 1596123358\n",
      "  timesteps_since_restore: 1432600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1432600\n",
      "  training_iteration: 551\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1934 s, 551 iter, 1432600 ts, 535 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-36-04\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 534.5759243958535\n",
      "  episode_reward_min: 183.50029495949883\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 572\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 24.018\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.429597020149231\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.0919094393102569e-06\n",
      "        policy_loss: 0.006929831113666296\n",
      "        total_loss: 55.88737487792969\n",
      "        vf_explained_var: 0.03028404712677002\n",
      "        vf_loss: 55.88044357299805\n",
      "    load_time_ms: 1.241\n",
      "    num_steps_sampled: 1437800\n",
      "    num_steps_trained: 1382500\n",
      "    sample_time_ms: 3442.647\n",
      "    update_time_ms: 3.93\n",
      "  iterations_since_restore: 553\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 65.46\n",
      "    ram_util_percent: 65.9\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.074519462033155\n",
      "    mean_inference_ms: 0.9791685552362844\n",
      "    mean_processing_ms: 0.6968066201205856\n",
      "  time_since_restore: 1940.8685598373413\n",
      "  time_this_iter_s: 3.32810640335083\n",
      "  time_total_s: 1940.8685598373413\n",
      "  timestamp: 1596123364\n",
      "  timesteps_since_restore: 1437800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1437800\n",
      "  training_iteration: 553\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1940 s, 553 iter, 1437800 ts, 535 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-36-11\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 533.9374075409748\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 575\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 22.809\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.430366039276123\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.0757446489151334e-06\n",
      "        policy_loss: -0.008846146985888481\n",
      "        total_loss: 43.24910354614258\n",
      "        vf_explained_var: 0.036395490169525146\n",
      "        vf_loss: 43.25795364379883\n",
      "    load_time_ms: 1.225\n",
      "    num_steps_sampled: 1443000\n",
      "    num_steps_trained: 1387500\n",
      "    sample_time_ms: 3457.525\n",
      "    update_time_ms: 3.538\n",
      "  iterations_since_restore: 555\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.725\n",
      "    ram_util_percent: 65.875\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.072910594042106\n",
      "    mean_inference_ms: 0.978789842463501\n",
      "    mean_processing_ms: 0.6966924660299542\n",
      "  time_since_restore: 1948.0846829414368\n",
      "  time_this_iter_s: 3.0469000339508057\n",
      "  time_total_s: 1948.0846829414368\n",
      "  timestamp: 1596123371\n",
      "  timesteps_since_restore: 1443000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1443000\n",
      "  training_iteration: 555\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1948 s, 555 iter, 1443000 ts, 534 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-36-18\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 536.3671267555004\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 577\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 22.272\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4326014518737793\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 7.876634526837734e-07\n",
      "        policy_loss: 0.0027517187409102917\n",
      "        total_loss: 74.5429916381836\n",
      "        vf_explained_var: 0.028462588787078857\n",
      "        vf_loss: 74.54025268554688\n",
      "    load_time_ms: 1.22\n",
      "    num_steps_sampled: 1448200\n",
      "    num_steps_trained: 1392500\n",
      "    sample_time_ms: 3434.715\n",
      "    update_time_ms: 3.451\n",
      "  iterations_since_restore: 557\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.95\n",
      "    ram_util_percent: 66.025\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.071464946364518\n",
      "    mean_inference_ms: 0.9784959425829944\n",
      "    mean_processing_ms: 0.6965826540365417\n",
      "  time_since_restore: 1954.3234848976135\n",
      "  time_this_iter_s: 3.0593152046203613\n",
      "  time_total_s: 1954.3234848976135\n",
      "  timestamp: 1596123378\n",
      "  timesteps_since_restore: 1448200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1448200\n",
      "  training_iteration: 557\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1954 s, 557 iter, 1448200 ts, 536 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-36-25\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 544.1267145624495\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 579\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 23.305\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.44028639793396\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.989981903236185e-07\n",
      "        policy_loss: -0.012487863190472126\n",
      "        total_loss: 72.6399917602539\n",
      "        vf_explained_var: 0.01566016674041748\n",
      "        vf_loss: 72.65249633789062\n",
      "    load_time_ms: 1.221\n",
      "    num_steps_sampled: 1453400\n",
      "    num_steps_trained: 1397500\n",
      "    sample_time_ms: 3417.969\n",
      "    update_time_ms: 3.495\n",
      "  iterations_since_restore: 559\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.0\n",
      "    ram_util_percent: 66.96666666666668\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.070058146374936\n",
      "    mean_inference_ms: 0.978078735632479\n",
      "    mean_processing_ms: 0.6964866259965576\n",
      "  time_since_restore: 1961.1245923042297\n",
      "  time_this_iter_s: 3.62934947013855\n",
      "  time_total_s: 1961.1245923042297\n",
      "  timestamp: 1596123385\n",
      "  timesteps_since_restore: 1453400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1453400\n",
      "  training_iteration: 559\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1961 s, 559 iter, 1453400 ts, 544 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-36-32\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 547.7613571394053\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 582\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 22.085\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4286701679229736\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 9.336471862297913e-08\n",
      "        policy_loss: 0.002150067128241062\n",
      "        total_loss: 42.04347610473633\n",
      "        vf_explained_var: 0.04279887676239014\n",
      "        vf_loss: 42.04132843017578\n",
      "    load_time_ms: 1.189\n",
      "    num_steps_sampled: 1458600\n",
      "    num_steps_trained: 1402500\n",
      "    sample_time_ms: 3349.897\n",
      "    update_time_ms: 3.437\n",
      "  iterations_since_restore: 561\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 68.0\n",
      "    ram_util_percent: 64.95\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.068563989869574\n",
      "    mean_inference_ms: 0.9778563243398358\n",
      "    mean_processing_ms: 0.6963744206581326\n",
      "  time_since_restore: 1968.4798996448517\n",
      "  time_this_iter_s: 3.2290000915527344\n",
      "  time_total_s: 1968.4798996448517\n",
      "  timestamp: 1596123392\n",
      "  timesteps_since_restore: 1458600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1458600\n",
      "  training_iteration: 561\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.6/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1968 s, 561 iter, 1458600 ts, 548 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-36-38\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 547.7613571394053\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 582\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 22.162\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4365483522415161\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.7171364510868443e-06\n",
      "        policy_loss: -0.0037459670566022396\n",
      "        total_loss: 75.0539779663086\n",
      "        vf_explained_var: 0.019911348819732666\n",
      "        vf_loss: 75.05773162841797\n",
      "    load_time_ms: 1.16\n",
      "    num_steps_sampled: 1463800\n",
      "    num_steps_trained: 1407500\n",
      "    sample_time_ms: 3385.621\n",
      "    update_time_ms: 3.251\n",
      "  iterations_since_restore: 563\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.29999999999999\n",
      "    ram_util_percent: 64.4\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.068563989869574\n",
      "    mean_inference_ms: 0.9778563243398358\n",
      "    mean_processing_ms: 0.6963744206581326\n",
      "  time_since_restore: 1975.0595774650574\n",
      "  time_this_iter_s: 3.0771167278289795\n",
      "  time_total_s: 1975.0595774650574\n",
      "  timestamp: 1596123398\n",
      "  timesteps_since_restore: 1463800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1463800\n",
      "  training_iteration: 563\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.6/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1975 s, 563 iter, 1463800 ts, 548 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-36-46\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 550.500411832922\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 586\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 25.166\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.431909441947937\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.265375868177216e-07\n",
      "        policy_loss: 0.000514371320605278\n",
      "        total_loss: 50.768890380859375\n",
      "        vf_explained_var: 0.03801572322845459\n",
      "        vf_loss: 50.76837158203125\n",
      "    load_time_ms: 1.274\n",
      "    num_steps_sampled: 1469000\n",
      "    num_steps_trained: 1412500\n",
      "    sample_time_ms: 3360.181\n",
      "    update_time_ms: 3.586\n",
      "  iterations_since_restore: 565\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.54\n",
      "    ram_util_percent: 64.28\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.066472460316578\n",
      "    mean_inference_ms: 0.9774753225928784\n",
      "    mean_processing_ms: 0.6962295565074396\n",
      "  time_since_restore: 1982.060583114624\n",
      "  time_this_iter_s: 3.2388432025909424\n",
      "  time_total_s: 1982.060583114624\n",
      "  timestamp: 1596123406\n",
      "  timesteps_since_restore: 1469000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1469000\n",
      "  training_iteration: 565\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.6/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1982 s, 565 iter, 1469000 ts, 551 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-36-53\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 548.8106832944079\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 587\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 26.009\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.429866075515747\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.458997745539818e-07\n",
      "        policy_loss: -0.0005409539444372058\n",
      "        total_loss: 59.85634994506836\n",
      "        vf_explained_var: 0.0369415283203125\n",
      "        vf_loss: 59.85688781738281\n",
      "    load_time_ms: 1.283\n",
      "    num_steps_sampled: 1474200\n",
      "    num_steps_trained: 1417500\n",
      "    sample_time_ms: 3448.693\n",
      "    update_time_ms: 3.634\n",
      "  iterations_since_restore: 567\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.21666666666665\n",
      "    ram_util_percent: 65.41666666666666\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.065821413187163\n",
      "    mean_inference_ms: 0.9772573590896139\n",
      "    mean_processing_ms: 0.6961691911175149\n",
      "  time_since_restore: 1989.1949579715729\n",
      "  time_this_iter_s: 3.7181990146636963\n",
      "  time_total_s: 1989.1949579715729\n",
      "  timestamp: 1596123413\n",
      "  timesteps_since_restore: 1474200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1474200\n",
      "  training_iteration: 567\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1989 s, 567 iter, 1474200 ts, 549 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-36-59\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 553.3947683426176\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 588\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 25.034\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4306285381317139\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.3400058896404516e-07\n",
      "        policy_loss: 0.0010159004013985395\n",
      "        total_loss: 44.10845184326172\n",
      "        vf_explained_var: 0.02631521224975586\n",
      "        vf_loss: 44.107444763183594\n",
      "    load_time_ms: 1.273\n",
      "    num_steps_sampled: 1479400\n",
      "    num_steps_trained: 1422500\n",
      "    sample_time_ms: 3427.4\n",
      "    update_time_ms: 3.754\n",
      "  iterations_since_restore: 569\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.2\n",
      "    ram_util_percent: 66.22500000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.065362711736114\n",
      "    mean_inference_ms: 0.9770422975010525\n",
      "    mean_processing_ms: 0.6961385001463628\n",
      "  time_since_restore: 1995.7709124088287\n",
      "  time_this_iter_s: 2.976907968521118\n",
      "  time_total_s: 1995.7709124088287\n",
      "  timestamp: 1596123419\n",
      "  timesteps_since_restore: 1479400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1479400\n",
      "  training_iteration: 569\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 11.0/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 1995 s, 569 iter, 1479400 ts, 553 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-37-06\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 556.8943559076963\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 592\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 23.564\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4219106435775757\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.8827914516350575e-07\n",
      "        policy_loss: -0.00011961309792241082\n",
      "        total_loss: 27.936290740966797\n",
      "        vf_explained_var: 0.03761976957321167\n",
      "        vf_loss: 27.9364070892334\n",
      "    load_time_ms: 1.198\n",
      "    num_steps_sampled: 1484600\n",
      "    num_steps_trained: 1427500\n",
      "    sample_time_ms: 3356.71\n",
      "    update_time_ms: 3.727\n",
      "  iterations_since_restore: 571\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.48\n",
      "    ram_util_percent: 66.32000000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.063593511829779\n",
      "    mean_inference_ms: 0.9767919159729125\n",
      "    mean_processing_ms: 0.6960271727391167\n",
      "  time_since_restore: 2002.3997387886047\n",
      "  time_this_iter_s: 2.9558818340301514\n",
      "  time_total_s: 2002.3997387886047\n",
      "  timestamp: 1596123426\n",
      "  timesteps_since_restore: 1484600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1484600\n",
      "  training_iteration: 571\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 11.0/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2002 s, 571 iter, 1484600 ts, 557 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-37-13\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 554.5744027306067\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 593\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 23.687\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4320425987243652\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.1217593964829575e-07\n",
      "        policy_loss: 0.0036707737017422915\n",
      "        total_loss: 64.28057861328125\n",
      "        vf_explained_var: 0.022569775581359863\n",
      "        vf_loss: 64.27691650390625\n",
      "    load_time_ms: 1.21\n",
      "    num_steps_sampled: 1489800\n",
      "    num_steps_trained: 1432500\n",
      "    sample_time_ms: 3371.354\n",
      "    update_time_ms: 3.722\n",
      "  iterations_since_restore: 573\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.42\n",
      "    ram_util_percent: 66.03999999999999\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.062812403324082\n",
      "    mean_inference_ms: 0.9764956097000119\n",
      "    mean_processing_ms: 0.6959346017521919\n",
      "  time_since_restore: 2009.1287634372711\n",
      "  time_this_iter_s: 3.9490973949432373\n",
      "  time_total_s: 2009.1287634372711\n",
      "  timestamp: 1596123433\n",
      "  timesteps_since_restore: 1489800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1489800\n",
      "  training_iteration: 573\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2009 s, 573 iter, 1489800 ts, 555 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-37-22\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 555.9107927795919\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 597\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 22.792\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4273130893707275\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.3715743989450857e-06\n",
      "        policy_loss: -0.0018057208508253098\n",
      "        total_loss: 31.988187789916992\n",
      "        vf_explained_var: 0.03675729036331177\n",
      "        vf_loss: 31.989988327026367\n",
      "    load_time_ms: 1.24\n",
      "    num_steps_sampled: 1495000\n",
      "    num_steps_trained: 1437500\n",
      "    sample_time_ms: 3572.139\n",
      "    update_time_ms: 3.833\n",
      "  iterations_since_restore: 575\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 65.5142857142857\n",
      "    ram_util_percent: 65.77142857142857\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.061029476854966\n",
      "    mean_inference_ms: 0.9762381913802016\n",
      "    mean_processing_ms: 0.6957993139298534\n",
      "  time_since_restore: 2018.1319098472595\n",
      "  time_this_iter_s: 4.89835262298584\n",
      "  time_total_s: 2018.1319098472595\n",
      "  timestamp: 1596123442\n",
      "  timesteps_since_restore: 1495000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1495000\n",
      "  training_iteration: 575\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2018 s, 575 iter, 1495000 ts, 556 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-37-30\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 553.9812773526432\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 598\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 22.453\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.429484248161316\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.0512811122207495e-07\n",
      "        policy_loss: -0.008033080957829952\n",
      "        total_loss: 61.50151062011719\n",
      "        vf_explained_var: 0.012273669242858887\n",
      "        vf_loss: 61.509544372558594\n",
      "    load_time_ms: 1.334\n",
      "    num_steps_sampled: 1500200\n",
      "    num_steps_trained: 1442500\n",
      "    sample_time_ms: 3705.81\n",
      "    update_time_ms: 4.278\n",
      "  iterations_since_restore: 577\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.46666666666667\n",
      "    ram_util_percent: 64.56666666666668\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.06048662323371\n",
      "    mean_inference_ms: 0.9760788573835736\n",
      "    mean_processing_ms: 0.6957360316879899\n",
      "  time_since_restore: 2026.607045173645\n",
      "  time_this_iter_s: 4.310816287994385\n",
      "  time_total_s: 2026.607045173645\n",
      "  timestamp: 1596123450\n",
      "  timesteps_since_restore: 1500200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1500200\n",
      "  training_iteration: 577\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2026 s, 577 iter, 1500200 ts, 554 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-37-36\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 555.8216169579099\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 599\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 22.775\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4396378993988037\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.9451617845334113e-06\n",
      "        policy_loss: 0.0035441459622234106\n",
      "        total_loss: 100.96504211425781\n",
      "        vf_explained_var: 0.010450959205627441\n",
      "        vf_loss: 100.96149444580078\n",
      "    load_time_ms: 1.344\n",
      "    num_steps_sampled: 1505400\n",
      "    num_steps_trained: 1447500\n",
      "    sample_time_ms: 3626.438\n",
      "    update_time_ms: 4.125\n",
      "  iterations_since_restore: 579\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.04\n",
      "    ram_util_percent: 63.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.059985320182411\n",
      "    mean_inference_ms: 0.9760824122999466\n",
      "    mean_processing_ms: 0.6957062299680001\n",
      "  time_since_restore: 2032.392300605774\n",
      "  time_this_iter_s: 3.1451575756073\n",
      "  time_total_s: 2032.392300605774\n",
      "  timestamp: 1596123456\n",
      "  timesteps_since_restore: 1505400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1505400\n",
      "  training_iteration: 579\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2032 s, 579 iter, 1505400 ts, 556 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-37-43\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 561.7912385559628\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 602\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 23.58\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4237878322601318\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.0136833711603686e-07\n",
      "        policy_loss: -0.0015225696843117476\n",
      "        total_loss: 23.449481964111328\n",
      "        vf_explained_var: 0.041400015354156494\n",
      "        vf_loss: 23.45100212097168\n",
      "    load_time_ms: 1.32\n",
      "    num_steps_sampled: 1510600\n",
      "    num_steps_trained: 1452500\n",
      "    sample_time_ms: 3623.126\n",
      "    update_time_ms: 4.149\n",
      "  iterations_since_restore: 581\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.4\n",
      "    ram_util_percent: 63.224999999999994\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.059086324571923\n",
      "    mean_inference_ms: 0.975840529475339\n",
      "    mean_processing_ms: 0.6956634192987731\n",
      "  time_since_restore: 2038.99835896492\n",
      "  time_this_iter_s: 2.9189698696136475\n",
      "  time_total_s: 2038.99835896492\n",
      "  timestamp: 1596123463\n",
      "  timesteps_since_restore: 1510600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1510600\n",
      "  training_iteration: 581\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2038 s, 581 iter, 1510600 ts, 562 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-37-49\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 561.9212687059601\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 603\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 22.968\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.433585524559021\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.9550064911964e-07\n",
      "        policy_loss: 0.0005427363212220371\n",
      "        total_loss: 56.30771255493164\n",
      "        vf_explained_var: 0.023782849311828613\n",
      "        vf_loss: 56.30717468261719\n",
      "    load_time_ms: 1.377\n",
      "    num_steps_sampled: 1515800\n",
      "    num_steps_trained: 1457500\n",
      "    sample_time_ms: 3559.758\n",
      "    update_time_ms: 4.393\n",
      "  iterations_since_restore: 583\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.7\n",
      "    ram_util_percent: 63.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.0585830990110825\n",
      "    mean_inference_ms: 0.9756900232150144\n",
      "    mean_processing_ms: 0.6956126428802001\n",
      "  time_since_restore: 2045.0873057842255\n",
      "  time_this_iter_s: 2.961897373199463\n",
      "  time_total_s: 2045.0873057842255\n",
      "  timestamp: 1596123469\n",
      "  timesteps_since_restore: 1515800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1515800\n",
      "  training_iteration: 583\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2045 s, 583 iter, 1515800 ts, 562 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-37-55\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 564.3073068514507\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 606\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 21.944\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4261642694473267\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.750158323294727e-08\n",
      "        policy_loss: -0.0006300881505012512\n",
      "        total_loss: 31.523147583007812\n",
      "        vf_explained_var: 0.04224348068237305\n",
      "        vf_loss: 31.523778915405273\n",
      "    load_time_ms: 1.259\n",
      "    num_steps_sampled: 1521000\n",
      "    num_steps_trained: 1462500\n",
      "    sample_time_ms: 3340.989\n",
      "    update_time_ms: 4.027\n",
      "  iterations_since_restore: 585\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.55\n",
      "    ram_util_percent: 63.150000000000006\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.057945747749377\n",
      "    mean_inference_ms: 0.9756947107852735\n",
      "    mean_processing_ms: 0.6955991885868358\n",
      "  time_since_restore: 2051.8819210529327\n",
      "  time_this_iter_s: 2.7789275646209717\n",
      "  time_total_s: 2051.8819210529327\n",
      "  timestamp: 1596123475\n",
      "  timesteps_since_restore: 1521000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1521000\n",
      "  training_iteration: 585\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2051 s, 585 iter, 1521000 ts, 564 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-38-02\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 562.2467838546033\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 608\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.917\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4280574321746826\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.4414310953725362e-06\n",
      "        policy_loss: -0.0036919654812663794\n",
      "        total_loss: 48.5516471862793\n",
      "        vf_explained_var: 0.038976430892944336\n",
      "        vf_loss: 48.555335998535156\n",
      "    load_time_ms: 1.157\n",
      "    num_steps_sampled: 1526200\n",
      "    num_steps_trained: 1467500\n",
      "    sample_time_ms: 3160.534\n",
      "    update_time_ms: 3.596\n",
      "  iterations_since_restore: 587\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.85\n",
      "    ram_util_percent: 63.150000000000006\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.0570488796934905\n",
      "    mean_inference_ms: 0.97540212607571\n",
      "    mean_processing_ms: 0.6955430906516675\n",
      "  time_since_restore: 2058.5340609550476\n",
      "  time_this_iter_s: 2.681312322616577\n",
      "  time_total_s: 2058.5340609550476\n",
      "  timestamp: 1596123482\n",
      "  timesteps_since_restore: 1526200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1526200\n",
      "  training_iteration: 587\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2058 s, 587 iter, 1526200 ts, 562 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-38-10\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 563.5863388370049\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 611\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.835\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4275171756744385\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.4635075988044264e-06\n",
      "        policy_loss: 0.00853901170194149\n",
      "        total_loss: 45.891475677490234\n",
      "        vf_explained_var: 0.02317887544631958\n",
      "        vf_loss: 45.882938385009766\n",
      "    load_time_ms: 1.121\n",
      "    num_steps_sampled: 1531400\n",
      "    num_steps_trained: 1472500\n",
      "    sample_time_ms: 3340.372\n",
      "    update_time_ms: 3.63\n",
      "  iterations_since_restore: 589\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.17999999999999\n",
      "    ram_util_percent: 63.160000000000004\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.05605179686908\n",
      "    mean_inference_ms: 0.9753146117586211\n",
      "    mean_processing_ms: 0.6954748609024501\n",
      "  time_since_restore: 2066.1044924259186\n",
      "  time_this_iter_s: 3.551326036453247\n",
      "  time_total_s: 2066.1044924259186\n",
      "  timestamp: 1596123490\n",
      "  timesteps_since_restore: 1531400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1531400\n",
      "  training_iteration: 589\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2066 s, 589 iter, 1531400 ts, 564 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-38-16\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1166.0592011823494\n",
      "  episode_reward_mean: 566.5198401182133\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 612\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.558\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4280555248260498\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.199214676096744e-07\n",
      "        policy_loss: 0.00134045141749084\n",
      "        total_loss: 41.65107345581055\n",
      "        vf_explained_var: 0.029781043529510498\n",
      "        vf_loss: 41.64972686767578\n",
      "    load_time_ms: 1.133\n",
      "    num_steps_sampled: 1536600\n",
      "    num_steps_trained: 1477500\n",
      "    sample_time_ms: 3298.411\n",
      "    update_time_ms: 3.535\n",
      "  iterations_since_restore: 591\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.9\n",
      "    ram_util_percent: 63.239999999999995\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.055719190143355\n",
      "    mean_inference_ms: 0.9751330499709282\n",
      "    mean_processing_ms: 0.6954501644504026\n",
      "  time_since_restore: 2072.286030769348\n",
      "  time_this_iter_s: 3.2437593936920166\n",
      "  time_total_s: 2072.286030769348\n",
      "  timestamp: 1596123496\n",
      "  timesteps_since_restore: 1536600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1536600\n",
      "  training_iteration: 591\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2072 s, 591 iter, 1536600 ts, 567 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-38-23\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1097.5016173988267\n",
      "  episode_reward_mean: 562.562061253421\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 615\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.766\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4334865808486938\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.7461518331838306e-07\n",
      "        policy_loss: -0.0015593226999044418\n",
      "        total_loss: 75.6963119506836\n",
      "        vf_explained_var: 0.020385801792144775\n",
      "        vf_loss: 75.69786834716797\n",
      "    load_time_ms: 1.025\n",
      "    num_steps_sampled: 1541800\n",
      "    num_steps_trained: 1482500\n",
      "    sample_time_ms: 3400.047\n",
      "    update_time_ms: 3.405\n",
      "  iterations_since_restore: 593\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.73333333333333\n",
      "    ram_util_percent: 63.199999999999996\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.054598334904753\n",
      "    mean_inference_ms: 0.9749661926753721\n",
      "    mean_processing_ms: 0.6954079151350537\n",
      "  time_since_restore: 2079.3798916339874\n",
      "  time_this_iter_s: 3.9803621768951416\n",
      "  time_total_s: 2079.3798916339874\n",
      "  timestamp: 1596123503\n",
      "  timesteps_since_restore: 1541800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1541800\n",
      "  training_iteration: 593\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2079 s, 593 iter, 1541800 ts, 563 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-38-29\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1097.5016173988267\n",
      "  episode_reward_mean: 562.8947650576155\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 616\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.61\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.429209589958191\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.7704237481884775e-07\n",
      "        policy_loss: 0.0006625659298151731\n",
      "        total_loss: 62.53950119018555\n",
      "        vf_explained_var: 0.015511095523834229\n",
      "        vf_loss: 62.53884506225586\n",
      "    load_time_ms: 1.032\n",
      "    num_steps_sampled: 1547000\n",
      "    num_steps_trained: 1487500\n",
      "    sample_time_ms: 3333.67\n",
      "    update_time_ms: 3.337\n",
      "  iterations_since_restore: 595\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.3\n",
      "    ram_util_percent: 63.475\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.054299950278871\n",
      "    mean_inference_ms: 0.9749724134652017\n",
      "    mean_processing_ms: 0.6953612429037668\n",
      "  time_since_restore: 2085.508323431015\n",
      "  time_this_iter_s: 3.0613787174224854\n",
      "  time_total_s: 2085.508323431015\n",
      "  timestamp: 1596123509\n",
      "  timesteps_since_restore: 1547000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1547000\n",
      "  training_iteration: 595\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2085 s, 595 iter, 1547000 ts, 563 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-38-36\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1097.5016173988267\n",
      "  episode_reward_mean: 568.2872090906942\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 619\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.118\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4382628202438354\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.741668817587197e-07\n",
      "        policy_loss: 0.0027124336920678616\n",
      "        total_loss: 100.04331970214844\n",
      "        vf_explained_var: 0.011052548885345459\n",
      "        vf_loss: 100.04060363769531\n",
      "    load_time_ms: 1.02\n",
      "    num_steps_sampled: 1552200\n",
      "    num_steps_trained: 1492500\n",
      "    sample_time_ms: 3385.888\n",
      "    update_time_ms: 3.262\n",
      "  iterations_since_restore: 597\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 40.56666666666667\n",
      "    ram_util_percent: 63.31666666666667\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.0530398491015625\n",
      "    mean_inference_ms: 0.9745459217463767\n",
      "    mean_processing_ms: 0.695271292317027\n",
      "  time_since_restore: 2092.6753182411194\n",
      "  time_this_iter_s: 3.91386342048645\n",
      "  time_total_s: 2092.6753182411194\n",
      "  timestamp: 1596123516\n",
      "  timesteps_since_restore: 1552200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1552200\n",
      "  training_iteration: 597\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2092 s, 597 iter, 1552200 ts, 568 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-38-43\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1097.5016173988267\n",
      "  episode_reward_mean: 571.0992739435584\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 621\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.562\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4241716861724854\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.233764568401966e-07\n",
      "        policy_loss: 0.0033747784327715635\n",
      "        total_loss: 41.57365036010742\n",
      "        vf_explained_var: 0.02720510959625244\n",
      "        vf_loss: 41.57027816772461\n",
      "    load_time_ms: 1.035\n",
      "    num_steps_sampled: 1557400\n",
      "    num_steps_trained: 1497500\n",
      "    sample_time_ms: 3254.231\n",
      "    update_time_ms: 3.191\n",
      "  iterations_since_restore: 599\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 51.925\n",
      "    ram_util_percent: 63.25\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.052680528735125\n",
      "    mean_inference_ms: 0.9746727428216304\n",
      "    mean_processing_ms: 0.6952555828764626\n",
      "  time_since_restore: 2098.9338896274567\n",
      "  time_this_iter_s: 2.4698877334594727\n",
      "  time_total_s: 2098.9338896274567\n",
      "  timestamp: 1596123523\n",
      "  timesteps_since_restore: 1557400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1557400\n",
      "  training_iteration: 599\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2098 s, 599 iter, 1557400 ts, 571 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-38-49\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1097.5016173988267\n",
      "  episode_reward_mean: 576.2467686375549\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 622\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.738\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.43648099899292\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.153679921932053e-06\n",
      "        policy_loss: 0.003998132888227701\n",
      "        total_loss: 97.81682586669922\n",
      "        vf_explained_var: 0.015339255332946777\n",
      "        vf_loss: 97.81283569335938\n",
      "    load_time_ms: 1.021\n",
      "    num_steps_sampled: 1562600\n",
      "    num_steps_trained: 1502500\n",
      "    sample_time_ms: 3298.315\n",
      "    update_time_ms: 3.222\n",
      "  iterations_since_restore: 601\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.68\n",
      "    ram_util_percent: 63.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.052391693376771\n",
      "    mean_inference_ms: 0.9745054344551898\n",
      "    mean_processing_ms: 0.6952335409588716\n",
      "  time_since_restore: 2105.5465738773346\n",
      "  time_this_iter_s: 3.797797203063965\n",
      "  time_total_s: 2105.5465738773346\n",
      "  timestamp: 1596123529\n",
      "  timesteps_since_restore: 1562600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1562600\n",
      "  training_iteration: 601\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2105 s, 601 iter, 1562600 ts, 576 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-38-56\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1097.5016173988267\n",
      "  episode_reward_mean: 571.9153938639538\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 626\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.39\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.423328161239624\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.588058466950315e-06\n",
      "        policy_loss: -0.002976805903017521\n",
      "        total_loss: 24.55198097229004\n",
      "        vf_explained_var: 0.023168742656707764\n",
      "        vf_loss: 24.55495834350586\n",
      "    load_time_ms: 1.016\n",
      "    num_steps_sampled: 1567800\n",
      "    num_steps_trained: 1507500\n",
      "    sample_time_ms: 3267.802\n",
      "    update_time_ms: 3.001\n",
      "  iterations_since_restore: 603\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.260000000000005\n",
      "    ram_util_percent: 63.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.050924953959783\n",
      "    mean_inference_ms: 0.9743327402114446\n",
      "    mean_processing_ms: 0.6951273244674249\n",
      "  time_since_restore: 2112.32835149765\n",
      "  time_this_iter_s: 3.120314359664917\n",
      "  time_total_s: 2112.32835149765\n",
      "  timestamp: 1596123536\n",
      "  timesteps_since_restore: 1567800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1567800\n",
      "  training_iteration: 603\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2112 s, 603 iter, 1567800 ts, 572 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-39-03\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1030.5710320502847\n",
      "  episode_reward_mean: 563.9843691538802\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 627\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 16.892\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4301327466964722\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.538108901717351e-06\n",
      "        policy_loss: -0.0042144074104726315\n",
      "        total_loss: 50.46963119506836\n",
      "        vf_explained_var: 0.014225184917449951\n",
      "        vf_loss: 50.47385025024414\n",
      "    load_time_ms: 1.011\n",
      "    num_steps_sampled: 1573000\n",
      "    num_steps_trained: 1512500\n",
      "    sample_time_ms: 3317.448\n",
      "    update_time_ms: 3.044\n",
      "  iterations_since_restore: 605\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.440000000000005\n",
      "    ram_util_percent: 63.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.050611232364125\n",
      "    mean_inference_ms: 0.974159210815958\n",
      "    mean_processing_ms: 0.6951066231521666\n",
      "  time_since_restore: 2118.9493639469147\n",
      "  time_this_iter_s: 3.8873395919799805\n",
      "  time_total_s: 2118.9493639469147\n",
      "  timestamp: 1596123543\n",
      "  timesteps_since_restore: 1573000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1573000\n",
      "  training_iteration: 605\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2118 s, 605 iter, 1573000 ts, 564 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-39-09\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1030.5710320502847\n",
      "  episode_reward_mean: 565.4769536027336\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 628\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.12\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4360216856002808\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.385663092103641e-07\n",
      "        policy_loss: -0.0029003925155848265\n",
      "        total_loss: 82.80919647216797\n",
      "        vf_explained_var: 0.023040175437927246\n",
      "        vf_loss: 82.81209564208984\n",
      "    load_time_ms: 1.065\n",
      "    num_steps_sampled: 1578200\n",
      "    num_steps_trained: 1517500\n",
      "    sample_time_ms: 3210.265\n",
      "    update_time_ms: 3.06\n",
      "  iterations_since_restore: 607\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.875\n",
      "    ram_util_percent: 63.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.049927337689703\n",
      "    mean_inference_ms: 0.9739414803700781\n",
      "    mean_processing_ms: 0.6950600799054202\n",
      "  time_since_restore: 2125.0605368614197\n",
      "  time_this_iter_s: 2.5229663848876953\n",
      "  time_total_s: 2125.0605368614197\n",
      "  timestamp: 1596123549\n",
      "  timesteps_since_restore: 1578200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1578200\n",
      "  training_iteration: 607\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2125 s, 607 iter, 1578200 ts, 565 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-39-15\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1030.5710320502847\n",
      "  episode_reward_mean: 572.9370964295965\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 631\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.197\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4245986938476562\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.5268444713001372e-06\n",
      "        policy_loss: 0.004162356723099947\n",
      "        total_loss: 38.065914154052734\n",
      "        vf_explained_var: 0.03950965404510498\n",
      "        vf_loss: 38.06175231933594\n",
      "    load_time_ms: 1.086\n",
      "    num_steps_sampled: 1583400\n",
      "    num_steps_trained: 1522500\n",
      "    sample_time_ms: 3228.079\n",
      "    update_time_ms: 3.243\n",
      "  iterations_since_restore: 609\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.833333333333336\n",
      "    ram_util_percent: 63.20000000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.049009948689607\n",
      "    mean_inference_ms: 0.9738925304357577\n",
      "    mean_processing_ms: 0.6950304350540369\n",
      "  time_since_restore: 2131.50248670578\n",
      "  time_this_iter_s: 2.5060784816741943\n",
      "  time_total_s: 2131.50248670578\n",
      "  timestamp: 1596123555\n",
      "  timesteps_since_restore: 1583400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1583400\n",
      "  training_iteration: 609\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2131 s, 609 iter, 1583400 ts, 573 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-39-21\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1030.5710320502847\n",
      "  episode_reward_mean: 575.2392638500427\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 633\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.392\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4289826154708862\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.701567550251639e-07\n",
      "        policy_loss: -0.0021087569184601307\n",
      "        total_loss: 48.576255798339844\n",
      "        vf_explained_var: 0.022820353507995605\n",
      "        vf_loss: 48.5783576965332\n",
      "    load_time_ms: 1.089\n",
      "    num_steps_sampled: 1588600\n",
      "    num_steps_trained: 1527500\n",
      "    sample_time_ms: 3154.845\n",
      "    update_time_ms: 3.286\n",
      "  iterations_since_restore: 611\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 51.36\n",
      "    ram_util_percent: 63.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.048005096041135\n",
      "    mean_inference_ms: 0.973562167945656\n",
      "    mean_processing_ms: 0.6949288958000301\n",
      "  time_since_restore: 2137.3860771656036\n",
      "  time_this_iter_s: 2.928412914276123\n",
      "  time_total_s: 2137.3860771656036\n",
      "  timestamp: 1596123561\n",
      "  timesteps_since_restore: 1588600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1588600\n",
      "  training_iteration: 611\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2137 s, 611 iter, 1588600 ts, 575 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-39-27\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1030.5710320502847\n",
      "  episode_reward_mean: 573.4416944164387\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 636\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.862\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4270374774932861\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.882428920107486e-07\n",
      "        policy_loss: 0.0012709691654890776\n",
      "        total_loss: 36.76872253417969\n",
      "        vf_explained_var: 0.025513410568237305\n",
      "        vf_loss: 36.767452239990234\n",
      "    load_time_ms: 1.107\n",
      "    num_steps_sampled: 1593800\n",
      "    num_steps_trained: 1532500\n",
      "    sample_time_ms: 3089.434\n",
      "    update_time_ms: 3.399\n",
      "  iterations_since_restore: 613\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 51.519999999999996\n",
      "    ram_util_percent: 63.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.04707628761546\n",
      "    mean_inference_ms: 0.9735697429641362\n",
      "    mean_processing_ms: 0.6948658779231962\n",
      "  time_since_restore: 2143.5197319984436\n",
      "  time_this_iter_s: 3.398987293243408\n",
      "  time_total_s: 2143.5197319984436\n",
      "  timestamp: 1596123567\n",
      "  timesteps_since_restore: 1593800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1593800\n",
      "  training_iteration: 613\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2143 s, 613 iter, 1593800 ts, 573 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-39-34\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1030.5710320502847\n",
      "  episode_reward_mean: 570.9119557047601\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 638\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.751\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4304256439208984\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.4829846501670545e-07\n",
      "        policy_loss: -0.0012681508669629693\n",
      "        total_loss: 46.10427474975586\n",
      "        vf_explained_var: 0.015873074531555176\n",
      "        vf_loss: 46.10554504394531\n",
      "    load_time_ms: 1.095\n",
      "    num_steps_sampled: 1599000\n",
      "    num_steps_trained: 1537500\n",
      "    sample_time_ms: 3087.708\n",
      "    update_time_ms: 3.383\n",
      "  iterations_since_restore: 615\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.5\n",
      "    ram_util_percent: 63.199999999999996\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.046023125155069\n",
      "    mean_inference_ms: 0.9731580239605188\n",
      "    mean_processing_ms: 0.6947960641420902\n",
      "  time_since_restore: 2150.122087240219\n",
      "  time_this_iter_s: 3.866313934326172\n",
      "  time_total_s: 2150.122087240219\n",
      "  timestamp: 1596123574\n",
      "  timesteps_since_restore: 1599000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1599000\n",
      "  training_iteration: 615\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2150 s, 615 iter, 1599000 ts, 571 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-39-40\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1030.5710320502847\n",
      "  episode_reward_mean: 572.5437311691358\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 640\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.765\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4300259351730347\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.0217428325631772e-07\n",
      "        policy_loss: 0.0016612140461802483\n",
      "        total_loss: 45.3099365234375\n",
      "        vf_explained_var: 0.005999505519866943\n",
      "        vf_loss: 45.30828094482422\n",
      "    load_time_ms: 1.039\n",
      "    num_steps_sampled: 1604200\n",
      "    num_steps_trained: 1542500\n",
      "    sample_time_ms: 3126.58\n",
      "    update_time_ms: 3.33\n",
      "  iterations_since_restore: 617\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.98333333333334\n",
      "    ram_util_percent: 63.199999999999996\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.045066128526778\n",
      "    mean_inference_ms: 0.9730721427143003\n",
      "    mean_processing_ms: 0.6947387363362801\n",
      "  time_since_restore: 2156.6083450317383\n",
      "  time_this_iter_s: 4.023531198501587\n",
      "  time_total_s: 2156.6083450317383\n",
      "  timestamp: 1596123580\n",
      "  timesteps_since_restore: 1604200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1604200\n",
      "  training_iteration: 617\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2156 s, 617 iter, 1604200 ts, 573 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-39-46\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1030.5710320502847\n",
      "  episode_reward_mean: 569.2850439773753\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 641\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.344\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4314512014389038\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.211353482081904e-07\n",
      "        policy_loss: -0.003014572197571397\n",
      "        total_loss: 70.9941635131836\n",
      "        vf_explained_var: 0.02438211441040039\n",
      "        vf_loss: 70.9971694946289\n",
      "    load_time_ms: 1.0\n",
      "    num_steps_sampled: 1609400\n",
      "    num_steps_trained: 1547500\n",
      "    sample_time_ms: 3086.187\n",
      "    update_time_ms: 3.088\n",
      "  iterations_since_restore: 619\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.5\n",
      "    ram_util_percent: 63.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.045039963820586\n",
      "    mean_inference_ms: 0.9731441228409907\n",
      "    mean_processing_ms: 0.6947385380539014\n",
      "  time_since_restore: 2162.637272834778\n",
      "  time_this_iter_s: 2.5860562324523926\n",
      "  time_total_s: 2162.637272834778\n",
      "  timestamp: 1596123586\n",
      "  timesteps_since_restore: 1609400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1609400\n",
      "  training_iteration: 619\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2162 s, 619 iter, 1609400 ts, 569 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-39-52\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1030.5710320502847\n",
      "  episode_reward_mean: 575.4317631199788\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 643\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.702\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4296042919158936\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.613901983750111e-07\n",
      "        policy_loss: -0.0009032919770106673\n",
      "        total_loss: 62.35084915161133\n",
      "        vf_explained_var: 0.028485119342803955\n",
      "        vf_loss: 62.351776123046875\n",
      "    load_time_ms: 1.007\n",
      "    num_steps_sampled: 1614600\n",
      "    num_steps_trained: 1552500\n",
      "    sample_time_ms: 3075.255\n",
      "    update_time_ms: 3.056\n",
      "  iterations_since_restore: 621\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.699999999999996\n",
      "    ram_util_percent: 63.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.043911384244671\n",
      "    mean_inference_ms: 0.9727107170912477\n",
      "    mean_processing_ms: 0.6946572826279902\n",
      "  time_since_restore: 2168.4147102832794\n",
      "  time_this_iter_s: 2.7663087844848633\n",
      "  time_total_s: 2168.4147102832794\n",
      "  timestamp: 1596123592\n",
      "  timesteps_since_restore: 1614600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1614600\n",
      "  training_iteration: 621\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2168 s, 621 iter, 1614600 ts, 575 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-39-59\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1030.5710320502847\n",
      "  episode_reward_mean: 577.3960324865989\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 645\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.453\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4267667531967163\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 7.813453635208134e-07\n",
      "        policy_loss: -0.0009487365023232996\n",
      "        total_loss: 43.608882904052734\n",
      "        vf_explained_var: 0.015792667865753174\n",
      "        vf_loss: 43.60981750488281\n",
      "    load_time_ms: 0.987\n",
      "    num_steps_sampled: 1619800\n",
      "    num_steps_trained: 1557500\n",
      "    sample_time_ms: 3095.447\n",
      "    update_time_ms: 2.991\n",
      "  iterations_since_restore: 623\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 51.075\n",
      "    ram_util_percent: 63.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.042875668087368\n",
      "    mean_inference_ms: 0.9726000695983824\n",
      "    mean_processing_ms: 0.6945946597263437\n",
      "  time_since_restore: 2174.747389793396\n",
      "  time_this_iter_s: 2.5465214252471924\n",
      "  time_total_s: 2174.747389793396\n",
      "  timestamp: 1596123599\n",
      "  timesteps_since_restore: 1619800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1619800\n",
      "  training_iteration: 623\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2174 s, 623 iter, 1619800 ts, 577 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-40-05\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1030.5710320502847\n",
      "  episode_reward_mean: 571.2206204621168\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 648\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.75\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4227724075317383\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.884906605999277e-07\n",
      "        policy_loss: 0.004326416179537773\n",
      "        total_loss: 35.85725021362305\n",
      "        vf_explained_var: 0.03410083055496216\n",
      "        vf_loss: 35.85292053222656\n",
      "    load_time_ms: 0.978\n",
      "    num_steps_sampled: 1625000\n",
      "    num_steps_trained: 1562500\n",
      "    sample_time_ms: 3086.567\n",
      "    update_time_ms: 3.03\n",
      "  iterations_since_restore: 625\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.53333333333333\n",
      "    ram_util_percent: 63.20000000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.041653885218845\n",
      "    mean_inference_ms: 0.9722190236987136\n",
      "    mean_processing_ms: 0.6945155643257308\n",
      "  time_since_restore: 2181.263413667679\n",
      "  time_this_iter_s: 2.4501779079437256\n",
      "  time_total_s: 2181.263413667679\n",
      "  timestamp: 1596123605\n",
      "  timesteps_since_restore: 1625000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1625000\n",
      "  training_iteration: 625\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2181 s, 625 iter, 1625000 ts, 571 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-40-11\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1030.5710320502847\n",
      "  episode_reward_mean: 575.8689474551206\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 650\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.772\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4341778755187988\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.832744480154361e-07\n",
      "        policy_loss: 0.004327103961259127\n",
      "        total_loss: 94.12163543701172\n",
      "        vf_explained_var: 0.011470675468444824\n",
      "        vf_loss: 94.1173095703125\n",
      "    load_time_ms: 0.984\n",
      "    num_steps_sampled: 1630200\n",
      "    num_steps_trained: 1567500\n",
      "    sample_time_ms: 3026.973\n",
      "    update_time_ms: 3.093\n",
      "  iterations_since_restore: 627\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.580000000000005\n",
      "    ram_util_percent: 63.160000000000004\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.040541634279064\n",
      "    mean_inference_ms: 0.9720868403031738\n",
      "    mean_processing_ms: 0.6944425149190491\n",
      "  time_since_restore: 2187.154350757599\n",
      "  time_this_iter_s: 3.119306802749634\n",
      "  time_total_s: 2187.154350757599\n",
      "  timestamp: 1596123611\n",
      "  timesteps_since_restore: 1630200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1630200\n",
      "  training_iteration: 627\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2187 s, 627 iter, 1630200 ts, 576 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-40-17\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1030.5710320502847\n",
      "  episode_reward_mean: 577.5554015548217\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 653\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.889\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4309312105178833\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.132173439254984e-06\n",
      "        policy_loss: 0.006173249799758196\n",
      "        total_loss: 71.70234680175781\n",
      "        vf_explained_var: 0.02205902338027954\n",
      "        vf_loss: 71.6961898803711\n",
      "    load_time_ms: 0.991\n",
      "    num_steps_sampled: 1635400\n",
      "    num_steps_trained: 1572500\n",
      "    sample_time_ms: 3067.591\n",
      "    update_time_ms: 3.198\n",
      "  iterations_since_restore: 629\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.22\n",
      "    ram_util_percent: 63.160000000000004\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.039230164441294\n",
      "    mean_inference_ms: 0.9716822287839154\n",
      "    mean_processing_ms: 0.6943472077259851\n",
      "  time_since_restore: 2193.591139316559\n",
      "  time_this_iter_s: 3.6832761764526367\n",
      "  time_total_s: 2193.591139316559\n",
      "  timestamp: 1596123617\n",
      "  timesteps_since_restore: 1635400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1635400\n",
      "  training_iteration: 629\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2193 s, 629 iter, 1635400 ts, 578 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-40-23\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1030.5710320502847\n",
      "  episode_reward_mean: 577.5554015548217\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 653\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.811\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.42580246925354\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.5759936761460267e-07\n",
      "        policy_loss: 0.007052143104374409\n",
      "        total_loss: 66.42821502685547\n",
      "        vf_explained_var: 0.014105796813964844\n",
      "        vf_loss: 66.42117309570312\n",
      "    load_time_ms: 1.001\n",
      "    num_steps_sampled: 1640600\n",
      "    num_steps_trained: 1577500\n",
      "    sample_time_ms: 3023.02\n",
      "    update_time_ms: 3.13\n",
      "  iterations_since_restore: 631\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.49999999999999\n",
      "    ram_util_percent: 63.20000000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.039230164441294\n",
      "    mean_inference_ms: 0.9716822287839156\n",
      "    mean_processing_ms: 0.6943472077259852\n",
      "  time_since_restore: 2198.9223263263702\n",
      "  time_this_iter_s: 2.745914936065674\n",
      "  time_total_s: 2198.9223263263702\n",
      "  timestamp: 1596123623\n",
      "  timesteps_since_restore: 1640600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1640600\n",
      "  training_iteration: 631\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2198 s, 631 iter, 1640600 ts, 578 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-40-29\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1030.5710320502847\n",
      "  episode_reward_mean: 576.8028221037749\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 655\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.168\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4334254264831543\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.9437742240552325e-06\n",
      "        policy_loss: 0.0016912550199776888\n",
      "        total_loss: 96.5839614868164\n",
      "        vf_explained_var: 0.014633238315582275\n",
      "        vf_loss: 96.58226013183594\n",
      "    load_time_ms: 1.028\n",
      "    num_steps_sampled: 1645800\n",
      "    num_steps_trained: 1582500\n",
      "    sample_time_ms: 2963.132\n",
      "    update_time_ms: 3.157\n",
      "  iterations_since_restore: 633\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.324999999999996\n",
      "    ram_util_percent: 63.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.038084486732901\n",
      "    mean_inference_ms: 0.9715399555419866\n",
      "    mean_processing_ms: 0.6942720860568078\n",
      "  time_since_restore: 2204.661118745804\n",
      "  time_this_iter_s: 2.7650880813598633\n",
      "  time_total_s: 2204.661118745804\n",
      "  timestamp: 1596123629\n",
      "  timesteps_since_restore: 1645800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1645800\n",
      "  training_iteration: 633\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2204 s, 633 iter, 1645800 ts, 577 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-40-34\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1030.5710320502847\n",
      "  episode_reward_mean: 583.3746911344468\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 658\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.668\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.430690884590149\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.3116312402416952e-05\n",
      "        policy_loss: -0.0008998126140795648\n",
      "        total_loss: 69.40534973144531\n",
      "        vf_explained_var: 0.023727834224700928\n",
      "        vf_loss: 69.40625762939453\n",
      "    load_time_ms: 1.026\n",
      "    num_steps_sampled: 1651000\n",
      "    num_steps_trained: 1587500\n",
      "    sample_time_ms: 2907.568\n",
      "    update_time_ms: 3.047\n",
      "  iterations_since_restore: 635\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.6\n",
      "    ram_util_percent: 63.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.036855448808714\n",
      "    mean_inference_ms: 0.9712303944454499\n",
      "    mean_processing_ms: 0.6941922900988861\n",
      "  time_since_restore: 2210.614681005478\n",
      "  time_this_iter_s: 2.74422550201416\n",
      "  time_total_s: 2210.614681005478\n",
      "  timestamp: 1596123634\n",
      "  timesteps_since_restore: 1651000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1651000\n",
      "  training_iteration: 635\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2210 s, 635 iter, 1651000 ts, 583 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-40-40\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1030.5710320502847\n",
      "  episode_reward_mean: 589.4466846549533\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 660\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.176\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4331398010253906\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.968619123246754e-06\n",
      "        policy_loss: 0.004202247131615877\n",
      "        total_loss: 50.39419937133789\n",
      "        vf_explained_var: 0.02574557065963745\n",
      "        vf_loss: 50.38999557495117\n",
      "    load_time_ms: 1.045\n",
      "    num_steps_sampled: 1656200\n",
      "    num_steps_trained: 1592500\n",
      "    sample_time_ms: 2912.25\n",
      "    update_time_ms: 3.112\n",
      "  iterations_since_restore: 637\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.650000000000006\n",
      "    ram_util_percent: 63.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.035589102904421\n",
      "    mean_inference_ms: 0.9709776784557494\n",
      "    mean_processing_ms: 0.6941019456906603\n",
      "  time_since_restore: 2216.558947324753\n",
      "  time_this_iter_s: 2.81380558013916\n",
      "  time_total_s: 2216.558947324753\n",
      "  timestamp: 1596123640\n",
      "  timesteps_since_restore: 1656200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1656200\n",
      "  training_iteration: 637\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2216 s, 637 iter, 1656200 ts, 589 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-40-47\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1030.5710320502847\n",
      "  episode_reward_mean: 588.2344576556098\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 663\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.994\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4295023679733276\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.947755650799081e-07\n",
      "        policy_loss: 0.002772041130810976\n",
      "        total_loss: 34.1837043762207\n",
      "        vf_explained_var: 0.022884905338287354\n",
      "        vf_loss: 34.18093490600586\n",
      "    load_time_ms: 1.028\n",
      "    num_steps_sampled: 1661400\n",
      "    num_steps_trained: 1597500\n",
      "    sample_time_ms: 2915.405\n",
      "    update_time_ms: 3.064\n",
      "  iterations_since_restore: 639\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.324999999999996\n",
      "    ram_util_percent: 63.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.034198445660988\n",
      "    mean_inference_ms: 0.9705465253758448\n",
      "    mean_processing_ms: 0.6939962688410453\n",
      "  time_since_restore: 2223.024710416794\n",
      "  time_this_iter_s: 2.707139492034912\n",
      "  time_total_s: 2223.024710416794\n",
      "  timestamp: 1596123647\n",
      "  timesteps_since_restore: 1661400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1661400\n",
      "  training_iteration: 639\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2223 s, 639 iter, 1661400 ts, 588 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-40-53\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1030.5710320502847\n",
      "  episode_reward_mean: 583.0994484141513\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 664\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.851\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4433977603912354\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.0192441550316289e-05\n",
      "        policy_loss: 0.003489180700853467\n",
      "        total_loss: 95.64799499511719\n",
      "        vf_explained_var: 0.015163004398345947\n",
      "        vf_loss: 95.64450073242188\n",
      "    load_time_ms: 1.006\n",
      "    num_steps_sampled: 1666600\n",
      "    num_steps_trained: 1602500\n",
      "    sample_time_ms: 2952.666\n",
      "    update_time_ms: 3.046\n",
      "  iterations_since_restore: 641\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.10000000000001\n",
      "    ram_util_percent: 63.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.033406053918758\n",
      "    mean_inference_ms: 0.9704262935043159\n",
      "    mean_processing_ms: 0.6939291430902731\n",
      "  time_since_restore: 2228.7253737449646\n",
      "  time_this_iter_s: 2.9498088359832764\n",
      "  time_total_s: 2228.7253737449646\n",
      "  timestamp: 1596123653\n",
      "  timesteps_since_restore: 1666600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1666600\n",
      "  training_iteration: 641\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2228 s, 641 iter, 1666600 ts, 583 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-40-59\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1030.5710320502847\n",
      "  episode_reward_mean: 585.5575154897242\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 667\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.473\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4408842325210571\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.165256885040435e-06\n",
      "        policy_loss: 0.006844432093203068\n",
      "        total_loss: 75.30753326416016\n",
      "        vf_explained_var: 0.019482195377349854\n",
      "        vf_loss: 75.30068969726562\n",
      "    load_time_ms: 0.992\n",
      "    num_steps_sampled: 1671800\n",
      "    num_steps_trained: 1607500\n",
      "    sample_time_ms: 2985.586\n",
      "    update_time_ms: 3.103\n",
      "  iterations_since_restore: 643\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 52.080000000000005\n",
      "    ram_util_percent: 63.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.032308788527188\n",
      "    mean_inference_ms: 0.9702368716512915\n",
      "    mean_processing_ms: 0.6938987293388224\n",
      "  time_since_restore: 2234.789571285248\n",
      "  time_this_iter_s: 2.996044397354126\n",
      "  time_total_s: 2234.789571285248\n",
      "  timestamp: 1596123659\n",
      "  timesteps_since_restore: 1671800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1671800\n",
      "  training_iteration: 643\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2234 s, 643 iter, 1671800 ts, 586 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-41-04\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1030.5710320502847\n",
      "  episode_reward_mean: 589.9866846505244\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 668\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.685\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4355480670928955\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.385350388882216e-06\n",
      "        policy_loss: 0.005772717297077179\n",
      "        total_loss: 51.283565521240234\n",
      "        vf_explained_var: 0.02564483880996704\n",
      "        vf_loss: 51.27779769897461\n",
      "    load_time_ms: 0.984\n",
      "    num_steps_sampled: 1677000\n",
      "    num_steps_trained: 1612500\n",
      "    sample_time_ms: 2967.871\n",
      "    update_time_ms: 3.144\n",
      "  iterations_since_restore: 645\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 51.87499999999999\n",
      "    ram_util_percent: 63.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.031789333111442\n",
      "    mean_inference_ms: 0.9701153159400748\n",
      "    mean_processing_ms: 0.6938627214775893\n",
      "  time_since_restore: 2240.5686321258545\n",
      "  time_this_iter_s: 2.6451241970062256\n",
      "  time_total_s: 2240.5686321258545\n",
      "  timestamp: 1596123664\n",
      "  timesteps_since_restore: 1677000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1677000\n",
      "  training_iteration: 645\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2240 s, 645 iter, 1677000 ts, 590 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-41-11\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1030.5710320502847\n",
      "  episode_reward_mean: 590.4868078022395\n",
      "  episode_reward_min: 176.78854378406191\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 670\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.247\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4417537450790405\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.8993497405972448e-06\n",
      "        policy_loss: -0.001515496289357543\n",
      "        total_loss: 62.86637496948242\n",
      "        vf_explained_var: 0.02119380235671997\n",
      "        vf_loss: 62.867889404296875\n",
      "    load_time_ms: 0.972\n",
      "    num_steps_sampled: 1682200\n",
      "    num_steps_trained: 1617500\n",
      "    sample_time_ms: 3015.267\n",
      "    update_time_ms: 3.006\n",
      "  iterations_since_restore: 647\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.29999999999999\n",
      "    ram_util_percent: 63.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.030559820230705\n",
      "    mean_inference_ms: 0.9698138887204911\n",
      "    mean_processing_ms: 0.6937450451714773\n",
      "  time_since_restore: 2246.980789899826\n",
      "  time_this_iter_s: 2.538918972015381\n",
      "  time_total_s: 2246.980789899826\n",
      "  timestamp: 1596123671\n",
      "  timesteps_since_restore: 1682200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1682200\n",
      "  training_iteration: 647\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2246 s, 647 iter, 1682200 ts, 590 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-41-17\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1030.5710320502847\n",
      "  episode_reward_mean: 592.6535594829045\n",
      "  episode_reward_min: 260.07709487651357\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 673\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.137\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4337172508239746\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.1824110919842497e-06\n",
      "        policy_loss: -0.004023275338113308\n",
      "        total_loss: 37.95551300048828\n",
      "        vf_explained_var: 0.03173720836639404\n",
      "        vf_loss: 37.95953369140625\n",
      "    load_time_ms: 0.983\n",
      "    num_steps_sampled: 1687400\n",
      "    num_steps_trained: 1622500\n",
      "    sample_time_ms: 3018.509\n",
      "    update_time_ms: 3.042\n",
      "  iterations_since_restore: 649\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.03333333333334\n",
      "    ram_util_percent: 63.03333333333333\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.029167447128796\n",
      "    mean_inference_ms: 0.9694533725864157\n",
      "    mean_processing_ms: 0.693653728238912\n",
      "  time_since_restore: 2253.478808403015\n",
      "  time_this_iter_s: 2.6921114921569824\n",
      "  time_total_s: 2253.478808403015\n",
      "  timestamp: 1596123677\n",
      "  timesteps_since_restore: 1687400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1687400\n",
      "  training_iteration: 649\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2253 s, 649 iter, 1687400 ts, 593 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-41-24\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1030.5710320502847\n",
      "  episode_reward_mean: 591.7875225171504\n",
      "  episode_reward_min: 260.07709487651357\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 675\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 16.766\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4349087476730347\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.546429641370196e-06\n",
      "        policy_loss: 0.0063319094479084015\n",
      "        total_loss: 26.237092971801758\n",
      "        vf_explained_var: 0.02463477849960327\n",
      "        vf_loss: 26.23076820373535\n",
      "    load_time_ms: 0.978\n",
      "    num_steps_sampled: 1692600\n",
      "    num_steps_trained: 1627500\n",
      "    sample_time_ms: 3095.52\n",
      "    update_time_ms: 3.097\n",
      "  iterations_since_restore: 651\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.04999999999999\n",
      "    ram_util_percent: 63.050000000000004\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.02774097305077\n",
      "    mean_inference_ms: 0.9691527678360954\n",
      "    mean_processing_ms: 0.6935554038078202\n",
      "  time_since_restore: 2259.9463078975677\n",
      "  time_this_iter_s: 3.728286027908325\n",
      "  time_total_s: 2259.9463078975677\n",
      "  timestamp: 1596123684\n",
      "  timesteps_since_restore: 1692600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1692600\n",
      "  training_iteration: 651\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2259 s, 651 iter, 1692600 ts, 592 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-41-30\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1030.5710320502847\n",
      "  episode_reward_mean: 589.4381865754574\n",
      "  episode_reward_min: 181.5620350593278\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 677\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.026\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4369568824768066\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.3879060816179845e-06\n",
      "        policy_loss: -0.004373582545667887\n",
      "        total_loss: 45.95743942260742\n",
      "        vf_explained_var: 0.013282299041748047\n",
      "        vf_loss: 45.961822509765625\n",
      "    load_time_ms: 0.985\n",
      "    num_steps_sampled: 1697800\n",
      "    num_steps_trained: 1632500\n",
      "    sample_time_ms: 3107.421\n",
      "    update_time_ms: 2.981\n",
      "  iterations_since_restore: 653\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.87499999999999\n",
      "    ram_util_percent: 63.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.026721345900622\n",
      "    mean_inference_ms: 0.9689278808065866\n",
      "    mean_processing_ms: 0.6935239390330049\n",
      "  time_since_restore: 2266.1319279670715\n",
      "  time_this_iter_s: 2.4916296005249023\n",
      "  time_total_s: 2266.1319279670715\n",
      "  timestamp: 1596123690\n",
      "  timesteps_since_restore: 1697800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1697800\n",
      "  training_iteration: 653\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2266 s, 653 iter, 1697800 ts, 589 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-41-36\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1030.5710320502847\n",
      "  episode_reward_mean: 585.3532524882332\n",
      "  episode_reward_min: 181.5620350593278\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 678\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.06\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4406511783599854\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.281952904719219e-06\n",
      "        policy_loss: -0.006352525670081377\n",
      "        total_loss: 47.92448806762695\n",
      "        vf_explained_var: 0.0164334774017334\n",
      "        vf_loss: 47.93083572387695\n",
      "    load_time_ms: 1.011\n",
      "    num_steps_sampled: 1703000\n",
      "    num_steps_trained: 1637500\n",
      "    sample_time_ms: 3088.699\n",
      "    update_time_ms: 3.072\n",
      "  iterations_since_restore: 655\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.400000000000006\n",
      "    ram_util_percent: 63.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.026135739151372\n",
      "    mean_inference_ms: 0.9687891855665655\n",
      "    mean_processing_ms: 0.6934845698585559\n",
      "  time_since_restore: 2271.725824356079\n",
      "  time_this_iter_s: 2.7516825199127197\n",
      "  time_total_s: 2271.725824356079\n",
      "  timestamp: 1596123696\n",
      "  timesteps_since_restore: 1703000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1703000\n",
      "  training_iteration: 655\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2271 s, 655 iter, 1703000 ts, 585 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-41-42\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1030.5710320502847\n",
      "  episode_reward_mean: 583.4976168328933\n",
      "  episode_reward_min: 181.5620350593278\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 681\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.135\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.43892502784729\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.479100203345297e-06\n",
      "        policy_loss: -0.002773654880002141\n",
      "        total_loss: 34.01131057739258\n",
      "        vf_explained_var: 0.03217512369155884\n",
      "        vf_loss: 34.01408767700195\n",
      "    load_time_ms: 0.997\n",
      "    num_steps_sampled: 1708200\n",
      "    num_steps_trained: 1642500\n",
      "    sample_time_ms: 3034.681\n",
      "    update_time_ms: 3.053\n",
      "  iterations_since_restore: 657\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.574999999999996\n",
      "    ram_util_percent: 63.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.024485563734491\n",
      "    mean_inference_ms: 0.9683939346992233\n",
      "    mean_processing_ms: 0.6933639738756483\n",
      "  time_since_restore: 2277.5979223251343\n",
      "  time_this_iter_s: 2.8018879890441895\n",
      "  time_total_s: 2277.5979223251343\n",
      "  timestamp: 1596123702\n",
      "  timesteps_since_restore: 1708200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1708200\n",
      "  training_iteration: 657\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2277 s, 657 iter, 1708200 ts, 583 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-41-47\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1030.5710320502847\n",
      "  episode_reward_mean: 581.3671828930452\n",
      "  episode_reward_min: 181.5620350593278\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 683\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.074\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4502949714660645\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 7.923603334347717e-06\n",
      "        policy_loss: -0.003300340613350272\n",
      "        total_loss: 79.95227813720703\n",
      "        vf_explained_var: 0.014309167861938477\n",
      "        vf_loss: 79.95558166503906\n",
      "    load_time_ms: 1.032\n",
      "    num_steps_sampled: 1713400\n",
      "    num_steps_trained: 1647500\n",
      "    sample_time_ms: 2946.53\n",
      "    update_time_ms: 3.117\n",
      "  iterations_since_restore: 659\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.875\n",
      "    ram_util_percent: 63.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.023030546141814\n",
      "    mean_inference_ms: 0.9680489317015463\n",
      "    mean_processing_ms: 0.6932745134457342\n",
      "  time_since_restore: 2283.2270431518555\n",
      "  time_this_iter_s: 2.8021786212921143\n",
      "  time_total_s: 2283.2270431518555\n",
      "  timestamp: 1596123707\n",
      "  timesteps_since_restore: 1713400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1713400\n",
      "  training_iteration: 659\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2283 s, 659 iter, 1713400 ts, 581 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-41-54\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1030.5710320502847\n",
      "  episode_reward_mean: 578.6812066994577\n",
      "  episode_reward_min: 181.5620350593278\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 685\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.891\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.452365756034851\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.997494791794452e-06\n",
      "        policy_loss: 0.0038588172756135464\n",
      "        total_loss: 71.86032104492188\n",
      "        vf_explained_var: 0.01771014928817749\n",
      "        vf_loss: 71.8564453125\n",
      "    load_time_ms: 1.023\n",
      "    num_steps_sampled: 1718600\n",
      "    num_steps_trained: 1652500\n",
      "    sample_time_ms: 2943.573\n",
      "    update_time_ms: 3.206\n",
      "  iterations_since_restore: 661\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.074999999999996\n",
      "    ram_util_percent: 63.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.021557508228818\n",
      "    mean_inference_ms: 0.9676810783866477\n",
      "    mean_processing_ms: 0.693138912111127\n",
      "  time_since_restore: 2289.6756014823914\n",
      "  time_this_iter_s: 2.723616361618042\n",
      "  time_total_s: 2289.6756014823914\n",
      "  timestamp: 1596123714\n",
      "  timesteps_since_restore: 1718600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1718600\n",
      "  training_iteration: 661\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2289 s, 661 iter, 1718600 ts, 579 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-42-01\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 581.5887443757075\n",
      "  episode_reward_min: 181.5620350593278\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 688\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.788\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4505023956298828\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.620715561846737e-06\n",
      "        policy_loss: -0.002617180347442627\n",
      "        total_loss: 63.42667007446289\n",
      "        vf_explained_var: 0.01985466480255127\n",
      "        vf_loss: 63.42928695678711\n",
      "    load_time_ms: 1.014\n",
      "    num_steps_sampled: 1723800\n",
      "    num_steps_trained: 1657500\n",
      "    sample_time_ms: 3020.46\n",
      "    update_time_ms: 3.316\n",
      "  iterations_since_restore: 663\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.519999999999996\n",
      "    ram_util_percent: 63.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.01968589836704\n",
      "    mean_inference_ms: 0.9672379752164832\n",
      "    mean_processing_ms: 0.6930504339748071\n",
      "  time_since_restore: 2296.6285076141357\n",
      "  time_this_iter_s: 3.830268383026123\n",
      "  time_total_s: 2296.6285076141357\n",
      "  timestamp: 1596123721\n",
      "  timesteps_since_restore: 1723800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1723800\n",
      "  training_iteration: 663\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2296 s, 663 iter, 1723800 ts, 582 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-42-06\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 584.0566600634256\n",
      "  episode_reward_min: 181.5620350593278\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 689\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.876\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4511473178863525\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.641247872110398e-07\n",
      "        policy_loss: 0.005734886974096298\n",
      "        total_loss: 72.50151824951172\n",
      "        vf_explained_var: 0.008150637149810791\n",
      "        vf_loss: 72.49578094482422\n",
      "    load_time_ms: 1.006\n",
      "    num_steps_sampled: 1729000\n",
      "    num_steps_trained: 1662500\n",
      "    sample_time_ms: 2987.383\n",
      "    update_time_ms: 3.217\n",
      "  iterations_since_restore: 665\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.25\n",
      "    ram_util_percent: 63.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.01857800278306\n",
      "    mean_inference_ms: 0.966954567716217\n",
      "    mean_processing_ms: 0.6929538404023431\n",
      "  time_since_restore: 2301.891426086426\n",
      "  time_this_iter_s: 2.792424440383911\n",
      "  time_total_s: 2301.891426086426\n",
      "  timestamp: 1596123726\n",
      "  timesteps_since_restore: 1729000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1729000\n",
      "  training_iteration: 665\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2301 s, 665 iter, 1729000 ts, 584 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-42-12\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 589.1550546090001\n",
      "  episode_reward_min: 181.5620350593278\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 691\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.768\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4509602785110474\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.1840820661745965e-06\n",
      "        policy_loss: 0.001407128176651895\n",
      "        total_loss: 68.08174896240234\n",
      "        vf_explained_var: 0.024077653884887695\n",
      "        vf_loss: 68.0803451538086\n",
      "    load_time_ms: 1.084\n",
      "    num_steps_sampled: 1734200\n",
      "    num_steps_trained: 1667500\n",
      "    sample_time_ms: 2972.434\n",
      "    update_time_ms: 3.988\n",
      "  iterations_since_restore: 667\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.575\n",
      "    ram_util_percent: 63.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.017490511162933\n",
      "    mean_inference_ms: 0.9666962208201244\n",
      "    mean_processing_ms: 0.6929106377213243\n",
      "  time_since_restore: 2307.651624441147\n",
      "  time_this_iter_s: 2.8688952922821045\n",
      "  time_total_s: 2307.651624441147\n",
      "  timestamp: 1596123732\n",
      "  timesteps_since_restore: 1734200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1734200\n",
      "  training_iteration: 667\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2307 s, 667 iter, 1734200 ts, 589 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-42-17\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 588.2596494204563\n",
      "  episode_reward_min: 181.5620350593278\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 693\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.633\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4407126903533936\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.907608970621368e-06\n",
      "        policy_loss: 0.00018505763728171587\n",
      "        total_loss: 46.417144775390625\n",
      "        vf_explained_var: 0.01500856876373291\n",
      "        vf_loss: 46.41695022583008\n",
      "    load_time_ms: 1.062\n",
      "    num_steps_sampled: 1739400\n",
      "    num_steps_trained: 1672500\n",
      "    sample_time_ms: 2981.961\n",
      "    update_time_ms: 3.973\n",
      "  iterations_since_restore: 669\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.35000000000001\n",
      "    ram_util_percent: 63.175\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.01612562111635\n",
      "    mean_inference_ms: 0.9663638169478532\n",
      "    mean_processing_ms: 0.6928189917161381\n",
      "  time_since_restore: 2313.3729400634766\n",
      "  time_this_iter_s: 2.762377977371216\n",
      "  time_total_s: 2313.3729400634766\n",
      "  timestamp: 1596123737\n",
      "  timesteps_since_restore: 1739400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1739400\n",
      "  training_iteration: 669\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2313 s, 669 iter, 1739400 ts, 588 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-42-23\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 591.5335166041001\n",
      "  episode_reward_min: 181.5620350593278\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 695\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.292\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4510037899017334\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.114902534027351e-05\n",
      "        policy_loss: -0.002326594665646553\n",
      "        total_loss: 50.985443115234375\n",
      "        vf_explained_var: 0.01681053638458252\n",
      "        vf_loss: 50.987770080566406\n",
      "    load_time_ms: 1.093\n",
      "    num_steps_sampled: 1744600\n",
      "    num_steps_trained: 1677500\n",
      "    sample_time_ms: 2905.863\n",
      "    update_time_ms: 3.826\n",
      "  iterations_since_restore: 671\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.5\n",
      "    ram_util_percent: 63.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.014167401698993\n",
      "    mean_inference_ms: 0.9658703435042425\n",
      "    mean_processing_ms: 0.6926630040650948\n",
      "  time_since_restore: 2319.0549535751343\n",
      "  time_this_iter_s: 2.7786786556243896\n",
      "  time_total_s: 2319.0549535751343\n",
      "  timestamp: 1596123743\n",
      "  timesteps_since_restore: 1744600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1744600\n",
      "  training_iteration: 671\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2319 s, 671 iter, 1744600 ts, 592 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-42-29\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 589.0565778522264\n",
      "  episode_reward_min: 181.5620350593278\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 698\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.151\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4415799379348755\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.5454521619394654e-06\n",
      "        policy_loss: -0.0007988247671164572\n",
      "        total_loss: 44.79937744140625\n",
      "        vf_explained_var: 0.026632189750671387\n",
      "        vf_loss: 44.80018615722656\n",
      "    load_time_ms: 1.092\n",
      "    num_steps_sampled: 1749800\n",
      "    num_steps_trained: 1682500\n",
      "    sample_time_ms: 2806.443\n",
      "    update_time_ms: 3.841\n",
      "  iterations_since_restore: 673\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.825\n",
      "    ram_util_percent: 63.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.012207678101871\n",
      "    mean_inference_ms: 0.9653895579047687\n",
      "    mean_processing_ms: 0.6925657375828354\n",
      "  time_since_restore: 2325.0126569271088\n",
      "  time_this_iter_s: 2.695787191390991\n",
      "  time_total_s: 2325.0126569271088\n",
      "  timestamp: 1596123749\n",
      "  timesteps_since_restore: 1749800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1749800\n",
      "  training_iteration: 673\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2325 s, 673 iter, 1749800 ts, 589 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-42-35\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 589.363285524515\n",
      "  episode_reward_min: 181.5620350593278\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 699\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.867\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4471029043197632\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.785324966225744e-07\n",
      "        policy_loss: -0.003265239065513015\n",
      "        total_loss: 46.855567932128906\n",
      "        vf_explained_var: 0.025223910808563232\n",
      "        vf_loss: 46.858829498291016\n",
      "    load_time_ms: 1.087\n",
      "    num_steps_sampled: 1755000\n",
      "    num_steps_trained: 1687500\n",
      "    sample_time_ms: 2857.888\n",
      "    update_time_ms: 3.853\n",
      "  iterations_since_restore: 675\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.175\n",
      "    ram_util_percent: 63.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.011362436524796\n",
      "    mean_inference_ms: 0.9651738080599672\n",
      "    mean_processing_ms: 0.6925106375893951\n",
      "  time_since_restore: 2330.7862808704376\n",
      "  time_this_iter_s: 2.683577537536621\n",
      "  time_total_s: 2330.7862808704376\n",
      "  timestamp: 1596123755\n",
      "  timesteps_since_restore: 1755000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1755000\n",
      "  training_iteration: 675\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2330 s, 675 iter, 1755000 ts, 589 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-42-42\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 585.4494856600112\n",
      "  episode_reward_min: 181.5620350593278\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 703\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.732\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4496686458587646\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.3054609553364571e-06\n",
      "        policy_loss: 0.000632756797131151\n",
      "        total_loss: 39.563194274902344\n",
      "        vf_explained_var: 0.02207660675048828\n",
      "        vf_loss: 39.56256103515625\n",
      "    load_time_ms: 1.025\n",
      "    num_steps_sampled: 1760200\n",
      "    num_steps_trained: 1692500\n",
      "    sample_time_ms: 3008.062\n",
      "    update_time_ms: 3.131\n",
      "  iterations_since_restore: 677\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 41.779999999999994\n",
      "    ram_util_percent: 63.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.008074620447129\n",
      "    mean_inference_ms: 0.9643536450241098\n",
      "    mean_processing_ms: 0.6922877668341233\n",
      "  time_since_restore: 2338.0093994140625\n",
      "  time_this_iter_s: 3.3730177879333496\n",
      "  time_total_s: 2338.0093994140625\n",
      "  timestamp: 1596123762\n",
      "  timesteps_since_restore: 1760200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1760200\n",
      "  training_iteration: 677\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2338 s, 677 iter, 1760200 ts, 585 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-42-48\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 580.7741111395399\n",
      "  episode_reward_min: 166.18092327538963\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 704\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.55\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4492027759552002\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.0059585494891508e-06\n",
      "        policy_loss: 0.0038584782741963863\n",
      "        total_loss: 61.03873062133789\n",
      "        vf_explained_var: 0.01087874174118042\n",
      "        vf_loss: 61.03487014770508\n",
      "    load_time_ms: 1.013\n",
      "    num_steps_sampled: 1765400\n",
      "    num_steps_trained: 1697500\n",
      "    sample_time_ms: 2987.388\n",
      "    update_time_ms: 2.978\n",
      "  iterations_since_restore: 679\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.375\n",
      "    ram_util_percent: 63.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.006830426085586\n",
      "    mean_inference_ms: 0.9640311670132665\n",
      "    mean_processing_ms: 0.692178574582296\n",
      "  time_since_restore: 2343.5190136432648\n",
      "  time_this_iter_s: 2.898178815841675\n",
      "  time_total_s: 2343.5190136432648\n",
      "  timestamp: 1596123768\n",
      "  timesteps_since_restore: 1765400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1765400\n",
      "  training_iteration: 679\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2343 s, 679 iter, 1765400 ts, 581 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-42-54\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 585.6750411522439\n",
      "  episode_reward_min: 166.18092327538963\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 705\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.731\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.475894808769226\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.38577761896886e-06\n",
      "        policy_loss: 0.0011229823576286435\n",
      "        total_loss: 111.26360321044922\n",
      "        vf_explained_var: 0.01149129867553711\n",
      "        vf_loss: 111.26249694824219\n",
      "    load_time_ms: 0.996\n",
      "    num_steps_sampled: 1770600\n",
      "    num_steps_trained: 1702500\n",
      "    sample_time_ms: 3077.926\n",
      "    update_time_ms: 2.952\n",
      "  iterations_since_restore: 681\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.75000000000001\n",
      "    ram_util_percent: 63.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.005875870976567\n",
      "    mean_inference_ms: 0.9637443315289363\n",
      "    mean_processing_ms: 0.6920943016124227\n",
      "  time_since_restore: 2350.106816291809\n",
      "  time_this_iter_s: 3.8774898052215576\n",
      "  time_total_s: 2350.106816291809\n",
      "  timestamp: 1596123774\n",
      "  timesteps_since_restore: 1770600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1770600\n",
      "  training_iteration: 681\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2350 s, 681 iter, 1770600 ts, 586 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-43-00\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 586.9448413775974\n",
      "  episode_reward_min: 166.18092327538963\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 709\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.909\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4400984048843384\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.055644128835411e-06\n",
      "        policy_loss: -0.0004821309703402221\n",
      "        total_loss: 33.439491271972656\n",
      "        vf_explained_var: 0.024059653282165527\n",
      "        vf_loss: 33.439979553222656\n",
      "    load_time_ms: 1.003\n",
      "    num_steps_sampled: 1775800\n",
      "    num_steps_trained: 1707500\n",
      "    sample_time_ms: 3087.094\n",
      "    update_time_ms: 2.907\n",
      "  iterations_since_restore: 683\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.375\n",
      "    ram_util_percent: 63.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.002777389723492\n",
      "    mean_inference_ms: 0.9630804741560012\n",
      "    mean_processing_ms: 0.6919076025641765\n",
      "  time_since_restore: 2356.158509016037\n",
      "  time_this_iter_s: 3.143099546432495\n",
      "  time_total_s: 2356.158509016037\n",
      "  timestamp: 1596123780\n",
      "  timesteps_since_restore: 1775800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1775800\n",
      "  training_iteration: 683\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2356 s, 683 iter, 1775800 ts, 587 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-43-06\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 586.9448413775974\n",
      "  episode_reward_min: 166.18092327538963\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 709\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.966\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4494105577468872\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 9.847879312019359e-08\n",
      "        policy_loss: 0.0013699167175218463\n",
      "        total_loss: 47.19916534423828\n",
      "        vf_explained_var: 0.014732301235198975\n",
      "        vf_loss: 47.197792053222656\n",
      "    load_time_ms: 1.007\n",
      "    num_steps_sampled: 1781000\n",
      "    num_steps_trained: 1712500\n",
      "    sample_time_ms: 3047.273\n",
      "    update_time_ms: 2.924\n",
      "  iterations_since_restore: 685\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.3\n",
      "    ram_util_percent: 63.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.002777389723493\n",
      "    mean_inference_ms: 0.963080474156001\n",
      "    mean_processing_ms: 0.6919076025641764\n",
      "  time_since_restore: 2361.535299062729\n",
      "  time_this_iter_s: 2.721917152404785\n",
      "  time_total_s: 2361.535299062729\n",
      "  timestamp: 1596123786\n",
      "  timesteps_since_restore: 1781000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1781000\n",
      "  training_iteration: 685\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2361 s, 685 iter, 1781000 ts, 587 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-43-12\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 587.6511912044014\n",
      "  episode_reward_min: 166.18092327538963\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 713\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.823\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4437638521194458\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.181288543099072e-06\n",
      "        policy_loss: -0.004375671036541462\n",
      "        total_loss: 31.057966232299805\n",
      "        vf_explained_var: 0.024783313274383545\n",
      "        vf_loss: 31.062339782714844\n",
      "    load_time_ms: 0.985\n",
      "    num_steps_sampled: 1786200\n",
      "    num_steps_trained: 1717500\n",
      "    sample_time_ms: 2981.893\n",
      "    update_time_ms: 2.882\n",
      "  iterations_since_restore: 687\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.825\n",
      "    ram_util_percent: 63.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.999645328283311\n",
      "    mean_inference_ms: 0.962229677465756\n",
      "    mean_processing_ms: 0.6917032453036667\n",
      "  time_since_restore: 2368.1021435260773\n",
      "  time_this_iter_s: 2.7725882530212402\n",
      "  time_total_s: 2368.1021435260773\n",
      "  timestamp: 1596123792\n",
      "  timesteps_since_restore: 1786200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1786200\n",
      "  training_iteration: 687\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2368 s, 687 iter, 1786200 ts, 588 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-43-18\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 584.0573943785743\n",
      "  episode_reward_min: 166.18092327538963\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 714\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.744\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4444034099578857\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.76751507044537e-06\n",
      "        policy_loss: 0.00019187963334843516\n",
      "        total_loss: 67.03845977783203\n",
      "        vf_explained_var: 0.013115346431732178\n",
      "        vf_loss: 67.03826141357422\n",
      "    load_time_ms: 0.999\n",
      "    num_steps_sampled: 1791400\n",
      "    num_steps_trained: 1722500\n",
      "    sample_time_ms: 2992.865\n",
      "    update_time_ms: 2.969\n",
      "  iterations_since_restore: 689\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.4\n",
      "    ram_util_percent: 63.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9983936995499763\n",
      "    mean_inference_ms: 0.9619033992165918\n",
      "    mean_processing_ms: 0.6915920467997494\n",
      "  time_since_restore: 2373.7227721214294\n",
      "  time_this_iter_s: 2.7240405082702637\n",
      "  time_total_s: 2373.7227721214294\n",
      "  timestamp: 1596123798\n",
      "  timesteps_since_restore: 1791400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1791400\n",
      "  training_iteration: 689\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2373 s, 689 iter, 1791400 ts, 584 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-43-24\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 592.3509583133965\n",
      "  episode_reward_min: 166.18092327538963\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 716\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.72\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4615310430526733\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.2307953511481173e-05\n",
      "        policy_loss: 0.0027345851995050907\n",
      "        total_loss: 96.7257308959961\n",
      "        vf_explained_var: 0.007083594799041748\n",
      "        vf_loss: 96.72298431396484\n",
      "    load_time_ms: 1.312\n",
      "    num_steps_sampled: 1796600\n",
      "    num_steps_trained: 1727500\n",
      "    sample_time_ms: 2919.138\n",
      "    update_time_ms: 3.03\n",
      "  iterations_since_restore: 691\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 51.660000000000004\n",
      "    ram_util_percent: 63.120000000000005\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.996806264197653\n",
      "    mean_inference_ms: 0.9613909547912732\n",
      "    mean_processing_ms: 0.6914749046886555\n",
      "  time_since_restore: 2379.5888085365295\n",
      "  time_this_iter_s: 3.1179447174072266\n",
      "  time_total_s: 2379.5888085365295\n",
      "  timestamp: 1596123804\n",
      "  timesteps_since_restore: 1796600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1796600\n",
      "  training_iteration: 691\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2379 s, 691 iter, 1796600 ts, 592 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-43-30\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 590.5473195339654\n",
      "  episode_reward_min: 166.18092327538963\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 719\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.831\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4304596185684204\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.109646857206826e-07\n",
      "        policy_loss: 0.0055650766007602215\n",
      "        total_loss: 19.009605407714844\n",
      "        vf_explained_var: 0.027426958084106445\n",
      "        vf_loss: 19.004037857055664\n",
      "    load_time_ms: 1.308\n",
      "    num_steps_sampled: 1801800\n",
      "    num_steps_trained: 1732500\n",
      "    sample_time_ms: 2941.237\n",
      "    update_time_ms: 3.09\n",
      "  iterations_since_restore: 693\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 51.075\n",
      "    ram_util_percent: 63.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9942640957469218\n",
      "    mean_inference_ms: 0.9609133660984227\n",
      "    mean_processing_ms: 0.6913136128642948\n",
      "  time_since_restore: 2385.862619161606\n",
      "  time_this_iter_s: 2.484888792037964\n",
      "  time_total_s: 2385.862619161606\n",
      "  timestamp: 1596123810\n",
      "  timesteps_since_restore: 1801800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1801800\n",
      "  training_iteration: 693\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2385 s, 693 iter, 1801800 ts, 591 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-43-36\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 590.5473195339654\n",
      "  episode_reward_min: 166.18092327538963\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 719\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.309\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4547785520553589\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.0513067394413156e-07\n",
      "        policy_loss: -0.010194866918027401\n",
      "        total_loss: 85.30386352539062\n",
      "        vf_explained_var: 0.0015793442726135254\n",
      "        vf_loss: 85.3140869140625\n",
      "    load_time_ms: 1.315\n",
      "    num_steps_sampled: 1807000\n",
      "    num_steps_trained: 1737500\n",
      "    sample_time_ms: 2959.308\n",
      "    update_time_ms: 3.076\n",
      "  iterations_since_restore: 695\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.8\n",
      "    ram_util_percent: 63.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9942640957469218\n",
      "    mean_inference_ms: 0.9609133660984227\n",
      "    mean_processing_ms: 0.6913136128642948\n",
      "  time_since_restore: 2391.423588037491\n",
      "  time_this_iter_s: 2.7855913639068604\n",
      "  time_total_s: 2391.423588037491\n",
      "  timestamp: 1596123816\n",
      "  timesteps_since_restore: 1807000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1807000\n",
      "  training_iteration: 695\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2391 s, 695 iter, 1807000 ts, 591 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-43-43\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 579.9994535509968\n",
      "  episode_reward_min: 166.18092327538963\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 724\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.156\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.441646695137024\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.493542509313556e-07\n",
      "        policy_loss: 0.0022375835105776787\n",
      "        total_loss: 55.146148681640625\n",
      "        vf_explained_var: 0.02007126808166504\n",
      "        vf_loss: 55.14391326904297\n",
      "    load_time_ms: 1.295\n",
      "    num_steps_sampled: 1812200\n",
      "    num_steps_trained: 1742500\n",
      "    sample_time_ms: 3042.86\n",
      "    update_time_ms: 3.126\n",
      "  iterations_since_restore: 697\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.0\n",
      "    ram_util_percent: 63.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9898843520967144\n",
      "    mean_inference_ms: 0.9597228042493826\n",
      "    mean_processing_ms: 0.6909992754925635\n",
      "  time_since_restore: 2398.8228986263275\n",
      "  time_this_iter_s: 3.629460334777832\n",
      "  time_total_s: 2398.8228986263275\n",
      "  timestamp: 1596123823\n",
      "  timesteps_since_restore: 1812200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1812200\n",
      "  training_iteration: 697\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2398 s, 697 iter, 1812200 ts, 580 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-43-49\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 579.9994535509968\n",
      "  episode_reward_min: 166.18092327538963\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 724\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.474\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4495371580123901\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.0734796660472057e-06\n",
      "        policy_loss: -0.0015817679231986403\n",
      "        total_loss: 84.08401489257812\n",
      "        vf_explained_var: 0.003498256206512451\n",
      "        vf_loss: 84.08560943603516\n",
      "    load_time_ms: 1.318\n",
      "    num_steps_sampled: 1817400\n",
      "    num_steps_trained: 1747500\n",
      "    sample_time_ms: 3028.672\n",
      "    update_time_ms: 3.089\n",
      "  iterations_since_restore: 699\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.64999999999999\n",
      "    ram_util_percent: 63.15\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9898843520967135\n",
      "    mean_inference_ms: 0.9597228042493826\n",
      "    mean_processing_ms: 0.6909992754925635\n",
      "  time_since_restore: 2404.3051052093506\n",
      "  time_this_iter_s: 2.977726697921753\n",
      "  time_total_s: 2404.3051052093506\n",
      "  timestamp: 1596123829\n",
      "  timesteps_since_restore: 1817400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1817400\n",
      "  training_iteration: 699\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2404 s, 699 iter, 1817400 ts, 580 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-43-55\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 586.0800937218356\n",
      "  episode_reward_min: 166.18092327538963\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 726\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.832\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4722659587860107\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.887720231432468e-05\n",
      "        policy_loss: -0.006441743578761816\n",
      "        total_loss: 122.52893829345703\n",
      "        vf_explained_var: 0.011363804340362549\n",
      "        vf_loss: 122.535400390625\n",
      "    load_time_ms: 1.015\n",
      "    num_steps_sampled: 1822600\n",
      "    num_steps_trained: 1752500\n",
      "    sample_time_ms: 3122.585\n",
      "    update_time_ms: 3.095\n",
      "  iterations_since_restore: 701\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.550000000000004\n",
      "    ram_util_percent: 63.125\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.988376460641384\n",
      "    mean_inference_ms: 0.9593450349759804\n",
      "    mean_processing_ms: 0.6909378322555638\n",
      "  time_since_restore: 2411.088886976242\n",
      "  time_this_iter_s: 2.923034191131592\n",
      "  time_total_s: 2411.088886976242\n",
      "  timestamp: 1596123835\n",
      "  timesteps_since_restore: 1822600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1822600\n",
      "  training_iteration: 701\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2411 s, 701 iter, 1822600 ts, 586 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-44-01\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 592.6438481287291\n",
      "  episode_reward_min: 166.18092327538963\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 729\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.965\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4408178329467773\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 9.983777715660835e-08\n",
      "        policy_loss: -0.0017690840177237988\n",
      "        total_loss: 43.51957702636719\n",
      "        vf_explained_var: 0.018573760986328125\n",
      "        vf_loss: 43.521339416503906\n",
      "    load_time_ms: 1.012\n",
      "    num_steps_sampled: 1827800\n",
      "    num_steps_trained: 1757500\n",
      "    sample_time_ms: 3076.334\n",
      "    update_time_ms: 3.0\n",
      "  iterations_since_restore: 703\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.775000000000006\n",
      "    ram_util_percent: 63.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9857455482930213\n",
      "    mean_inference_ms: 0.958661649022625\n",
      "    mean_processing_ms: 0.6907102650092931\n",
      "  time_since_restore: 2416.9014542102814\n",
      "  time_this_iter_s: 2.7422854900360107\n",
      "  time_total_s: 2416.9014542102814\n",
      "  timestamp: 1596123841\n",
      "  timesteps_since_restore: 1827800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1827800\n",
      "  training_iteration: 703\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2416 s, 703 iter, 1827800 ts, 593 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-44-07\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 594.3675394253354\n",
      "  episode_reward_min: 166.18092327538963\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 730\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.306\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4664522409439087\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.542138020089624e-07\n",
      "        policy_loss: 0.0017894608899950981\n",
      "        total_loss: 94.11219787597656\n",
      "        vf_explained_var: 0.007777035236358643\n",
      "        vf_loss: 94.1103744506836\n",
      "    load_time_ms: 0.994\n",
      "    num_steps_sampled: 1833000\n",
      "    num_steps_trained: 1762500\n",
      "    sample_time_ms: 3088.163\n",
      "    update_time_ms: 3.078\n",
      "  iterations_since_restore: 705\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.775000000000006\n",
      "    ram_util_percent: 63.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.985015342166891\n",
      "    mean_inference_ms: 0.9585385020154308\n",
      "    mean_processing_ms: 0.6906706952556746\n",
      "  time_since_restore: 2422.574982881546\n",
      "  time_this_iter_s: 2.925062656402588\n",
      "  time_total_s: 2422.574982881546\n",
      "  timestamp: 1596123847\n",
      "  timesteps_since_restore: 1833000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1833000\n",
      "  training_iteration: 705\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2422 s, 705 iter, 1833000 ts, 594 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-44-13\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 592.063756691417\n",
      "  episode_reward_min: 166.18092327538963\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 734\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.802\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.438146710395813\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.1749267514460371e-07\n",
      "        policy_loss: -0.0013539587380364537\n",
      "        total_loss: 23.023374557495117\n",
      "        vf_explained_var: 0.021530985832214355\n",
      "        vf_loss: 23.024728775024414\n",
      "    load_time_ms: 1.007\n",
      "    num_steps_sampled: 1838200\n",
      "    num_steps_trained: 1767500\n",
      "    sample_time_ms: 3004.323\n",
      "    update_time_ms: 3.006\n",
      "  iterations_since_restore: 707\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.333333333333336\n",
      "    ram_util_percent: 63.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9816666708326913\n",
      "    mean_inference_ms: 0.9576076055551844\n",
      "    mean_processing_ms: 0.6904184771214255\n",
      "  time_since_restore: 2429.1423597335815\n",
      "  time_this_iter_s: 2.747830867767334\n",
      "  time_total_s: 2429.1423597335815\n",
      "  timestamp: 1596123853\n",
      "  timesteps_since_restore: 1838200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1838200\n",
      "  training_iteration: 707\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2429 s, 707 iter, 1838200 ts, 592 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-44-20\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 591.0411915162366\n",
      "  episode_reward_min: 166.18092327538963\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 735\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.662\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4513003826141357\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.1512756827869453e-06\n",
      "        policy_loss: -0.004034173674881458\n",
      "        total_loss: 52.833892822265625\n",
      "        vf_explained_var: 0.0027039647102355957\n",
      "        vf_loss: 52.83792495727539\n",
      "    load_time_ms: 0.999\n",
      "    num_steps_sampled: 1843400\n",
      "    num_steps_trained: 1772500\n",
      "    sample_time_ms: 3118.451\n",
      "    update_time_ms: 3.072\n",
      "  iterations_since_restore: 709\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.36666666666667\n",
      "    ram_util_percent: 63.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.980944721706055\n",
      "    mean_inference_ms: 0.9574867067569829\n",
      "    mean_processing_ms: 0.6903822531141138\n",
      "  time_since_restore: 2435.7648956775665\n",
      "  time_this_iter_s: 3.8678011894226074\n",
      "  time_total_s: 2435.7648956775665\n",
      "  timestamp: 1596123860\n",
      "  timesteps_since_restore: 1843400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1843400\n",
      "  training_iteration: 709\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2435 s, 709 iter, 1843400 ts, 591 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-44-26\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 594.0723373378617\n",
      "  episode_reward_min: 166.18092327538963\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 736\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.91\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4574925899505615\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.3201704379971488e-07\n",
      "        policy_loss: 0.00024154558195732534\n",
      "        total_loss: 74.45734405517578\n",
      "        vf_explained_var: 0.01593559980392456\n",
      "        vf_loss: 74.45711517333984\n",
      "    load_time_ms: 1.004\n",
      "    num_steps_sampled: 1848600\n",
      "    num_steps_trained: 1777500\n",
      "    sample_time_ms: 3045.395\n",
      "    update_time_ms: 3.011\n",
      "  iterations_since_restore: 711\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.3\n",
      "    ram_util_percent: 63.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.980070832594245\n",
      "    mean_inference_ms: 0.9572552455432767\n",
      "    mean_processing_ms: 0.6903270697747881\n",
      "  time_since_restore: 2441.82075881958\n",
      "  time_this_iter_s: 2.526182174682617\n",
      "  time_total_s: 2441.82075881958\n",
      "  timestamp: 1596123866\n",
      "  timesteps_since_restore: 1848600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1848600\n",
      "  training_iteration: 711\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2441 s, 711 iter, 1848600 ts, 594 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-44-32\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 597.3025857977453\n",
      "  episode_reward_min: 166.18092327538963\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 739\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.814\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4415905475616455\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.179003675133572e-06\n",
      "        policy_loss: 0.002046120585873723\n",
      "        total_loss: 35.44963836669922\n",
      "        vf_explained_var: 0.022796988487243652\n",
      "        vf_loss: 35.44758224487305\n",
      "    load_time_ms: 1.012\n",
      "    num_steps_sampled: 1853800\n",
      "    num_steps_trained: 1782500\n",
      "    sample_time_ms: 3061.804\n",
      "    update_time_ms: 3.012\n",
      "  iterations_since_restore: 713\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.974999999999994\n",
      "    ram_util_percent: 63.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9777462766190057\n",
      "    mean_inference_ms: 0.9566591018646001\n",
      "    mean_processing_ms: 0.6901539373651278\n",
      "  time_since_restore: 2447.795396089554\n",
      "  time_this_iter_s: 2.7529213428497314\n",
      "  time_total_s: 2447.795396089554\n",
      "  timestamp: 1596123872\n",
      "  timesteps_since_restore: 1853800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1853800\n",
      "  training_iteration: 713\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2447 s, 713 iter, 1853800 ts, 597 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-44-38\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 602.4375892466098\n",
      "  episode_reward_min: 166.18092327538963\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 741\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.575\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4484033584594727\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.7576813888808829e-06\n",
      "        policy_loss: -0.000938981247600168\n",
      "        total_loss: 35.11317825317383\n",
      "        vf_explained_var: 0.019636452198028564\n",
      "        vf_loss: 35.11410903930664\n",
      "    load_time_ms: 0.996\n",
      "    num_steps_sampled: 1859000\n",
      "    num_steps_trained: 1787500\n",
      "    sample_time_ms: 3079.449\n",
      "    update_time_ms: 2.938\n",
      "  iterations_since_restore: 715\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.71999999999999\n",
      "    ram_util_percent: 63.1\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.976018757022354\n",
      "    mean_inference_ms: 0.9562116605962621\n",
      "    mean_processing_ms: 0.690034527237015\n",
      "  time_since_restore: 2453.642465353012\n",
      "  time_this_iter_s: 2.9081578254699707\n",
      "  time_total_s: 2453.642465353012\n",
      "  timestamp: 1596123878\n",
      "  timesteps_since_restore: 1859000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1859000\n",
      "  training_iteration: 715\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.4/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2453 s, 715 iter, 1859000 ts, 602 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-44-45\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 596.9746536637092\n",
      "  episode_reward_min: 166.18092327538963\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 744\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.863\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.439119577407837\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.697965548279171e-07\n",
      "        policy_loss: 0.0014930047327652574\n",
      "        total_loss: 36.85101318359375\n",
      "        vf_explained_var: 0.015016913414001465\n",
      "        vf_loss: 36.84951400756836\n",
      "    load_time_ms: 1.025\n",
      "    num_steps_sampled: 1864200\n",
      "    num_steps_trained: 1792500\n",
      "    sample_time_ms: 3123.471\n",
      "    update_time_ms: 3.017\n",
      "  iterations_since_restore: 717\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.28000000000001\n",
      "    ram_util_percent: 63.58\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.973777285150868\n",
      "    mean_inference_ms: 0.9556335813724768\n",
      "    mean_processing_ms: 0.6898731004650936\n",
      "  time_since_restore: 2460.6544649600983\n",
      "  time_this_iter_s: 3.1332290172576904\n",
      "  time_total_s: 2460.6544649600983\n",
      "  timestamp: 1596123885\n",
      "  timesteps_since_restore: 1864200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1864200\n",
      "  training_iteration: 717\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2460 s, 717 iter, 1864200 ts, 597 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-44-51\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 590.1646567464975\n",
      "  episode_reward_min: 166.18092327538963\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 745\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.73\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.464505910873413\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.522251171896642e-07\n",
      "        policy_loss: 0.0006319739622995257\n",
      "        total_loss: 110.54002380371094\n",
      "        vf_explained_var: 0.0034635066986083984\n",
      "        vf_loss: 110.53937530517578\n",
      "    load_time_ms: 1.019\n",
      "    num_steps_sampled: 1869400\n",
      "    num_steps_trained: 1797500\n",
      "    sample_time_ms: 3044.063\n",
      "    update_time_ms: 3.121\n",
      "  iterations_since_restore: 719\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.0\n",
      "    ram_util_percent: 63.4\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.973317839393699\n",
      "    mean_inference_ms: 0.9555191289179105\n",
      "    mean_processing_ms: 0.6898697849182784\n",
      "  time_since_restore: 2466.4820098876953\n",
      "  time_this_iter_s: 3.0843350887298584\n",
      "  time_total_s: 2466.4820098876953\n",
      "  timestamp: 1596123891\n",
      "  timesteps_since_restore: 1869400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1869400\n",
      "  training_iteration: 719\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2466 s, 719 iter, 1869400 ts, 590 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-44-57\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 602.8807793372227\n",
      "  episode_reward_min: 166.18092327538963\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 748\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.329\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4427059888839722\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.7907381106851972e-06\n",
      "        policy_loss: -0.0019224077695980668\n",
      "        total_loss: 32.528961181640625\n",
      "        vf_explained_var: 0.021749794483184814\n",
      "        vf_loss: 32.530879974365234\n",
      "    load_time_ms: 1.089\n",
      "    num_steps_sampled: 1874600\n",
      "    num_steps_trained: 1802500\n",
      "    sample_time_ms: 3036.717\n",
      "    update_time_ms: 3.332\n",
      "  iterations_since_restore: 721\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 52.0\n",
      "    ram_util_percent: 63.3\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9707336907977826\n",
      "    mean_inference_ms: 0.9548915353856734\n",
      "    mean_processing_ms: 0.6896716423788449\n",
      "  time_since_restore: 2472.4887013435364\n",
      "  time_this_iter_s: 2.9104437828063965\n",
      "  time_total_s: 2472.4887013435364\n",
      "  timestamp: 1596123897\n",
      "  timesteps_since_restore: 1874600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1874600\n",
      "  training_iteration: 721\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2472 s, 721 iter, 1874600 ts, 603 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-45-02\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 601.6639349218077\n",
      "  episode_reward_min: 166.18092327538963\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 749\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.794\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.442155122756958\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.887917449039378e-07\n",
      "        policy_loss: 0.003077580826357007\n",
      "        total_loss: 25.23180389404297\n",
      "        vf_explained_var: 0.02587491273880005\n",
      "        vf_loss: 25.22872543334961\n",
      "    load_time_ms: 1.135\n",
      "    num_steps_sampled: 1879800\n",
      "    num_steps_trained: 1807500\n",
      "    sample_time_ms: 2990.625\n",
      "    update_time_ms: 3.405\n",
      "  iterations_since_restore: 723\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.425\n",
      "    ram_util_percent: 63.3\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9699053208392865\n",
      "    mean_inference_ms: 0.9546273225855976\n",
      "    mean_processing_ms: 0.6895964677455737\n",
      "  time_since_restore: 2478.0097115039825\n",
      "  time_this_iter_s: 2.7323036193847656\n",
      "  time_total_s: 2478.0097115039825\n",
      "  timestamp: 1596123902\n",
      "  timesteps_since_restore: 1879800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1879800\n",
      "  training_iteration: 723\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2478 s, 723 iter, 1879800 ts, 602 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-45-09\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 593.3701024585479\n",
      "  episode_reward_min: 166.18092327538963\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 752\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.168\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4540454149246216\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.729463631112594e-06\n",
      "        policy_loss: -0.002962906612083316\n",
      "        total_loss: 54.52017593383789\n",
      "        vf_explained_var: 0.014695286750793457\n",
      "        vf_loss: 54.52314376831055\n",
      "    load_time_ms: 1.158\n",
      "    num_steps_sampled: 1885000\n",
      "    num_steps_trained: 1812500\n",
      "    sample_time_ms: 3063.953\n",
      "    update_time_ms: 3.436\n",
      "  iterations_since_restore: 725\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.449999999999996\n",
      "    ram_util_percent: 63.300000000000004\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9676356925290266\n",
      "    mean_inference_ms: 0.9540842720751379\n",
      "    mean_processing_ms: 0.689455184938333\n",
      "  time_since_restore: 2484.5947930812836\n",
      "  time_this_iter_s: 3.8133034706115723\n",
      "  time_total_s: 2484.5947930812836\n",
      "  timestamp: 1596123909\n",
      "  timesteps_since_restore: 1885000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1885000\n",
      "  training_iteration: 725\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2484 s, 725 iter, 1885000 ts, 593 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-45-14\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 587.4293703027586\n",
      "  episode_reward_min: 166.18092327538963\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 754\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.21\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4406087398529053\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.1632204177658423e-06\n",
      "        policy_loss: -0.00415867380797863\n",
      "        total_loss: 36.13257598876953\n",
      "        vf_explained_var: 0.015803158283233643\n",
      "        vf_loss: 36.13672637939453\n",
      "    load_time_ms: 1.165\n",
      "    num_steps_sampled: 1890200\n",
      "    num_steps_trained: 1817500\n",
      "    sample_time_ms: 2895.273\n",
      "    update_time_ms: 3.434\n",
      "  iterations_since_restore: 727\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.375\n",
      "    ram_util_percent: 63.3\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9660850901272324\n",
      "    mean_inference_ms: 0.9536338467160346\n",
      "    mean_processing_ms: 0.6893253276462431\n",
      "  time_since_restore: 2489.9206092357635\n",
      "  time_this_iter_s: 2.7627549171447754\n",
      "  time_total_s: 2489.9206092357635\n",
      "  timestamp: 1596123914\n",
      "  timesteps_since_restore: 1890200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1890200\n",
      "  training_iteration: 727\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2489 s, 727 iter, 1890200 ts, 587 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-45-21\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 588.4650756317305\n",
      "  episode_reward_min: 166.18092327538963\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 756\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.977\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.456859827041626\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.479407263919711e-06\n",
      "        policy_loss: -0.004011711571365595\n",
      "        total_loss: 78.27516174316406\n",
      "        vf_explained_var: 0.008180022239685059\n",
      "        vf_loss: 78.2791748046875\n",
      "    load_time_ms: 1.154\n",
      "    num_steps_sampled: 1895400\n",
      "    num_steps_trained: 1822500\n",
      "    sample_time_ms: 2974.688\n",
      "    update_time_ms: 3.325\n",
      "  iterations_since_restore: 729\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.916666666666664\n",
      "    ram_util_percent: 63.300000000000004\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9644618677404613\n",
      "    mean_inference_ms: 0.9532104525635781\n",
      "    mean_processing_ms: 0.6892219134544516\n",
      "  time_since_restore: 2496.5390207767487\n",
      "  time_this_iter_s: 3.8659210205078125\n",
      "  time_total_s: 2496.5390207767487\n",
      "  timestamp: 1596123921\n",
      "  timesteps_since_restore: 1895400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1895400\n",
      "  training_iteration: 729\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2496 s, 729 iter, 1895400 ts, 588 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-45-28\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 579.9880660792297\n",
      "  episode_reward_min: 166.18092327538963\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 759\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.18\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4328973293304443\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.592802061940347e-08\n",
      "        policy_loss: 0.0010214365320280194\n",
      "        total_loss: 19.483993530273438\n",
      "        vf_explained_var: 0.012822866439819336\n",
      "        vf_loss: 19.482973098754883\n",
      "    load_time_ms: 1.088\n",
      "    num_steps_sampled: 1900600\n",
      "    num_steps_trained: 1827500\n",
      "    sample_time_ms: 3098.145\n",
      "    update_time_ms: 3.07\n",
      "  iterations_since_restore: 731\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 43.6\n",
      "    ram_util_percent: 63.3\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.962525344880737\n",
      "    mean_inference_ms: 0.9526492331955957\n",
      "    mean_processing_ms: 0.689096426194002\n",
      "  time_since_restore: 2503.753575325012\n",
      "  time_this_iter_s: 3.653301954269409\n",
      "  time_total_s: 2503.753575325012\n",
      "  timestamp: 1596123928\n",
      "  timesteps_since_restore: 1900600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1900600\n",
      "  training_iteration: 731\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2503 s, 731 iter, 1900600 ts, 580 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-45-33\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 579.9880660792297\n",
      "  episode_reward_min: 166.18092327538963\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 759\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.829\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4445997476577759\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.3299227248353418e-06\n",
      "        policy_loss: 0.007813814096152782\n",
      "        total_loss: 47.53923416137695\n",
      "        vf_explained_var: 0.013983309268951416\n",
      "        vf_loss: 47.531402587890625\n",
      "    load_time_ms: 1.059\n",
      "    num_steps_sampled: 1905800\n",
      "    num_steps_trained: 1832500\n",
      "    sample_time_ms: 3062.46\n",
      "    update_time_ms: 3.028\n",
      "  iterations_since_restore: 733\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.1\n",
      "    ram_util_percent: 63.29999999999999\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.962525344880737\n",
      "    mean_inference_ms: 0.9526492331955957\n",
      "    mean_processing_ms: 0.689096426194002\n",
      "  time_since_restore: 2508.913549184799\n",
      "  time_this_iter_s: 2.729646921157837\n",
      "  time_total_s: 2508.913549184799\n",
      "  timestamp: 1596123933\n",
      "  timesteps_since_restore: 1905800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1905800\n",
      "  training_iteration: 733\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2508 s, 733 iter, 1905800 ts, 580 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-45-40\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 576.9477465453708\n",
      "  episode_reward_min: 166.18092327538963\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 763\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.587\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.43928861618042\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.01753969881247e-07\n",
      "        policy_loss: -0.002388776047155261\n",
      "        total_loss: 25.68168067932129\n",
      "        vf_explained_var: 0.02199655771255493\n",
      "        vf_loss: 25.684064865112305\n",
      "    load_time_ms: 1.046\n",
      "    num_steps_sampled: 1911000\n",
      "    num_steps_trained: 1837500\n",
      "    sample_time_ms: 3018.615\n",
      "    update_time_ms: 3.06\n",
      "  iterations_since_restore: 735\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 52.15\n",
      "    ram_util_percent: 63.275000000000006\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9593320316650953\n",
      "    mean_inference_ms: 0.9519301922823951\n",
      "    mean_processing_ms: 0.6888792672460187\n",
      "  time_since_restore: 2515.0579698085785\n",
      "  time_this_iter_s: 3.23783540725708\n",
      "  time_total_s: 2515.0579698085785\n",
      "  timestamp: 1596123940\n",
      "  timesteps_since_restore: 1911000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1911000\n",
      "  training_iteration: 735\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2515 s, 735 iter, 1911000 ts, 577 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-45-45\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 577.3306809191341\n",
      "  episode_reward_min: 166.18092327538963\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 764\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.191\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4361369609832764\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.524064879911748e-07\n",
      "        policy_loss: -0.003222077852115035\n",
      "        total_loss: 34.387359619140625\n",
      "        vf_explained_var: 0.0237962007522583\n",
      "        vf_loss: 34.39058303833008\n",
      "    load_time_ms: 1.012\n",
      "    num_steps_sampled: 1916200\n",
      "    num_steps_trained: 1842500\n",
      "    sample_time_ms: 3044.565\n",
      "    update_time_ms: 3.034\n",
      "  iterations_since_restore: 737\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.349999999999994\n",
      "    ram_util_percent: 63.3\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9587358712048246\n",
      "    mean_inference_ms: 0.9516689530023321\n",
      "    mean_processing_ms: 0.6888319354392763\n",
      "  time_since_restore: 2520.637545108795\n",
      "  time_this_iter_s: 2.6942195892333984\n",
      "  time_total_s: 2520.637545108795\n",
      "  timestamp: 1596123945\n",
      "  timesteps_since_restore: 1916200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1916200\n",
      "  training_iteration: 737\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2520 s, 737 iter, 1916200 ts, 577 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-45-51\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 574.1586312379071\n",
      "  episode_reward_min: 166.18092327538963\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 765\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.682\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.44015371799469\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.0125636862312604e-07\n",
      "        policy_loss: 0.0015329758170992136\n",
      "        total_loss: 37.65831756591797\n",
      "        vf_explained_var: 0.013982772827148438\n",
      "        vf_loss: 37.65678787231445\n",
      "    load_time_ms: 1.015\n",
      "    num_steps_sampled: 1921400\n",
      "    num_steps_trained: 1847500\n",
      "    sample_time_ms: 2955.087\n",
      "    update_time_ms: 3.027\n",
      "  iterations_since_restore: 739\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.53333333333333\n",
      "    ram_util_percent: 63.29999999999999\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.957690455908085\n",
      "    mean_inference_ms: 0.9514542964567463\n",
      "    mean_processing_ms: 0.688747603373924\n",
      "  time_since_restore: 2526.365685224533\n",
      "  time_this_iter_s: 2.6537063121795654\n",
      "  time_total_s: 2526.365685224533\n",
      "  timestamp: 1596123951\n",
      "  timesteps_since_restore: 1921400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1921400\n",
      "  training_iteration: 739\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2526 s, 739 iter, 1921400 ts, 574 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-45-57\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 564.455292915999\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 769\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.518\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.433841586112976\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.542091325745787e-07\n",
      "        policy_loss: 0.0024900182615965605\n",
      "        total_loss: 23.67344856262207\n",
      "        vf_explained_var: 0.02326035499572754\n",
      "        vf_loss: 23.670961380004883\n",
      "    load_time_ms: 1.02\n",
      "    num_steps_sampled: 1926600\n",
      "    num_steps_trained: 1852500\n",
      "    sample_time_ms: 2831.397\n",
      "    update_time_ms: 3.088\n",
      "  iterations_since_restore: 741\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.45\n",
      "    ram_util_percent: 63.3\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9547399945503496\n",
      "    mean_inference_ms: 0.9506963685187714\n",
      "    mean_processing_ms: 0.6885409565474953\n",
      "  time_since_restore: 2532.355087041855\n",
      "  time_this_iter_s: 2.7968344688415527\n",
      "  time_total_s: 2532.355087041855\n",
      "  timestamp: 1596123957\n",
      "  timesteps_since_restore: 1926600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1926600\n",
      "  training_iteration: 741\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2532 s, 741 iter, 1926600 ts, 564 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-46-03\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 563.5337223763204\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 770\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.333\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4341940879821777\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.814458864326298e-07\n",
      "        policy_loss: -0.003157811239361763\n",
      "        total_loss: 23.378934860229492\n",
      "        vf_explained_var: 0.026991069316864014\n",
      "        vf_loss: 23.38209342956543\n",
      "    load_time_ms: 0.984\n",
      "    num_steps_sampled: 1931800\n",
      "    num_steps_trained: 1857500\n",
      "    sample_time_ms: 2934.231\n",
      "    update_time_ms: 3.069\n",
      "  iterations_since_restore: 743\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.8\n",
      "    ram_util_percent: 63.3\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.953919745323068\n",
      "    mean_inference_ms: 0.9504790614353111\n",
      "    mean_processing_ms: 0.6884822401829078\n",
      "  time_since_restore: 2538.540061235428\n",
      "  time_this_iter_s: 2.498058795928955\n",
      "  time_total_s: 2538.540061235428\n",
      "  timestamp: 1596123963\n",
      "  timesteps_since_restore: 1931800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1931800\n",
      "  training_iteration: 743\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2538 s, 743 iter, 1931800 ts, 564 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-46-10\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 555.9035693079212\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 774\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.323\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4486849308013916\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.245353639158566e-07\n",
      "        policy_loss: -0.004930407274514437\n",
      "        total_loss: 54.5075798034668\n",
      "        vf_explained_var: 0.01215064525604248\n",
      "        vf_loss: 54.51251220703125\n",
      "    load_time_ms: 0.992\n",
      "    num_steps_sampled: 1937000\n",
      "    num_steps_trained: 1862500\n",
      "    sample_time_ms: 3027.481\n",
      "    update_time_ms: 3.145\n",
      "  iterations_since_restore: 745\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.099999999999994\n",
      "    ram_util_percent: 63.300000000000004\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.951028528217429\n",
      "    mean_inference_ms: 0.949734024504328\n",
      "    mean_processing_ms: 0.688281983959389\n",
      "  time_since_restore: 2545.6169486045837\n",
      "  time_this_iter_s: 4.30096173286438\n",
      "  time_total_s: 2545.6169486045837\n",
      "  timestamp: 1596123970\n",
      "  timesteps_since_restore: 1937000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1937000\n",
      "  training_iteration: 745\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2545 s, 745 iter, 1937000 ts, 556 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-46-15\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 554.9785909727404\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 775\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.714\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4346201419830322\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.183292503512348e-07\n",
      "        policy_loss: -0.0006835355306975543\n",
      "        total_loss: 30.36113739013672\n",
      "        vf_explained_var: 0.0067909955978393555\n",
      "        vf_loss: 30.36181640625\n",
      "    load_time_ms: 1.013\n",
      "    num_steps_sampled: 1942200\n",
      "    num_steps_trained: 1867500\n",
      "    sample_time_ms: 3000.599\n",
      "    update_time_ms: 3.146\n",
      "  iterations_since_restore: 747\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.500000000000014\n",
      "    ram_util_percent: 63.3\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9502199253273407\n",
      "    mean_inference_ms: 0.9495193974710961\n",
      "    mean_processing_ms: 0.6882263370480293\n",
      "  time_since_restore: 2550.9327878952026\n",
      "  time_this_iter_s: 2.8312768936157227\n",
      "  time_total_s: 2550.9327878952026\n",
      "  timestamp: 1596123975\n",
      "  timesteps_since_restore: 1942200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1942200\n",
      "  training_iteration: 747\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2550 s, 747 iter, 1942200 ts, 555 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-46-22\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 557.124248918019\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 776\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.446\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4454809427261353\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.3970375221106224e-06\n",
      "        policy_loss: -0.0019358398858457804\n",
      "        total_loss: 56.95645523071289\n",
      "        vf_explained_var: 0.0017172694206237793\n",
      "        vf_loss: 56.95839309692383\n",
      "    load_time_ms: 1.021\n",
      "    num_steps_sampled: 1947400\n",
      "    num_steps_trained: 1872500\n",
      "    sample_time_ms: 3087.383\n",
      "    update_time_ms: 3.178\n",
      "  iterations_since_restore: 749\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.4\n",
      "    ram_util_percent: 63.300000000000004\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9492464069810636\n",
      "    mean_inference_ms: 0.9491574648985954\n",
      "    mean_processing_ms: 0.6881290927626416\n",
      "  time_since_restore: 2557.5277054309845\n",
      "  time_this_iter_s: 3.8503661155700684\n",
      "  time_total_s: 2557.5277054309845\n",
      "  timestamp: 1596123982\n",
      "  timesteps_since_restore: 1947400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1947400\n",
      "  training_iteration: 749\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2557 s, 749 iter, 1947400 ts, 557 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-46-28\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 557.2178543107705\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 779\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.617\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4350990056991577\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.2022376267850632e-06\n",
      "        policy_loss: 0.006902067456394434\n",
      "        total_loss: 52.39432907104492\n",
      "        vf_explained_var: 0.010387778282165527\n",
      "        vf_loss: 52.387428283691406\n",
      "    load_time_ms: 1.002\n",
      "    num_steps_sampled: 1952600\n",
      "    num_steps_trained: 1877500\n",
      "    sample_time_ms: 3089.301\n",
      "    update_time_ms: 3.151\n",
      "  iterations_since_restore: 751\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.974999999999994\n",
      "    ram_util_percent: 63.3\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.947363359428404\n",
      "    mean_inference_ms: 0.9487826596045887\n",
      "    mean_processing_ms: 0.688024862498828\n",
      "  time_since_restore: 2563.5240750312805\n",
      "  time_this_iter_s: 2.564119815826416\n",
      "  time_total_s: 2563.5240750312805\n",
      "  timestamp: 1596123988\n",
      "  timesteps_since_restore: 1952600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1952600\n",
      "  training_iteration: 751\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2563 s, 751 iter, 1952600 ts, 557 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-46-34\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 559.3344721152197\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 780\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.035\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4529471397399902\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.579373229622433e-07\n",
      "        policy_loss: -0.006071760319173336\n",
      "        total_loss: 91.80022430419922\n",
      "        vf_explained_var: 0.006873130798339844\n",
      "        vf_loss: 91.8062973022461\n",
      "    load_time_ms: 1.029\n",
      "    num_steps_sampled: 1957800\n",
      "    num_steps_trained: 1882500\n",
      "    sample_time_ms: 3036.33\n",
      "    update_time_ms: 3.19\n",
      "  iterations_since_restore: 753\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.1\n",
      "    ram_util_percent: 63.3\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9465780710043528\n",
      "    mean_inference_ms: 0.9485731794136543\n",
      "    mean_processing_ms: 0.6879710260102349\n",
      "  time_since_restore: 2569.186144590378\n",
      "  time_this_iter_s: 2.899972438812256\n",
      "  time_total_s: 2569.186144590378\n",
      "  timestamp: 1596123994\n",
      "  timesteps_since_restore: 1957800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1957800\n",
      "  training_iteration: 753\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2569 s, 753 iter, 1957800 ts, 559 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-46-40\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 564.0068000746141\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 784\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.978\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.438590407371521\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 9.944677685780334e-07\n",
      "        policy_loss: -0.0012367950985208154\n",
      "        total_loss: 56.69749450683594\n",
      "        vf_explained_var: 0.013197243213653564\n",
      "        vf_loss: 56.69873046875\n",
      "    load_time_ms: 1.024\n",
      "    num_steps_sampled: 1963000\n",
      "    num_steps_trained: 1887500\n",
      "    sample_time_ms: 2973.346\n",
      "    update_time_ms: 3.039\n",
      "  iterations_since_restore: 755\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.075\n",
      "    ram_util_percent: 63.275000000000006\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9439747272926526\n",
      "    mean_inference_ms: 0.9478421482922801\n",
      "    mean_processing_ms: 0.6878022824660518\n",
      "  time_since_restore: 2575.6308937072754\n",
      "  time_this_iter_s: 2.807354688644409\n",
      "  time_total_s: 2575.6308937072754\n",
      "  timestamp: 1596124000\n",
      "  timesteps_since_restore: 1963000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1963000\n",
      "  training_iteration: 755\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2575 s, 755 iter, 1963000 ts, 564 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-46-47\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1065.7183618542192\n",
      "  episode_reward_mean: 569.3748786002021\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 785\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.568\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4487985372543335\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.063466015693848e-06\n",
      "        policy_loss: 0.007790709845721722\n",
      "        total_loss: 92.8300552368164\n",
      "        vf_explained_var: 0.0030120015144348145\n",
      "        vf_loss: 92.82225036621094\n",
      "    load_time_ms: 1.017\n",
      "    num_steps_sampled: 1968200\n",
      "    num_steps_trained: 1892500\n",
      "    sample_time_ms: 3103.091\n",
      "    update_time_ms: 3.099\n",
      "  iterations_since_restore: 757\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.72\n",
      "    ram_util_percent: 63.3\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.942965164221544\n",
      "    mean_inference_ms: 0.9476340985258929\n",
      "    mean_processing_ms: 0.6877204135141565\n",
      "  time_since_restore: 2582.2394857406616\n",
      "  time_this_iter_s: 3.8682167530059814\n",
      "  time_total_s: 2582.2394857406616\n",
      "  timestamp: 1596124007\n",
      "  timesteps_since_restore: 1968200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1968200\n",
      "  training_iteration: 757\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2582 s, 757 iter, 1968200 ts, 569 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-46-53\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1050.6834632103746\n",
      "  episode_reward_mean: 568.1665138081638\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 788\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.801\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4521375894546509\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.3780346509738592e-06\n",
      "        policy_loss: -0.0014425672125071287\n",
      "        total_loss: 81.55843353271484\n",
      "        vf_explained_var: 0.002900242805480957\n",
      "        vf_loss: 81.55989074707031\n",
      "    load_time_ms: 1.016\n",
      "    num_steps_sampled: 1973400\n",
      "    num_steps_trained: 1897500\n",
      "    sample_time_ms: 3077.538\n",
      "    update_time_ms: 3.12\n",
      "  iterations_since_restore: 759\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.58\n",
      "    ram_util_percent: 63.279999999999994\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9408182732510584\n",
      "    mean_inference_ms: 0.947083091044124\n",
      "    mean_processing_ms: 0.6875745756978939\n",
      "  time_since_restore: 2588.5813653469086\n",
      "  time_this_iter_s: 3.899514675140381\n",
      "  time_total_s: 2588.5813653469086\n",
      "  timestamp: 1596124013\n",
      "  timesteps_since_restore: 1973400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1973400\n",
      "  training_iteration: 759\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2588 s, 759 iter, 1973400 ts, 568 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-46-58\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1050.6834632103746\n",
      "  episode_reward_mean: 565.9274047352975\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 789\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.334\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.437738060951233\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 9.74249815044459e-07\n",
      "        policy_loss: -0.0004388199304230511\n",
      "        total_loss: 65.80032348632812\n",
      "        vf_explained_var: 0.010788142681121826\n",
      "        vf_loss: 65.80076599121094\n",
      "    load_time_ms: 1.039\n",
      "    num_steps_sampled: 1978600\n",
      "    num_steps_trained: 1902500\n",
      "    sample_time_ms: 3005.484\n",
      "    update_time_ms: 3.243\n",
      "  iterations_since_restore: 761\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.849999999999994\n",
      "    ram_util_percent: 63.3\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9403952124418145\n",
      "    mean_inference_ms: 0.946912186515392\n",
      "    mean_processing_ms: 0.6875523971267904\n",
      "  time_since_restore: 2593.8656029701233\n",
      "  time_this_iter_s: 2.775921583175659\n",
      "  time_total_s: 2593.8656029701233\n",
      "  timestamp: 1596124018\n",
      "  timesteps_since_restore: 1978600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1978600\n",
      "  training_iteration: 761\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2593 s, 761 iter, 1978600 ts, 566 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-47-04\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1050.6834632103746\n",
      "  episode_reward_mean: 565.9467182031077\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 790\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.015\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4471063613891602\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.111362500973769e-09\n",
      "        policy_loss: 0.0029088729061186314\n",
      "        total_loss: 96.22516632080078\n",
      "        vf_explained_var: 0.0024185776710510254\n",
      "        vf_loss: 96.22225952148438\n",
      "    load_time_ms: 1.031\n",
      "    num_steps_sampled: 1983800\n",
      "    num_steps_trained: 1907500\n",
      "    sample_time_ms: 3005.223\n",
      "    update_time_ms: 3.184\n",
      "  iterations_since_restore: 763\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.574999999999996\n",
      "    ram_util_percent: 63.3\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.93938758481199\n",
      "    mean_inference_ms: 0.9467046105586941\n",
      "    mean_processing_ms: 0.6874680325406741\n",
      "  time_since_restore: 2599.518796682358\n",
      "  time_this_iter_s: 2.7053213119506836\n",
      "  time_total_s: 2599.518796682358\n",
      "  timestamp: 1596124024\n",
      "  timesteps_since_restore: 1983800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1983800\n",
      "  training_iteration: 763\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2599 s, 763 iter, 1983800 ts, 566 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-47-11\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 566.4869656612233\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 794\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.102\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4424103498458862\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.947783514173352e-06\n",
      "        policy_loss: 0.0027439144905656576\n",
      "        total_loss: 84.87593841552734\n",
      "        vf_explained_var: 0.00992286205291748\n",
      "        vf_loss: 84.87319946289062\n",
      "    load_time_ms: 1.033\n",
      "    num_steps_sampled: 1989000\n",
      "    num_steps_trained: 1912500\n",
      "    sample_time_ms: 2999.499\n",
      "    update_time_ms: 3.192\n",
      "  iterations_since_restore: 765\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.325\n",
      "    ram_util_percent: 63.3\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9368658057624613\n",
      "    mean_inference_ms: 0.9459945387942195\n",
      "    mean_processing_ms: 0.6873094233849902\n",
      "  time_since_restore: 2605.907938480377\n",
      "  time_this_iter_s: 3.202476739883423\n",
      "  time_total_s: 2605.907938480377\n",
      "  timestamp: 1596124031\n",
      "  timesteps_since_restore: 1989000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1989000\n",
      "  training_iteration: 765\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2605 s, 765 iter, 1989000 ts, 566 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-47-16\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 573.3712048494675\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 795\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.252\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4360765218734741\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.2724757425530697e-06\n",
      "        policy_loss: 0.0037721304688602686\n",
      "        total_loss: 53.53235626220703\n",
      "        vf_explained_var: 0.01568770408630371\n",
      "        vf_loss: 53.528594970703125\n",
      "    load_time_ms: 1.039\n",
      "    num_steps_sampled: 1994200\n",
      "    num_steps_trained: 1917500\n",
      "    sample_time_ms: 2906.559\n",
      "    update_time_ms: 3.115\n",
      "  iterations_since_restore: 767\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 51.675\n",
      "    ram_util_percent: 63.3\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.935867015402133\n",
      "    mean_inference_ms: 0.9457886172948028\n",
      "    mean_processing_ms: 0.6872281423667644\n",
      "  time_since_restore: 2611.5875990390778\n",
      "  time_this_iter_s: 2.645648956298828\n",
      "  time_total_s: 2611.5875990390778\n",
      "  timestamp: 1596124036\n",
      "  timesteps_since_restore: 1994200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1994200\n",
      "  training_iteration: 767\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2611 s, 767 iter, 1994200 ts, 573 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-47-22\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 577.7960968208096\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 798\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.777\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.438675045967102\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.6307831174344756e-06\n",
      "        policy_loss: -0.001278293551877141\n",
      "        total_loss: 36.883079528808594\n",
      "        vf_explained_var: 0.011343657970428467\n",
      "        vf_loss: 36.88435745239258\n",
      "    load_time_ms: 1.023\n",
      "    num_steps_sampled: 1999400\n",
      "    num_steps_trained: 1922500\n",
      "    sample_time_ms: 2880.624\n",
      "    update_time_ms: 3.135\n",
      "  iterations_since_restore: 769\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.739999999999995\n",
      "    ram_util_percent: 63.3\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9337610961039444\n",
      "    mean_inference_ms: 0.9452495460580574\n",
      "    mean_processing_ms: 0.6870804933073381\n",
      "  time_since_restore: 2617.6641232967377\n",
      "  time_this_iter_s: 3.1594254970550537\n",
      "  time_total_s: 2617.6641232967377\n",
      "  timestamp: 1596124042\n",
      "  timesteps_since_restore: 1999400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 1999400\n",
      "  training_iteration: 769\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2617 s, 769 iter, 1999400 ts, 578 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-47-28\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 570.6203179985139\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 800\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.684\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4377869367599487\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.1338930739366333e-07\n",
      "        policy_loss: -0.0034667872823774815\n",
      "        total_loss: 63.004356384277344\n",
      "        vf_explained_var: 0.014039814472198486\n",
      "        vf_loss: 63.00782012939453\n",
      "    load_time_ms: 1.022\n",
      "    num_steps_sampled: 2004600\n",
      "    num_steps_trained: 1927500\n",
      "    sample_time_ms: 2931.66\n",
      "    update_time_ms: 3.153\n",
      "  iterations_since_restore: 771\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.550000000000004\n",
      "    ram_util_percent: 63.349999999999994\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9323571766308008\n",
      "    mean_inference_ms: 0.9448788233133327\n",
      "    mean_processing_ms: 0.6869763172811875\n",
      "  time_since_restore: 2623.4578721523285\n",
      "  time_this_iter_s: 2.900012254714966\n",
      "  time_total_s: 2623.4578721523285\n",
      "  timestamp: 1596124048\n",
      "  timesteps_since_restore: 2004600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2004600\n",
      "  training_iteration: 771\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2623 s, 771 iter, 2004600 ts, 571 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-47-34\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 570.6203179985139\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 800\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.763\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4518568515777588\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.7695665519568138e-06\n",
      "        policy_loss: -0.004352667834609747\n",
      "        total_loss: 108.45480346679688\n",
      "        vf_explained_var: 0.002406895160675049\n",
      "        vf_loss: 108.45915222167969\n",
      "    load_time_ms: 1.022\n",
      "    num_steps_sampled: 2009800\n",
      "    num_steps_trained: 1932500\n",
      "    sample_time_ms: 2914.097\n",
      "    update_time_ms: 3.138\n",
      "  iterations_since_restore: 773\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.425000000000004\n",
      "    ram_util_percent: 63.4\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9323571766308003\n",
      "    mean_inference_ms: 0.944878823313333\n",
      "    mean_processing_ms: 0.6869763172811877\n",
      "  time_since_restore: 2628.9365174770355\n",
      "  time_this_iter_s: 2.724477767944336\n",
      "  time_total_s: 2628.9365174770355\n",
      "  timestamp: 1596124054\n",
      "  timesteps_since_restore: 2009800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2009800\n",
      "  training_iteration: 773\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2628 s, 773 iter, 2009800 ts, 571 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-47-40\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 582.0021902823278\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 804\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.903\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4294179677963257\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.470109900012176e-07\n",
      "        policy_loss: -0.006717112846672535\n",
      "        total_loss: 24.431169509887695\n",
      "        vf_explained_var: 0.019871115684509277\n",
      "        vf_loss: 24.437885284423828\n",
      "    load_time_ms: 1.036\n",
      "    num_steps_sampled: 2015000\n",
      "    num_steps_trained: 1937500\n",
      "    sample_time_ms: 2908.714\n",
      "    update_time_ms: 3.159\n",
      "  iterations_since_restore: 775\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 52.625\n",
      "    ram_util_percent: 63.4\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.929914796246406\n",
      "    mean_inference_ms: 0.9441925142386141\n",
      "    mean_processing_ms: 0.6868169531761623\n",
      "  time_since_restore: 2635.2731273174286\n",
      "  time_this_iter_s: 2.645462989807129\n",
      "  time_total_s: 2635.2731273174286\n",
      "  timestamp: 1596124060\n",
      "  timesteps_since_restore: 2015000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2015000\n",
      "  training_iteration: 775\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2635 s, 775 iter, 2015000 ts, 582 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-47-46\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 580.0649173571711\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 805\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.129\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4339936971664429\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.2260913990758127e-06\n",
      "        policy_loss: 0.001384576316922903\n",
      "        total_loss: 42.05666732788086\n",
      "        vf_explained_var: 0.016100645065307617\n",
      "        vf_loss: 42.05527877807617\n",
      "    load_time_ms: 1.034\n",
      "    num_steps_sampled: 2020200\n",
      "    num_steps_trained: 1942500\n",
      "    sample_time_ms: 2897.858\n",
      "    update_time_ms: 3.212\n",
      "  iterations_since_restore: 777\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.375\n",
      "    ram_util_percent: 63.4\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.929049407118996\n",
      "    mean_inference_ms: 0.9440695171327288\n",
      "    mean_processing_ms: 0.6867636308617135\n",
      "  time_since_restore: 2640.8489882946014\n",
      "  time_this_iter_s: 2.788691282272339\n",
      "  time_total_s: 2640.8489882946014\n",
      "  timestamp: 1596124066\n",
      "  timesteps_since_restore: 2020200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2020200\n",
      "  training_iteration: 777\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2640 s, 777 iter, 2020200 ts, 580 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-47-52\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 575.685951570587\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 809\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.171\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4318751096725464\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 7.185697654676915e-07\n",
      "        policy_loss: 0.0017456070054322481\n",
      "        total_loss: 28.863414764404297\n",
      "        vf_explained_var: 0.01448369026184082\n",
      "        vf_loss: 28.861671447753906\n",
      "    load_time_ms: 1.066\n",
      "    num_steps_sampled: 2025400\n",
      "    num_steps_trained: 1947500\n",
      "    sample_time_ms: 2957.684\n",
      "    update_time_ms: 3.087\n",
      "  iterations_since_restore: 779\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.46\n",
      "    ram_util_percent: 63.379999999999995\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9265396251172233\n",
      "    mean_inference_ms: 0.9433193716509065\n",
      "    mean_processing_ms: 0.6865807496077394\n",
      "  time_since_restore: 2647.525383710861\n",
      "  time_this_iter_s: 2.8610329627990723\n",
      "  time_total_s: 2647.525383710861\n",
      "  timestamp: 1596124072\n",
      "  timesteps_since_restore: 2025400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2025400\n",
      "  training_iteration: 779\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2647 s, 779 iter, 2025400 ts, 576 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-47-58\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 574.3781013155218\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 810\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.032\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4319393634796143\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.078724878311732e-07\n",
      "        policy_loss: 0.0028505437076091766\n",
      "        total_loss: 29.712797164916992\n",
      "        vf_explained_var: 0.01044541597366333\n",
      "        vf_loss: 29.709949493408203\n",
      "    load_time_ms: 1.049\n",
      "    num_steps_sampled: 2030600\n",
      "    num_steps_trained: 1952500\n",
      "    sample_time_ms: 2949.963\n",
      "    update_time_ms: 3.028\n",
      "  iterations_since_restore: 781\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.325\n",
      "    ram_util_percent: 63.4\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9255671494928244\n",
      "    mean_inference_ms: 0.943119975278697\n",
      "    mean_processing_ms: 0.6865011494630698\n",
      "  time_since_restore: 2653.2385835647583\n",
      "  time_this_iter_s: 2.9391226768493652\n",
      "  time_total_s: 2653.2385835647583\n",
      "  timestamp: 1596124078\n",
      "  timesteps_since_restore: 2030600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2030600\n",
      "  training_iteration: 781\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2653 s, 781 iter, 2030600 ts, 574 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-48-05\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 570.0456109022269\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 813\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.663\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4340060949325562\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.743503450617027e-08\n",
      "        policy_loss: -0.0056912461295723915\n",
      "        total_loss: 23.13998031616211\n",
      "        vf_explained_var: 0.015023946762084961\n",
      "        vf_loss: 23.145666122436523\n",
      "    load_time_ms: 1.049\n",
      "    num_steps_sampled: 2035800\n",
      "    num_steps_trained: 1957500\n",
      "    sample_time_ms: 3059.968\n",
      "    update_time_ms: 3.074\n",
      "  iterations_since_restore: 783\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.08\n",
      "    ram_util_percent: 63.379999999999995\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9234962252821326\n",
      "    mean_inference_ms: 0.9425260670381469\n",
      "    mean_processing_ms: 0.6863433620261553\n",
      "  time_since_restore: 2659.8128259181976\n",
      "  time_this_iter_s: 3.8065381050109863\n",
      "  time_total_s: 2659.8128259181976\n",
      "  timestamp: 1596124085\n",
      "  timesteps_since_restore: 2035800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2035800\n",
      "  training_iteration: 783\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2659 s, 783 iter, 2035800 ts, 570 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-48-11\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 564.517347917835\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 815\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.817\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4283785820007324\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.6975402417074292e-08\n",
      "        policy_loss: -0.0010204967111349106\n",
      "        total_loss: 16.65713882446289\n",
      "        vf_explained_var: 0.0030131936073303223\n",
      "        vf_loss: 16.658164978027344\n",
      "    load_time_ms: 1.036\n",
      "    num_steps_sampled: 2041000\n",
      "    num_steps_trained: 1962500\n",
      "    sample_time_ms: 3078.959\n",
      "    update_time_ms: 3.031\n",
      "  iterations_since_restore: 785\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 51.499999999999986\n",
      "    ram_util_percent: 63.4\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.922261555894646\n",
      "    mean_inference_ms: 0.9422656157425117\n",
      "    mean_processing_ms: 0.6862734712524741\n",
      "  time_since_restore: 2666.3403639793396\n",
      "  time_this_iter_s: 4.010723114013672\n",
      "  time_total_s: 2666.3403639793396\n",
      "  timestamp: 1596124091\n",
      "  timesteps_since_restore: 2041000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2041000\n",
      "  training_iteration: 785\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2666 s, 785 iter, 2041000 ts, 565 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-48-16\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 564.5173479178351\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 815\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.769\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.433320164680481\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.9843578513700777e-07\n",
      "        policy_loss: -0.0016363982576876879\n",
      "        total_loss: 28.87273406982422\n",
      "        vf_explained_var: 0.010323882102966309\n",
      "        vf_loss: 28.87438201904297\n",
      "    load_time_ms: 1.041\n",
      "    num_steps_sampled: 2046200\n",
      "    num_steps_trained: 1967500\n",
      "    sample_time_ms: 3047.007\n",
      "    update_time_ms: 3.027\n",
      "  iterations_since_restore: 787\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.95\n",
      "    ram_util_percent: 63.4\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9222615558946448\n",
      "    mean_inference_ms: 0.9422656157425118\n",
      "    mean_processing_ms: 0.6862734712524741\n",
      "  time_since_restore: 2671.5958003997803\n",
      "  time_this_iter_s: 2.8103761672973633\n",
      "  time_total_s: 2671.5958003997803\n",
      "  timestamp: 1596124096\n",
      "  timesteps_since_restore: 2046200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2046200\n",
      "  training_iteration: 787\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2671 s, 787 iter, 2046200 ts, 565 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-48-23\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 554.9184726470761\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 818\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.581\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4323132038116455\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 7.280588079083827e-07\n",
      "        policy_loss: -0.0012057928834110498\n",
      "        total_loss: 37.135986328125\n",
      "        vf_explained_var: 0.01338571310043335\n",
      "        vf_loss: 37.13719177246094\n",
      "    load_time_ms: 1.007\n",
      "    num_steps_sampled: 2051400\n",
      "    num_steps_trained: 1972500\n",
      "    sample_time_ms: 3001.164\n",
      "    update_time_ms: 3.022\n",
      "  iterations_since_restore: 789\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.47500000000001\n",
      "    ram_util_percent: 63.4\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9203062333167544\n",
      "    mean_inference_ms: 0.9416486400792171\n",
      "    mean_processing_ms: 0.686141616726608\n",
      "  time_since_restore: 2677.8089821338654\n",
      "  time_this_iter_s: 2.67311692237854\n",
      "  time_total_s: 2677.8089821338654\n",
      "  timestamp: 1596124103\n",
      "  timesteps_since_restore: 2051400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2051400\n",
      "  training_iteration: 789\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2677 s, 789 iter, 2051400 ts, 555 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-48-29\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 553.8847362147122\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 820\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.872\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4359440803527832\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.1714220136127551e-06\n",
      "        policy_loss: -4.5563934691017494e-05\n",
      "        total_loss: 60.94116973876953\n",
      "        vf_explained_var: 0.013075530529022217\n",
      "        vf_loss: 60.94121170043945\n",
      "    load_time_ms: 1.001\n",
      "    num_steps_sampled: 2056600\n",
      "    num_steps_trained: 1977500\n",
      "    sample_time_ms: 3026.622\n",
      "    update_time_ms: 2.994\n",
      "  iterations_since_restore: 791\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.900000000000006\n",
      "    ram_util_percent: 63.5\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9188609567711366\n",
      "    mean_inference_ms: 0.9413275873206502\n",
      "    mean_processing_ms: 0.6860224937096467\n",
      "  time_since_restore: 2683.7794563770294\n",
      "  time_this_iter_s: 2.6922738552093506\n",
      "  time_total_s: 2683.7794563770294\n",
      "  timestamp: 1596124109\n",
      "  timesteps_since_restore: 2056600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2056600\n",
      "  training_iteration: 791\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2683 s, 791 iter, 2056600 ts, 554 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-48-35\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 555.2200082880005\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 823\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.085\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.433960199356079\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.2446642472241365e-07\n",
      "        policy_loss: -0.0006748466403223574\n",
      "        total_loss: 39.00785446166992\n",
      "        vf_explained_var: 0.015185296535491943\n",
      "        vf_loss: 39.00851821899414\n",
      "    load_time_ms: 0.992\n",
      "    num_steps_sampled: 2061800\n",
      "    num_steps_trained: 1982500\n",
      "    sample_time_ms: 2968.868\n",
      "    update_time_ms: 3.01\n",
      "  iterations_since_restore: 793\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.98\n",
      "    ram_util_percent: 63.5\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9169502943646832\n",
      "    mean_inference_ms: 0.9408417285928984\n",
      "    mean_processing_ms: 0.6858840444504114\n",
      "  time_since_restore: 2689.7801101207733\n",
      "  time_this_iter_s: 3.2359697818756104\n",
      "  time_total_s: 2689.7801101207733\n",
      "  timestamp: 1596124115\n",
      "  timesteps_since_restore: 2061800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2061800\n",
      "  training_iteration: 793\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2689 s, 793 iter, 2061800 ts, 555 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-48-42\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 553.2214557468782\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 825\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.521\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4307305812835693\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.0164719078129565e-07\n",
      "        policy_loss: -0.0048476457595825195\n",
      "        total_loss: 32.62972640991211\n",
      "        vf_explained_var: 0.007854700088500977\n",
      "        vf_loss: 32.63458251953125\n",
      "    load_time_ms: 0.984\n",
      "    num_steps_sampled: 2067000\n",
      "    num_steps_trained: 1987500\n",
      "    sample_time_ms: 3062.185\n",
      "    update_time_ms: 2.997\n",
      "  iterations_since_restore: 795\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 40.24999999999999\n",
      "    ram_util_percent: 63.43333333333333\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.915633419010364\n",
      "    mean_inference_ms: 0.9404966719580264\n",
      "    mean_processing_ms: 0.685792992661263\n",
      "  time_since_restore: 2697.23512506485\n",
      "  time_this_iter_s: 3.6357431411743164\n",
      "  time_total_s: 2697.23512506485\n",
      "  timestamp: 1596124122\n",
      "  timesteps_since_restore: 2067000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2067000\n",
      "  training_iteration: 795\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2697 s, 795 iter, 2067000 ts, 553 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-48-48\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 546.3474784050721\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 826\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.256\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.436368703842163\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.821062020710087e-07\n",
      "        policy_loss: 0.0016856346046552062\n",
      "        total_loss: 64.57587432861328\n",
      "        vf_explained_var: 0.0047234296798706055\n",
      "        vf_loss: 64.5741958618164\n",
      "    load_time_ms: 0.971\n",
      "    num_steps_sampled: 2072200\n",
      "    num_steps_trained: 1992500\n",
      "    sample_time_ms: 3174.236\n",
      "    update_time_ms: 2.989\n",
      "  iterations_since_restore: 797\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.98333333333333\n",
      "    ram_util_percent: 63.4\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9150185098401176\n",
      "    mean_inference_ms: 0.9403394645145035\n",
      "    mean_processing_ms: 0.6857475310668164\n",
      "  time_since_restore: 2703.60875582695\n",
      "  time_this_iter_s: 3.88496470451355\n",
      "  time_total_s: 2703.60875582695\n",
      "  timestamp: 1596124128\n",
      "  timesteps_since_restore: 2072200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2072200\n",
      "  training_iteration: 797\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2703 s, 797 iter, 2072200 ts, 546 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-48-54\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 542.2771801367138\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 829\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.669\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4329462051391602\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.801604968131869e-07\n",
      "        policy_loss: 0.004477752838283777\n",
      "        total_loss: 53.536685943603516\n",
      "        vf_explained_var: 0.009833335876464844\n",
      "        vf_loss: 53.53220748901367\n",
      "    load_time_ms: 0.99\n",
      "    num_steps_sampled: 2077400\n",
      "    num_steps_trained: 1997500\n",
      "    sample_time_ms: 3120.76\n",
      "    update_time_ms: 3.071\n",
      "  iterations_since_restore: 799\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.50000000000001\n",
      "    ram_util_percent: 63.4\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9130516226998333\n",
      "    mean_inference_ms: 0.939832397450604\n",
      "    mean_processing_ms: 0.6856183228372659\n",
      "  time_since_restore: 2709.294813156128\n",
      "  time_this_iter_s: 2.997175931930542\n",
      "  time_total_s: 2709.294813156128\n",
      "  timestamp: 1596124134\n",
      "  timesteps_since_restore: 2077400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2077400\n",
      "  training_iteration: 799\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2709 s, 799 iter, 2077400 ts, 542 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-49-00\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 540.4361001621547\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 830\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.728\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4360179901123047\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.344199962564744e-06\n",
      "        policy_loss: 0.008603843860328197\n",
      "        total_loss: 59.87718200683594\n",
      "        vf_explained_var: 0.008841514587402344\n",
      "        vf_loss: 59.86857986450195\n",
      "    load_time_ms: 1.026\n",
      "    num_steps_sampled: 2082600\n",
      "    num_steps_trained: 2002500\n",
      "    sample_time_ms: 3080.508\n",
      "    update_time_ms: 3.142\n",
      "  iterations_since_restore: 801\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.599999999999994\n",
      "    ram_util_percent: 63.4\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9124433241667096\n",
      "    mean_inference_ms: 0.939675628849251\n",
      "    mean_processing_ms: 0.6855802229815992\n",
      "  time_since_restore: 2714.86527967453\n",
      "  time_this_iter_s: 2.7950165271759033\n",
      "  time_total_s: 2714.86527967453\n",
      "  timestamp: 1596124140\n",
      "  timesteps_since_restore: 2082600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2082600\n",
      "  training_iteration: 801\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2714 s, 801 iter, 2082600 ts, 540 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-49-06\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 543.968553967319\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 834\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.86\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4443978071212769\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.40559005155228e-06\n",
      "        policy_loss: 0.0012940107844769955\n",
      "        total_loss: 71.21456909179688\n",
      "        vf_explained_var: 0.0109444260597229\n",
      "        vf_loss: 71.21328735351562\n",
      "    load_time_ms: 1.033\n",
      "    num_steps_sampled: 2087800\n",
      "    num_steps_trained: 2007500\n",
      "    sample_time_ms: 3149.349\n",
      "    update_time_ms: 3.073\n",
      "  iterations_since_restore: 803\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.38000000000001\n",
      "    ram_util_percent: 63.4\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9099031688720896\n",
      "    mean_inference_ms: 0.9390235894818066\n",
      "    mean_processing_ms: 0.685409494605773\n",
      "  time_since_restore: 2721.5541067123413\n",
      "  time_this_iter_s: 3.733419418334961\n",
      "  time_total_s: 2721.5541067123413\n",
      "  timestamp: 1596124146\n",
      "  timesteps_since_restore: 2087800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2087800\n",
      "  training_iteration: 803\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2721 s, 803 iter, 2087800 ts, 544 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-49-12\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 546.6226490531454\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 835\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.566\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4437764883041382\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.2049674751324346e-06\n",
      "        policy_loss: -0.0007596589275635779\n",
      "        total_loss: 88.73332214355469\n",
      "        vf_explained_var: 0.004251599311828613\n",
      "        vf_loss: 88.73408508300781\n",
      "    load_time_ms: 1.243\n",
      "    num_steps_sampled: 2093000\n",
      "    num_steps_trained: 2012500\n",
      "    sample_time_ms: 2952.357\n",
      "    update_time_ms: 3.129\n",
      "  iterations_since_restore: 805\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.099999999999994\n",
      "    ram_util_percent: 63.4\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9093070413636166\n",
      "    mean_inference_ms: 0.9388692311324778\n",
      "    mean_processing_ms: 0.68536990143641\n",
      "  time_since_restore: 2727.0597953796387\n",
      "  time_this_iter_s: 2.9803667068481445\n",
      "  time_total_s: 2727.0597953796387\n",
      "  timestamp: 1596124152\n",
      "  timesteps_since_restore: 2093000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2093000\n",
      "  training_iteration: 805\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2727 s, 805 iter, 2093000 ts, 547 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-49-17\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 547.06490661946\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 836\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.839\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4557944536209106\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 9.67860273703991e-07\n",
      "        policy_loss: -0.0018560297321528196\n",
      "        total_loss: 123.04080200195312\n",
      "        vf_explained_var: 0.003922164440155029\n",
      "        vf_loss: 123.04266357421875\n",
      "    load_time_ms: 1.254\n",
      "    num_steps_sampled: 2098200\n",
      "    num_steps_trained: 2017500\n",
      "    sample_time_ms: 2870.827\n",
      "    update_time_ms: 3.076\n",
      "  iterations_since_restore: 807\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.45\n",
      "    ram_util_percent: 63.4\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.908833524531257\n",
      "    mean_inference_ms: 0.9386940012565297\n",
      "    mean_processing_ms: 0.6853591862194783\n",
      "  time_since_restore: 2732.6198403835297\n",
      "  time_this_iter_s: 2.817803382873535\n",
      "  time_total_s: 2732.6198403835297\n",
      "  timestamp: 1596124157\n",
      "  timesteps_since_restore: 2098200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2098200\n",
      "  training_iteration: 807\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2732 s, 807 iter, 2098200 ts, 547 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-49-23\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 552.5246957118732\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 839\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.895\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.434374213218689\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.704216003872716e-07\n",
      "        policy_loss: -0.003588747000321746\n",
      "        total_loss: 41.74441146850586\n",
      "        vf_explained_var: 0.008955299854278564\n",
      "        vf_loss: 41.74800491333008\n",
      "    load_time_ms: 1.263\n",
      "    num_steps_sampled: 2103400\n",
      "    num_steps_trained: 2022500\n",
      "    sample_time_ms: 2888.226\n",
      "    update_time_ms: 3.079\n",
      "  iterations_since_restore: 809\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.575\n",
      "    ram_util_percent: 63.4\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9068184581081136\n",
      "    mean_inference_ms: 0.9382275898672383\n",
      "    mean_processing_ms: 0.6851963138333168\n",
      "  time_since_restore: 2738.4796500205994\n",
      "  time_this_iter_s: 2.714294910430908\n",
      "  time_total_s: 2738.4796500205994\n",
      "  timestamp: 1596124163\n",
      "  timesteps_since_restore: 2103400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2103400\n",
      "  training_iteration: 809\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2738 s, 809 iter, 2103400 ts, 553 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-49-29\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 549.4687384604581\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 840\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 20.051\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.438264012336731\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.02762907469878e-06\n",
      "        policy_loss: -0.0024484298191964626\n",
      "        total_loss: 37.14413070678711\n",
      "        vf_explained_var: 0.013348639011383057\n",
      "        vf_loss: 37.14657211303711\n",
      "    load_time_ms: 1.247\n",
      "    num_steps_sampled: 2108600\n",
      "    num_steps_trained: 2027500\n",
      "    sample_time_ms: 2892.305\n",
      "    update_time_ms: 3.14\n",
      "  iterations_since_restore: 811\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.15\n",
      "    ram_util_percent: 63.4\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9062415808453888\n",
      "    mean_inference_ms: 0.9380776660488495\n",
      "    mean_processing_ms: 0.6851602954416977\n",
      "  time_since_restore: 2744.0934116840363\n",
      "  time_this_iter_s: 2.7400195598602295\n",
      "  time_total_s: 2744.0934116840363\n",
      "  timestamp: 1596124169\n",
      "  timesteps_since_restore: 2108600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2108600\n",
      "  training_iteration: 811\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2744 s, 811 iter, 2108600 ts, 549 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-49-35\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 551.967480256529\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 844\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.734\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4288442134857178\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.273367781275738e-07\n",
      "        policy_loss: 0.0025724058505147696\n",
      "        total_loss: 16.099149703979492\n",
      "        vf_explained_var: 0.02160578966140747\n",
      "        vf_loss: 16.096572875976562\n",
      "    load_time_ms: 1.247\n",
      "    num_steps_sampled: 2113800\n",
      "    num_steps_trained: 2032500\n",
      "    sample_time_ms: 2864.705\n",
      "    update_time_ms: 3.183\n",
      "  iterations_since_restore: 813\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 51.625\n",
      "    ram_util_percent: 63.4\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.90379082796871\n",
      "    mean_inference_ms: 0.9374473700242831\n",
      "    mean_processing_ms: 0.6849936108779631\n",
      "  time_since_restore: 2750.5031056404114\n",
      "  time_this_iter_s: 2.511554479598999\n",
      "  time_total_s: 2750.5031056404114\n",
      "  timestamp: 1596124175\n",
      "  timesteps_since_restore: 2113800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2113800\n",
      "  training_iteration: 813\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2750 s, 813 iter, 2113800 ts, 552 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-49-41\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 551.967480256529\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 844\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.513\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.446916937828064\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.627371825132286e-06\n",
      "        policy_loss: -0.004788974765688181\n",
      "        total_loss: 70.40765380859375\n",
      "        vf_explained_var: 0.0029219388961791992\n",
      "        vf_loss: 70.41243743896484\n",
      "    load_time_ms: 1.065\n",
      "    num_steps_sampled: 2119000\n",
      "    num_steps_trained: 2037500\n",
      "    sample_time_ms: 2884.722\n",
      "    update_time_ms: 3.221\n",
      "  iterations_since_restore: 815\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.3\n",
      "    ram_util_percent: 63.4\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.90379082796871\n",
      "    mean_inference_ms: 0.9374473700242831\n",
      "    mean_processing_ms: 0.6849936108779631\n",
      "  time_since_restore: 2756.195322751999\n",
      "  time_this_iter_s: 2.943140745162964\n",
      "  time_total_s: 2756.195322751999\n",
      "  timestamp: 1596124181\n",
      "  timesteps_since_restore: 2119000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2119000\n",
      "  training_iteration: 815\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2756 s, 815 iter, 2119000 ts, 552 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-49-48\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 544.257408825068\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 849\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.116\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4397027492523193\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.4251809211127693e-06\n",
      "        policy_loss: 0.012127963826060295\n",
      "        total_loss: 43.683189392089844\n",
      "        vf_explained_var: 0.01300269365310669\n",
      "        vf_loss: 43.67106246948242\n",
      "    load_time_ms: 1.054\n",
      "    num_steps_sampled: 2124200\n",
      "    num_steps_trained: 2042500\n",
      "    sample_time_ms: 3002.446\n",
      "    update_time_ms: 3.253\n",
      "  iterations_since_restore: 817\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 42.375\n",
      "    ram_util_percent: 63.349999999999994\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.900758299827347\n",
      "    mean_inference_ms: 0.9366671834289322\n",
      "    mean_processing_ms: 0.6847888982623851\n",
      "  time_since_restore: 2762.9277563095093\n",
      "  time_this_iter_s: 2.878403663635254\n",
      "  time_total_s: 2762.9277563095093\n",
      "  timestamp: 1596124188\n",
      "  timesteps_since_restore: 2124200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2124200\n",
      "  training_iteration: 817\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2762 s, 817 iter, 2124200 ts, 544 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-49-53\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 544.257408825068\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 849\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.057\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4370838403701782\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.712198228342459e-07\n",
      "        policy_loss: 8.648624498164281e-05\n",
      "        total_loss: 44.715057373046875\n",
      "        vf_explained_var: 0.008645951747894287\n",
      "        vf_loss: 44.71497344970703\n",
      "    load_time_ms: 1.043\n",
      "    num_steps_sampled: 2129400\n",
      "    num_steps_trained: 2047500\n",
      "    sample_time_ms: 2965.006\n",
      "    update_time_ms: 3.196\n",
      "  iterations_since_restore: 819\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.75\n",
      "    ram_util_percent: 63.4\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9007582998273476\n",
      "    mean_inference_ms: 0.9366671834289322\n",
      "    mean_processing_ms: 0.6847888982623851\n",
      "  time_since_restore: 2768.411579847336\n",
      "  time_this_iter_s: 2.7662291526794434\n",
      "  time_total_s: 2768.411579847336\n",
      "  timestamp: 1596124193\n",
      "  timesteps_since_restore: 2129400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2129400\n",
      "  training_iteration: 819\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2768 s, 819 iter, 2129400 ts, 544 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-50-00\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 546.3141103808077\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 852\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 17.784\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4560831785202026\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.4057088264962658e-05\n",
      "        policy_loss: 0.004160492680966854\n",
      "        total_loss: 85.20409393310547\n",
      "        vf_explained_var: 0.001585841178894043\n",
      "        vf_loss: 85.1999282836914\n",
      "    load_time_ms: 1.046\n",
      "    num_steps_sampled: 2134600\n",
      "    num_steps_trained: 2052500\n",
      "    sample_time_ms: 3079.792\n",
      "    update_time_ms: 3.032\n",
      "  iterations_since_restore: 821\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.300000000000004\n",
      "    ram_util_percent: 63.4\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.8989444398354096\n",
      "    mean_inference_ms: 0.9361963050640363\n",
      "    mean_processing_ms: 0.6846658390714431\n",
      "  time_since_restore: 2775.1681916713715\n",
      "  time_this_iter_s: 3.9161367416381836\n",
      "  time_total_s: 2775.1681916713715\n",
      "  timestamp: 1596124200\n",
      "  timesteps_since_restore: 2134600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2134600\n",
      "  training_iteration: 821\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2775 s, 821 iter, 2134600 ts, 546 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-50-06\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 551.0177751329156\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 854\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.255\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4319133758544922\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.906679981151683e-07\n",
      "        policy_loss: -0.0019630780443549156\n",
      "        total_loss: 23.209138870239258\n",
      "        vf_explained_var: 0.017745256423950195\n",
      "        vf_loss: 23.211103439331055\n",
      "    load_time_ms: 1.041\n",
      "    num_steps_sampled: 2139800\n",
      "    num_steps_trained: 2057500\n",
      "    sample_time_ms: 2988.89\n",
      "    update_time_ms: 3.033\n",
      "  iterations_since_restore: 823\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.95\n",
      "    ram_util_percent: 63.4\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.897754541436709\n",
      "    mean_inference_ms: 0.9358932394314476\n",
      "    mean_processing_ms: 0.6845824467951399\n",
      "  time_since_restore: 2780.678904056549\n",
      "  time_this_iter_s: 2.792659282684326\n",
      "  time_total_s: 2780.678904056549\n",
      "  timestamp: 1596124206\n",
      "  timesteps_since_restore: 2139800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2139800\n",
      "  training_iteration: 823\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2780 s, 823 iter, 2139800 ts, 551 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-50-11\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 551.0177751329156\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 854\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.667\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4498084783554077\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.643725216941675e-06\n",
      "        policy_loss: 0.00026275819982402027\n",
      "        total_loss: 59.93925476074219\n",
      "        vf_explained_var: 0.002667367458343506\n",
      "        vf_loss: 59.938995361328125\n",
      "    load_time_ms: 1.032\n",
      "    num_steps_sampled: 2145000\n",
      "    num_steps_trained: 2062500\n",
      "    sample_time_ms: 2979.494\n",
      "    update_time_ms: 3.013\n",
      "  iterations_since_restore: 825\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.025\n",
      "    ram_util_percent: 63.4\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.897754541436709\n",
      "    mean_inference_ms: 0.9358932394314476\n",
      "    mean_processing_ms: 0.6845824467951399\n",
      "  time_since_restore: 2786.280732154846\n",
      "  time_this_iter_s: 2.8470187187194824\n",
      "  time_total_s: 2786.280732154846\n",
      "  timestamp: 1596124211\n",
      "  timesteps_since_restore: 2145000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2145000\n",
      "  training_iteration: 825\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2786 s, 825 iter, 2145000 ts, 551 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-50-18\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 549.4199836039231\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 859\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.826\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4328217506408691\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.39565098733874e-06\n",
      "        policy_loss: -0.0005320545751601458\n",
      "        total_loss: 16.49497413635254\n",
      "        vf_explained_var: 0.015365004539489746\n",
      "        vf_loss: 16.49550437927246\n",
      "    load_time_ms: 1.034\n",
      "    num_steps_sampled: 2150200\n",
      "    num_steps_trained: 2067500\n",
      "    sample_time_ms: 2943.648\n",
      "    update_time_ms: 2.92\n",
      "  iterations_since_restore: 827\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 51.849999999999994\n",
      "    ram_util_percent: 63.4\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.8948039873845444\n",
      "    mean_inference_ms: 0.9351312099309588\n",
      "    mean_processing_ms: 0.684376442215345\n",
      "  time_since_restore: 2792.6565425395966\n",
      "  time_this_iter_s: 2.6564557552337646\n",
      "  time_total_s: 2792.6565425395966\n",
      "  timestamp: 1596124218\n",
      "  timesteps_since_restore: 2150200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2150200\n",
      "  training_iteration: 827\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2792 s, 827 iter, 2150200 ts, 549 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-50-23\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 549.4199836039231\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 859\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 18.817\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4547549486160278\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.7232637168926885e-06\n",
      "        policy_loss: -6.396093522198498e-05\n",
      "        total_loss: 69.86652374267578\n",
      "        vf_explained_var: 0.00798046588897705\n",
      "        vf_loss: 69.86659240722656\n",
      "    load_time_ms: 1.033\n",
      "    num_steps_sampled: 2155400\n",
      "    num_steps_trained: 2072500\n",
      "    sample_time_ms: 2943.514\n",
      "    update_time_ms: 2.996\n",
      "  iterations_since_restore: 829\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.35000000000001\n",
      "    ram_util_percent: 63.4\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.8948039873845444\n",
      "    mean_inference_ms: 0.9351312099309588\n",
      "    mean_processing_ms: 0.684376442215345\n",
      "  time_since_restore: 2798.139726161957\n",
      "  time_this_iter_s: 2.723991632461548\n",
      "  time_total_s: 2798.139726161957\n",
      "  timestamp: 1596124223\n",
      "  timesteps_since_restore: 2155400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2155400\n",
      "  training_iteration: 829\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2798 s, 829 iter, 2155400 ts, 549 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-50-31\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 553.5625427215615\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 863\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 19.974\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4522901773452759\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.052825819504505e-07\n",
      "        policy_loss: -0.0024920389987528324\n",
      "        total_loss: 47.85613250732422\n",
      "        vf_explained_var: 0.0101395845413208\n",
      "        vf_loss: 47.85862350463867\n",
      "    load_time_ms: 1.075\n",
      "    num_steps_sampled: 2160600\n",
      "    num_steps_trained: 2077500\n",
      "    sample_time_ms: 3039.238\n",
      "    update_time_ms: 3.001\n",
      "  iterations_since_restore: 831\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.21666666666667\n",
      "    ram_util_percent: 63.4\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.892512146913088\n",
      "    mean_inference_ms: 0.934531852453698\n",
      "    mean_processing_ms: 0.6842198855610822\n",
      "  time_since_restore: 2805.8684413433075\n",
      "  time_this_iter_s: 3.753403902053833\n",
      "  time_total_s: 2805.8684413433075\n",
      "  timestamp: 1596124231\n",
      "  timesteps_since_restore: 2160600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2160600\n",
      "  training_iteration: 831\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2805 s, 831 iter, 2160600 ts, 554 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-50-40\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 552.5184211853834\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 864\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 26.555\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.447654366493225\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.52034760958486e-06\n",
      "        policy_loss: -0.00012995877477806062\n",
      "        total_loss: 53.44718933105469\n",
      "        vf_explained_var: 0.007804274559020996\n",
      "        vf_loss: 53.44731903076172\n",
      "    load_time_ms: 1.322\n",
      "    num_steps_sampled: 2165800\n",
      "    num_steps_trained: 2082500\n",
      "    sample_time_ms: 3398.651\n",
      "    update_time_ms: 3.375\n",
      "  iterations_since_restore: 833\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.05000000000001\n",
      "    ram_util_percent: 63.4\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.8919646543441524\n",
      "    mean_inference_ms: 0.934392124773335\n",
      "    mean_processing_ms: 0.6841849276221162\n",
      "  time_since_restore: 2815.0580773353577\n",
      "  time_this_iter_s: 4.483449935913086\n",
      "  time_total_s: 2815.0580773353577\n",
      "  timestamp: 1596124240\n",
      "  timesteps_since_restore: 2165800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2165800\n",
      "  training_iteration: 833\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2815 s, 833 iter, 2165800 ts, 553 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-50-46\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 552.5184211853834\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 864\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 27.555\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4615111351013184\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.6360255510080606e-06\n",
      "        policy_loss: -0.003937127534300089\n",
      "        total_loss: 84.08391571044922\n",
      "        vf_explained_var: 0.0015057921409606934\n",
      "        vf_loss: 84.08785247802734\n",
      "    load_time_ms: 1.384\n",
      "    num_steps_sampled: 2168400\n",
      "    num_steps_trained: 2085000\n",
      "    sample_time_ms: 3663.655\n",
      "    update_time_ms: 4.19\n",
      "  iterations_since_restore: 834\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.175\n",
      "    ram_util_percent: 63.4\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.8919646543441524\n",
      "    mean_inference_ms: 0.934392124773335\n",
      "    mean_processing_ms: 0.6841849276221162\n",
      "  time_since_restore: 2820.4851071834564\n",
      "  time_this_iter_s: 5.427029848098755\n",
      "  time_total_s: 2820.4851071834564\n",
      "  timestamp: 1596124246\n",
      "  timesteps_since_restore: 2168400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2168400\n",
      "  training_iteration: 834\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2820 s, 834 iter, 2168400 ts, 553 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-50-51\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 560.2359057612924\n",
      "  episode_reward_min: 154.2684189978663\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 866\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 28.61\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4696091413497925\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 9.097647307498846e-06\n",
      "        policy_loss: 0.0018460266292095184\n",
      "        total_loss: 85.4178237915039\n",
      "        vf_explained_var: 0.00569230318069458\n",
      "        vf_loss: 85.41598510742188\n",
      "    load_time_ms: 1.426\n",
      "    num_steps_sampled: 2171000\n",
      "    num_steps_trained: 2087500\n",
      "    sample_time_ms: 3886.705\n",
      "    update_time_ms: 4.408\n",
      "  iterations_since_restore: 835\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.38571428571429\n",
      "    ram_util_percent: 63.37142857142857\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.890945348357901\n",
      "    mean_inference_ms: 0.9340494142888819\n",
      "    mean_processing_ms: 0.6840946656045989\n",
      "  time_since_restore: 2825.579866886139\n",
      "  time_this_iter_s: 5.094759702682495\n",
      "  time_total_s: 2825.579866886139\n",
      "  timestamp: 1596124251\n",
      "  timesteps_since_restore: 2171000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2171000\n",
      "  training_iteration: 835\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2825 s, 835 iter, 2171000 ts, 560 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-50-56\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 563.0427639501148\n",
      "  episode_reward_min: 222.2270392332099\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 868\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 30.098\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.460601568222046\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.5689054382382892e-05\n",
      "        policy_loss: 0.008155649527907372\n",
      "        total_loss: 61.02948760986328\n",
      "        vf_explained_var: 0.010814964771270752\n",
      "        vf_loss: 61.02132034301758\n",
      "    load_time_ms: 1.484\n",
      "    num_steps_sampled: 2173600\n",
      "    num_steps_trained: 2090000\n",
      "    sample_time_ms: 4088.94\n",
      "    update_time_ms: 4.64\n",
      "  iterations_since_restore: 836\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.6875\n",
      "    ram_util_percent: 63.3625\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.8901951748552825\n",
      "    mean_inference_ms: 0.933906972585939\n",
      "    mean_processing_ms: 0.6840576240974025\n",
      "  time_since_restore: 2831.3436629772186\n",
      "  time_this_iter_s: 5.763796091079712\n",
      "  time_total_s: 2831.3436629772186\n",
      "  timestamp: 1596124256\n",
      "  timesteps_since_restore: 2173600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2173600\n",
      "  training_iteration: 836\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2831 s, 836 iter, 2173600 ts, 563 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-51-05\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 564.5766272003219\n",
      "  episode_reward_min: 222.2270392332099\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 869\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 36.57\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4511501789093018\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.2453509599436074e-06\n",
      "        policy_loss: -0.0006100049358792603\n",
      "        total_loss: 45.111515045166016\n",
      "        vf_explained_var: 0.005077779293060303\n",
      "        vf_loss: 45.112125396728516\n",
      "    load_time_ms: 1.752\n",
      "    num_steps_sampled: 2178800\n",
      "    num_steps_trained: 2095000\n",
      "    sample_time_ms: 4429.634\n",
      "    update_time_ms: 5.103\n",
      "  iterations_since_restore: 838\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.42857142857143\n",
      "    ram_util_percent: 63.300000000000004\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.889788923569282\n",
      "    mean_inference_ms: 0.9337969827419278\n",
      "    mean_processing_ms: 0.6840286831070731\n",
      "  time_since_restore: 2840.2551305294037\n",
      "  time_this_iter_s: 4.989543437957764\n",
      "  time_total_s: 2840.2551305294037\n",
      "  timestamp: 1596124265\n",
      "  timesteps_since_restore: 2178800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2178800\n",
      "  training_iteration: 838\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2840 s, 838 iter, 2178800 ts, 565 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-51-11\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 561.135611279282\n",
      "  episode_reward_min: 222.2270392332099\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 870\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 41.664\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4651429653167725\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.6237779315561056e-05\n",
      "        policy_loss: -0.0017605869797989726\n",
      "        total_loss: 55.04177474975586\n",
      "        vf_explained_var: 0.003731846809387207\n",
      "        vf_loss: 55.043548583984375\n",
      "    load_time_ms: 1.965\n",
      "    num_steps_sampled: 2181400\n",
      "    num_steps_trained: 2097500\n",
      "    sample_time_ms: 4743.349\n",
      "    update_time_ms: 5.886\n",
      "  iterations_since_restore: 839\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.92222222222223\n",
      "    ram_util_percent: 63.29999999999999\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.889453730327649\n",
      "    mean_inference_ms: 0.9336961204454588\n",
      "    mean_processing_ms: 0.6840064182597281\n",
      "  time_since_restore: 2846.1920716762543\n",
      "  time_this_iter_s: 5.936941146850586\n",
      "  time_total_s: 2846.1920716762543\n",
      "  timestamp: 1596124271\n",
      "  timesteps_since_restore: 2181400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2181400\n",
      "  training_iteration: 839\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2846 s, 839 iter, 2181400 ts, 561 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-51-17\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 565.2775625849129\n",
      "  episode_reward_min: 222.2270392332099\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 871\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 46.665\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4723131656646729\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.8788885427056812e-05\n",
      "        policy_loss: -0.0027995810378342867\n",
      "        total_loss: 66.2655029296875\n",
      "        vf_explained_var: 0.006810903549194336\n",
      "        vf_loss: 66.26830291748047\n",
      "    load_time_ms: 2.161\n",
      "    num_steps_sampled: 2184000\n",
      "    num_steps_trained: 2100000\n",
      "    sample_time_ms: 4879.419\n",
      "    update_time_ms: 6.725\n",
      "  iterations_since_restore: 840\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 51.942857142857136\n",
      "    ram_util_percent: 63.300000000000004\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.889010683437603\n",
      "    mean_inference_ms: 0.9335068384835433\n",
      "    mean_processing_ms: 0.6839584045465766\n",
      "  time_since_restore: 2851.6030378341675\n",
      "  time_this_iter_s: 5.410966157913208\n",
      "  time_total_s: 2851.6030378341675\n",
      "  timestamp: 1596124277\n",
      "  timesteps_since_restore: 2184000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2184000\n",
      "  training_iteration: 840\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2851 s, 840 iter, 2184000 ts, 565 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-51-23\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 564.413696458497\n",
      "  episode_reward_min: 222.2270392332099\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 873\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 46.872\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4585931301116943\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.6143322056905163e-07\n",
      "        policy_loss: -0.0006039076833985746\n",
      "        total_loss: 31.21372413635254\n",
      "        vf_explained_var: 0.009898483753204346\n",
      "        vf_loss: 31.214330673217773\n",
      "    load_time_ms: 2.191\n",
      "    num_steps_sampled: 2186600\n",
      "    num_steps_trained: 2102500\n",
      "    sample_time_ms: 5131.213\n",
      "    update_time_ms: 7.715\n",
      "  iterations_since_restore: 841\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.922222222222224\n",
      "    ram_util_percent: 63.29999999999999\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.888490920758323\n",
      "    mean_inference_ms: 0.933461965072358\n",
      "    mean_processing_ms: 0.6839649264538743\n",
      "  time_since_restore: 2857.8884973526\n",
      "  time_this_iter_s: 6.285459518432617\n",
      "  time_total_s: 2857.8884973526\n",
      "  timestamp: 1596124283\n",
      "  timesteps_since_restore: 2186600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2186600\n",
      "  training_iteration: 841\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2857 s, 841 iter, 2186600 ts, 564 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-51-33\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 565.8603601907477\n",
      "  episode_reward_min: 222.2270392332099\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 874\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 42.396\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4587286710739136\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.164550541143399e-07\n",
      "        policy_loss: 0.0007630899199284613\n",
      "        total_loss: 37.574302673339844\n",
      "        vf_explained_var: 0.008974254131317139\n",
      "        vf_loss: 37.57353591918945\n",
      "    load_time_ms: 2.038\n",
      "    num_steps_sampled: 2191800\n",
      "    num_steps_trained: 2107500\n",
      "    sample_time_ms: 5179.998\n",
      "    update_time_ms: 7.898\n",
      "  iterations_since_restore: 843\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.614285714285714\n",
      "    ram_util_percent: 63.300000000000004\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.8882899178145105\n",
      "    mean_inference_ms: 0.9333493756235819\n",
      "    mean_processing_ms: 0.6839244873483341\n",
      "  time_since_restore: 2867.5108947753906\n",
      "  time_this_iter_s: 5.074048280715942\n",
      "  time_total_s: 2867.5108947753906\n",
      "  timestamp: 1596124293\n",
      "  timesteps_since_restore: 2191800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2191800\n",
      "  training_iteration: 843\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2867 s, 843 iter, 2191800 ts, 566 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-51-42\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 567.9446775598823\n",
      "  episode_reward_min: 222.2270392332099\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 875\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 44.369\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.473791241645813\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.48999492416624e-06\n",
      "        policy_loss: 0.0008540124981664121\n",
      "        total_loss: 67.9911117553711\n",
      "        vf_explained_var: 0.0012922883033752441\n",
      "        vf_loss: 67.99027252197266\n",
      "    load_time_ms: 2.111\n",
      "    num_steps_sampled: 2197000\n",
      "    num_steps_trained: 2112500\n",
      "    sample_time_ms: 5007.174\n",
      "    update_time_ms: 7.305\n",
      "  iterations_since_restore: 845\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.65714285714286\n",
      "    ram_util_percent: 63.300000000000004\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.888120527233752\n",
      "    mean_inference_ms: 0.9332835833073335\n",
      "    mean_processing_ms: 0.6839068353252693\n",
      "  time_since_restore: 2876.322585582733\n",
      "  time_this_iter_s: 4.824071407318115\n",
      "  time_total_s: 2876.322585582733\n",
      "  timestamp: 1596124302\n",
      "  timesteps_since_restore: 2197000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2197000\n",
      "  training_iteration: 845\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2876 s, 845 iter, 2197000 ts, 568 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-51-48\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 571.0999141706243\n",
      "  episode_reward_min: 222.2270392332099\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 879\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 49.968\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4690197706222534\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.90062143146497e-07\n",
      "        policy_loss: -0.001691775512881577\n",
      "        total_loss: 48.43449401855469\n",
      "        vf_explained_var: 0.01135265827178955\n",
      "        vf_loss: 48.43619155883789\n",
      "    load_time_ms: 2.322\n",
      "    num_steps_sampled: 2199600\n",
      "    num_steps_trained: 2115000\n",
      "    sample_time_ms: 5040.743\n",
      "    update_time_ms: 7.892\n",
      "  iterations_since_restore: 846\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.337500000000006\n",
      "    ram_util_percent: 63.3375\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.8875377108224374\n",
      "    mean_inference_ms: 0.9330664841409344\n",
      "    mean_processing_ms: 0.6838592161070517\n",
      "  time_since_restore: 2882.502744913101\n",
      "  time_this_iter_s: 6.180159330368042\n",
      "  time_total_s: 2882.502744913101\n",
      "  timestamp: 1596124308\n",
      "  timesteps_since_restore: 2199600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2199600\n",
      "  training_iteration: 846\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2882 s, 846 iter, 2199600 ts, 571 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-51-57\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 566.7834691636085\n",
      "  episode_reward_min: 222.2270392332099\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 880\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 46.33\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4566576480865479\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.1217593964829575e-07\n",
      "        policy_loss: 0.0009788143215700984\n",
      "        total_loss: 37.5128288269043\n",
      "        vf_explained_var: 0.007472813129425049\n",
      "        vf_loss: 37.51184844970703\n",
      "    load_time_ms: 2.137\n",
      "    num_steps_sampled: 2204800\n",
      "    num_steps_trained: 2120000\n",
      "    sample_time_ms: 5106.453\n",
      "    update_time_ms: 9.122\n",
      "  iterations_since_restore: 848\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 66.12857142857143\n",
      "    ram_util_percent: 63.58571428571428\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.887501336726359\n",
      "    mean_inference_ms: 0.9330308931874276\n",
      "    mean_processing_ms: 0.683855030996581\n",
      "  time_since_restore: 2892.040303468704\n",
      "  time_this_iter_s: 4.6778929233551025\n",
      "  time_total_s: 2892.040303468704\n",
      "  timestamp: 1596124317\n",
      "  timesteps_since_restore: 2204800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2204800\n",
      "  training_iteration: 848\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2892 s, 848 iter, 2204800 ts, 567 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-52-02\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 566.7834691636084\n",
      "  episode_reward_min: 222.2270392332099\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 880\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 42.627\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.455756425857544\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.615379284838127e-07\n",
      "        policy_loss: 0.006727034226059914\n",
      "        total_loss: 32.623146057128906\n",
      "        vf_explained_var: 0.01168733835220337\n",
      "        vf_loss: 32.61641311645508\n",
      "    load_time_ms: 1.966\n",
      "    num_steps_sampled: 2207400\n",
      "    num_steps_trained: 2122500\n",
      "    sample_time_ms: 5017.297\n",
      "    update_time_ms: 9.115\n",
      "  iterations_since_restore: 849\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.11428571428571\n",
      "    ram_util_percent: 63.75714285714286\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.887501336726359\n",
      "    mean_inference_ms: 0.9330308931874278\n",
      "    mean_processing_ms: 0.6838550309965811\n",
      "  time_since_restore: 2897.0417354106903\n",
      "  time_this_iter_s: 5.001431941986084\n",
      "  time_total_s: 2897.0417354106903\n",
      "  timestamp: 1596124322\n",
      "  timesteps_since_restore: 2207400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2207400\n",
      "  training_iteration: 849\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2897 s, 849 iter, 2207400 ts, 567 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-52-13\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 559.3348442519552\n",
      "  episode_reward_min: 222.2270392332099\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 883\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 42.67\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4671591520309448\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.0397652608371573e-06\n",
      "        policy_loss: -0.001391204888932407\n",
      "        total_loss: 52.39551544189453\n",
      "        vf_explained_var: 0.010530710220336914\n",
      "        vf_loss: 52.396907806396484\n",
      "    load_time_ms: 1.971\n",
      "    num_steps_sampled: 2212600\n",
      "    num_steps_trained: 2127500\n",
      "    sample_time_ms: 4915.359\n",
      "    update_time_ms: 8.927\n",
      "  iterations_since_restore: 851\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.32222222222222\n",
      "    ram_util_percent: 63.55555555555556\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.8876343116720853\n",
      "    mean_inference_ms: 0.9330442949607288\n",
      "    mean_processing_ms: 0.6838668046118944\n",
      "  time_since_restore: 2907.7146480083466\n",
      "  time_this_iter_s: 5.931538820266724\n",
      "  time_total_s: 2907.7146480083466\n",
      "  timestamp: 1596124333\n",
      "  timesteps_since_restore: 2212600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2212600\n",
      "  training_iteration: 851\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2907 s, 851 iter, 2212600 ts, 559 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-52-22\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 556.3924004983744\n",
      "  episode_reward_min: 222.2270392332099\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 885\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 44.998\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4612616300582886\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.646706656785682e-06\n",
      "        policy_loss: 0.004016960505396128\n",
      "        total_loss: 49.03915023803711\n",
      "        vf_explained_var: 0.005993545055389404\n",
      "        vf_loss: 49.03512954711914\n",
      "    load_time_ms: 2.026\n",
      "    num_steps_sampled: 2217800\n",
      "    num_steps_trained: 2132500\n",
      "    sample_time_ms: 4869.206\n",
      "    update_time_ms: 9.816\n",
      "  iterations_since_restore: 853\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.05\n",
      "    ram_util_percent: 63.587500000000006\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.887696077325535\n",
      "    mean_inference_ms: 0.9329605242152514\n",
      "    mean_processing_ms: 0.6838504653035844\n",
      "  time_since_restore: 2916.929121017456\n",
      "  time_this_iter_s: 5.070305585861206\n",
      "  time_total_s: 2916.929121017456\n",
      "  timestamp: 1596124342\n",
      "  timesteps_since_restore: 2217800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2217800\n",
      "  training_iteration: 853\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2916 s, 853 iter, 2217800 ts, 556 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-52-33\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 548.9112757095456\n",
      "  episode_reward_min: 222.2270392332099\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 887\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 44.653\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4733690023422241\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.2301196622720454e-06\n",
      "        policy_loss: -0.008567067794501781\n",
      "        total_loss: 58.66999816894531\n",
      "        vf_explained_var: 0.004027962684631348\n",
      "        vf_loss: 58.67858123779297\n",
      "    load_time_ms: 1.999\n",
      "    num_steps_sampled: 2223000\n",
      "    num_steps_trained: 2137500\n",
      "    sample_time_ms: 5064.166\n",
      "    update_time_ms: 10.911\n",
      "  iterations_since_restore: 855\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.31250000000001\n",
      "    ram_util_percent: 63.525\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.887815736109605\n",
      "    mean_inference_ms: 0.9329224925166575\n",
      "    mean_processing_ms: 0.6838625446163882\n",
      "  time_since_restore: 2927.6984181404114\n",
      "  time_this_iter_s: 5.858351469039917\n",
      "  time_total_s: 2927.6984181404114\n",
      "  timestamp: 1596124353\n",
      "  timesteps_since_restore: 2223000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2223000\n",
      "  training_iteration: 855\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2927 s, 855 iter, 2223000 ts, 549 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-52-42\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 553.5684202140312\n",
      "  episode_reward_min: 222.2270392332099\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 889\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 42.841\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4531586170196533\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.8658847617844e-07\n",
      "        policy_loss: 0.0009673611493781209\n",
      "        total_loss: 24.354280471801758\n",
      "        vf_explained_var: 0.010990142822265625\n",
      "        vf_loss: 24.353313446044922\n",
      "    load_time_ms: 1.89\n",
      "    num_steps_sampled: 2228200\n",
      "    num_steps_trained: 2142500\n",
      "    sample_time_ms: 4837.642\n",
      "    update_time_ms: 9.819\n",
      "  iterations_since_restore: 857\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.60000000000001\n",
      "    ram_util_percent: 63.67142857142857\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.8883060184422247\n",
      "    mean_inference_ms: 0.9330070276939973\n",
      "    mean_processing_ms: 0.6838818386157187\n",
      "  time_since_restore: 2936.4424118995667\n",
      "  time_this_iter_s: 4.454527854919434\n",
      "  time_total_s: 2936.4424118995667\n",
      "  timestamp: 1596124362\n",
      "  timesteps_since_restore: 2228200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2228200\n",
      "  training_iteration: 857\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2936 s, 857 iter, 2228200 ts, 554 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-52-51\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1092.076866493051\n",
      "  episode_reward_mean: 549.3277428232687\n",
      "  episode_reward_min: 222.2270392332099\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 890\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 47.662\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4539881944656372\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.296924549227697e-06\n",
      "        policy_loss: 0.0011316920863464475\n",
      "        total_loss: 17.786306381225586\n",
      "        vf_explained_var: 0.017840683460235596\n",
      "        vf_loss: 17.78517723083496\n",
      "    load_time_ms: 2.096\n",
      "    num_steps_sampled: 2233400\n",
      "    num_steps_trained: 2147500\n",
      "    sample_time_ms: 4736.421\n",
      "    update_time_ms: 10.501\n",
      "  iterations_since_restore: 859\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.21666666666667\n",
      "    ram_util_percent: 63.6\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.888591807222864\n",
      "    mean_inference_ms: 0.9330437429719711\n",
      "    mean_processing_ms: 0.6838958365977079\n",
      "  time_since_restore: 2945.174917936325\n",
      "  time_this_iter_s: 4.428287982940674\n",
      "  time_total_s: 2945.174917936325\n",
      "  timestamp: 1596124371\n",
      "  timesteps_since_restore: 2233400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2233400\n",
      "  training_iteration: 859\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2945 s, 859 iter, 2233400 ts, 549 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-52-59\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.42198971329\n",
      "  episode_reward_mean: 538.2794185577345\n",
      "  episode_reward_min: 222.2270392332099\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 894\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 45.378\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4468286037445068\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.137920311426569e-09\n",
      "        policy_loss: 0.0028575987089425325\n",
      "        total_loss: 15.341838836669922\n",
      "        vf_explained_var: 0.0022229552268981934\n",
      "        vf_loss: 15.338979721069336\n",
      "    load_time_ms: 1.878\n",
      "    num_steps_sampled: 2238600\n",
      "    num_steps_trained: 2152500\n",
      "    sample_time_ms: 4525.862\n",
      "    update_time_ms: 9.734\n",
      "  iterations_since_restore: 861\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.17999999999999\n",
      "    ram_util_percent: 63.6\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.889678997058474\n",
      "    mean_inference_ms: 0.9331976260617855\n",
      "    mean_processing_ms: 0.683956851513941\n",
      "  time_since_restore: 2953.7085037231445\n",
      "  time_this_iter_s: 4.018597364425659\n",
      "  time_total_s: 2953.7085037231445\n",
      "  timestamp: 1596124379\n",
      "  timesteps_since_restore: 2238600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2238600\n",
      "  training_iteration: 861\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2953 s, 861 iter, 2238600 ts, 538 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-53-08\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.42198971329\n",
      "  episode_reward_mean: 531.2756328950354\n",
      "  episode_reward_min: 222.2270392332099\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 895\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 44.266\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4636235237121582\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.850791922057397e-07\n",
      "        policy_loss: -0.0013877321034669876\n",
      "        total_loss: 44.392189025878906\n",
      "        vf_explained_var: 0.006605982780456543\n",
      "        vf_loss: 44.393585205078125\n",
      "    load_time_ms: 1.889\n",
      "    num_steps_sampled: 2243800\n",
      "    num_steps_trained: 2157500\n",
      "    sample_time_ms: 4497.243\n",
      "    update_time_ms: 9.354\n",
      "  iterations_since_restore: 863\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.46666666666666\n",
      "    ram_util_percent: 63.583333333333336\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.890082657025002\n",
      "    mean_inference_ms: 0.9332611306132241\n",
      "    mean_processing_ms: 0.6839783771923126\n",
      "  time_since_restore: 2962.604697704315\n",
      "  time_this_iter_s: 4.555542230606079\n",
      "  time_total_s: 2962.604697704315\n",
      "  timestamp: 1596124388\n",
      "  timesteps_since_restore: 2243800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2243800\n",
      "  training_iteration: 863\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2962 s, 863 iter, 2243800 ts, 531 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-53-18\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.42198971329\n",
      "  episode_reward_mean: 527.7839410557298\n",
      "  episode_reward_min: 222.2270392332099\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 898\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 49.442\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.465262532234192\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.4844408130775264e-07\n",
      "        policy_loss: 0.011346966959536076\n",
      "        total_loss: 39.35573196411133\n",
      "        vf_explained_var: 0.006247818470001221\n",
      "        vf_loss: 39.344390869140625\n",
      "    load_time_ms: 2.002\n",
      "    num_steps_sampled: 2249000\n",
      "    num_steps_trained: 2162500\n",
      "    sample_time_ms: 4426.565\n",
      "    update_time_ms: 9.865\n",
      "  iterations_since_restore: 865\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.0\n",
      "    ram_util_percent: 63.6\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.891158571729789\n",
      "    mean_inference_ms: 0.9333656379414492\n",
      "    mean_processing_ms: 0.6840265684616729\n",
      "  time_since_restore: 2972.744631052017\n",
      "  time_this_iter_s: 5.621668100357056\n",
      "  time_total_s: 2972.744631052017\n",
      "  timestamp: 1596124398\n",
      "  timesteps_since_restore: 2249000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2249000\n",
      "  training_iteration: 865\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2972 s, 865 iter, 2249000 ts, 528 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-53-27\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.42198971329\n",
      "  episode_reward_mean: 528.1121892500933\n",
      "  episode_reward_min: 222.2270392332099\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 899\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 45.568\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4675549268722534\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.127524557086872e-06\n",
      "        policy_loss: 0.0033746291883289814\n",
      "        total_loss: 70.43634033203125\n",
      "        vf_explained_var: 0.006530404090881348\n",
      "        vf_loss: 70.43295288085938\n",
      "    load_time_ms: 1.917\n",
      "    num_steps_sampled: 2254200\n",
      "    num_steps_trained: 2167500\n",
      "    sample_time_ms: 4426.138\n",
      "    update_time_ms: 9.759\n",
      "  iterations_since_restore: 867\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.63333333333333\n",
      "    ram_util_percent: 63.583333333333336\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.891645407672789\n",
      "    mean_inference_ms: 0.9335195337341046\n",
      "    mean_processing_ms: 0.6840719043904244\n",
      "  time_since_restore: 2981.4270765781403\n",
      "  time_this_iter_s: 4.4183032512664795\n",
      "  time_total_s: 2981.4270765781403\n",
      "  timestamp: 1596124407\n",
      "  timesteps_since_restore: 2254200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2254200\n",
      "  training_iteration: 867\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2981 s, 867 iter, 2254200 ts, 528 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-53-36\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.42198971329\n",
      "  episode_reward_mean: 529.0997429798966\n",
      "  episode_reward_min: 222.2270392332099\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 900\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 43.479\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4796706438064575\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.0391139767307322e-05\n",
      "        policy_loss: -0.002339128404855728\n",
      "        total_loss: 73.27437591552734\n",
      "        vf_explained_var: 0.008684396743774414\n",
      "        vf_loss: 73.27671813964844\n",
      "    load_time_ms: 1.826\n",
      "    num_steps_sampled: 2259400\n",
      "    num_steps_trained: 2172500\n",
      "    sample_time_ms: 4469.187\n",
      "    update_time_ms: 8.753\n",
      "  iterations_since_restore: 869\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.24285714285714\n",
      "    ram_util_percent: 63.60000000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.892165670016177\n",
      "    mean_inference_ms: 0.9336093431920014\n",
      "    mean_processing_ms: 0.6841029407537863\n",
      "  time_since_restore: 2990.547303915024\n",
      "  time_this_iter_s: 4.661897659301758\n",
      "  time_total_s: 2990.547303915024\n",
      "  timestamp: 1596124416\n",
      "  timesteps_since_restore: 2259400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2259400\n",
      "  training_iteration: 869\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2990 s, 869 iter, 2259400 ts, 529 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-53-42\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 526.6099428735156\n",
      "  episode_reward_min: 222.2270392332099\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 904\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 44.052\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4641244411468506\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.465293841349194e-06\n",
      "        policy_loss: -0.0020866040140390396\n",
      "        total_loss: 29.703805923461914\n",
      "        vf_explained_var: 0.009414315223693848\n",
      "        vf_loss: 29.705894470214844\n",
      "    load_time_ms: 1.844\n",
      "    num_steps_sampled: 2262000\n",
      "    num_steps_trained: 2175000\n",
      "    sample_time_ms: 4561.98\n",
      "    update_time_ms: 8.902\n",
      "  iterations_since_restore: 870\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.5375\n",
      "    ram_util_percent: 63.650000000000006\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.8942172189323196\n",
      "    mean_inference_ms: 0.9339726677268879\n",
      "    mean_processing_ms: 0.6842232696494652\n",
      "  time_since_restore: 2995.999763727188\n",
      "  time_this_iter_s: 5.452459812164307\n",
      "  time_total_s: 2995.999763727188\n",
      "  timestamp: 1596124422\n",
      "  timesteps_since_restore: 2262000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2262000\n",
      "  training_iteration: 870\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 2995 s, 870 iter, 2262000 ts, 527 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-53-50\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 526.6099428735156\n",
      "  episode_reward_min: 222.2270392332099\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 904\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 47.526\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4708131551742554\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.269810678029899e-06\n",
      "        policy_loss: -0.0010203694691881537\n",
      "        total_loss: 56.903743743896484\n",
      "        vf_explained_var: 0.0026854872703552246\n",
      "        vf_loss: 56.90476989746094\n",
      "    load_time_ms: 2.034\n",
      "    num_steps_sampled: 2267200\n",
      "    num_steps_trained: 2180000\n",
      "    sample_time_ms: 4592.21\n",
      "    update_time_ms: 8.847\n",
      "  iterations_since_restore: 872\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.81666666666667\n",
      "    ram_util_percent: 63.583333333333336\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.8942172189323196\n",
      "    mean_inference_ms: 0.9339726677268878\n",
      "    mean_processing_ms: 0.6842232696494651\n",
      "  time_since_restore: 3004.7114231586456\n",
      "  time_this_iter_s: 4.74382472038269\n",
      "  time_total_s: 3004.7114231586456\n",
      "  timestamp: 1596124430\n",
      "  timesteps_since_restore: 2267200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2267200\n",
      "  training_iteration: 872\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3004 s, 872 iter, 2267200 ts, 527 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-54-00\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 524.9862342344834\n",
      "  episode_reward_min: 222.2270392332099\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 906\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 44.44\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4812393188476562\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.968404709870811e-07\n",
      "        policy_loss: 0.002182157477363944\n",
      "        total_loss: 59.377655029296875\n",
      "        vf_explained_var: 0.007233917713165283\n",
      "        vf_loss: 59.375457763671875\n",
      "    load_time_ms: 1.975\n",
      "    num_steps_sampled: 2272400\n",
      "    num_steps_trained: 2185000\n",
      "    sample_time_ms: 4621.842\n",
      "    update_time_ms: 9.327\n",
      "  iterations_since_restore: 874\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.3142857142857\n",
      "    ram_util_percent: 63.6857142857143\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.895459752441098\n",
      "    mean_inference_ms: 0.9342461873708102\n",
      "    mean_processing_ms: 0.6843233156505804\n",
      "  time_since_restore: 3014.048945426941\n",
      "  time_this_iter_s: 4.716969728469849\n",
      "  time_total_s: 3014.048945426941\n",
      "  timestamp: 1596124440\n",
      "  timesteps_since_restore: 2272400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2272400\n",
      "  training_iteration: 874\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3014 s, 874 iter, 2272400 ts, 525 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-54-06\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 529.2374120708265\n",
      "  episode_reward_min: 222.2270392332099\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 909\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 41.994\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4650911092758179\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.6678781018272275e-07\n",
      "        policy_loss: 0.0022952654398977757\n",
      "        total_loss: 34.906917572021484\n",
      "        vf_explained_var: 0.008041739463806152\n",
      "        vf_loss: 34.90462875366211\n",
      "    load_time_ms: 1.928\n",
      "    num_steps_sampled: 2275000\n",
      "    num_steps_trained: 2187500\n",
      "    sample_time_ms: 4650.52\n",
      "    update_time_ms: 9.203\n",
      "  iterations_since_restore: 875\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.9375\n",
      "    ram_util_percent: 63.5875\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.8974410700655517\n",
      "    mean_inference_ms: 0.9345715140863411\n",
      "    mean_processing_ms: 0.6844230218858373\n",
      "  time_since_restore: 3019.9250178337097\n",
      "  time_this_iter_s: 5.876072406768799\n",
      "  time_total_s: 3019.9250178337097\n",
      "  timestamp: 1596124446\n",
      "  timesteps_since_restore: 2275000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2275000\n",
      "  training_iteration: 875\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3019 s, 875 iter, 2275000 ts, 529 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-54-15\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 529.2374120708265\n",
      "  episode_reward_min: 222.2270392332099\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 909\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 45.304\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.468703031539917\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.098343081044732e-07\n",
      "        policy_loss: 0.0005962926661595702\n",
      "        total_loss: 51.158485412597656\n",
      "        vf_explained_var: 0.006312251091003418\n",
      "        vf_loss: 51.15789794921875\n",
      "    load_time_ms: 2.034\n",
      "    num_steps_sampled: 2280200\n",
      "    num_steps_trained: 2192500\n",
      "    sample_time_ms: 4700.004\n",
      "    update_time_ms: 9.346\n",
      "  iterations_since_restore: 877\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.25\n",
      "    ram_util_percent: 63.6\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.8974410700655513\n",
      "    mean_inference_ms: 0.9345715140863411\n",
      "    mean_processing_ms: 0.6844230218858371\n",
      "  time_since_restore: 3029.149129629135\n",
      "  time_this_iter_s: 4.6029298305511475\n",
      "  time_total_s: 3029.149129629135\n",
      "  timestamp: 1596124455\n",
      "  timesteps_since_restore: 2280200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2280200\n",
      "  training_iteration: 877\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3029 s, 877 iter, 2280200 ts, 529 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-54-25\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 530.0772176347234\n",
      "  episode_reward_min: 222.2270392332099\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 912\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 51.753\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4754633903503418\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 7.995176019903738e-06\n",
      "        policy_loss: -0.0031093128491193056\n",
      "        total_loss: 51.09224319458008\n",
      "        vf_explained_var: 0.009712159633636475\n",
      "        vf_loss: 51.09535217285156\n",
      "    load_time_ms: 2.192\n",
      "    num_steps_sampled: 2285400\n",
      "    num_steps_trained: 2197500\n",
      "    sample_time_ms: 4752.545\n",
      "    update_time_ms: 9.963\n",
      "  iterations_since_restore: 879\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.275\n",
      "    ram_util_percent: 63.575\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.899827025863213\n",
      "    mean_inference_ms: 0.9351457337592788\n",
      "    mean_processing_ms: 0.6846173957538011\n",
      "  time_since_restore: 3038.890904903412\n",
      "  time_this_iter_s: 5.616330146789551\n",
      "  time_total_s: 3038.890904903412\n",
      "  timestamp: 1596124465\n",
      "  timesteps_since_restore: 2285400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2285400\n",
      "  training_iteration: 879\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3038 s, 879 iter, 2285400 ts, 530 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-54-33\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 535.6642639999028\n",
      "  episode_reward_min: 222.2270392332099\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 914\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 52.584\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4509057998657227\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.062273097180878e-06\n",
      "        policy_loss: -0.0023676911368966103\n",
      "        total_loss: 23.3753719329834\n",
      "        vf_explained_var: 0.008588194847106934\n",
      "        vf_loss: 23.37773895263672\n",
      "    load_time_ms: 2.325\n",
      "    num_steps_sampled: 2290600\n",
      "    num_steps_trained: 2202500\n",
      "    sample_time_ms: 4657.113\n",
      "    update_time_ms: 10.487\n",
      "  iterations_since_restore: 881\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.75000000000001\n",
      "    ram_util_percent: 63.599999999999994\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9012936484892093\n",
      "    mean_inference_ms: 0.9353112525336859\n",
      "    mean_processing_ms: 0.6846634049734945\n",
      "  time_since_restore: 3047.369647026062\n",
      "  time_this_iter_s: 4.329997777938843\n",
      "  time_total_s: 3047.369647026062\n",
      "  timestamp: 1596124473\n",
      "  timesteps_since_restore: 2290600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2290600\n",
      "  training_iteration: 881\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3047 s, 881 iter, 2290600 ts, 536 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-54-42\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 535.0497073120238\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 915\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 49.062\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.475329875946045\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 7.710576142017089e-07\n",
      "        policy_loss: -0.0070840646512806416\n",
      "        total_loss: 55.29148864746094\n",
      "        vf_explained_var: 0.0052032470703125\n",
      "        vf_loss: 55.29857635498047\n",
      "    load_time_ms: 2.1\n",
      "    num_steps_sampled: 2295800\n",
      "    num_steps_trained: 2207500\n",
      "    sample_time_ms: 4637.371\n",
      "    update_time_ms: 10.382\n",
      "  iterations_since_restore: 883\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 68.88333333333334\n",
      "    ram_util_percent: 63.6\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.902210726854563\n",
      "    mean_inference_ms: 0.935490561149267\n",
      "    mean_processing_ms: 0.6847178715419439\n",
      "  time_since_restore: 3056.5023369789124\n",
      "  time_this_iter_s: 4.740746021270752\n",
      "  time_total_s: 3056.5023369789124\n",
      "  timestamp: 1596124482\n",
      "  timesteps_since_restore: 2295800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2295800\n",
      "  training_iteration: 883\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3056 s, 883 iter, 2295800 ts, 535 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-54-48\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 536.8379051806374\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 918\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 48.922\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4706848859786987\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.856513780599926e-07\n",
      "        policy_loss: 0.0031096478924155235\n",
      "        total_loss: 46.9434928894043\n",
      "        vf_explained_var: 0.008879601955413818\n",
      "        vf_loss: 46.94038009643555\n",
      "    load_time_ms: 2.069\n",
      "    num_steps_sampled: 2298400\n",
      "    num_steps_trained: 2210000\n",
      "    sample_time_ms: 4724.975\n",
      "    update_time_ms: 10.706\n",
      "  iterations_since_restore: 884\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.037499999999994\n",
      "    ram_util_percent: 63.6\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9050388524270563\n",
      "    mean_inference_ms: 0.9361173708718095\n",
      "    mean_processing_ms: 0.6849152248388283\n",
      "  time_since_restore: 3062.0913684368134\n",
      "  time_this_iter_s: 5.589031457901001\n",
      "  time_total_s: 3062.0913684368134\n",
      "  timestamp: 1596124488\n",
      "  timesteps_since_restore: 2298400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2298400\n",
      "  training_iteration: 884\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3062 s, 884 iter, 2298400 ts, 537 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-54-57\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 540.7114250731429\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 919\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 48.549\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4545376300811768\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.148100055725081e-07\n",
      "        policy_loss: -0.0027814763598144054\n",
      "        total_loss: 28.604578018188477\n",
      "        vf_explained_var: 0.009431540966033936\n",
      "        vf_loss: 28.607358932495117\n",
      "    load_time_ms: 2.025\n",
      "    num_steps_sampled: 2303600\n",
      "    num_steps_trained: 2215000\n",
      "    sample_time_ms: 4557.857\n",
      "    update_time_ms: 11.15\n",
      "  iterations_since_restore: 886\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.8\n",
      "    ram_util_percent: 63.5\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.905771478971955\n",
      "    mean_inference_ms: 0.9361891464539183\n",
      "    mean_processing_ms: 0.6849415359908834\n",
      "  time_since_restore: 3070.916713953018\n",
      "  time_this_iter_s: 4.790472507476807\n",
      "  time_total_s: 3070.916713953018\n",
      "  timestamp: 1596124497\n",
      "  timesteps_since_restore: 2303600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2303600\n",
      "  training_iteration: 886\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3070 s, 886 iter, 2303600 ts, 541 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-55-08\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 538.3490160287397\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 921\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 54.597\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.467527985572815\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.755662755291269e-07\n",
      "        policy_loss: -0.0020711056422442198\n",
      "        total_loss: 32.97560119628906\n",
      "        vf_explained_var: 0.003885626792907715\n",
      "        vf_loss: 32.97766876220703\n",
      "    load_time_ms: 2.199\n",
      "    num_steps_sampled: 2308800\n",
      "    num_steps_trained: 2220000\n",
      "    sample_time_ms: 4755.248\n",
      "    update_time_ms: 11.52\n",
      "  iterations_since_restore: 888\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.225\n",
      "    ram_util_percent: 63.5\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.907928693780327\n",
      "    mean_inference_ms: 0.936688029099308\n",
      "    mean_processing_ms: 0.6850970524996568\n",
      "  time_since_restore: 3081.7114074230194\n",
      "  time_this_iter_s: 5.997619390487671\n",
      "  time_total_s: 3081.7114074230194\n",
      "  timestamp: 1596124508\n",
      "  timesteps_since_restore: 2308800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2308800\n",
      "  training_iteration: 888\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3081 s, 888 iter, 2308800 ts, 538 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-55-14\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 531.6034682654843\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 923\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 52.717\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4624446630477905\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.067089077684159e-08\n",
      "        policy_loss: -0.007774475030601025\n",
      "        total_loss: 37.33987045288086\n",
      "        vf_explained_var: 0.006065309047698975\n",
      "        vf_loss: 37.3476448059082\n",
      "    load_time_ms: 2.129\n",
      "    num_steps_sampled: 2311400\n",
      "    num_steps_trained: 2222500\n",
      "    sample_time_ms: 4793.844\n",
      "    update_time_ms: 11.678\n",
      "  iterations_since_restore: 889\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.95555555555555\n",
      "    ram_util_percent: 63.5\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9100124537197947\n",
      "    mean_inference_ms: 0.9371524126057054\n",
      "    mean_processing_ms: 0.6852518627450382\n",
      "  time_since_restore: 3087.6907966136932\n",
      "  time_this_iter_s: 5.979389190673828\n",
      "  time_total_s: 3087.6907966136932\n",
      "  timestamp: 1596124514\n",
      "  timesteps_since_restore: 2311400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2311400\n",
      "  training_iteration: 889\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3087 s, 889 iter, 2311400 ts, 532 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-55-23\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 531.1426095988951\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 924\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 58.782\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4680075645446777\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.424427283491241e-07\n",
      "        policy_loss: -0.000963442784268409\n",
      "        total_loss: 69.65531921386719\n",
      "        vf_explained_var: 0.007185995578765869\n",
      "        vf_loss: 69.65628051757812\n",
      "    load_time_ms: 2.288\n",
      "    num_steps_sampled: 2316600\n",
      "    num_steps_trained: 2227500\n",
      "    sample_time_ms: 4893.095\n",
      "    update_time_ms: 11.729\n",
      "  iterations_since_restore: 891\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.17142857142858\n",
      "    ram_util_percent: 63.5\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.911304953351614\n",
      "    mean_inference_ms: 0.9373287418558549\n",
      "    mean_processing_ms: 0.685327092950558\n",
      "  time_since_restore: 3097.2374403476715\n",
      "  time_this_iter_s: 4.885582208633423\n",
      "  time_total_s: 3097.2374403476715\n",
      "  timestamp: 1596124523\n",
      "  timesteps_since_restore: 2316600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2316600\n",
      "  training_iteration: 891\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3097 s, 891 iter, 2316600 ts, 531 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-55-28\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 531.1426095988951\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 924\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 61.2\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4835370779037476\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.366806031910528e-06\n",
      "        policy_loss: 0.0010580627713352442\n",
      "        total_loss: 83.79706573486328\n",
      "        vf_explained_var: 0.0019835829734802246\n",
      "        vf_loss: 83.79600524902344\n",
      "    load_time_ms: 2.41\n",
      "    num_steps_sampled: 2319200\n",
      "    num_steps_trained: 2230000\n",
      "    sample_time_ms: 4948.717\n",
      "    update_time_ms: 12.178\n",
      "  iterations_since_restore: 892\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.828571428571436\n",
      "    ram_util_percent: 63.57142857142858\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.911304953351614\n",
      "    mean_inference_ms: 0.9373287418558549\n",
      "    mean_processing_ms: 0.685327092950558\n",
      "  time_since_restore: 3102.2297551631927\n",
      "  time_this_iter_s: 4.99231481552124\n",
      "  time_total_s: 3102.2297551631927\n",
      "  timestamp: 1596124528\n",
      "  timesteps_since_restore: 2319200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2319200\n",
      "  training_iteration: 892\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3102 s, 892 iter, 2319200 ts, 531 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-55-39\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 535.8596441664117\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 929\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 67.154\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.45982825756073\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.0010480764321983e-06\n",
      "        policy_loss: -0.0065545798279345036\n",
      "        total_loss: 28.19582176208496\n",
      "        vf_explained_var: 0.00820225477218628\n",
      "        vf_loss: 28.202377319335938\n",
      "    load_time_ms: 2.543\n",
      "    num_steps_sampled: 2324400\n",
      "    num_steps_trained: 2235000\n",
      "    sample_time_ms: 4959.543\n",
      "    update_time_ms: 13.407\n",
      "  iterations_since_restore: 894\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.47777777777778\n",
      "    ram_util_percent: 63.588888888888896\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9171118166501784\n",
      "    mean_inference_ms: 0.9384964786092053\n",
      "    mean_processing_ms: 0.6856912040274853\n",
      "  time_since_restore: 3112.743213415146\n",
      "  time_this_iter_s: 6.0354533195495605\n",
      "  time_total_s: 3112.743213415146\n",
      "  timestamp: 1596124539\n",
      "  timesteps_since_restore: 2324400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2324400\n",
      "  training_iteration: 894\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3112 s, 894 iter, 2324400 ts, 536 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-55-48\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 535.8596441664117\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 929\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 66.243\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4570392370224\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.695032084280683e-07\n",
      "        policy_loss: 0.0007311344961635768\n",
      "        total_loss: 27.675203323364258\n",
      "        vf_explained_var: 0.009439706802368164\n",
      "        vf_loss: 27.674474716186523\n",
      "    load_time_ms: 2.437\n",
      "    num_steps_sampled: 2329600\n",
      "    num_steps_trained: 2240000\n",
      "    sample_time_ms: 4987.685\n",
      "    update_time_ms: 12.791\n",
      "  iterations_since_restore: 896\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.957142857142856\n",
      "    ram_util_percent: 63.685714285714276\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9171118166501775\n",
      "    mean_inference_ms: 0.9384964786092053\n",
      "    mean_processing_ms: 0.6856912040274851\n",
      "  time_since_restore: 3121.82972741127\n",
      "  time_this_iter_s: 5.117857456207275\n",
      "  time_total_s: 3121.82972741127\n",
      "  timestamp: 1596124548\n",
      "  timesteps_since_restore: 2329600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2329600\n",
      "  training_iteration: 896\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3121 s, 896 iter, 2329600 ts, 536 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-55-53\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 535.8596441664117\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 929\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 62.94\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.468640923500061\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.5140761863440275e-06\n",
      "        policy_loss: 0.0001272667432203889\n",
      "        total_loss: 42.96287155151367\n",
      "        vf_explained_var: 0.003629148006439209\n",
      "        vf_loss: 42.96274948120117\n",
      "    load_time_ms: 2.411\n",
      "    num_steps_sampled: 2332200\n",
      "    num_steps_trained: 2242500\n",
      "    sample_time_ms: 5031.13\n",
      "    update_time_ms: 13.264\n",
      "  iterations_since_restore: 897\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.25714285714285\n",
      "    ram_util_percent: 63.64285714285715\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9171118166501775\n",
      "    mean_inference_ms: 0.9384964786092053\n",
      "    mean_processing_ms: 0.6856912040274851\n",
      "  time_since_restore: 3127.0119655132294\n",
      "  time_this_iter_s: 5.1822381019592285\n",
      "  time_total_s: 3127.0119655132294\n",
      "  timestamp: 1596124553\n",
      "  timesteps_since_restore: 2332200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2332200\n",
      "  training_iteration: 897\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3127 s, 897 iter, 2332200 ts, 536 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-56-03\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 522.6561855060929\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 934\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 51.83\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4516164064407349\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.350994112835906e-07\n",
      "        policy_loss: -0.0052284961566329\n",
      "        total_loss: 17.029041290283203\n",
      "        vf_explained_var: 0.009936749935150146\n",
      "        vf_loss: 17.03427505493164\n",
      "    load_time_ms: 2.042\n",
      "    num_steps_sampled: 2337400\n",
      "    num_steps_trained: 2247500\n",
      "    sample_time_ms: 4828.445\n",
      "    update_time_ms: 12.307\n",
      "  iterations_since_restore: 899\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.87142857142857\n",
      "    ram_util_percent: 63.67142857142857\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9235601198823544\n",
      "    mean_inference_ms: 0.9398086260660286\n",
      "    mean_processing_ms: 0.6860891361695738\n",
      "  time_since_restore: 3136.8034212589264\n",
      "  time_this_iter_s: 5.4003143310546875\n",
      "  time_total_s: 3136.8034212589264\n",
      "  timestamp: 1596124563\n",
      "  timesteps_since_restore: 2337400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2337400\n",
      "  training_iteration: 899\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3136 s, 899 iter, 2337400 ts, 523 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-56-12\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 522.6561855060929\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 934\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 44.188\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4739221334457397\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.941701945426757e-07\n",
      "        policy_loss: -0.0037284314166754484\n",
      "        total_loss: 80.82422637939453\n",
      "        vf_explained_var: 0.000832676887512207\n",
      "        vf_loss: 80.82797241210938\n",
      "    load_time_ms: 1.758\n",
      "    num_steps_sampled: 2342600\n",
      "    num_steps_trained: 2252500\n",
      "    sample_time_ms: 4782.841\n",
      "    update_time_ms: 11.593\n",
      "  iterations_since_restore: 901\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.22857142857144\n",
      "    ram_util_percent: 63.64285714285715\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9235601198823544\n",
      "    mean_inference_ms: 0.9398086260660286\n",
      "    mean_processing_ms: 0.6860891361695739\n",
      "  time_since_restore: 3145.790197134018\n",
      "  time_this_iter_s: 4.733686923980713\n",
      "  time_total_s: 3145.790197134018\n",
      "  timestamp: 1596124572\n",
      "  timesteps_since_restore: 2342600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2342600\n",
      "  training_iteration: 901\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3145 s, 901 iter, 2342600 ts, 523 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-56-17\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 522.6561855060929\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 934\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 45.459\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.487586498260498\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.402160811878275e-06\n",
      "        policy_loss: -0.00012686531408689916\n",
      "        total_loss: 99.04553985595703\n",
      "        vf_explained_var: 0.0002987980842590332\n",
      "        vf_loss: 99.04568481445312\n",
      "    load_time_ms: 1.863\n",
      "    num_steps_sampled: 2345200\n",
      "    num_steps_trained: 2255000\n",
      "    sample_time_ms: 4795.536\n",
      "    update_time_ms: 10.757\n",
      "  iterations_since_restore: 902\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.3\n",
      "    ram_util_percent: 63.6\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9235601198823544\n",
      "    mean_inference_ms: 0.9398086260660286\n",
      "    mean_processing_ms: 0.6860891361695739\n",
      "  time_since_restore: 3150.9023702144623\n",
      "  time_this_iter_s: 5.112173080444336\n",
      "  time_total_s: 3150.9023702144623\n",
      "  timestamp: 1596124577\n",
      "  timesteps_since_restore: 2345200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2345200\n",
      "  training_iteration: 902\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3150 s, 902 iter, 2345200 ts, 523 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-56-23\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 519.2786988772277\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 937\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 45.557\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4853686094284058\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.662656333995983e-05\n",
      "        policy_loss: -0.0025638758670538664\n",
      "        total_loss: 92.18729400634766\n",
      "        vf_explained_var: 0.00586855411529541\n",
      "        vf_loss: 92.18986511230469\n",
      "    load_time_ms: 1.877\n",
      "    num_steps_sampled: 2347800\n",
      "    num_steps_trained: 2257500\n",
      "    sample_time_ms: 4925.799\n",
      "    update_time_ms: 9.626\n",
      "  iterations_since_restore: 903\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 52.724999999999994\n",
      "    ram_util_percent: 63.6\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.927475837762943\n",
      "    mean_inference_ms: 0.9406459616477001\n",
      "    mean_processing_ms: 0.6863217973578467\n",
      "  time_since_restore: 3156.6670095920563\n",
      "  time_this_iter_s: 5.764639377593994\n",
      "  time_total_s: 3156.6670095920563\n",
      "  timestamp: 1596124583\n",
      "  timesteps_since_restore: 2347800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2347800\n",
      "  training_iteration: 903\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3156 s, 903 iter, 2347800 ts, 519 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-56-32\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 518.6733480157235\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 939\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 40.784\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.448607087135315\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.6555996391361987e-07\n",
      "        policy_loss: 0.004155256785452366\n",
      "        total_loss: 24.44725227355957\n",
      "        vf_explained_var: 0.0074530839920043945\n",
      "        vf_loss: 24.443098068237305\n",
      "    load_time_ms: 1.862\n",
      "    num_steps_sampled: 2353000\n",
      "    num_steps_trained: 2262500\n",
      "    sample_time_ms: 4850.337\n",
      "    update_time_ms: 9.453\n",
      "  iterations_since_restore: 905\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.96666666666667\n",
      "    ram_util_percent: 63.68333333333333\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.930632884997758\n",
      "    mean_inference_ms: 0.9412608740166271\n",
      "    mean_processing_ms: 0.6865351139512369\n",
      "  time_since_restore: 3165.8667442798615\n",
      "  time_this_iter_s: 4.447790622711182\n",
      "  time_total_s: 3165.8667442798615\n",
      "  timestamp: 1596124592\n",
      "  timesteps_since_restore: 2353000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2353000\n",
      "  training_iteration: 905\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.6/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3165 s, 905 iter, 2353000 ts, 519 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-56-43\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 518.0972339506449\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 940\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 43.234\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4696643352508545\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.3312568941946665e-07\n",
      "        policy_loss: -0.0037052009720355272\n",
      "        total_loss: 43.32522201538086\n",
      "        vf_explained_var: 0.0016644001007080078\n",
      "        vf_loss: 43.328922271728516\n",
      "    load_time_ms: 1.998\n",
      "    num_steps_sampled: 2358200\n",
      "    num_steps_trained: 2267500\n",
      "    sample_time_ms: 4876.46\n",
      "    update_time_ms: 9.762\n",
      "  iterations_since_restore: 907\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.65555555555555\n",
      "    ram_util_percent: 63.800000000000004\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9317574067724843\n",
      "    mean_inference_ms: 0.9414589245718678\n",
      "    mean_processing_ms: 0.6865731153143072\n",
      "  time_since_restore: 3176.475707769394\n",
      "  time_this_iter_s: 6.512173891067505\n",
      "  time_total_s: 3176.475707769394\n",
      "  timestamp: 1596124603\n",
      "  timesteps_since_restore: 2358200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2358200\n",
      "  training_iteration: 907\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.6/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3176 s, 907 iter, 2358200 ts, 518 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-56-48\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 519.9008530471881\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 943\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 46.145\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4627094268798828\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.1935701965958287e-07\n",
      "        policy_loss: 0.0008553796797059476\n",
      "        total_loss: 32.847652435302734\n",
      "        vf_explained_var: 0.01065593957901001\n",
      "        vf_loss: 32.8467903137207\n",
      "    load_time_ms: 2.01\n",
      "    num_steps_sampled: 2360800\n",
      "    num_steps_trained: 2270000\n",
      "    sample_time_ms: 4994.911\n",
      "    update_time_ms: 10.384\n",
      "  iterations_since_restore: 908\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.012499999999996\n",
      "    ram_util_percent: 63.824999999999996\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.93664653456505\n",
      "    mean_inference_ms: 0.9425002296763452\n",
      "    mean_processing_ms: 0.686923956400487\n",
      "  time_since_restore: 3182.0993163585663\n",
      "  time_this_iter_s: 5.623608589172363\n",
      "  time_total_s: 3182.0993163585663\n",
      "  timestamp: 1596124608\n",
      "  timesteps_since_restore: 2360800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2360800\n",
      "  training_iteration: 908\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3182 s, 908 iter, 2360800 ts, 520 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-56-58\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 517.136222271523\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 944\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 48.023\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4496076107025146\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.004572128404106e-07\n",
      "        policy_loss: 0.00161940383259207\n",
      "        total_loss: 21.92696189880371\n",
      "        vf_explained_var: 0.0062909722328186035\n",
      "        vf_loss: 21.925344467163086\n",
      "    load_time_ms: 2.056\n",
      "    num_steps_sampled: 2366000\n",
      "    num_steps_trained: 2275000\n",
      "    sample_time_ms: 4989.035\n",
      "    update_time_ms: 9.964\n",
      "  iterations_since_restore: 910\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.22857142857143\n",
      "    ram_util_percent: 63.75714285714286\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9382691000782892\n",
      "    mean_inference_ms: 0.9428402817672563\n",
      "    mean_processing_ms: 0.6870181810340307\n",
      "  time_since_restore: 3191.7261645793915\n",
      "  time_this_iter_s: 5.080679655075073\n",
      "  time_total_s: 3191.7261645793915\n",
      "  timestamp: 1596124618\n",
      "  timesteps_since_restore: 2366000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2366000\n",
      "  training_iteration: 910\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.6/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3191 s, 910 iter, 2366000 ts, 517 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-57-09\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 515.5869771403778\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 945\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 44.85\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.46847665309906\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 9.793519666345674e-07\n",
      "        policy_loss: -0.0029449095018208027\n",
      "        total_loss: 44.37870407104492\n",
      "        vf_explained_var: 0.0038560032844543457\n",
      "        vf_loss: 44.38164520263672\n",
      "    load_time_ms: 1.858\n",
      "    num_steps_sampled: 2371200\n",
      "    num_steps_trained: 2280000\n",
      "    sample_time_ms: 5071.793\n",
      "    update_time_ms: 10.896\n",
      "  iterations_since_restore: 912\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 52.425\n",
      "    ram_util_percent: 63.8\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9396275583773774\n",
      "    mean_inference_ms: 0.9430495103037403\n",
      "    mean_processing_ms: 0.6870997564651469\n",
      "  time_since_restore: 3202.361538887024\n",
      "  time_this_iter_s: 5.907210111618042\n",
      "  time_total_s: 3202.361538887024\n",
      "  timestamp: 1596124629\n",
      "  timesteps_since_restore: 2371200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2371200\n",
      "  training_iteration: 912\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.6/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3202 s, 912 iter, 2371200 ts, 516 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-57-15\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 512.3082799827229\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 949\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 46.171\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4593719244003296\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.149483399691235e-07\n",
      "        policy_loss: 0.004088457673788071\n",
      "        total_loss: 30.638944625854492\n",
      "        vf_explained_var: 0.007560551166534424\n",
      "        vf_loss: 30.634862899780273\n",
      "    load_time_ms: 1.844\n",
      "    num_steps_sampled: 2373800\n",
      "    num_steps_trained: 2282500\n",
      "    sample_time_ms: 5120.329\n",
      "    update_time_ms: 10.015\n",
      "  iterations_since_restore: 913\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.111111111111114\n",
      "    ram_util_percent: 63.955555555555556\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9465411162855544\n",
      "    mean_inference_ms: 0.9445644374015572\n",
      "    mean_processing_ms: 0.6875457381130132\n",
      "  time_since_restore: 3208.6176488399506\n",
      "  time_this_iter_s: 6.256109952926636\n",
      "  time_total_s: 3208.6176488399506\n",
      "  timestamp: 1596124635\n",
      "  timesteps_since_restore: 2373800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2373800\n",
      "  training_iteration: 913\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.6/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3208 s, 913 iter, 2373800 ts, 512 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-57-25\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 512.3082799827229\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 949\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 49.902\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4630309343338013\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.224417575140251e-06\n",
      "        policy_loss: 0.008299537003040314\n",
      "        total_loss: 59.817054748535156\n",
      "        vf_explained_var: 0.005020856857299805\n",
      "        vf_loss: 59.80875778198242\n",
      "    load_time_ms: 2.003\n",
      "    num_steps_sampled: 2379000\n",
      "    num_steps_trained: 2287500\n",
      "    sample_time_ms: 5146.973\n",
      "    update_time_ms: 9.959\n",
      "  iterations_since_restore: 915\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.471428571428575\n",
      "    ram_util_percent: 63.94285714285714\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9465411162855535\n",
      "    mean_inference_ms: 0.9445644374015572\n",
      "    mean_processing_ms: 0.6875457381130131\n",
      "  time_since_restore: 3218.131912469864\n",
      "  time_this_iter_s: 4.65262246131897\n",
      "  time_total_s: 3218.131912469864\n",
      "  timestamp: 1596124645\n",
      "  timesteps_since_restore: 2379000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2379000\n",
      "  training_iteration: 915\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.6/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3218 s, 915 iter, 2379000 ts, 512 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-57-30\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 512.3082799827229\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 949\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 50.541\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4723867177963257\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.170366072590696e-07\n",
      "        policy_loss: 0.00023966676963027567\n",
      "        total_loss: 64.6678695678711\n",
      "        vf_explained_var: 0.0022687911987304688\n",
      "        vf_loss: 64.6676254272461\n",
      "    load_time_ms: 2.149\n",
      "    num_steps_sampled: 2381600\n",
      "    num_steps_trained: 2290000\n",
      "    sample_time_ms: 5253.351\n",
      "    update_time_ms: 10.283\n",
      "  iterations_since_restore: 916\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 65.27142857142857\n",
      "    ram_util_percent: 63.942857142857136\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9465411162855535\n",
      "    mean_inference_ms: 0.9445644374015572\n",
      "    mean_processing_ms: 0.6875457381130131\n",
      "  time_since_restore: 3223.292580604553\n",
      "  time_this_iter_s: 5.160668134689331\n",
      "  time_total_s: 3223.292580604553\n",
      "  timestamp: 1596124650\n",
      "  timesteps_since_restore: 2381600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2381600\n",
      "  training_iteration: 916\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.6/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3223 s, 916 iter, 2381600 ts, 512 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-57-36\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 514.1514239186554\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 951\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 52.191\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4815847873687744\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 9.28525969356997e-06\n",
      "        policy_loss: 0.0016828180523589253\n",
      "        total_loss: 73.8158187866211\n",
      "        vf_explained_var: 0.0025162100791931152\n",
      "        vf_loss: 73.81413269042969\n",
      "    load_time_ms: 2.221\n",
      "    num_steps_sampled: 2384200\n",
      "    num_steps_trained: 2292500\n",
      "    sample_time_ms: 5207.662\n",
      "    update_time_ms: 9.67\n",
      "  iterations_since_restore: 917\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.5\n",
      "    ram_util_percent: 63.833333333333336\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9499200987014627\n",
      "    mean_inference_ms: 0.9452688658922875\n",
      "    mean_processing_ms: 0.68777567462318\n",
      "  time_since_restore: 3229.3649904727936\n",
      "  time_this_iter_s: 6.0724098682403564\n",
      "  time_total_s: 3229.3649904727936\n",
      "  timestamp: 1596124656\n",
      "  timesteps_since_restore: 2384200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2384200\n",
      "  training_iteration: 917\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3229 s, 917 iter, 2384200 ts, 514 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-57-42\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 512.2427827297993\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 954\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 49.568\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.460106611251831\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 9.955168025044259e-06\n",
      "        policy_loss: -0.00209763809107244\n",
      "        total_loss: 48.66748046875\n",
      "        vf_explained_var: 0.0064907073974609375\n",
      "        vf_loss: 48.66958236694336\n",
      "    load_time_ms: 2.2\n",
      "    num_steps_sampled: 2386800\n",
      "    num_steps_trained: 2295000\n",
      "    sample_time_ms: 5213.745\n",
      "    update_time_ms: 9.613\n",
      "  iterations_since_restore: 918\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.775000000000006\n",
      "    ram_util_percent: 63.849999999999994\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9554610919089335\n",
      "    mean_inference_ms: 0.9464380965190506\n",
      "    mean_processing_ms: 0.6881232968857703\n",
      "  time_since_restore: 3235.009729385376\n",
      "  time_this_iter_s: 5.6447389125823975\n",
      "  time_total_s: 3235.009729385376\n",
      "  timestamp: 1596124662\n",
      "  timesteps_since_restore: 2386800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2386800\n",
      "  training_iteration: 918\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.6/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3235 s, 918 iter, 2386800 ts, 512 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-57-51\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 512.2427827297993\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 954\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 53.168\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4634253978729248\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.506853095634142e-06\n",
      "        policy_loss: -0.004430784378200769\n",
      "        total_loss: 74.28563690185547\n",
      "        vf_explained_var: 0.001753687858581543\n",
      "        vf_loss: 74.2900619506836\n",
      "    load_time_ms: 2.263\n",
      "    num_steps_sampled: 2392000\n",
      "    num_steps_trained: 2300000\n",
      "    sample_time_ms: 5185.358\n",
      "    update_time_ms: 9.427\n",
      "  iterations_since_restore: 920\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.15714285714286\n",
      "    ram_util_percent: 63.89999999999999\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9554610919089335\n",
      "    mean_inference_ms: 0.9464380965190506\n",
      "    mean_processing_ms: 0.6881232968857702\n",
      "  time_since_restore: 3244.386602640152\n",
      "  time_this_iter_s: 5.235353469848633\n",
      "  time_total_s: 3244.386602640152\n",
      "  timestamp: 1596124671\n",
      "  timesteps_since_restore: 2392000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2392000\n",
      "  training_iteration: 920\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.6/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3244 s, 920 iter, 2392000 ts, 512 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-57-56\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 512.2427827297993\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 954\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 56.02\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.471853494644165\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.0937910651118727e-06\n",
      "        policy_loss: -0.001281921984627843\n",
      "        total_loss: 82.09521484375\n",
      "        vf_explained_var: 0.001416325569152832\n",
      "        vf_loss: 82.09646606445312\n",
      "    load_time_ms: 2.361\n",
      "    num_steps_sampled: 2394600\n",
      "    num_steps_trained: 2302500\n",
      "    sample_time_ms: 5223.874\n",
      "    update_time_ms: 9.308\n",
      "  iterations_since_restore: 921\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.425\n",
      "    ram_util_percent: 63.8625\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9554610919089335\n",
      "    mean_inference_ms: 0.9464380965190506\n",
      "    mean_processing_ms: 0.6881232968857702\n",
      "  time_since_restore: 3249.539400100708\n",
      "  time_this_iter_s: 5.15279746055603\n",
      "  time_total_s: 3249.539400100708\n",
      "  timestamp: 1596124676\n",
      "  timesteps_since_restore: 2394600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2394600\n",
      "  training_iteration: 921\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.6/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3249 s, 921 iter, 2394600 ts, 512 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-58-02\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 515.6763961544356\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 957\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 54.951\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.478578805923462\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.4320602278748993e-06\n",
      "        policy_loss: 0.00047522183740511537\n",
      "        total_loss: 79.27775573730469\n",
      "        vf_explained_var: 0.002431929111480713\n",
      "        vf_loss: 79.27729797363281\n",
      "    load_time_ms: 2.347\n",
      "    num_steps_sampled: 2397200\n",
      "    num_steps_trained: 2305000\n",
      "    sample_time_ms: 5231.891\n",
      "    update_time_ms: 9.879\n",
      "  iterations_since_restore: 922\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.662499999999994\n",
      "    ram_util_percent: 63.824999999999996\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9612692744351796\n",
      "    mean_inference_ms: 0.9475745296270524\n",
      "    mean_processing_ms: 0.688516370989136\n",
      "  time_since_restore: 3255.521148443222\n",
      "  time_this_iter_s: 5.981748342514038\n",
      "  time_total_s: 3255.521148443222\n",
      "  timestamp: 1596124682\n",
      "  timesteps_since_restore: 2397200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2397200\n",
      "  training_iteration: 922\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3255 s, 922 iter, 2397200 ts, 516 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-58-11\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 521.3326338175866\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 959\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 53.991\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.446574091911316\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 9.088515895427918e-08\n",
      "        policy_loss: -0.0030052729416638613\n",
      "        total_loss: 23.27351188659668\n",
      "        vf_explained_var: 0.0063318610191345215\n",
      "        vf_loss: 23.27651596069336\n",
      "    load_time_ms: 2.359\n",
      "    num_steps_sampled: 2402400\n",
      "    num_steps_trained: 2310000\n",
      "    sample_time_ms: 4989.482\n",
      "    update_time_ms: 9.481\n",
      "  iterations_since_restore: 924\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.32857142857143\n",
      "    ram_util_percent: 63.8\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.965006381404623\n",
      "    mean_inference_ms: 0.9484523400670912\n",
      "    mean_processing_ms: 0.688746200618152\n",
      "  time_since_restore: 3264.1994774341583\n",
      "  time_this_iter_s: 4.509081840515137\n",
      "  time_total_s: 3264.1994774341583\n",
      "  timestamp: 1596124691\n",
      "  timesteps_since_restore: 2402400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2402400\n",
      "  training_iteration: 924\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3264 s, 924 iter, 2402400 ts, 521 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-58-20\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 521.3326338175866\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 959\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 53.145\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4656790494918823\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.964878947546822e-06\n",
      "        policy_loss: -0.0074799200519919395\n",
      "        total_loss: 49.08163070678711\n",
      "        vf_explained_var: 0.0026724934577941895\n",
      "        vf_loss: 49.08910369873047\n",
      "    load_time_ms: 2.214\n",
      "    num_steps_sampled: 2407600\n",
      "    num_steps_trained: 2315000\n",
      "    sample_time_ms: 4906.21\n",
      "    update_time_ms: 9.826\n",
      "  iterations_since_restore: 926\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.81666666666667\n",
      "    ram_util_percent: 63.699999999999996\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.965006381404623\n",
      "    mean_inference_ms: 0.9484523400670912\n",
      "    mean_processing_ms: 0.688746200618152\n",
      "  time_since_restore: 3273.1786663532257\n",
      "  time_this_iter_s: 4.212478160858154\n",
      "  time_total_s: 3273.1786663532257\n",
      "  timestamp: 1596124700\n",
      "  timesteps_since_restore: 2407600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2407600\n",
      "  training_iteration: 926\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3273 s, 926 iter, 2407600 ts, 521 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-58-26\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 517.3547102712105\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 964\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 52.426\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4705861806869507\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.4825820926489541e-06\n",
      "        policy_loss: -0.0013100310461595654\n",
      "        total_loss: 48.170448303222656\n",
      "        vf_explained_var: 0.0035407543182373047\n",
      "        vf_loss: 48.1717643737793\n",
      "    load_time_ms: 2.196\n",
      "    num_steps_sampled: 2410200\n",
      "    num_steps_trained: 2317500\n",
      "    sample_time_ms: 4876.383\n",
      "    update_time_ms: 10.055\n",
      "  iterations_since_restore: 927\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.425000000000004\n",
      "    ram_util_percent: 63.712500000000006\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9750262868475357\n",
      "    mean_inference_ms: 0.9505720655607399\n",
      "    mean_processing_ms: 0.6894035115428728\n",
      "  time_since_restore: 3278.9445157051086\n",
      "  time_this_iter_s: 5.765849351882935\n",
      "  time_total_s: 3278.9445157051086\n",
      "  timestamp: 1596124706\n",
      "  timesteps_since_restore: 2410200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2410200\n",
      "  training_iteration: 927\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.5/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3278 s, 927 iter, 2410200 ts, 517 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-58-31\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 517.3547102712105\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 964\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 56.16\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4408681392669678\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.2238961011898937e-07\n",
      "        policy_loss: 0.0018668314442038536\n",
      "        total_loss: 10.347217559814453\n",
      "        vf_explained_var: 0.01438361406326294\n",
      "        vf_loss: 10.34535026550293\n",
      "    load_time_ms: 2.386\n",
      "    num_steps_sampled: 2412800\n",
      "    num_steps_trained: 2320000\n",
      "    sample_time_ms: 4854.26\n",
      "    update_time_ms: 9.887\n",
      "  iterations_since_restore: 928\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.075\n",
      "    ram_util_percent: 63.8625\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9750262868475357\n",
      "    mean_inference_ms: 0.95057206556074\n",
      "    mean_processing_ms: 0.6894035115428728\n",
      "  time_since_restore: 3284.4173924922943\n",
      "  time_this_iter_s: 5.472876787185669\n",
      "  time_total_s: 3284.4173924922943\n",
      "  timestamp: 1596124711\n",
      "  timesteps_since_restore: 2412800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2412800\n",
      "  training_iteration: 928\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.6/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3284 s, 928 iter, 2412800 ts, 517 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-58-41\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 517.3547102712105\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 964\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 56.276\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4595293998718262\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.051115046697305e-07\n",
      "        policy_loss: 0.007208586670458317\n",
      "        total_loss: 43.19606018066406\n",
      "        vf_explained_var: 0.004124701023101807\n",
      "        vf_loss: 43.18883514404297\n",
      "    load_time_ms: 2.478\n",
      "    num_steps_sampled: 2418000\n",
      "    num_steps_trained: 2325000\n",
      "    sample_time_ms: 4853.336\n",
      "    update_time_ms: 10.569\n",
      "  iterations_since_restore: 930\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.48571428571428\n",
      "    ram_util_percent: 63.92857142857142\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9750262868475357\n",
      "    mean_inference_ms: 0.95057206556074\n",
      "    mean_processing_ms: 0.6894035115428728\n",
      "  time_since_restore: 3293.7954828739166\n",
      "  time_this_iter_s: 4.709263801574707\n",
      "  time_total_s: 3293.7954828739166\n",
      "  timestamp: 1596124721\n",
      "  timesteps_since_restore: 2418000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2418000\n",
      "  training_iteration: 930\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.6/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3293 s, 930 iter, 2418000 ts, 517 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-58-51\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 506.97561697614196\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 969\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 57.559\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4576610326766968\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.601550244842656e-06\n",
      "        policy_loss: -0.0011240339372307062\n",
      "        total_loss: 23.649850845336914\n",
      "        vf_explained_var: 0.006615757942199707\n",
      "        vf_loss: 23.650978088378906\n",
      "    load_time_ms: 2.764\n",
      "    num_steps_sampled: 2423200\n",
      "    num_steps_trained: 2330000\n",
      "    sample_time_ms: 4807.534\n",
      "    update_time_ms: 10.995\n",
      "  iterations_since_restore: 932\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 66.0375\n",
      "    ram_util_percent: 63.8375\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.985069559473452\n",
      "    mean_inference_ms: 0.9527077708491763\n",
      "    mean_processing_ms: 0.6900709759701813\n",
      "  time_since_restore: 3304.490170955658\n",
      "  time_this_iter_s: 6.202009916305542\n",
      "  time_total_s: 3304.490170955658\n",
      "  timestamp: 1596124731\n",
      "  timesteps_since_restore: 2423200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2423200\n",
      "  training_iteration: 932\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.6/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3304 s, 932 iter, 2423200 ts, 507 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-59-01\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 506.97561697614196\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 969\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 63.017\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4511617422103882\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.198883073516015e-10\n",
      "        policy_loss: 0.0013156358618289232\n",
      "        total_loss: 36.316951751708984\n",
      "        vf_explained_var: 0.005683183670043945\n",
      "        vf_loss: 36.315635681152344\n",
      "    load_time_ms: 2.911\n",
      "    num_steps_sampled: 2428400\n",
      "    num_steps_trained: 2335000\n",
      "    sample_time_ms: 4920.5\n",
      "    update_time_ms: 11.532\n",
      "  iterations_since_restore: 934\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.0125\n",
      "    ram_util_percent: 64.0875\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9850695594734526\n",
      "    mean_inference_ms: 0.9527077708491762\n",
      "    mean_processing_ms: 0.6900709759701813\n",
      "  time_since_restore: 3314.372088432312\n",
      "  time_this_iter_s: 5.386659383773804\n",
      "  time_total_s: 3314.372088432312\n",
      "  timestamp: 1596124741\n",
      "  timesteps_since_restore: 2428400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2428400\n",
      "  training_iteration: 934\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.6/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3314 s, 934 iter, 2428400 ts, 507 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-59-10\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 506.97561697614196\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 969\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 60.227\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4749070405960083\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.7275572190555977e-06\n",
      "        policy_loss: -0.006523466669023037\n",
      "        total_loss: 67.69857025146484\n",
      "        vf_explained_var: 0.0010623931884765625\n",
      "        vf_loss: 67.705078125\n",
      "    load_time_ms: 2.831\n",
      "    num_steps_sampled: 2433600\n",
      "    num_steps_trained: 2340000\n",
      "    sample_time_ms: 4941.098\n",
      "    update_time_ms: 11.672\n",
      "  iterations_since_restore: 936\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 67.84285714285714\n",
      "    ram_util_percent: 65.08571428571429\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9850695594734526\n",
      "    mean_inference_ms: 0.9527077708491762\n",
      "    mean_processing_ms: 0.6900709759701813\n",
      "  time_since_restore: 3323.518849134445\n",
      "  time_this_iter_s: 4.601199150085449\n",
      "  time_total_s: 3323.518849134445\n",
      "  timestamp: 1596124750\n",
      "  timesteps_since_restore: 2433600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2433600\n",
      "  training_iteration: 936\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3323 s, 936 iter, 2433600 ts, 507 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-59-17\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 507.2721345243026\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 974\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 59.511\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4628294706344604\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.745312811697659e-07\n",
      "        policy_loss: -0.003406069939956069\n",
      "        total_loss: 43.83781814575195\n",
      "        vf_explained_var: 0.0066852569580078125\n",
      "        vf_loss: 43.84123229980469\n",
      "    load_time_ms: 2.733\n",
      "    num_steps_sampled: 2436200\n",
      "    num_steps_trained: 2342500\n",
      "    sample_time_ms: 4976.629\n",
      "    update_time_ms: 11.2\n",
      "  iterations_since_restore: 937\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.475\n",
      "    ram_util_percent: 64.5\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.995140183608661\n",
      "    mean_inference_ms: 0.9548584286584297\n",
      "    mean_processing_ms: 0.6907265914900153\n",
      "  time_since_restore: 3329.623195171356\n",
      "  time_this_iter_s: 6.104346036911011\n",
      "  time_total_s: 3329.623195171356\n",
      "  timestamp: 1596124757\n",
      "  timesteps_since_restore: 2436200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2436200\n",
      "  training_iteration: 937\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.6/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3329 s, 937 iter, 2436200 ts, 507 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-59-26\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 507.27213452430266\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 974\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 55.41\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.454683542251587\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.531290022034227e-07\n",
      "        policy_loss: -0.001128487172536552\n",
      "        total_loss: 40.16108703613281\n",
      "        vf_explained_var: 0.0023383498191833496\n",
      "        vf_loss: 40.1622200012207\n",
      "    load_time_ms: 2.503\n",
      "    num_steps_sampled: 2441400\n",
      "    num_steps_trained: 2347500\n",
      "    sample_time_ms: 4892.533\n",
      "    update_time_ms: 10.96\n",
      "  iterations_since_restore: 939\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.57142857142857\n",
      "    ram_util_percent: 64.48571428571428\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.995140183608661\n",
      "    mean_inference_ms: 0.9548584286584297\n",
      "    mean_processing_ms: 0.6907265914900154\n",
      "  time_since_restore: 3338.873247385025\n",
      "  time_this_iter_s: 4.613686561584473\n",
      "  time_total_s: 3338.873247385025\n",
      "  timestamp: 1596124766\n",
      "  timesteps_since_restore: 2441400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2441400\n",
      "  training_iteration: 939\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.6/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3338 s, 939 iter, 2441400 ts, 507 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-59-37\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 505.4395047627185\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 976\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 55.146\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4729816913604736\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 7.755756428196037e-07\n",
      "        policy_loss: -0.0019009477691724896\n",
      "        total_loss: 56.063751220703125\n",
      "        vf_explained_var: 0.0012879371643066406\n",
      "        vf_loss: 56.06565475463867\n",
      "    load_time_ms: 2.252\n",
      "    num_steps_sampled: 2446600\n",
      "    num_steps_trained: 2352500\n",
      "    sample_time_ms: 5049.927\n",
      "    update_time_ms: 10.439\n",
      "  iterations_since_restore: 941\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.411111111111104\n",
      "    ram_util_percent: 64.32222222222222\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9990456305511235\n",
      "    mean_inference_ms: 0.9555371320407666\n",
      "    mean_processing_ms: 0.6909836604099027\n",
      "  time_since_restore: 3349.64360165596\n",
      "  time_this_iter_s: 6.182892799377441\n",
      "  time_total_s: 3349.64360165596\n",
      "  timestamp: 1596124777\n",
      "  timesteps_since_restore: 2446600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2446600\n",
      "  training_iteration: 941\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3349 s, 941 iter, 2446600 ts, 505 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-59-43\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 506.0299580695006\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 979\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 57.092\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4532217979431152\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.7039986839081394e-07\n",
      "        policy_loss: -0.0013669851468876004\n",
      "        total_loss: 24.100120544433594\n",
      "        vf_explained_var: 0.00894474983215332\n",
      "        vf_loss: 24.10148811340332\n",
      "    load_time_ms: 2.323\n",
      "    num_steps_sampled: 2449200\n",
      "    num_steps_trained: 2355000\n",
      "    sample_time_ms: 5007.591\n",
      "    update_time_ms: 10.233\n",
      "  iterations_since_restore: 942\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.837500000000006\n",
      "    ram_util_percent: 64.7625\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.005082442220513\n",
      "    mean_inference_ms: 0.9569865102090764\n",
      "    mean_processing_ms: 0.6913906938013544\n",
      "  time_since_restore: 3355.4448454380035\n",
      "  time_this_iter_s: 5.801243782043457\n",
      "  time_total_s: 3355.4448454380035\n",
      "  timestamp: 1596124783\n",
      "  timesteps_since_restore: 2449200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2449200\n",
      "  training_iteration: 942\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3355 s, 942 iter, 2449200 ts, 506 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-59-52\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 506.0299580695004\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 979\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 51.589\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4511419534683228\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.339124733907738e-07\n",
      "        policy_loss: 0.0004935403703711927\n",
      "        total_loss: 18.7145938873291\n",
      "        vf_explained_var: 0.005831360816955566\n",
      "        vf_loss: 18.714101791381836\n",
      "    load_time_ms: 2.172\n",
      "    num_steps_sampled: 2454400\n",
      "    num_steps_trained: 2360000\n",
      "    sample_time_ms: 4988.508\n",
      "    update_time_ms: 10.772\n",
      "  iterations_since_restore: 944\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.32857142857143\n",
      "    ram_util_percent: 64.25714285714285\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.005082442220512\n",
      "    mean_inference_ms: 0.9569865102090767\n",
      "    mean_processing_ms: 0.6913906938013544\n",
      "  time_since_restore: 3365.0744240283966\n",
      "  time_this_iter_s: 4.945566892623901\n",
      "  time_total_s: 3365.0744240283966\n",
      "  timestamp: 1596124792\n",
      "  timesteps_since_restore: 2454400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2454400\n",
      "  training_iteration: 944\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.6/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3365 s, 944 iter, 2454400 ts, 506 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_18-59-58\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 506.0299580695004\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 979\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 53.806\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4616079330444336\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.363681801398343e-07\n",
      "        policy_loss: -0.0070132422260940075\n",
      "        total_loss: 34.11901092529297\n",
      "        vf_explained_var: 0.005145907402038574\n",
      "        vf_loss: 34.12602996826172\n",
      "    load_time_ms: 2.245\n",
      "    num_steps_sampled: 2457000\n",
      "    num_steps_trained: 2362500\n",
      "    sample_time_ms: 5078.785\n",
      "    update_time_ms: 10.555\n",
      "  iterations_since_restore: 945\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.75\n",
      "    ram_util_percent: 64.2\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.005082442220512\n",
      "    mean_inference_ms: 0.9569865102090767\n",
      "    mean_processing_ms: 0.6913906938013544\n",
      "  time_since_restore: 3370.5434329509735\n",
      "  time_this_iter_s: 5.469008922576904\n",
      "  time_total_s: 3370.5434329509735\n",
      "  timestamp: 1596124798\n",
      "  timesteps_since_restore: 2457000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2457000\n",
      "  training_iteration: 945\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.6/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3370 s, 945 iter, 2457000 ts, 506 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-00-08\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 499.28624685202544\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 984\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 49.318\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4541438817977905\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 9.32598140934715e-07\n",
      "        policy_loss: 0.003312246408313513\n",
      "        total_loss: 32.19086456298828\n",
      "        vf_explained_var: 0.0054267048835754395\n",
      "        vf_loss: 32.18755340576172\n",
      "    load_time_ms: 2.062\n",
      "    num_steps_sampled: 2462200\n",
      "    num_steps_trained: 2367500\n",
      "    sample_time_ms: 5064.31\n",
      "    update_time_ms: 10.916\n",
      "  iterations_since_restore: 947\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.875\n",
      "    ram_util_percent: 64.1625\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.014964559942562\n",
      "    mean_inference_ms: 0.9591010084414034\n",
      "    mean_processing_ms: 0.6920459017148403\n",
      "  time_since_restore: 3381.0621609687805\n",
      "  time_this_iter_s: 5.925594806671143\n",
      "  time_total_s: 3381.0621609687805\n",
      "  timestamp: 1596124808\n",
      "  timesteps_since_restore: 2462200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2462200\n",
      "  training_iteration: 947\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.6/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3381 s, 947 iter, 2462200 ts, 499 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-00-13\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 499.2862468520255\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 984\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 47.464\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4470375776290894\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.3307799779104243e-07\n",
      "        policy_loss: -0.006182670593261719\n",
      "        total_loss: 28.855300903320312\n",
      "        vf_explained_var: 0.008445262908935547\n",
      "        vf_loss: 28.86148452758789\n",
      "    load_time_ms: 1.955\n",
      "    num_steps_sampled: 2464800\n",
      "    num_steps_trained: 2370000\n",
      "    sample_time_ms: 5116.846\n",
      "    update_time_ms: 10.535\n",
      "  iterations_since_restore: 948\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.28571428571428\n",
      "    ram_util_percent: 64.11428571428573\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.014964559942562\n",
      "    mean_inference_ms: 0.9591010084414034\n",
      "    mean_processing_ms: 0.6920459017148402\n",
      "  time_since_restore: 3386.1933269500732\n",
      "  time_this_iter_s: 5.131165981292725\n",
      "  time_total_s: 3386.1933269500732\n",
      "  timestamp: 1596124813\n",
      "  timesteps_since_restore: 2464800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2464800\n",
      "  training_iteration: 948\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.6/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3386 s, 948 iter, 2464800 ts, 499 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-00-23\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 499.2862468520255\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 984\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 48.261\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4580904245376587\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.2935638551425654e-06\n",
      "        policy_loss: 0.004599682055413723\n",
      "        total_loss: 43.190189361572266\n",
      "        vf_explained_var: 0.00531536340713501\n",
      "        vf_loss: 43.18559265136719\n",
      "    load_time_ms: 2.101\n",
      "    num_steps_sampled: 2470000\n",
      "    num_steps_trained: 2375000\n",
      "    sample_time_ms: 5143.395\n",
      "    update_time_ms: 10.667\n",
      "  iterations_since_restore: 950\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.65714285714286\n",
      "    ram_util_percent: 65.24285714285715\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.014964559942562\n",
      "    mean_inference_ms: 0.9591010084414034\n",
      "    mean_processing_ms: 0.6920459017148402\n",
      "  time_since_restore: 3395.657241821289\n",
      "  time_this_iter_s: 4.740078687667847\n",
      "  time_total_s: 3395.657241821289\n",
      "  timestamp: 1596124823\n",
      "  timesteps_since_restore: 2470000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2470000\n",
      "  training_iteration: 950\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3395 s, 950 iter, 2470000 ts, 499 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-00-29\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 982.2050207458504\n",
      "  episode_reward_mean: 498.9683380533624\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 987\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 45.192\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.457790493965149\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.9515275653247954e-06\n",
      "        policy_loss: 0.0004978143842890859\n",
      "        total_loss: 32.28989028930664\n",
      "        vf_explained_var: 0.005755126476287842\n",
      "        vf_loss: 32.289390563964844\n",
      "    load_time_ms: 1.996\n",
      "    num_steps_sampled: 2472600\n",
      "    num_steps_trained: 2377500\n",
      "    sample_time_ms: 5173.305\n",
      "    update_time_ms: 10.45\n",
      "  iterations_since_restore: 951\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.15555555555555\n",
      "    ram_util_percent: 65.40000000000002\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.020864165111125\n",
      "    mean_inference_ms: 0.9603157352243548\n",
      "    mean_processing_ms: 0.6924168666789494\n",
      "  time_since_restore: 3402.0969128608704\n",
      "  time_this_iter_s: 6.439671039581299\n",
      "  time_total_s: 3402.0969128608704\n",
      "  timestamp: 1596124829\n",
      "  timesteps_since_restore: 2472600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2472600\n",
      "  training_iteration: 951\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3402 s, 951 iter, 2472600 ts, 499 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-00-38\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 919.6535183330809\n",
      "  episode_reward_mean: 494.29777911511775\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 989\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 50.341\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4492449760437012\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 9.499073030383443e-07\n",
      "        policy_loss: 0.001195581746287644\n",
      "        total_loss: 27.272687911987305\n",
      "        vf_explained_var: 0.006071209907531738\n",
      "        vf_loss: 27.2714900970459\n",
      "    load_time_ms: 2.06\n",
      "    num_steps_sampled: 2477800\n",
      "    num_steps_trained: 2382500\n",
      "    sample_time_ms: 4978.391\n",
      "    update_time_ms: 10.215\n",
      "  iterations_since_restore: 953\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.26666666666667\n",
      "    ram_util_percent: 65.16666666666667\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.024829979190654\n",
      "    mean_inference_ms: 0.9612170644611385\n",
      "    mean_processing_ms: 0.6926914744079149\n",
      "  time_since_restore: 3410.69784116745\n",
      "  time_this_iter_s: 4.373401165008545\n",
      "  time_total_s: 3410.69784116745\n",
      "  timestamp: 1596124838\n",
      "  timesteps_since_restore: 2477800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2477800\n",
      "  training_iteration: 953\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3410 s, 953 iter, 2477800 ts, 494 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-00-48\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 919.6535183330809\n",
      "  episode_reward_mean: 495.148772326823\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 990\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 48.781\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.46573805809021\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.5426159052367439e-06\n",
      "        policy_loss: -0.0006867553456686437\n",
      "        total_loss: 36.097232818603516\n",
      "        vf_explained_var: 0.0021647214889526367\n",
      "        vf_loss: 36.097923278808594\n",
      "    load_time_ms: 2.062\n",
      "    num_steps_sampled: 2483000\n",
      "    num_steps_trained: 2387500\n",
      "    sample_time_ms: 4934.834\n",
      "    update_time_ms: 9.062\n",
      "  iterations_since_restore: 955\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.45\n",
      "    ram_util_percent: 64.6\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.026797302662387\n",
      "    mean_inference_ms: 0.9616396297652375\n",
      "    mean_processing_ms: 0.6928255770864707\n",
      "  time_since_restore: 3420.646405696869\n",
      "  time_this_iter_s: 5.258487224578857\n",
      "  time_total_s: 3420.646405696869\n",
      "  timestamp: 1596124848\n",
      "  timesteps_since_restore: 2483000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2483000\n",
      "  training_iteration: 955\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3420 s, 955 iter, 2483000 ts, 495 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-00-54\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 919.6535183330809\n",
      "  episode_reward_mean: 499.5303659395951\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 993\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 50.539\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4598639011383057\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.822685246428591e-06\n",
      "        policy_loss: -0.006587977521121502\n",
      "        total_loss: 27.424821853637695\n",
      "        vf_explained_var: 0.005051553249359131\n",
      "        vf_loss: 27.431415557861328\n",
      "    load_time_ms: 2.203\n",
      "    num_steps_sampled: 2485600\n",
      "    num_steps_trained: 2390000\n",
      "    sample_time_ms: 5065.511\n",
      "    update_time_ms: 9.605\n",
      "  iterations_since_restore: 956\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.9875\n",
      "    ram_util_percent: 65.19999999999999\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.032614761451529\n",
      "    mean_inference_ms: 0.9628374064822741\n",
      "    mean_processing_ms: 0.6931954798931129\n",
      "  time_since_restore: 3426.561672449112\n",
      "  time_this_iter_s: 5.915266752243042\n",
      "  time_total_s: 3426.561672449112\n",
      "  timestamp: 1596124854\n",
      "  timesteps_since_restore: 2485600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2485600\n",
      "  training_iteration: 956\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3426 s, 956 iter, 2485600 ts, 500 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-01-03\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 919.6535183330809\n",
      "  episode_reward_mean: 498.02852326448766\n",
      "  episode_reward_min: 160.77137044531065\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 994\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 51.711\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4538400173187256\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.04660590650019e-07\n",
      "        policy_loss: -0.0007401317125186324\n",
      "        total_loss: 41.400115966796875\n",
      "        vf_explained_var: 0.007057070732116699\n",
      "        vf_loss: 41.400856018066406\n",
      "    load_time_ms: 2.322\n",
      "    num_steps_sampled: 2490800\n",
      "    num_steps_trained: 2395000\n",
      "    sample_time_ms: 4867.329\n",
      "    update_time_ms: 8.77\n",
      "  iterations_since_restore: 958\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.12857142857143\n",
      "    ram_util_percent: 65.07142857142857\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.03456634569235\n",
      "    mean_inference_ms: 0.9633055304111892\n",
      "    mean_processing_ms: 0.6933449778075028\n",
      "  time_since_restore: 3435.641652584076\n",
      "  time_this_iter_s: 4.694041967391968\n",
      "  time_total_s: 3435.641652584076\n",
      "  timestamp: 1596124863\n",
      "  timesteps_since_restore: 2490800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2490800\n",
      "  training_iteration: 958\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3435 s, 958 iter, 2490800 ts, 498 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-01-14\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 919.6535183330809\n",
      "  episode_reward_mean: 497.0246827674611\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 995\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 50.566\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4699410200119019\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.607913746847771e-06\n",
      "        policy_loss: 0.0005884249694645405\n",
      "        total_loss: 53.78744888305664\n",
      "        vf_explained_var: 0.002041637897491455\n",
      "        vf_loss: 53.786861419677734\n",
      "    load_time_ms: 2.294\n",
      "    num_steps_sampled: 2496000\n",
      "    num_steps_trained: 2400000\n",
      "    sample_time_ms: 5062.982\n",
      "    update_time_ms: 8.253\n",
      "  iterations_since_restore: 960\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.21111111111111\n",
      "    ram_util_percent: 64.52222222222223\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.03674383864827\n",
      "    mean_inference_ms: 0.9636871379781156\n",
      "    mean_processing_ms: 0.6934874625345059\n",
      "  time_since_restore: 3447.054307937622\n",
      "  time_this_iter_s: 6.601994037628174\n",
      "  time_total_s: 3447.054307937622\n",
      "  timestamp: 1596124874\n",
      "  timesteps_since_restore: 2496000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2496000\n",
      "  training_iteration: 960\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3447 s, 960 iter, 2496000 ts, 497 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-01-20\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 919.6535183330809\n",
      "  episode_reward_mean: 499.6958290188957\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 999\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 50.661\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.465256690979004\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.4790010583237745e-06\n",
      "        policy_loss: 0.000844600610435009\n",
      "        total_loss: 45.81718063354492\n",
      "        vf_explained_var: 0.006269276142120361\n",
      "        vf_loss: 45.81632995605469\n",
      "    load_time_ms: 2.295\n",
      "    num_steps_sampled: 2498600\n",
      "    num_steps_trained: 2402500\n",
      "    sample_time_ms: 4990.631\n",
      "    update_time_ms: 8.556\n",
      "  iterations_since_restore: 961\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.58888888888888\n",
      "    ram_util_percent: 64.96666666666665\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.0443216276701035\n",
      "    mean_inference_ms: 0.9654036280970847\n",
      "    mean_processing_ms: 0.6939978866505777\n",
      "  time_since_restore: 3452.7738840579987\n",
      "  time_this_iter_s: 5.719576120376587\n",
      "  time_total_s: 3452.7738840579987\n",
      "  timestamp: 1596124880\n",
      "  timesteps_since_restore: 2498600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2498600\n",
      "  training_iteration: 961\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3452 s, 961 iter, 2498600 ts, 500 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-01-29\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 919.6535183330809\n",
      "  episode_reward_mean: 499.69582901889567\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 999\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 47.375\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4555245637893677\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.7230511275556637e-06\n",
      "        policy_loss: 0.003004198893904686\n",
      "        total_loss: 30.488000869750977\n",
      "        vf_explained_var: 0.005110442638397217\n",
      "        vf_loss: 30.484996795654297\n",
      "    load_time_ms: 2.41\n",
      "    num_steps_sampled: 2503800\n",
      "    num_steps_trained: 2407500\n",
      "    sample_time_ms: 5023.265\n",
      "    update_time_ms: 8.719\n",
      "  iterations_since_restore: 963\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.39999999999999\n",
      "    ram_util_percent: 65.23333333333333\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.0443216276701035\n",
      "    mean_inference_ms: 0.9654036280970847\n",
      "    mean_processing_ms: 0.6939978866505776\n",
      "  time_since_restore: 3461.660506248474\n",
      "  time_this_iter_s: 4.294678449630737\n",
      "  time_total_s: 3461.660506248474\n",
      "  timestamp: 1596124889\n",
      "  timesteps_since_restore: 2503800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2503800\n",
      "  training_iteration: 963\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3461 s, 963 iter, 2503800 ts, 500 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-01-39\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 919.6535183330809\n",
      "  episode_reward_mean: 500.47863679847194\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1000\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 50.098\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.477843999862671\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.069354110290078e-07\n",
      "        policy_loss: -0.0022425903007388115\n",
      "        total_loss: 62.28451919555664\n",
      "        vf_explained_var: 0.0015954971313476562\n",
      "        vf_loss: 62.28676986694336\n",
      "    load_time_ms: 2.544\n",
      "    num_steps_sampled: 2509000\n",
      "    num_steps_trained: 2412500\n",
      "    sample_time_ms: 5048.114\n",
      "    update_time_ms: 8.78\n",
      "  iterations_since_restore: 965\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.0625\n",
      "    ram_util_percent: 64.73750000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.046493710449394\n",
      "    mean_inference_ms: 0.9658355806166871\n",
      "    mean_processing_ms: 0.6941603492159202\n",
      "  time_since_restore: 3471.9002389907837\n",
      "  time_this_iter_s: 5.645149230957031\n",
      "  time_total_s: 3471.9002389907837\n",
      "  timestamp: 1596124899\n",
      "  timesteps_since_restore: 2509000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2509000\n",
      "  training_iteration: 965\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3471 s, 965 iter, 2509000 ts, 500 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-01-45\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 919.6535183330809\n",
      "  episode_reward_mean: 491.17415878190417\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 1004\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 47.484\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4556173086166382\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.0087243228772422e-06\n",
      "        policy_loss: 0.0015569418901577592\n",
      "        total_loss: 28.303752899169922\n",
      "        vf_explained_var: 0.006603598594665527\n",
      "        vf_loss: 28.302200317382812\n",
      "    load_time_ms: 2.404\n",
      "    num_steps_sampled: 2511600\n",
      "    num_steps_trained: 2415000\n",
      "    sample_time_ms: 5014.124\n",
      "    update_time_ms: 8.527\n",
      "  iterations_since_restore: 966\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.1625\n",
      "    ram_util_percent: 65.1875\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.053999554589965\n",
      "    mean_inference_ms: 0.9674914398707702\n",
      "    mean_processing_ms: 0.694650713209846\n",
      "  time_since_restore: 3477.4422295093536\n",
      "  time_this_iter_s: 5.541990518569946\n",
      "  time_total_s: 3477.4422295093536\n",
      "  timestamp: 1596124905\n",
      "  timesteps_since_restore: 2511600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2511600\n",
      "  training_iteration: 966\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3477 s, 966 iter, 2511600 ts, 491 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-01-54\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 919.6535183330809\n",
      "  episode_reward_mean: 491.1741587819043\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1004\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 47.562\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4509825706481934\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.2642145463814813e-07\n",
      "        policy_loss: -0.002780477050691843\n",
      "        total_loss: 17.70207405090332\n",
      "        vf_explained_var: 0.004864394664764404\n",
      "        vf_loss: 17.704856872558594\n",
      "    load_time_ms: 2.362\n",
      "    num_steps_sampled: 2516800\n",
      "    num_steps_trained: 2420000\n",
      "    sample_time_ms: 4972.526\n",
      "    update_time_ms: 9.0\n",
      "  iterations_since_restore: 968\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.649999999999984\n",
      "    ram_util_percent: 64.58333333333333\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.053999554589965\n",
      "    mean_inference_ms: 0.96749143987077\n",
      "    mean_processing_ms: 0.694650713209846\n",
      "  time_since_restore: 3486.1195738315582\n",
      "  time_this_iter_s: 4.252275466918945\n",
      "  time_total_s: 3486.1195738315582\n",
      "  timestamp: 1596124914\n",
      "  timesteps_since_restore: 2516800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2516800\n",
      "  training_iteration: 968\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3486 s, 968 iter, 2516800 ts, 491 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-02-03\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 919.6535183330809\n",
      "  episode_reward_mean: 489.86990819567325\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 1006\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 45.364\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4616928100585938\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.2180795440363e-06\n",
      "        policy_loss: 0.0022547312546521425\n",
      "        total_loss: 26.968936920166016\n",
      "        vf_explained_var: 0.007155001163482666\n",
      "        vf_loss: 26.9666805267334\n",
      "    load_time_ms: 2.299\n",
      "    num_steps_sampled: 2522000\n",
      "    num_steps_trained: 2425000\n",
      "    sample_time_ms: 4745.232\n",
      "    update_time_ms: 9.534\n",
      "  iterations_since_restore: 970\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.33333333333334\n",
      "    ram_util_percent: 65.35\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.057939615853309\n",
      "    mean_inference_ms: 0.9683443467784622\n",
      "    mean_processing_ms: 0.6949059824082693\n",
      "  time_since_restore: 3495.2348556518555\n",
      "  time_this_iter_s: 4.494035482406616\n",
      "  time_total_s: 3495.2348556518555\n",
      "  timestamp: 1596124923\n",
      "  timesteps_since_restore: 2522000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2522000\n",
      "  training_iteration: 970\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.9/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3495 s, 970 iter, 2522000 ts, 490 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-02-08\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 919.6535183330809\n",
      "  episode_reward_mean: 482.54543269927467\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 1009\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 45.232\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4575997591018677\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.0611057632559096e-06\n",
      "        policy_loss: -0.003957562148571014\n",
      "        total_loss: 30.725521087646484\n",
      "        vf_explained_var: 0.005144953727722168\n",
      "        vf_loss: 30.72947883605957\n",
      "    load_time_ms: 2.278\n",
      "    num_steps_sampled: 2524600\n",
      "    num_steps_trained: 2427500\n",
      "    sample_time_ms: 4705.51\n",
      "    update_time_ms: 9.577\n",
      "  iterations_since_restore: 971\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.45\n",
      "    ram_util_percent: 65.275\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.0635546804593465\n",
      "    mean_inference_ms: 0.9695558035484835\n",
      "    mean_processing_ms: 0.6952907893481786\n",
      "  time_since_restore: 3500.556980371475\n",
      "  time_this_iter_s: 5.322124719619751\n",
      "  time_total_s: 3500.556980371475\n",
      "  timestamp: 1596124928\n",
      "  timesteps_since_restore: 2524600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2524600\n",
      "  training_iteration: 971\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3500 s, 971 iter, 2524600 ts, 483 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-02-17\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 919.6535183330809\n",
      "  episode_reward_mean: 482.54543269927484\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1009\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 44.955\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.462490200996399\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.182674506912008e-06\n",
      "        policy_loss: 0.002434489084407687\n",
      "        total_loss: 55.50048828125\n",
      "        vf_explained_var: 0.00377655029296875\n",
      "        vf_loss: 55.49806213378906\n",
      "    load_time_ms: 2.155\n",
      "    num_steps_sampled: 2529800\n",
      "    num_steps_trained: 2432500\n",
      "    sample_time_ms: 4686.844\n",
      "    update_time_ms: 9.686\n",
      "  iterations_since_restore: 973\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.81666666666666\n",
      "    ram_util_percent: 65.0\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.063554680459346\n",
      "    mean_inference_ms: 0.9695558035484837\n",
      "    mean_processing_ms: 0.6952907893481788\n",
      "  time_since_restore: 3509.259710073471\n",
      "  time_this_iter_s: 4.18693208694458\n",
      "  time_total_s: 3509.259710073471\n",
      "  timestamp: 1596124937\n",
      "  timesteps_since_restore: 2529800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2529800\n",
      "  training_iteration: 973\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3509 s, 973 iter, 2529800 ts, 483 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-02-22\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 919.6535183330809\n",
      "  episode_reward_mean: 486.18495735279015\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1010\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 46.725\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4746010303497314\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.282785314695502e-07\n",
      "        policy_loss: -0.004835653584450483\n",
      "        total_loss: 67.94349670410156\n",
      "        vf_explained_var: 0.001320183277130127\n",
      "        vf_loss: 67.94833374023438\n",
      "    load_time_ms: 2.115\n",
      "    num_steps_sampled: 2532400\n",
      "    num_steps_trained: 2435000\n",
      "    sample_time_ms: 4766.201\n",
      "    update_time_ms: 10.557\n",
      "  iterations_since_restore: 974\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.699999999999996\n",
      "    ram_util_percent: 64.975\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.065435458108657\n",
      "    mean_inference_ms: 0.9699599094041852\n",
      "    mean_processing_ms: 0.6954186968104575\n",
      "  time_since_restore: 3514.6778540611267\n",
      "  time_this_iter_s: 5.41814398765564\n",
      "  time_total_s: 3514.6778540611267\n",
      "  timestamp: 1596124942\n",
      "  timesteps_since_restore: 2532400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2532400\n",
      "  training_iteration: 974\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3514 s, 974 iter, 2532400 ts, 486 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-02-27\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 919.6535183330809\n",
      "  episode_reward_mean: 490.85868625719394\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1011\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 46.46\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4669866561889648\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.963491614442319e-07\n",
      "        policy_loss: -0.006912789773195982\n",
      "        total_loss: 47.049354553222656\n",
      "        vf_explained_var: 0.004163086414337158\n",
      "        vf_loss: 47.0562629699707\n",
      "    load_time_ms: 2.106\n",
      "    num_steps_sampled: 2535000\n",
      "    num_steps_trained: 2437500\n",
      "    sample_time_ms: 4711.074\n",
      "    update_time_ms: 11.18\n",
      "  iterations_since_restore: 975\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.17142857142858\n",
      "    ram_util_percent: 65.17142857142858\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.067170092248466\n",
      "    mean_inference_ms: 0.9702661319198579\n",
      "    mean_processing_ms: 0.6955203568269589\n",
      "  time_since_restore: 3519.7725625038147\n",
      "  time_this_iter_s: 5.094708442687988\n",
      "  time_total_s: 3519.7725625038147\n",
      "  timestamp: 1596124947\n",
      "  timesteps_since_restore: 2535000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2535000\n",
      "  training_iteration: 975\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3519 s, 975 iter, 2535000 ts, 491 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-02-33\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 919.6535183330809\n",
      "  episode_reward_mean: 484.2471859661588\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 1014\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 46.822\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4555134773254395\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.301596734672785e-06\n",
      "        policy_loss: -0.0020188484340906143\n",
      "        total_loss: 28.869722366333008\n",
      "        vf_explained_var: 0.006690919399261475\n",
      "        vf_loss: 28.871740341186523\n",
      "    load_time_ms: 2.113\n",
      "    num_steps_sampled: 2537600\n",
      "    num_steps_trained: 2440000\n",
      "    sample_time_ms: 4719.257\n",
      "    update_time_ms: 11.235\n",
      "  iterations_since_restore: 976\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.7\n",
      "    ram_util_percent: 65.61111111111111\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.072999294002622\n",
      "    mean_inference_ms: 0.9715953208288383\n",
      "    mean_processing_ms: 0.6959270023402143\n",
      "  time_since_restore: 3525.401122570038\n",
      "  time_this_iter_s: 5.6285600662231445\n",
      "  time_total_s: 3525.401122570038\n",
      "  timestamp: 1596124953\n",
      "  timesteps_since_restore: 2537600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2537600\n",
      "  training_iteration: 976\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3525 s, 976 iter, 2537600 ts, 484 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-02-43\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 919.6535183330809\n",
      "  episode_reward_mean: 484.2471859661587\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1014\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 49.737\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4629751443862915\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.1144876225444023e-05\n",
      "        policy_loss: 0.00016716080426704139\n",
      "        total_loss: 35.810577392578125\n",
      "        vf_explained_var: 0.003776371479034424\n",
      "        vf_loss: 35.8104133605957\n",
      "    load_time_ms: 2.145\n",
      "    num_steps_sampled: 2542800\n",
      "    num_steps_trained: 2445000\n",
      "    sample_time_ms: 4835.623\n",
      "    update_time_ms: 11.875\n",
      "  iterations_since_restore: 978\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 65.74285714285713\n",
      "    ram_util_percent: 64.65714285714286\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.072999294002621\n",
      "    mean_inference_ms: 0.9715953208288383\n",
      "    mean_processing_ms: 0.6959270023402143\n",
      "  time_since_restore: 3535.2807936668396\n",
      "  time_this_iter_s: 4.968963861465454\n",
      "  time_total_s: 3535.2807936668396\n",
      "  timestamp: 1596124963\n",
      "  timesteps_since_restore: 2542800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2542800\n",
      "  training_iteration: 978\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3535 s, 978 iter, 2542800 ts, 484 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-02-48\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 919.6535183330809\n",
      "  episode_reward_mean: 484.2471859661587\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1014\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 53.278\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4734394550323486\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.4415645637200214e-05\n",
      "        policy_loss: -0.007875978946685791\n",
      "        total_loss: 42.10758590698242\n",
      "        vf_explained_var: 0.0016417503356933594\n",
      "        vf_loss: 42.11546325683594\n",
      "    load_time_ms: 2.259\n",
      "    num_steps_sampled: 2545400\n",
      "    num_steps_trained: 2447500\n",
      "    sample_time_ms: 4915.698\n",
      "    update_time_ms: 11.57\n",
      "  iterations_since_restore: 979\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 65.68571428571428\n",
      "    ram_util_percent: 64.65714285714287\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.072999294002621\n",
      "    mean_inference_ms: 0.9715953208288383\n",
      "    mean_processing_ms: 0.6959270023402143\n",
      "  time_since_restore: 3540.7435092926025\n",
      "  time_this_iter_s: 5.4627156257629395\n",
      "  time_total_s: 3540.7435092926025\n",
      "  timestamp: 1596124968\n",
      "  timesteps_since_restore: 2545400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2545400\n",
      "  training_iteration: 979\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3540 s, 979 iter, 2545400 ts, 484 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-02-54\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 919.6535183330809\n",
      "  episode_reward_mean: 486.746682956023\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 1018\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 56.917\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.47889244556427\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.3623457511566812e-06\n",
      "        policy_loss: 0.0009297375800088048\n",
      "        total_loss: 42.79253005981445\n",
      "        vf_explained_var: 0.004092574119567871\n",
      "        vf_loss: 42.791595458984375\n",
      "    load_time_ms: 2.363\n",
      "    num_steps_sampled: 2548000\n",
      "    num_steps_trained: 2450000\n",
      "    sample_time_ms: 5041.113\n",
      "    update_time_ms: 11.823\n",
      "  iterations_since_restore: 980\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.53333333333333\n",
      "    ram_util_percent: 64.6\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.080375494522878\n",
      "    mean_inference_ms: 0.9731185932471499\n",
      "    mean_processing_ms: 0.6964152069751103\n",
      "  time_since_restore: 3546.5390021800995\n",
      "  time_this_iter_s: 5.795492887496948\n",
      "  time_total_s: 3546.5390021800995\n",
      "  timestamp: 1596124974\n",
      "  timesteps_since_restore: 2548000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2548000\n",
      "  training_iteration: 980\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3546 s, 980 iter, 2548000 ts, 487 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-03-03\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 919.6535183330809\n",
      "  episode_reward_mean: 484.8171165660219\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1019\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 53.774\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4618752002716064\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.5172232653858373e-07\n",
      "        policy_loss: -0.007302435114979744\n",
      "        total_loss: 35.06182098388672\n",
      "        vf_explained_var: 0.004560351371765137\n",
      "        vf_loss: 35.069129943847656\n",
      "    load_time_ms: 2.238\n",
      "    num_steps_sampled: 2553200\n",
      "    num_steps_trained: 2455000\n",
      "    sample_time_ms: 4902.484\n",
      "    update_time_ms: 12.603\n",
      "  iterations_since_restore: 982\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.53333333333333\n",
      "    ram_util_percent: 64.58333333333333\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.08245863961721\n",
      "    mean_inference_ms: 0.9736385691723349\n",
      "    mean_processing_ms: 0.6965685067661649\n",
      "  time_since_restore: 3554.962747335434\n",
      "  time_this_iter_s: 4.267240285873413\n",
      "  time_total_s: 3554.962747335434\n",
      "  timestamp: 1596124983\n",
      "  timesteps_since_restore: 2553200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2553200\n",
      "  training_iteration: 982\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3554 s, 982 iter, 2553200 ts, 485 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-03-14\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 919.6535183330809\n",
      "  episode_reward_mean: 486.7162237295073\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1020\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 57.296\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.483859658241272\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.0131335329788271e-05\n",
      "        policy_loss: -0.004597466439008713\n",
      "        total_loss: 69.48775482177734\n",
      "        vf_explained_var: 0.0006818175315856934\n",
      "        vf_loss: 69.49235534667969\n",
      "    load_time_ms: 2.375\n",
      "    num_steps_sampled: 2558400\n",
      "    num_steps_trained: 2460000\n",
      "    sample_time_ms: 5063.639\n",
      "    update_time_ms: 11.668\n",
      "  iterations_since_restore: 984\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.333333333333336\n",
      "    ram_util_percent: 64.58888888888889\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.083949972318216\n",
      "    mean_inference_ms: 0.9739279523477016\n",
      "    mean_processing_ms: 0.6966392936615083\n",
      "  time_since_restore: 3566.2160410881042\n",
      "  time_this_iter_s: 6.3226542472839355\n",
      "  time_total_s: 3566.2160410881042\n",
      "  timestamp: 1596124994\n",
      "  timesteps_since_restore: 2558400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2558400\n",
      "  training_iteration: 984\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3566 s, 984 iter, 2558400 ts, 487 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-03-20\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 919.6535183330809\n",
      "  episode_reward_mean: 492.3588847936545\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 1023\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 56.673\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4643590450286865\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.452710603189189e-05\n",
      "        policy_loss: 0.003433709032833576\n",
      "        total_loss: 28.53603172302246\n",
      "        vf_explained_var: 0.007559299468994141\n",
      "        vf_loss: 28.532594680786133\n",
      "    load_time_ms: 2.358\n",
      "    num_steps_sampled: 2561000\n",
      "    num_steps_trained: 2462500\n",
      "    sample_time_ms: 5143.251\n",
      "    update_time_ms: 11.333\n",
      "  iterations_since_restore: 985\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.1\n",
      "    ram_util_percent: 64.5875\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.089947382713464\n",
      "    mean_inference_ms: 0.9752617680557455\n",
      "    mean_processing_ms: 0.6970714506873289\n",
      "  time_since_restore: 3572.093396425247\n",
      "  time_this_iter_s: 5.877355337142944\n",
      "  time_total_s: 3572.093396425247\n",
      "  timestamp: 1596125000\n",
      "  timesteps_since_restore: 2561000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2561000\n",
      "  training_iteration: 985\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3572 s, 985 iter, 2561000 ts, 492 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-03-29\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 919.6535183330809\n",
      "  episode_reward_mean: 493.0267231509234\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1024\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 55.998\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4541869163513184\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.4883270270947833e-06\n",
      "        policy_loss: 0.0024735049810260534\n",
      "        total_loss: 26.565139770507812\n",
      "        vf_explained_var: 0.00618666410446167\n",
      "        vf_loss: 26.56266212463379\n",
      "    load_time_ms: 2.364\n",
      "    num_steps_sampled: 2566200\n",
      "    num_steps_trained: 2467500\n",
      "    sample_time_ms: 5027.691\n",
      "    update_time_ms: 11.608\n",
      "  iterations_since_restore: 987\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.39999999999999\n",
      "    ram_util_percent: 64.74285714285715\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.0918197609075575\n",
      "    mean_inference_ms: 0.9756664100193455\n",
      "    mean_processing_ms: 0.6972005181495191\n",
      "  time_since_restore: 3581.479014158249\n",
      "  time_this_iter_s: 4.952803611755371\n",
      "  time_total_s: 3581.479014158249\n",
      "  timestamp: 1596125009\n",
      "  timesteps_since_restore: 2566200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2566200\n",
      "  training_iteration: 987\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3581 s, 987 iter, 2566200 ts, 493 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-03-40\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 886.6247928152688\n",
      "  episode_reward_mean: 484.3421903775717\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 1026\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 56.279\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4740577936172485\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.052640067835455e-06\n",
      "        policy_loss: -0.0046426765620708466\n",
      "        total_loss: 50.87324523925781\n",
      "        vf_explained_var: 0.0016508698463439941\n",
      "        vf_loss: 50.87788391113281\n",
      "    load_time_ms: 2.374\n",
      "    num_steps_sampled: 2571400\n",
      "    num_steps_trained: 2472500\n",
      "    sample_time_ms: 5036.665\n",
      "    update_time_ms: 11.794\n",
      "  iterations_since_restore: 989\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.8\n",
      "    ram_util_percent: 64.6888888888889\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.095200241043018\n",
      "    mean_inference_ms: 0.9763294158856753\n",
      "    mean_processing_ms: 0.6974319552369557\n",
      "  time_since_restore: 3592.008012533188\n",
      "  time_this_iter_s: 5.87182354927063\n",
      "  time_total_s: 3592.008012533188\n",
      "  timestamp: 1596125020\n",
      "  timesteps_since_restore: 2571400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2571400\n",
      "  training_iteration: 989\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3592 s, 989 iter, 2571400 ts, 484 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-03-49\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 886.6247928152688\n",
      "  episode_reward_mean: 481.83850115284486\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1029\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 51.839\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4584624767303467\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.297354685902974e-07\n",
      "        policy_loss: 0.0038119624368846416\n",
      "        total_loss: 52.322540283203125\n",
      "        vf_explained_var: 0.004834234714508057\n",
      "        vf_loss: 52.318729400634766\n",
      "    load_time_ms: 2.293\n",
      "    num_steps_sampled: 2576600\n",
      "    num_steps_trained: 2477500\n",
      "    sample_time_ms: 4975.035\n",
      "    update_time_ms: 10.99\n",
      "  iterations_since_restore: 991\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.166666666666664\n",
      "    ram_util_percent: 64.61666666666667\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.1010529471377755\n",
      "    mean_inference_ms: 0.9776731733349449\n",
      "    mean_processing_ms: 0.6978290254205419\n",
      "  time_since_restore: 3601.2737255096436\n",
      "  time_this_iter_s: 4.4296324253082275\n",
      "  time_total_s: 3601.2737255096436\n",
      "  timestamp: 1596125029\n",
      "  timesteps_since_restore: 2576600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2576600\n",
      "  training_iteration: 991\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3601 s, 991 iter, 2576600 ts, 482 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-03-59\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 886.6247928152688\n",
      "  episode_reward_mean: 481.83850115284474\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1029\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 55.501\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4798542261123657\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.394056309640291e-06\n",
      "        policy_loss: -0.008349642157554626\n",
      "        total_loss: 79.14804077148438\n",
      "        vf_explained_var: 0.000552833080291748\n",
      "        vf_loss: 79.15640258789062\n",
      "    load_time_ms: 2.377\n",
      "    num_steps_sampled: 2581800\n",
      "    num_steps_trained: 2482500\n",
      "    sample_time_ms: 5031.344\n",
      "    update_time_ms: 10.995\n",
      "  iterations_since_restore: 993\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.1\n",
      "    ram_util_percent: 64.5\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.1010529471377755\n",
      "    mean_inference_ms: 0.9776731733349451\n",
      "    mean_processing_ms: 0.697829025420542\n",
      "  time_since_restore: 3611.0859458446503\n",
      "  time_this_iter_s: 5.111380338668823\n",
      "  time_total_s: 3611.0859458446503\n",
      "  timestamp: 1596125039\n",
      "  timesteps_since_restore: 2581800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2581800\n",
      "  training_iteration: 993\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3611 s, 993 iter, 2581800 ts, 482 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-04-09\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 886.6247928152688\n",
      "  episode_reward_mean: 494.6209776537586\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 1034\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 50.58\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4645204544067383\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.0560393093328457e-05\n",
      "        policy_loss: -0.00011104455188615248\n",
      "        total_loss: 48.3596305847168\n",
      "        vf_explained_var: 0.00539928674697876\n",
      "        vf_loss: 48.3597412109375\n",
      "    load_time_ms: 2.197\n",
      "    num_steps_sampled: 2587000\n",
      "    num_steps_trained: 2487500\n",
      "    sample_time_ms: 4834.07\n",
      "    update_time_ms: 11.057\n",
      "  iterations_since_restore: 995\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.075\n",
      "    ram_util_percent: 64.525\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.110196003137203\n",
      "    mean_inference_ms: 0.9796593507780003\n",
      "    mean_processing_ms: 0.6984581716729693\n",
      "  time_since_restore: 3621.24925160408\n",
      "  time_this_iter_s: 5.3305583000183105\n",
      "  time_total_s: 3621.24925160408\n",
      "  timestamp: 1596125049\n",
      "  timesteps_since_restore: 2587000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2587000\n",
      "  training_iteration: 995\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3621 s, 995 iter, 2587000 ts, 495 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-04-18\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 886.6247928152688\n",
      "  episode_reward_mean: 494.6209776537586\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1034\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 51.653\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4611786603927612\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.1331072730390588e-06\n",
      "        policy_loss: 0.0078694187104702\n",
      "        total_loss: 27.451318740844727\n",
      "        vf_explained_var: 0.004077315330505371\n",
      "        vf_loss: 27.443452835083008\n",
      "    load_time_ms: 2.2\n",
      "    num_steps_sampled: 2592200\n",
      "    num_steps_trained: 2492500\n",
      "    sample_time_ms: 4810.608\n",
      "    update_time_ms: 10.458\n",
      "  iterations_since_restore: 997\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.41428571428571\n",
      "    ram_util_percent: 64.5\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.110196003137204\n",
      "    mean_inference_ms: 0.9796593507780001\n",
      "    mean_processing_ms: 0.6984581716729693\n",
      "  time_since_restore: 3630.3990445137024\n",
      "  time_this_iter_s: 4.794203996658325\n",
      "  time_total_s: 3630.3990445137024\n",
      "  timestamp: 1596125058\n",
      "  timesteps_since_restore: 2592200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2592200\n",
      "  training_iteration: 997\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3630 s, 997 iter, 2592200 ts, 495 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-04-24\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 886.6247928152688\n",
      "  episode_reward_mean: 497.36571122016403\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1035\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 54.264\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.471517562866211\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 7.716417371739226e-07\n",
      "        policy_loss: 0.0008760454365983605\n",
      "        total_loss: 31.583391189575195\n",
      "        vf_explained_var: 0.0025571584701538086\n",
      "        vf_loss: 31.58251953125\n",
      "    load_time_ms: 2.373\n",
      "    num_steps_sampled: 2594800\n",
      "    num_steps_trained: 2495000\n",
      "    sample_time_ms: 4883.617\n",
      "    update_time_ms: 9.816\n",
      "  iterations_since_restore: 998\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.528571428571425\n",
      "    ram_util_percent: 64.5\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.11167223706168\n",
      "    mean_inference_ms: 0.9799093001880085\n",
      "    mean_processing_ms: 0.6985591631194845\n",
      "  time_since_restore: 3635.798776626587\n",
      "  time_this_iter_s: 5.3997321128845215\n",
      "  time_total_s: 3635.798776626587\n",
      "  timestamp: 1596125064\n",
      "  timesteps_since_restore: 2594800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2594800\n",
      "  training_iteration: 998\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3635 s, 998 iter, 2594800 ts, 497 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-04-33\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 860.5125826951629\n",
      "  episode_reward_mean: 483.6420841483674\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 1039\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 53.719\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4634531736373901\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.8422345483013487e-07\n",
      "        policy_loss: 0.004968654830008745\n",
      "        total_loss: 30.386022567749023\n",
      "        vf_explained_var: 0.0032009482383728027\n",
      "        vf_loss: 30.38105010986328\n",
      "    load_time_ms: 2.238\n",
      "    num_steps_sampled: 2600000\n",
      "    num_steps_trained: 2500000\n",
      "    sample_time_ms: 4740.411\n",
      "    update_time_ms: 10.117\n",
      "  iterations_since_restore: 1000\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.2625\n",
      "    ram_util_percent: 64.5\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.1191617245916925\n",
      "    mean_inference_ms: 0.9816057775285932\n",
      "    mean_processing_ms: 0.6990769043455946\n",
      "  time_since_restore: 3645.073590993881\n",
      "  time_this_iter_s: 5.169496774673462\n",
      "  time_total_s: 3645.073590993881\n",
      "  timestamp: 1596125073\n",
      "  timesteps_since_restore: 2600000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2600000\n",
      "  training_iteration: 1000\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3645 s, 1000 iter, 2600000 ts, 484 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-04-43\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 860.5125826951629\n",
      "  episode_reward_mean: 483.6420841483676\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1039\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 59.266\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4671357870101929\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.860950528178364e-07\n",
      "        policy_loss: 0.003136739833280444\n",
      "        total_loss: 50.89761734008789\n",
      "        vf_explained_var: 0.0049294233322143555\n",
      "        vf_loss: 50.89447784423828\n",
      "    load_time_ms: 2.478\n",
      "    num_steps_sampled: 2605200\n",
      "    num_steps_trained: 2505000\n",
      "    sample_time_ms: 4797.805\n",
      "    update_time_ms: 11.152\n",
      "  iterations_since_restore: 1002\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.98571428571428\n",
      "    ram_util_percent: 64.41428571428571\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.1191617245916925\n",
      "    mean_inference_ms: 0.9816057775285931\n",
      "    mean_processing_ms: 0.6990769043455944\n",
      "  time_since_restore: 3654.8541865348816\n",
      "  time_this_iter_s: 4.886997699737549\n",
      "  time_total_s: 3654.8541865348816\n",
      "  timestamp: 1596125083\n",
      "  timesteps_since_restore: 2605200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2605200\n",
      "  training_iteration: 1002\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.6/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3654 s, 1002 iter, 2605200 ts, 484 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-04-53\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 860.5125826951629\n",
      "  episode_reward_mean: 486.92340998512987\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 1042\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 55.575\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4741265773773193\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.480910320125986e-06\n",
      "        policy_loss: 0.0012641770299524069\n",
      "        total_loss: 46.85371017456055\n",
      "        vf_explained_var: 0.002689540386199951\n",
      "        vf_loss: 46.852439880371094\n",
      "    load_time_ms: 2.335\n",
      "    num_steps_sampled: 2610400\n",
      "    num_steps_trained: 2510000\n",
      "    sample_time_ms: 4840.779\n",
      "    update_time_ms: 10.654\n",
      "  iterations_since_restore: 1004\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.712500000000006\n",
      "    ram_util_percent: 64.4875\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.124217432674772\n",
      "    mean_inference_ms: 0.9826800991856876\n",
      "    mean_processing_ms: 0.6994418916658902\n",
      "  time_since_restore: 3665.1762521266937\n",
      "  time_this_iter_s: 5.55016827583313\n",
      "  time_total_s: 3665.1762521266937\n",
      "  timestamp: 1596125093\n",
      "  timesteps_since_restore: 2610400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2610400\n",
      "  training_iteration: 1004\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3665 s, 1004 iter, 2610400 ts, 487 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-05-03\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 860.5125826951629\n",
      "  episode_reward_mean: 486.777801412885\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1044\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 54.824\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4645881652832031\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.3806800274760462e-06\n",
      "        policy_loss: 0.0038746967911720276\n",
      "        total_loss: 33.6157112121582\n",
      "        vf_explained_var: 0.0019205808639526367\n",
      "        vf_loss: 33.611839294433594\n",
      "    load_time_ms: 2.296\n",
      "    num_steps_sampled: 2615600\n",
      "    num_steps_trained: 2515000\n",
      "    sample_time_ms: 4818.596\n",
      "    update_time_ms: 11.213\n",
      "  iterations_since_restore: 1006\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 68.04285714285714\n",
      "    ram_util_percent: 64.52857142857142\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.128072315070339\n",
      "    mean_inference_ms: 0.9835400288700861\n",
      "    mean_processing_ms: 0.6996868778860619\n",
      "  time_since_restore: 3674.6416511535645\n",
      "  time_this_iter_s: 4.850434303283691\n",
      "  time_total_s: 3674.6416511535645\n",
      "  timestamp: 1596125103\n",
      "  timesteps_since_restore: 2615600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2615600\n",
      "  training_iteration: 1006\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3674 s, 1006 iter, 2615600 ts, 487 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-05-09\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 860.5125826951629\n",
      "  episode_reward_mean: 487.7401198358124\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1045\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 57.672\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4757777452468872\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.216195980508928e-06\n",
      "        policy_loss: 0.003316012676805258\n",
      "        total_loss: 47.3182258605957\n",
      "        vf_explained_var: 0.00031191110610961914\n",
      "        vf_loss: 47.314918518066406\n",
      "    load_time_ms: 2.319\n",
      "    num_steps_sampled: 2618200\n",
      "    num_steps_trained: 2517500\n",
      "    sample_time_ms: 4947.13\n",
      "    update_time_ms: 10.737\n",
      "  iterations_since_restore: 1007\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 52.611111111111114\n",
      "    ram_util_percent: 64.5\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.129800306622255\n",
      "    mean_inference_ms: 0.9839160496494392\n",
      "    mean_processing_ms: 0.6998076074184071\n",
      "  time_since_restore: 3680.7612557411194\n",
      "  time_this_iter_s: 6.119604587554932\n",
      "  time_total_s: 3680.7612557411194\n",
      "  timestamp: 1596125109\n",
      "  timesteps_since_restore: 2618200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2618200\n",
      "  training_iteration: 1007\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3680 s, 1007 iter, 2618200 ts, 488 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-05-18\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 860.5125826951629\n",
      "  episode_reward_mean: 486.5740619868393\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1046\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 55.728\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4722685813903809\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.948615810462798e-07\n",
      "        policy_loss: -0.0011793817393481731\n",
      "        total_loss: 34.36635971069336\n",
      "        vf_explained_var: 0.005179703235626221\n",
      "        vf_loss: 34.36754608154297\n",
      "    load_time_ms: 2.245\n",
      "    num_steps_sampled: 2623400\n",
      "    num_steps_trained: 2522500\n",
      "    sample_time_ms: 4911.011\n",
      "    update_time_ms: 12.195\n",
      "  iterations_since_restore: 1009\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.34285714285714\n",
      "    ram_util_percent: 64.5\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.131175277795546\n",
      "    mean_inference_ms: 0.9841840535158921\n",
      "    mean_processing_ms: 0.6998736088593676\n",
      "  time_since_restore: 3689.908822774887\n",
      "  time_this_iter_s: 4.649423360824585\n",
      "  time_total_s: 3689.908822774887\n",
      "  timestamp: 1596125118\n",
      "  timesteps_since_restore: 2623400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2623400\n",
      "  training_iteration: 1009\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3689 s, 1009 iter, 2623400 ts, 487 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-05-24\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 860.5125826951629\n",
      "  episode_reward_mean: 490.70432841663626\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 1049\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 55.681\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4612390995025635\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.053665125207772e-07\n",
      "        policy_loss: -0.005007087718695402\n",
      "        total_loss: 14.850255012512207\n",
      "        vf_explained_var: 0.006463289260864258\n",
      "        vf_loss: 14.855260848999023\n",
      "    load_time_ms: 2.241\n",
      "    num_steps_sampled: 2626000\n",
      "    num_steps_trained: 2525000\n",
      "    sample_time_ms: 4971.472\n",
      "    update_time_ms: 11.784\n",
      "  iterations_since_restore: 1010\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 51.3375\n",
      "    ram_util_percent: 64.5\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.13688418113788\n",
      "    mean_inference_ms: 0.9854514547342782\n",
      "    mean_processing_ms: 0.7002829993211015\n",
      "  time_since_restore: 3695.67804646492\n",
      "  time_this_iter_s: 5.769223690032959\n",
      "  time_total_s: 3695.67804646492\n",
      "  timestamp: 1596125124\n",
      "  timesteps_since_restore: 2626000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2626000\n",
      "  training_iteration: 1010\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3695 s, 1010 iter, 2626000 ts, 491 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-05-33\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 860.5125826951629\n",
      "  episode_reward_mean: 490.0749267971549\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1050\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 47.851\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.470165729522705\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.915092285453284e-07\n",
      "        policy_loss: 0.005161083769053221\n",
      "        total_loss: 41.422264099121094\n",
      "        vf_explained_var: 0.002127707004547119\n",
      "        vf_loss: 41.41709899902344\n",
      "    load_time_ms: 1.909\n",
      "    num_steps_sampled: 2631200\n",
      "    num_steps_trained: 2530000\n",
      "    sample_time_ms: 4887.639\n",
      "    update_time_ms: 10.585\n",
      "  iterations_since_restore: 1012\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.28333333333333\n",
      "    ram_util_percent: 64.53333333333333\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.138298611315083\n",
      "    mean_inference_ms: 0.9856876719252269\n",
      "    mean_processing_ms: 0.7003737950383458\n",
      "  time_since_restore: 3704.511381626129\n",
      "  time_this_iter_s: 4.195321798324585\n",
      "  time_total_s: 3704.511381626129\n",
      "  timestamp: 1596125133\n",
      "  timesteps_since_restore: 2631200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2631200\n",
      "  training_iteration: 1012\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3704 s, 1012 iter, 2631200 ts, 490 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-05-39\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 860.5125826951629\n",
      "  episode_reward_mean: 485.29745556491116\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1051\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 48.777\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.476444125175476\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.5950412186357426e-07\n",
      "        policy_loss: -0.008877194486558437\n",
      "        total_loss: 43.16192626953125\n",
      "        vf_explained_var: 0.0026512742042541504\n",
      "        vf_loss: 43.17080307006836\n",
      "    load_time_ms: 1.962\n",
      "    num_steps_sampled: 2633800\n",
      "    num_steps_trained: 2532500\n",
      "    sample_time_ms: 5002.438\n",
      "    update_time_ms: 10.364\n",
      "  iterations_since_restore: 1013\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.6125\n",
      "    ram_util_percent: 64.6125\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.139906518424144\n",
      "    mean_inference_ms: 0.9860768255078736\n",
      "    mean_processing_ms: 0.7004617869172691\n",
      "  time_since_restore: 3710.4411342144012\n",
      "  time_this_iter_s: 5.929752588272095\n",
      "  time_total_s: 3710.4411342144012\n",
      "  timestamp: 1596125139\n",
      "  timesteps_since_restore: 2633800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2633800\n",
      "  training_iteration: 1013\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3710 s, 1013 iter, 2633800 ts, 485 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-05-45\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 860.5125826951629\n",
      "  episode_reward_mean: 485.43506234771877\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1052\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 48.728\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4819316864013672\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.3208150448917877e-06\n",
      "        policy_loss: 0.0012260694056749344\n",
      "        total_loss: 46.993526458740234\n",
      "        vf_explained_var: 0.004931271076202393\n",
      "        vf_loss: 46.992305755615234\n",
      "    load_time_ms: 2.021\n",
      "    num_steps_sampled: 2636400\n",
      "    num_steps_trained: 2535000\n",
      "    sample_time_ms: 5081.812\n",
      "    update_time_ms: 10.157\n",
      "  iterations_since_restore: 1014\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.922222222222224\n",
      "    ram_util_percent: 64.63333333333334\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.1418179930751045\n",
      "    mean_inference_ms: 0.9865612317574075\n",
      "    mean_processing_ms: 0.7006019602145911\n",
      "  time_since_restore: 3716.778834104538\n",
      "  time_this_iter_s: 6.337699890136719\n",
      "  time_total_s: 3716.778834104538\n",
      "  timestamp: 1596125145\n",
      "  timesteps_since_restore: 2636400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2636400\n",
      "  training_iteration: 1014\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3716 s, 1014 iter, 2636400 ts, 485 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-05-56\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 860.5125826951629\n",
      "  episode_reward_mean: 481.78721765764743\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1055\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 53.357\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4660550355911255\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.029083356726915e-06\n",
      "        policy_loss: 0.002547456184402108\n",
      "        total_loss: 37.32292175292969\n",
      "        vf_explained_var: 0.005119204521179199\n",
      "        vf_loss: 37.32038116455078\n",
      "    load_time_ms: 2.442\n",
      "    num_steps_sampled: 2641600\n",
      "    num_steps_trained: 2540000\n",
      "    sample_time_ms: 5165.544\n",
      "    update_time_ms: 11.148\n",
      "  iterations_since_restore: 1016\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.9375\n",
      "    ram_util_percent: 64.58749999999999\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.14689212218595\n",
      "    mean_inference_ms: 0.9875504695307982\n",
      "    mean_processing_ms: 0.7009589103559974\n",
      "  time_since_restore: 3727.156339406967\n",
      "  time_this_iter_s: 5.8664655685424805\n",
      "  time_total_s: 3727.156339406967\n",
      "  timestamp: 1596125156\n",
      "  timesteps_since_restore: 2641600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2641600\n",
      "  training_iteration: 1016\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3727 s, 1016 iter, 2641600 ts, 482 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-06-05\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 860.5125826951629\n",
      "  episode_reward_mean: 481.7872176576475\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1055\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 53.408\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.471616506576538\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.7669080989435315e-05\n",
      "        policy_loss: 0.004845491144806147\n",
      "        total_loss: 49.819515228271484\n",
      "        vf_explained_var: 0.002810180187225342\n",
      "        vf_loss: 49.814659118652344\n",
      "    load_time_ms: 2.535\n",
      "    num_steps_sampled: 2646800\n",
      "    num_steps_trained: 2545000\n",
      "    sample_time_ms: 5034.348\n",
      "    update_time_ms: 11.783\n",
      "  iterations_since_restore: 1018\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 65.37142857142858\n",
      "    ram_util_percent: 64.67142857142856\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.14689212218595\n",
      "    mean_inference_ms: 0.9875504695307982\n",
      "    mean_processing_ms: 0.7009589103559974\n",
      "  time_since_restore: 3736.4591245651245\n",
      "  time_this_iter_s: 4.773290395736694\n",
      "  time_total_s: 3736.4591245651245\n",
      "  timestamp: 1596125165\n",
      "  timesteps_since_restore: 2646800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2646800\n",
      "  training_iteration: 1018\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3736 s, 1018 iter, 2646800 ts, 482 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-06-11\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 884.3356614709331\n",
      "  episode_reward_mean: 476.81189348380786\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 1058\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 54.312\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4700146913528442\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.649948510224931e-05\n",
      "        policy_loss: -0.0025752801448106766\n",
      "        total_loss: 32.680015563964844\n",
      "        vf_explained_var: 0.002695143222808838\n",
      "        vf_loss: 32.682594299316406\n",
      "    load_time_ms: 2.601\n",
      "    num_steps_sampled: 2649400\n",
      "    num_steps_trained: 2547500\n",
      "    sample_time_ms: 5143.543\n",
      "    update_time_ms: 11.895\n",
      "  iterations_since_restore: 1019\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.8\n",
      "    ram_util_percent: 64.725\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.152117785235651\n",
      "    mean_inference_ms: 0.9887913771279233\n",
      "    mean_processing_ms: 0.7012970791145512\n",
      "  time_since_restore: 3742.2072942256927\n",
      "  time_this_iter_s: 5.748169660568237\n",
      "  time_total_s: 3742.2072942256927\n",
      "  timestamp: 1596125171\n",
      "  timesteps_since_restore: 2649400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2649400\n",
      "  training_iteration: 1019\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3742 s, 1019 iter, 2649400 ts, 477 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-06-20\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 884.3356614709331\n",
      "  episode_reward_mean: 473.2606824002224\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1060\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 58.851\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4560626745224\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.910209590505474e-07\n",
      "        policy_loss: 0.0034763533622026443\n",
      "        total_loss: 30.79488754272461\n",
      "        vf_explained_var: 0.0041239261627197266\n",
      "        vf_loss: 30.79141616821289\n",
      "    load_time_ms: 2.617\n",
      "    num_steps_sampled: 2654600\n",
      "    num_steps_trained: 2552500\n",
      "    sample_time_ms: 5029.223\n",
      "    update_time_ms: 11.447\n",
      "  iterations_since_restore: 1021\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 65.72857142857143\n",
      "    ram_util_percent: 64.72857142857143\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.155423606206706\n",
      "    mean_inference_ms: 0.9894019704840871\n",
      "    mean_processing_ms: 0.7015302680921266\n",
      "  time_since_restore: 3751.527755022049\n",
      "  time_this_iter_s: 4.767150163650513\n",
      "  time_total_s: 3751.527755022049\n",
      "  timestamp: 1596125180\n",
      "  timesteps_since_restore: 2654600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2654600\n",
      "  training_iteration: 1021\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3751 s, 1021 iter, 2654600 ts, 473 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-06-31\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 884.3356614709331\n",
      "  episode_reward_mean: 470.9206947263417\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1061\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 62.179\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4791516065597534\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.927728577466041e-07\n",
      "        policy_loss: -0.005036517512053251\n",
      "        total_loss: 65.89998626708984\n",
      "        vf_explained_var: 0.00048792362213134766\n",
      "        vf_loss: 65.90502166748047\n",
      "    load_time_ms: 2.814\n",
      "    num_steps_sampled: 2659800\n",
      "    num_steps_trained: 2557500\n",
      "    sample_time_ms: 5083.033\n",
      "    update_time_ms: 12.118\n",
      "  iterations_since_restore: 1023\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 51.51111111111111\n",
      "    ram_util_percent: 64.82222222222224\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.157312639032927\n",
      "    mean_inference_ms: 0.9898835457128297\n",
      "    mean_processing_ms: 0.7016684338914558\n",
      "  time_since_restore: 3762.243136882782\n",
      "  time_this_iter_s: 5.835658311843872\n",
      "  time_total_s: 3762.243136882782\n",
      "  timestamp: 1596125191\n",
      "  timesteps_since_restore: 2659800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2659800\n",
      "  training_iteration: 1023\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3762 s, 1023 iter, 2659800 ts, 471 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-06-41\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 884.3356614709331\n",
      "  episode_reward_mean: 474.4545244729606\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 1065\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 54.171\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4632010459899902\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.088591478852322e-06\n",
      "        policy_loss: 0.0006404481828212738\n",
      "        total_loss: 41.02820587158203\n",
      "        vf_explained_var: 0.0044803619384765625\n",
      "        vf_loss: 41.02756118774414\n",
      "    load_time_ms: 2.265\n",
      "    num_steps_sampled: 2665000\n",
      "    num_steps_trained: 2562500\n",
      "    sample_time_ms: 5014.865\n",
      "    update_time_ms: 12.309\n",
      "  iterations_since_restore: 1025\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.724999999999994\n",
      "    ram_util_percent: 64.77499999999999\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.163928888844532\n",
      "    mean_inference_ms: 0.9912514610483062\n",
      "    mean_processing_ms: 0.7021017949788438\n",
      "  time_since_restore: 3772.307276248932\n",
      "  time_this_iter_s: 5.524169206619263\n",
      "  time_total_s: 3772.307276248932\n",
      "  timestamp: 1596125201\n",
      "  timesteps_since_restore: 2665000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2665000\n",
      "  training_iteration: 1025\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3772 s, 1025 iter, 2665000 ts, 474 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-06-50\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 884.3356614709331\n",
      "  episode_reward_mean: 474.4545244729606\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1065\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 48.804\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4687330722808838\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.980851033702493e-06\n",
      "        policy_loss: 0.0032129043247550726\n",
      "        total_loss: 56.28523635864258\n",
      "        vf_explained_var: 0.0029283761978149414\n",
      "        vf_loss: 56.282012939453125\n",
      "    load_time_ms: 2.084\n",
      "    num_steps_sampled: 2670200\n",
      "    num_steps_trained: 2567500\n",
      "    sample_time_ms: 4877.595\n",
      "    update_time_ms: 10.261\n",
      "  iterations_since_restore: 1027\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.357142857142854\n",
      "    ram_util_percent: 64.65714285714286\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.163928888844532\n",
      "    mean_inference_ms: 0.9912514610483063\n",
      "    mean_processing_ms: 0.7021017949788438\n",
      "  time_since_restore: 3781.235919713974\n",
      "  time_this_iter_s: 4.545250177383423\n",
      "  time_total_s: 3781.235919713974\n",
      "  timestamp: 1596125210\n",
      "  timesteps_since_restore: 2670200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2670200\n",
      "  training_iteration: 1027\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3781 s, 1027 iter, 2670200 ts, 474 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-06-59\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 884.3356614709331\n",
      "  episode_reward_mean: 476.39261627953135\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1067\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 45.046\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4750785827636719\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.859211920418602e-06\n",
      "        policy_loss: 0.005383512936532497\n",
      "        total_loss: 57.2322883605957\n",
      "        vf_explained_var: 0.00280076265335083\n",
      "        vf_loss: 57.22689437866211\n",
      "    load_time_ms: 1.779\n",
      "    num_steps_sampled: 2675400\n",
      "    num_steps_trained: 2572500\n",
      "    sample_time_ms: 4715.203\n",
      "    update_time_ms: 9.516\n",
      "  iterations_since_restore: 1029\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.65\n",
      "    ram_util_percent: 64.60000000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.16746854992771\n",
      "    mean_inference_ms: 0.9920863933627028\n",
      "    mean_processing_ms: 0.7023455940789889\n",
      "  time_since_restore: 3790.0816276073456\n",
      "  time_this_iter_s: 4.411150693893433\n",
      "  time_total_s: 3790.0816276073456\n",
      "  timestamp: 1596125219\n",
      "  timesteps_since_restore: 2675400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2675400\n",
      "  training_iteration: 1029\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3790 s, 1029 iter, 2675400 ts, 476 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-07-05\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 483.5383163272789\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 1070\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 44.239\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4674792289733887\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.5271425581886433e-06\n",
      "        policy_loss: 0.0016630126629024744\n",
      "        total_loss: 52.02500915527344\n",
      "        vf_explained_var: 0.002623617649078369\n",
      "        vf_loss: 52.02334213256836\n",
      "    load_time_ms: 1.774\n",
      "    num_steps_sampled: 2678000\n",
      "    num_steps_trained: 2575000\n",
      "    sample_time_ms: 4871.223\n",
      "    update_time_ms: 9.789\n",
      "  iterations_since_restore: 1030\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.41111111111112\n",
      "    ram_util_percent: 64.61111111111111\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.172276686467663\n",
      "    mean_inference_ms: 0.993062068457994\n",
      "    mean_processing_ms: 0.7026550816824291\n",
      "  time_since_restore: 3796.188647031784\n",
      "  time_this_iter_s: 6.107019424438477\n",
      "  time_total_s: 3796.188647031784\n",
      "  timestamp: 1596125225\n",
      "  timesteps_since_restore: 2678000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2678000\n",
      "  training_iteration: 1030\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3796 s, 1030 iter, 2678000 ts, 484 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-07-14\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 483.53831632727884\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1070\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 44.227\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4802908897399902\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.3320208154254942e-06\n",
      "        policy_loss: -0.0026060582604259253\n",
      "        total_loss: 92.69891357421875\n",
      "        vf_explained_var: 7.861852645874023e-05\n",
      "        vf_loss: 92.70152282714844\n",
      "    load_time_ms: 1.726\n",
      "    num_steps_sampled: 2683200\n",
      "    num_steps_trained: 2580000\n",
      "    sample_time_ms: 4793.884\n",
      "    update_time_ms: 9.474\n",
      "  iterations_since_restore: 1032\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.642857142857146\n",
      "    ram_util_percent: 64.67142857142856\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.172276686467663\n",
      "    mean_inference_ms: 0.9930620684579943\n",
      "    mean_processing_ms: 0.7026550816824289\n",
      "  time_since_restore: 3805.0525736808777\n",
      "  time_this_iter_s: 4.591869115829468\n",
      "  time_total_s: 3805.0525736808777\n",
      "  timestamp: 1596125234\n",
      "  timesteps_since_restore: 2683200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2683200\n",
      "  training_iteration: 1032\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3805 s, 1032 iter, 2683200 ts, 484 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-07-20\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 484.66554946691497\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 1072\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 41.811\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4866827726364136\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.599763774924213e-06\n",
      "        policy_loss: 0.00345993391238153\n",
      "        total_loss: 98.8471450805664\n",
      "        vf_explained_var: 0.002261638641357422\n",
      "        vf_loss: 98.84369659423828\n",
      "    load_time_ms: 1.62\n",
      "    num_steps_sampled: 2685800\n",
      "    num_steps_trained: 2582500\n",
      "    sample_time_ms: 4827.817\n",
      "    update_time_ms: 9.998\n",
      "  iterations_since_restore: 1033\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.12222222222221\n",
      "    ram_util_percent: 64.80000000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.175758623586968\n",
      "    mean_inference_ms: 0.9938844385736627\n",
      "    mean_processing_ms: 0.7029023557857932\n",
      "  time_since_restore: 3811.1966755390167\n",
      "  time_this_iter_s: 6.144101858139038\n",
      "  time_total_s: 3811.1966755390167\n",
      "  timestamp: 1596125240\n",
      "  timesteps_since_restore: 2685800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2685800\n",
      "  training_iteration: 1033\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3811 s, 1033 iter, 2685800 ts, 485 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-07-26\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 486.3644011616863\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1073\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 46.056\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4799690246582031\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.3942861187388189e-05\n",
      "        policy_loss: -0.0004140113014727831\n",
      "        total_loss: 94.25735473632812\n",
      "        vf_explained_var: 0.0017964839935302734\n",
      "        vf_loss: 94.25775146484375\n",
      "    load_time_ms: 1.782\n",
      "    num_steps_sampled: 2688400\n",
      "    num_steps_trained: 2585000\n",
      "    sample_time_ms: 5000.538\n",
      "    update_time_ms: 9.63\n",
      "  iterations_since_restore: 1034\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.42222222222222\n",
      "    ram_util_percent: 64.74444444444445\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.177407644450273\n",
      "    mean_inference_ms: 0.9942419773153026\n",
      "    mean_processing_ms: 0.7030172790145269\n",
      "  time_since_restore: 3817.5113644599915\n",
      "  time_this_iter_s: 6.3146889209747314\n",
      "  time_total_s: 3817.5113644599915\n",
      "  timestamp: 1596125246\n",
      "  timesteps_since_restore: 2688400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2688400\n",
      "  training_iteration: 1034\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3817 s, 1034 iter, 2688400 ts, 486 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-07-37\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 490.3574359486194\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1075\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 53.441\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4545080661773682\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.033138343904284e-06\n",
      "        policy_loss: 0.0013847054215148091\n",
      "        total_loss: 34.33156967163086\n",
      "        vf_explained_var: 0.005305886268615723\n",
      "        vf_loss: 34.330177307128906\n",
      "    load_time_ms: 2.005\n",
      "    num_steps_sampled: 2693600\n",
      "    num_steps_trained: 2590000\n",
      "    sample_time_ms: 5024.321\n",
      "    update_time_ms: 10.302\n",
      "  iterations_since_restore: 1036\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.237500000000004\n",
      "    ram_util_percent: 64.75\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.1806898296803805\n",
      "    mean_inference_ms: 0.9950034991837129\n",
      "    mean_processing_ms: 0.7032541711633356\n",
      "  time_since_restore: 3827.7604718208313\n",
      "  time_this_iter_s: 5.520774602890015\n",
      "  time_total_s: 3827.7604718208313\n",
      "  timestamp: 1596125257\n",
      "  timesteps_since_restore: 2693600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2693600\n",
      "  training_iteration: 1036\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3827 s, 1036 iter, 2693600 ts, 490 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-07-46\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 491.743027250035\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 1077\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 52.469\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4711970090866089\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.8676498661516234e-06\n",
      "        policy_loss: -0.00384737690910697\n",
      "        total_loss: 55.89262390136719\n",
      "        vf_explained_var: 0.002088189125061035\n",
      "        vf_loss: 55.89646911621094\n",
      "    load_time_ms: 2.025\n",
      "    num_steps_sampled: 2698800\n",
      "    num_steps_trained: 2595000\n",
      "    sample_time_ms: 5052.054\n",
      "    update_time_ms: 10.701\n",
      "  iterations_since_restore: 1038\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.24999999999999\n",
      "    ram_util_percent: 65.75\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.1841275390368\n",
      "    mean_inference_ms: 0.9956987242798283\n",
      "    mean_processing_ms: 0.7034504408352581\n",
      "  time_since_restore: 3837.0040979385376\n",
      "  time_this_iter_s: 4.665512323379517\n",
      "  time_total_s: 3837.0040979385376\n",
      "  timestamp: 1596125266\n",
      "  timesteps_since_restore: 2698800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2698800\n",
      "  training_iteration: 1038\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 11.0/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3837 s, 1038 iter, 2698800 ts, 492 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-07-51\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 491.0205849855465\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 1079\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 51.069\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4637929201126099\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.909871025418397e-05\n",
      "        policy_loss: -0.006775291636586189\n",
      "        total_loss: 40.60298156738281\n",
      "        vf_explained_var: 0.00441819429397583\n",
      "        vf_loss: 40.609764099121094\n",
      "    load_time_ms: 2.023\n",
      "    num_steps_sampled: 2701400\n",
      "    num_steps_trained: 2597500\n",
      "    sample_time_ms: 5162.099\n",
      "    update_time_ms: 10.514\n",
      "  iterations_since_restore: 1039\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.51249999999999\n",
      "    ram_util_percent: 66.75\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.1873035818346835\n",
      "    mean_inference_ms: 0.9963874948884944\n",
      "    mean_processing_ms: 0.703677232931135\n",
      "  time_since_restore: 3842.4937374591827\n",
      "  time_this_iter_s: 5.489639520645142\n",
      "  time_total_s: 3842.4937374591827\n",
      "  timestamp: 1596125271\n",
      "  timesteps_since_restore: 2701400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2701400\n",
      "  training_iteration: 1039\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 11.1/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3842 s, 1039 iter, 2701400 ts, 491 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-07-56\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 493.3273013492686\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1080\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 51.167\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4570403099060059\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.1498666026454885e-05\n",
      "        policy_loss: 0.00173848494887352\n",
      "        total_loss: 33.65144348144531\n",
      "        vf_explained_var: 0.002795279026031494\n",
      "        vf_loss: 33.64970779418945\n",
      "    load_time_ms: 2.042\n",
      "    num_steps_sampled: 2704000\n",
      "    num_steps_trained: 2600000\n",
      "    sample_time_ms: 5052.727\n",
      "    update_time_ms: 9.878\n",
      "  iterations_since_restore: 1040\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 68.67142857142858\n",
      "    ram_util_percent: 67.12857142857143\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.188848060330846\n",
      "    mean_inference_ms: 0.9967734079533652\n",
      "    mean_processing_ms: 0.7037995883010759\n",
      "  time_since_restore: 3847.502331972122\n",
      "  time_this_iter_s: 5.008594512939453\n",
      "  time_total_s: 3847.502331972122\n",
      "  timestamp: 1596125276\n",
      "  timesteps_since_restore: 2704000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2704000\n",
      "  training_iteration: 1040\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 11.1/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3847 s, 1040 iter, 2704000 ts, 493 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-08-06\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 493.3273013492686\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1080\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 48.038\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4717575311660767\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.15882868260087e-07\n",
      "        policy_loss: -0.006254149135202169\n",
      "        total_loss: 58.7424201965332\n",
      "        vf_explained_var: 0.0017327666282653809\n",
      "        vf_loss: 58.748695373535156\n",
      "    load_time_ms: 2.169\n",
      "    num_steps_sampled: 2709200\n",
      "    num_steps_trained: 2605000\n",
      "    sample_time_ms: 5170.159\n",
      "    update_time_ms: 10.191\n",
      "  iterations_since_restore: 1042\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.1625\n",
      "    ram_util_percent: 67.3\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.188848060330846\n",
      "    mean_inference_ms: 0.9967734079533653\n",
      "    mean_processing_ms: 0.7037995883010758\n",
      "  time_since_restore: 3857.507915496826\n",
      "  time_this_iter_s: 5.410106897354126\n",
      "  time_total_s: 3857.507915496826\n",
      "  timestamp: 1596125286\n",
      "  timesteps_since_restore: 2709200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2709200\n",
      "  training_iteration: 1042\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 11.1/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3857 s, 1042 iter, 2709200 ts, 493 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-08-14\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 495.45492286648846\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 1083\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 51.938\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4731658697128296\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.9968986180174397e-06\n",
      "        policy_loss: -0.0014919911045581102\n",
      "        total_loss: 53.99467468261719\n",
      "        vf_explained_var: 0.0015486478805541992\n",
      "        vf_loss: 53.99617004394531\n",
      "    load_time_ms: 2.314\n",
      "    num_steps_sampled: 2711800\n",
      "    num_steps_trained: 2607500\n",
      "    sample_time_ms: 5297.356\n",
      "    update_time_ms: 9.546\n",
      "  iterations_since_restore: 1043\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 68.99000000000001\n",
      "    ram_util_percent: 67.29999999999998\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.193680048832776\n",
      "    mean_inference_ms: 0.9978156470110126\n",
      "    mean_processing_ms: 0.7040832763556214\n",
      "  time_since_restore: 3864.971331357956\n",
      "  time_this_iter_s: 7.463415861129761\n",
      "  time_total_s: 3864.971331357956\n",
      "  timestamp: 1596125294\n",
      "  timesteps_since_restore: 2711800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2711800\n",
      "  training_iteration: 1043\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 11.1/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3864 s, 1043 iter, 2711800 ts, 495 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-08-19\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 499.4255768278506\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1084\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 48.501\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4613333940505981\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.4057140965160215e-06\n",
      "        policy_loss: -0.0024819180835038424\n",
      "        total_loss: 41.694705963134766\n",
      "        vf_explained_var: 0.005099773406982422\n",
      "        vf_loss: 41.69718933105469\n",
      "    load_time_ms: 2.36\n",
      "    num_steps_sampled: 2714400\n",
      "    num_steps_trained: 2610000\n",
      "    sample_time_ms: 5212.658\n",
      "    update_time_ms: 10.002\n",
      "  iterations_since_restore: 1044\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.22500000000001\n",
      "    ram_util_percent: 67.3\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.1954235200652565\n",
      "    mean_inference_ms: 0.9981588831917232\n",
      "    mean_processing_ms: 0.7042278898307935\n",
      "  time_since_restore: 3870.4002952575684\n",
      "  time_this_iter_s: 5.428963899612427\n",
      "  time_total_s: 3870.4002952575684\n",
      "  timestamp: 1596125299\n",
      "  timesteps_since_restore: 2714400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2714400\n",
      "  training_iteration: 1044\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 11.1/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3870 s, 1044 iter, 2714400 ts, 499 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-08-25\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 504.17913452667875\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1085\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 43.648\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4658479690551758\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.099275661748834e-06\n",
      "        policy_loss: 0.0026583573780953884\n",
      "        total_loss: 60.68489456176758\n",
      "        vf_explained_var: 0.002522587776184082\n",
      "        vf_loss: 60.68223190307617\n",
      "    load_time_ms: 2.229\n",
      "    num_steps_sampled: 2717000\n",
      "    num_steps_trained: 2612500\n",
      "    sample_time_ms: 5299.711\n",
      "    update_time_ms: 9.294\n",
      "  iterations_since_restore: 1045\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.5625\n",
      "    ram_util_percent: 67.39999999999999\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.196975275630088\n",
      "    mean_inference_ms: 0.9985493280377004\n",
      "    mean_processing_ms: 0.7043509367541739\n",
      "  time_since_restore: 3875.9275529384613\n",
      "  time_this_iter_s: 5.527257680892944\n",
      "  time_total_s: 3875.9275529384613\n",
      "  timestamp: 1596125305\n",
      "  timesteps_since_restore: 2717000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2717000\n",
      "  training_iteration: 1045\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 11.1/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3875 s, 1045 iter, 2717000 ts, 504 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-08-35\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 509.34831404164436\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1086\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 45.912\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4768149852752686\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.914855137234554e-06\n",
      "        policy_loss: 0.0008180229342542589\n",
      "        total_loss: 60.18553161621094\n",
      "        vf_explained_var: 0.0016716718673706055\n",
      "        vf_loss: 60.18471145629883\n",
      "    load_time_ms: 2.275\n",
      "    num_steps_sampled: 2722200\n",
      "    num_steps_trained: 2617500\n",
      "    sample_time_ms: 5328.372\n",
      "    update_time_ms: 8.504\n",
      "  iterations_since_restore: 1047\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.1888888888889\n",
      "    ram_util_percent: 64.91111111111111\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.198978073605181\n",
      "    mean_inference_ms: 0.9990204073247277\n",
      "    mean_processing_ms: 0.7045127483213868\n",
      "  time_since_restore: 3886.3368554115295\n",
      "  time_this_iter_s: 6.0323486328125\n",
      "  time_total_s: 3886.3368554115295\n",
      "  timestamp: 1596125315\n",
      "  timesteps_since_restore: 2722200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2722200\n",
      "  training_iteration: 1047\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3886 s, 1047 iter, 2722200 ts, 509 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-08-41\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 507.26119442332396\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 1088\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 44.091\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4763222932815552\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.4654141245482606e-07\n",
      "        policy_loss: -0.006328239571303129\n",
      "        total_loss: 61.65468215942383\n",
      "        vf_explained_var: 0.0016179084777832031\n",
      "        vf_loss: 61.660987854003906\n",
      "    load_time_ms: 2.207\n",
      "    num_steps_sampled: 2724800\n",
      "    num_steps_trained: 2620000\n",
      "    sample_time_ms: 5425.304\n",
      "    update_time_ms: 8.56\n",
      "  iterations_since_restore: 1048\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.125\n",
      "    ram_util_percent: 64.8625\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.201963686115352\n",
      "    mean_inference_ms: 0.9995932200070822\n",
      "    mean_processing_ms: 0.7046635274310468\n",
      "  time_since_restore: 3891.9493284225464\n",
      "  time_this_iter_s: 5.612473011016846\n",
      "  time_total_s: 3891.9493284225464\n",
      "  timestamp: 1596125321\n",
      "  timesteps_since_restore: 2724800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2724800\n",
      "  training_iteration: 1048\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3891 s, 1048 iter, 2724800 ts, 507 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-08-51\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 510.7861947397082\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1090\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 43.725\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4689728021621704\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.7639637235333794e-06\n",
      "        policy_loss: 0.0014634510735049844\n",
      "        total_loss: 53.029449462890625\n",
      "        vf_explained_var: 0.003868579864501953\n",
      "        vf_loss: 53.02798843383789\n",
      "    load_time_ms: 2.174\n",
      "    num_steps_sampled: 2730000\n",
      "    num_steps_trained: 2625000\n",
      "    sample_time_ms: 5374.152\n",
      "    update_time_ms: 8.965\n",
      "  iterations_since_restore: 1050\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.7625\n",
      "    ram_util_percent: 64.7\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.205228637214929\n",
      "    mean_inference_ms: 1.000272334320993\n",
      "    mean_processing_ms: 0.7049053847442877\n",
      "  time_since_restore: 3901.936747789383\n",
      "  time_this_iter_s: 5.724193572998047\n",
      "  time_total_s: 3901.936747789383\n",
      "  timestamp: 1596125331\n",
      "  timesteps_since_restore: 2730000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2730000\n",
      "  training_iteration: 1050\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3901 s, 1050 iter, 2730000 ts, 511 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-09-00\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 512.1692772273632\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1091\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 46.697\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4763773679733276\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.5933971958002076e-06\n",
      "        policy_loss: -0.0005111959180794656\n",
      "        total_loss: 61.20354461669922\n",
      "        vf_explained_var: 0.002209305763244629\n",
      "        vf_loss: 61.20405578613281\n",
      "    load_time_ms: 2.13\n",
      "    num_steps_sampled: 2735200\n",
      "    num_steps_trained: 2630000\n",
      "    sample_time_ms: 5297.041\n",
      "    update_time_ms: 8.578\n",
      "  iterations_since_restore: 1052\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.74285714285714\n",
      "    ram_util_percent: 64.75714285714285\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.206846246538688\n",
      "    mean_inference_ms: 1.0006281779954147\n",
      "    mean_processing_ms: 0.7050091273624852\n",
      "  time_since_restore: 3911.1985738277435\n",
      "  time_this_iter_s: 4.396644830703735\n",
      "  time_total_s: 3911.1985738277435\n",
      "  timestamp: 1596125340\n",
      "  timesteps_since_restore: 2735200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2735200\n",
      "  training_iteration: 1052\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3911 s, 1052 iter, 2735200 ts, 512 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-09-06\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 517.0484926392343\n",
      "  episode_reward_min: 158.68399777397497\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 1094\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 42.57\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4696615934371948\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.0465374745981535e-06\n",
      "        policy_loss: -0.0021052544470876455\n",
      "        total_loss: 43.22589874267578\n",
      "        vf_explained_var: 0.0025652050971984863\n",
      "        vf_loss: 43.22800827026367\n",
      "    load_time_ms: 1.993\n",
      "    num_steps_sampled: 2737800\n",
      "    num_steps_trained: 2632500\n",
      "    sample_time_ms: 5108.233\n",
      "    update_time_ms: 8.308\n",
      "  iterations_since_restore: 1053\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.41428571428571\n",
      "    ram_util_percent: 64.81428571428572\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.211523725159208\n",
      "    mean_inference_ms: 1.0016926998247289\n",
      "    mean_processing_ms: 0.705311497445756\n",
      "  time_since_restore: 3916.715040922165\n",
      "  time_this_iter_s: 5.516467094421387\n",
      "  time_total_s: 3916.715040922165\n",
      "  timestamp: 1596125346\n",
      "  timesteps_since_restore: 2737800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2737800\n",
      "  training_iteration: 1053\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3916 s, 1053 iter, 2737800 ts, 517 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-09-15\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 520.3957273675925\n",
      "  episode_reward_min: 221.34208940978556\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1095\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 45.654\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4608893394470215\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.4001809246528865e-08\n",
      "        policy_loss: -0.0004984012339264154\n",
      "        total_loss: 27.679943084716797\n",
      "        vf_explained_var: 0.0027279257774353027\n",
      "        vf_loss: 27.680442810058594\n",
      "    load_time_ms: 1.858\n",
      "    num_steps_sampled: 2743000\n",
      "    num_steps_trained: 2637500\n",
      "    sample_time_ms: 4906.487\n",
      "    update_time_ms: 8.655\n",
      "  iterations_since_restore: 1055\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.550000000000004\n",
      "    ram_util_percent: 64.7\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.21304013467883\n",
      "    mean_inference_ms: 1.0020776983218291\n",
      "    mean_processing_ms: 0.7054309397430761\n",
      "  time_since_restore: 3925.7014169692993\n",
      "  time_this_iter_s: 4.338183879852295\n",
      "  time_total_s: 3925.7014169692993\n",
      "  timestamp: 1596125355\n",
      "  timesteps_since_restore: 2743000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2743000\n",
      "  training_iteration: 1055\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3925 s, 1055 iter, 2743000 ts, 520 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-09-20\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 518.0572370018358\n",
      "  episode_reward_min: 221.34208940978556\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1096\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 40.36\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4598400592803955\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.1829614550151746e-06\n",
      "        policy_loss: 0.0028724647127091885\n",
      "        total_loss: 22.109811782836914\n",
      "        vf_explained_var: 0.004054129123687744\n",
      "        vf_loss: 22.106937408447266\n",
      "    load_time_ms: 1.697\n",
      "    num_steps_sampled: 2745600\n",
      "    num_steps_trained: 2640000\n",
      "    sample_time_ms: 5031.653\n",
      "    update_time_ms: 9.438\n",
      "  iterations_since_restore: 1056\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.0\n",
      "    ram_util_percent: 64.7\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.21461817057861\n",
      "    mean_inference_ms: 1.0024245015195643\n",
      "    mean_processing_ms: 0.7055345829040369\n",
      "  time_since_restore: 3931.2677295207977\n",
      "  time_this_iter_s: 5.566312551498413\n",
      "  time_total_s: 3931.2677295207977\n",
      "  timestamp: 1596125360\n",
      "  timesteps_since_restore: 2745600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2745600\n",
      "  training_iteration: 1056\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3931 s, 1056 iter, 2745600 ts, 518 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-09-31\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 514.8490380765404\n",
      "  episode_reward_min: 221.34208940978556\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 1099\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 45.195\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.464482307434082\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 9.76753199211089e-07\n",
      "        policy_loss: 0.0006146708619780838\n",
      "        total_loss: 36.88572311401367\n",
      "        vf_explained_var: 0.0026139020919799805\n",
      "        vf_loss: 36.885101318359375\n",
      "    load_time_ms: 1.793\n",
      "    num_steps_sampled: 2750800\n",
      "    num_steps_trained: 2645000\n",
      "    sample_time_ms: 4881.655\n",
      "    update_time_ms: 9.54\n",
      "  iterations_since_restore: 1058\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.45555555555555\n",
      "    ram_util_percent: 64.75555555555555\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.219426031469067\n",
      "    mean_inference_ms: 1.0034299831919395\n",
      "    mean_processing_ms: 0.7058384995704814\n",
      "  time_since_restore: 3941.478210926056\n",
      "  time_this_iter_s: 5.914232969284058\n",
      "  time_total_s: 3941.478210926056\n",
      "  timestamp: 1596125371\n",
      "  timesteps_since_restore: 2750800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2750800\n",
      "  training_iteration: 1058\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3941 s, 1058 iter, 2750800 ts, 515 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-09-39\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 514.8490380765403\n",
      "  episode_reward_min: 221.34208940978556\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1099\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 45.797\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.462918758392334\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.6292523115407676e-06\n",
      "        policy_loss: 0.0036004860885441303\n",
      "        total_loss: 28.372106552124023\n",
      "        vf_explained_var: 0.0039196014404296875\n",
      "        vf_loss: 28.368499755859375\n",
      "    load_time_ms: 1.838\n",
      "    num_steps_sampled: 2756000\n",
      "    num_steps_trained: 2650000\n",
      "    sample_time_ms: 4762.468\n",
      "    update_time_ms: 9.021\n",
      "  iterations_since_restore: 1060\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.16666666666666\n",
      "    ram_util_percent: 64.76666666666667\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.219426031469066\n",
      "    mean_inference_ms: 1.0034299831919395\n",
      "    mean_processing_ms: 0.7058384995704814\n",
      "  time_since_restore: 3950.2737896442413\n",
      "  time_this_iter_s: 4.288473844528198\n",
      "  time_total_s: 3950.2737896442413\n",
      "  timestamp: 1596125379\n",
      "  timesteps_since_restore: 2756000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2756000\n",
      "  training_iteration: 1060\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3950 s, 1060 iter, 2756000 ts, 515 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-09-51\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 514.1556805379444\n",
      "  episode_reward_min: 221.34208940978556\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 1103\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 48.355\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4603486061096191\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.8129348688944447e-07\n",
      "        policy_loss: 0.005095907486975193\n",
      "        total_loss: 24.96377182006836\n",
      "        vf_explained_var: 0.0039907097816467285\n",
      "        vf_loss: 24.958677291870117\n",
      "    load_time_ms: 1.904\n",
      "    num_steps_sampled: 2761200\n",
      "    num_steps_trained: 2655000\n",
      "    sample_time_ms: 4938.601\n",
      "    update_time_ms: 9.389\n",
      "  iterations_since_restore: 1062\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.43333333333334\n",
      "    ram_util_percent: 64.76666666666668\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.225549214588863\n",
      "    mean_inference_ms: 1.0048253156872038\n",
      "    mean_processing_ms: 0.70627960594869\n",
      "  time_since_restore: 3961.3373715877533\n",
      "  time_this_iter_s: 6.277655124664307\n",
      "  time_total_s: 3961.3373715877533\n",
      "  timestamp: 1596125391\n",
      "  timesteps_since_restore: 2761200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2761200\n",
      "  training_iteration: 1062\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3961 s, 1062 iter, 2761200 ts, 514 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-10-00\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 513.8331051712829\n",
      "  episode_reward_min: 221.34208940978556\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1104\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 52.301\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.458111047744751\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 9.906291609240725e-08\n",
      "        policy_loss: 0.003297648159787059\n",
      "        total_loss: 39.5194091796875\n",
      "        vf_explained_var: 0.0015006065368652344\n",
      "        vf_loss: 39.51610565185547\n",
      "    load_time_ms: 1.989\n",
      "    num_steps_sampled: 2766400\n",
      "    num_steps_trained: 2660000\n",
      "    sample_time_ms: 4852.119\n",
      "    update_time_ms: 10.131\n",
      "  iterations_since_restore: 1064\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.67142857142857\n",
      "    ram_util_percent: 64.74285714285715\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.227271659607149\n",
      "    mean_inference_ms: 1.0051538181719823\n",
      "    mean_processing_ms: 0.7063671310852758\n",
      "  time_since_restore: 3970.6968455314636\n",
      "  time_this_iter_s: 4.815359592437744\n",
      "  time_total_s: 3970.6968455314636\n",
      "  timestamp: 1596125400\n",
      "  timesteps_since_restore: 2766400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2766400\n",
      "  training_iteration: 1064\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3970 s, 1064 iter, 2766400 ts, 514 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-10-09\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 512.0497611524412\n",
      "  episode_reward_min: 221.34208940978556\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 1106\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 57.067\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4715503454208374\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.8431408029282466e-06\n",
      "        policy_loss: 0.0004202011041343212\n",
      "        total_loss: 48.8072395324707\n",
      "        vf_explained_var: 0.0038944482803344727\n",
      "        vf_loss: 48.80682373046875\n",
      "    load_time_ms: 2.288\n",
      "    num_steps_sampled: 2771600\n",
      "    num_steps_trained: 2665000\n",
      "    sample_time_ms: 4796.131\n",
      "    update_time_ms: 10.207\n",
      "  iterations_since_restore: 1066\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.542857142857144\n",
      "    ram_util_percent: 64.71428571428571\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.230760110706333\n",
      "    mean_inference_ms: 1.0059518733125297\n",
      "    mean_processing_ms: 0.7066211664110689\n",
      "  time_since_restore: 3980.102501630783\n",
      "  time_this_iter_s: 4.692605257034302\n",
      "  time_total_s: 3980.102501630783\n",
      "  timestamp: 1596125409\n",
      "  timesteps_since_restore: 2771600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2771600\n",
      "  training_iteration: 1066\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3980 s, 1066 iter, 2771600 ts, 512 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-10-15\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 515.8016345849051\n",
      "  episode_reward_min: 221.34208940978556\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 1108\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 53.208\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4633792638778687\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.192069021271891e-06\n",
      "        policy_loss: 0.0051371073350310326\n",
      "        total_loss: 30.43077850341797\n",
      "        vf_explained_var: 0.004628002643585205\n",
      "        vf_loss: 30.425640106201172\n",
      "    load_time_ms: 2.201\n",
      "    num_steps_sampled: 2774200\n",
      "    num_steps_trained: 2667500\n",
      "    sample_time_ms: 4916.638\n",
      "    update_time_ms: 10.571\n",
      "  iterations_since_restore: 1067\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.175\n",
      "    ram_util_percent: 64.73750000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.233395269763134\n",
      "    mean_inference_ms: 1.0065450598403982\n",
      "    mean_processing_ms: 0.7068035003720737\n",
      "  time_since_restore: 3985.560149669647\n",
      "  time_this_iter_s: 5.457648038864136\n",
      "  time_total_s: 3985.560149669647\n",
      "  timestamp: 1596125415\n",
      "  timesteps_since_restore: 2774200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2774200\n",
      "  training_iteration: 1067\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3985 s, 1067 iter, 2774200 ts, 516 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-10-24\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 518.9158235227627\n",
      "  episode_reward_min: 221.34208940978556\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1109\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 53.924\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4549477100372314\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.6243934624071699e-06\n",
      "        policy_loss: 0.0099778538569808\n",
      "        total_loss: 26.175962448120117\n",
      "        vf_explained_var: 0.0031381845474243164\n",
      "        vf_loss: 26.16599464416504\n",
      "    load_time_ms: 2.198\n",
      "    num_steps_sampled: 2779400\n",
      "    num_steps_trained: 2672500\n",
      "    sample_time_ms: 4781.859\n",
      "    update_time_ms: 9.951\n",
      "  iterations_since_restore: 1069\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 65.05714285714286\n",
      "    ram_util_percent: 64.8\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.2351126893298945\n",
      "    mean_inference_ms: 1.0068699231773308\n",
      "    mean_processing_ms: 0.7068891335292811\n",
      "  time_since_restore: 3994.6441247463226\n",
      "  time_this_iter_s: 5.012018918991089\n",
      "  time_total_s: 3994.6441247463226\n",
      "  timestamp: 1596125424\n",
      "  timesteps_since_restore: 2779400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2779400\n",
      "  training_iteration: 1069\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 3994 s, 1069 iter, 2779400 ts, 519 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-10-30\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 514.0248488328618\n",
      "  episode_reward_min: 221.34208940978556\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1110\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 57.228\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4624905586242676\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.520105332834646e-07\n",
      "        policy_loss: 0.004679720848798752\n",
      "        total_loss: 29.97133445739746\n",
      "        vf_explained_var: 0.001301407814025879\n",
      "        vf_loss: 29.966655731201172\n",
      "    load_time_ms: 2.353\n",
      "    num_steps_sampled: 2782000\n",
      "    num_steps_trained: 2675000\n",
      "    sample_time_ms: 4897.293\n",
      "    update_time_ms: 10.211\n",
      "  iterations_since_restore: 1070\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.0375\n",
      "    ram_util_percent: 64.7125\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.237082629373936\n",
      "    mean_inference_ms: 1.0073356421969075\n",
      "    mean_processing_ms: 0.7070454349604718\n",
      "  time_since_restore: 4000.1325483322144\n",
      "  time_this_iter_s: 5.488423585891724\n",
      "  time_total_s: 4000.1325483322144\n",
      "  timestamp: 1596125430\n",
      "  timesteps_since_restore: 2782000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2782000\n",
      "  training_iteration: 1070\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4000 s, 1070 iter, 2782000 ts, 514 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-10-40\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 509.55486187321725\n",
      "  episode_reward_min: 221.34208940978556\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 1114\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 53.818\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4637231826782227\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.1743516021597316e-07\n",
      "        policy_loss: -0.00031688495073467493\n",
      "        total_loss: 37.44984817504883\n",
      "        vf_explained_var: 0.001681208610534668\n",
      "        vf_loss: 37.450164794921875\n",
      "    load_time_ms: 2.284\n",
      "    num_steps_sampled: 2787200\n",
      "    num_steps_trained: 2680000\n",
      "    sample_time_ms: 4800.058\n",
      "    update_time_ms: 10.607\n",
      "  iterations_since_restore: 1072\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.4375\n",
      "    ram_util_percent: 64.76249999999999\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.242884041914882\n",
      "    mean_inference_ms: 1.0085749495263558\n",
      "    mean_processing_ms: 0.7074068923797491\n",
      "  time_since_restore: 4010.1861503124237\n",
      "  time_this_iter_s: 5.5748186111450195\n",
      "  time_total_s: 4010.1861503124237\n",
      "  timestamp: 1596125440\n",
      "  timesteps_since_restore: 2787200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2787200\n",
      "  training_iteration: 1072\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4010 s, 1072 iter, 2787200 ts, 510 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-10-45\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 509.55486187321725\n",
      "  episode_reward_min: 221.34208940978556\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1114\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 54.829\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4498661756515503\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.182525590427758e-08\n",
      "        policy_loss: -0.0038257979322224855\n",
      "        total_loss: 22.701953887939453\n",
      "        vf_explained_var: 0.005640268325805664\n",
      "        vf_loss: 22.70578384399414\n",
      "    load_time_ms: 2.421\n",
      "    num_steps_sampled: 2789800\n",
      "    num_steps_trained: 2682500\n",
      "    sample_time_ms: 4855.298\n",
      "    update_time_ms: 9.896\n",
      "  iterations_since_restore: 1073\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.125\n",
      "    ram_util_percent: 64.725\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.242884041914883\n",
      "    mean_inference_ms: 1.0085749495263558\n",
      "    mean_processing_ms: 0.7074068923797492\n",
      "  time_since_restore: 4015.2851679325104\n",
      "  time_this_iter_s: 5.09901762008667\n",
      "  time_total_s: 4015.2851679325104\n",
      "  timestamp: 1596125445\n",
      "  timesteps_since_restore: 2789800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2789800\n",
      "  training_iteration: 1073\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4015 s, 1073 iter, 2789800 ts, 510 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-10-50\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 509.55486187321725\n",
      "  episode_reward_min: 221.34208940978556\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1114\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 53.719\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4544003009796143\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.1905898961449566e-07\n",
      "        policy_loss: 0.004595388192683458\n",
      "        total_loss: 22.680370330810547\n",
      "        vf_explained_var: 0.0012102127075195312\n",
      "        vf_loss: 22.675777435302734\n",
      "    load_time_ms: 2.351\n",
      "    num_steps_sampled: 2792400\n",
      "    num_steps_trained: 2685000\n",
      "    sample_time_ms: 4924.232\n",
      "    update_time_ms: 9.9\n",
      "  iterations_since_restore: 1074\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.25714285714286\n",
      "    ram_util_percent: 64.7\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.242884041914883\n",
      "    mean_inference_ms: 1.0085749495263558\n",
      "    mean_processing_ms: 0.7074068923797492\n",
      "  time_since_restore: 4020.776045322418\n",
      "  time_this_iter_s: 5.490877389907837\n",
      "  time_total_s: 4020.776045322418\n",
      "  timestamp: 1596125450\n",
      "  timesteps_since_restore: 2792400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2792400\n",
      "  training_iteration: 1074\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4020 s, 1074 iter, 2792400 ts, 510 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-11-00\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 511.41487025548065\n",
      "  episode_reward_min: 229.4382216915332\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1116\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 52.137\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4596070051193237\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 7.628011644555954e-06\n",
      "        policy_loss: 0.003683973802253604\n",
      "        total_loss: 26.27736473083496\n",
      "        vf_explained_var: 0.0053827762603759766\n",
      "        vf_loss: 26.273683547973633\n",
      "    load_time_ms: 2.228\n",
      "    num_steps_sampled: 2797600\n",
      "    num_steps_trained: 2690000\n",
      "    sample_time_ms: 4949.707\n",
      "    update_time_ms: 10.175\n",
      "  iterations_since_restore: 1076\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.22857142857141\n",
      "    ram_util_percent: 64.8\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.246080437546423\n",
      "    mean_inference_ms: 1.0093953274961516\n",
      "    mean_processing_ms: 0.7076428422506388\n",
      "  time_since_restore: 4030.4185268878937\n",
      "  time_this_iter_s: 4.812661409378052\n",
      "  time_total_s: 4030.4185268878937\n",
      "  timestamp: 1596125460\n",
      "  timesteps_since_restore: 2797600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2797600\n",
      "  training_iteration: 1076\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4030 s, 1076 iter, 2797600 ts, 511 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-11-06\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 507.2827189782732\n",
      "  episode_reward_min: 229.4382216915332\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 1119\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 52.639\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4507067203521729\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.1705160432029516e-06\n",
      "        policy_loss: 0.0016875186702236533\n",
      "        total_loss: 14.02872371673584\n",
      "        vf_explained_var: 0.003594040870666504\n",
      "        vf_loss: 14.027034759521484\n",
      "    load_time_ms: 2.225\n",
      "    num_steps_sampled: 2800200\n",
      "    num_steps_trained: 2692500\n",
      "    sample_time_ms: 5012.708\n",
      "    update_time_ms: 9.92\n",
      "  iterations_since_restore: 1077\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.65555555555555\n",
      "    ram_util_percent: 64.77777777777777\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.25059388749326\n",
      "    mean_inference_ms: 1.0102675671405148\n",
      "    mean_processing_ms: 0.707912735388344\n",
      "  time_since_restore: 4036.5081820487976\n",
      "  time_this_iter_s: 6.089655160903931\n",
      "  time_total_s: 4036.5081820487976\n",
      "  timestamp: 1596125466\n",
      "  timesteps_since_restore: 2800200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2800200\n",
      "  training_iteration: 1077\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4036 s, 1077 iter, 2800200 ts, 507 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-11-15\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 507.2827189782731\n",
      "  episode_reward_min: 229.4382216915332\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1119\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 56.492\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4556206464767456\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.407737487279519e-07\n",
      "        policy_loss: -0.003947692923247814\n",
      "        total_loss: 28.51411247253418\n",
      "        vf_explained_var: 0.002434968948364258\n",
      "        vf_loss: 28.51805877685547\n",
      "    load_time_ms: 2.446\n",
      "    num_steps_sampled: 2805400\n",
      "    num_steps_trained: 2697500\n",
      "    sample_time_ms: 4977.813\n",
      "    update_time_ms: 10.376\n",
      "  iterations_since_restore: 1079\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.28333333333334\n",
      "    ram_util_percent: 64.8\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.25059388749326\n",
      "    mean_inference_ms: 1.0102675671405148\n",
      "    mean_processing_ms: 0.707912735388344\n",
      "  time_since_restore: 4045.2870483398438\n",
      "  time_this_iter_s: 4.289055109024048\n",
      "  time_total_s: 4045.2870483398438\n",
      "  timestamp: 1596125475\n",
      "  timesteps_since_restore: 2805400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2805400\n",
      "  training_iteration: 1079\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4045 s, 1079 iter, 2805400 ts, 507 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-11-20\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 504.8112939009027\n",
      "  episode_reward_min: 229.4382216915332\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1120\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 57.486\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4605172872543335\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 9.89317868516082e-07\n",
      "        policy_loss: -0.0029662305023521185\n",
      "        total_loss: 27.995943069458008\n",
      "        vf_explained_var: 0.0011996030807495117\n",
      "        vf_loss: 27.99890899658203\n",
      "    load_time_ms: 2.456\n",
      "    num_steps_sampled: 2808000\n",
      "    num_steps_trained: 2700000\n",
      "    sample_time_ms: 4937.227\n",
      "    update_time_ms: 10.459\n",
      "  iterations_since_restore: 1080\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.31249999999999\n",
      "    ram_util_percent: 64.8\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.252526907075716\n",
      "    mean_inference_ms: 1.0107250564307089\n",
      "    mean_processing_ms: 0.708065917305512\n",
      "  time_since_restore: 4050.384072303772\n",
      "  time_this_iter_s: 5.097023963928223\n",
      "  time_total_s: 4050.384072303772\n",
      "  timestamp: 1596125480\n",
      "  timesteps_since_restore: 2808000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2808000\n",
      "  training_iteration: 1080\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4050 s, 1080 iter, 2808000 ts, 505 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-11-26\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 499.5315377002911\n",
      "  episode_reward_min: 229.4382216915332\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 1123\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 57.66\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4606801271438599\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.421756552299485e-06\n",
      "        policy_loss: 0.0034478595480322838\n",
      "        total_loss: 22.038393020629883\n",
      "        vf_explained_var: 0.0015857219696044922\n",
      "        vf_loss: 22.034942626953125\n",
      "    load_time_ms: 2.516\n",
      "    num_steps_sampled: 2810600\n",
      "    num_steps_trained: 2702500\n",
      "    sample_time_ms: 5069.655\n",
      "    update_time_ms: 10.692\n",
      "  iterations_since_restore: 1081\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.775\n",
      "    ram_util_percent: 64.75\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.256684079342809\n",
      "    mean_inference_ms: 1.011605484368408\n",
      "    mean_processing_ms: 0.7083168225789173\n",
      "  time_since_restore: 4056.1978013515472\n",
      "  time_this_iter_s: 5.8137290477752686\n",
      "  time_total_s: 4056.1978013515472\n",
      "  timestamp: 1596125486\n",
      "  timesteps_since_restore: 2810600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2810600\n",
      "  training_iteration: 1081\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4056 s, 1081 iter, 2810600 ts, 500 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-11-36\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 498.3240792356711\n",
      "  episode_reward_min: 229.4382216915332\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1124\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 59.367\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4555569887161255\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.942583243268018e-07\n",
      "        policy_loss: -0.001052295439876616\n",
      "        total_loss: 37.10064697265625\n",
      "        vf_explained_var: 0.0033627748489379883\n",
      "        vf_loss: 37.10170364379883\n",
      "    load_time_ms: 2.46\n",
      "    num_steps_sampled: 2815800\n",
      "    num_steps_trained: 2707500\n",
      "    sample_time_ms: 4970.153\n",
      "    update_time_ms: 11.693\n",
      "  iterations_since_restore: 1083\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.412499999999994\n",
      "    ram_util_percent: 64.6875\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.258216300237591\n",
      "    mean_inference_ms: 1.011942964797079\n",
      "    mean_processing_ms: 0.7084159049528961\n",
      "  time_since_restore: 4065.9044094085693\n",
      "  time_this_iter_s: 5.4815709590911865\n",
      "  time_total_s: 4065.9044094085693\n",
      "  timestamp: 1596125496\n",
      "  timesteps_since_restore: 2815800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2815800\n",
      "  training_iteration: 1083\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4065 s, 1083 iter, 2815800 ts, 498 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-11-41\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 498.3240792356711\n",
      "  episode_reward_min: 229.4382216915332\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1124\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 60.915\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.459098219871521\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.1163712088091415e-06\n",
      "        policy_loss: -0.0026378303300589323\n",
      "        total_loss: 36.006103515625\n",
      "        vf_explained_var: 0.002684295177459717\n",
      "        vf_loss: 36.00874328613281\n",
      "    load_time_ms: 2.533\n",
      "    num_steps_sampled: 2818400\n",
      "    num_steps_trained: 2710000\n",
      "    sample_time_ms: 4965.855\n",
      "    update_time_ms: 11.029\n",
      "  iterations_since_restore: 1084\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.5875\n",
      "    ram_util_percent: 64.6\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.258216300237591\n",
      "    mean_inference_ms: 1.011942964797079\n",
      "    mean_processing_ms: 0.7084159049528961\n",
      "  time_since_restore: 4071.367738008499\n",
      "  time_this_iter_s: 5.46332859992981\n",
      "  time_total_s: 4071.367738008499\n",
      "  timestamp: 1596125501\n",
      "  timesteps_since_restore: 2818400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2818400\n",
      "  training_iteration: 1084\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4071 s, 1084 iter, 2818400 ts, 498 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-11-46\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 501.3021484063902\n",
      "  episode_reward_min: 229.4382216915332\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1125\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 58.265\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4652363061904907\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.105829131935025e-06\n",
      "        policy_loss: 0.001251008827239275\n",
      "        total_loss: 34.72962951660156\n",
      "        vf_explained_var: 0.0020173192024230957\n",
      "        vf_loss: 34.72837829589844\n",
      "    load_time_ms: 2.451\n",
      "    num_steps_sampled: 2821000\n",
      "    num_steps_trained: 2712500\n",
      "    sample_time_ms: 4996.532\n",
      "    update_time_ms: 10.746\n",
      "  iterations_since_restore: 1085\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.528571428571425\n",
      "    ram_util_percent: 64.60000000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.2601445083551095\n",
      "    mean_inference_ms: 1.012398249841259\n",
      "    mean_processing_ms: 0.7085687584972478\n",
      "  time_since_restore: 4076.46467256546\n",
      "  time_this_iter_s: 5.09693455696106\n",
      "  time_total_s: 4076.46467256546\n",
      "  timestamp: 1596125506\n",
      "  timesteps_since_restore: 2821000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2821000\n",
      "  training_iteration: 1085\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4076 s, 1085 iter, 2821000 ts, 501 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-11-52\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 500.6056612531328\n",
      "  episode_reward_min: 206.60878524365535\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 1129\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 54.827\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.468741536140442\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.5884618228010368e-06\n",
      "        policy_loss: -0.004415305331349373\n",
      "        total_loss: 45.187522888183594\n",
      "        vf_explained_var: 0.002371490001678467\n",
      "        vf_loss: 45.19193649291992\n",
      "    load_time_ms: 2.324\n",
      "    num_steps_sampled: 2823600\n",
      "    num_steps_trained: 2715000\n",
      "    sample_time_ms: 5052.299\n",
      "    update_time_ms: 10.246\n",
      "  iterations_since_restore: 1086\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 51.5875\n",
      "    ram_util_percent: 64.65\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.265808886847001\n",
      "    mean_inference_ms: 1.0136107474265843\n",
      "    mean_processing_ms: 0.7089125135402586\n",
      "  time_since_restore: 4081.786950111389\n",
      "  time_this_iter_s: 5.322277545928955\n",
      "  time_total_s: 4081.786950111389\n",
      "  timestamp: 1596125512\n",
      "  timesteps_since_restore: 2823600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2823600\n",
      "  training_iteration: 1086\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4081 s, 1086 iter, 2823600 ts, 501 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-11-57\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 500.60566125313284\n",
      "  episode_reward_min: 206.60878524365535\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1129\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 59.476\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4453160762786865\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.438825602752331e-07\n",
      "        policy_loss: -0.0041356440633535385\n",
      "        total_loss: 11.313042640686035\n",
      "        vf_explained_var: 0.006244242191314697\n",
      "        vf_loss: 11.317176818847656\n",
      "    load_time_ms: 2.518\n",
      "    num_steps_sampled: 2826200\n",
      "    num_steps_trained: 2717500\n",
      "    sample_time_ms: 4957.05\n",
      "    update_time_ms: 9.761\n",
      "  iterations_since_restore: 1087\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.55714285714286\n",
      "    ram_util_percent: 64.60000000000001\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.265808886847001\n",
      "    mean_inference_ms: 1.013610747426584\n",
      "    mean_processing_ms: 0.7089125135402584\n",
      "  time_since_restore: 4086.981648206711\n",
      "  time_this_iter_s: 5.194698095321655\n",
      "  time_total_s: 4086.981648206711\n",
      "  timestamp: 1596125517\n",
      "  timesteps_since_restore: 2826200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2826200\n",
      "  training_iteration: 1087\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4086 s, 1087 iter, 2826200 ts, 501 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-12-02\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 500.60566125313284\n",
      "  episode_reward_min: 206.60878524365535\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1129\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 59.927\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.453578233718872\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 7.0095063087194376e-09\n",
      "        policy_loss: 0.0013931564753875136\n",
      "        total_loss: 22.361312866210938\n",
      "        vf_explained_var: 0.002789914608001709\n",
      "        vf_loss: 22.35991668701172\n",
      "    load_time_ms: 2.599\n",
      "    num_steps_sampled: 2828800\n",
      "    num_steps_trained: 2720000\n",
      "    sample_time_ms: 5052.557\n",
      "    update_time_ms: 10.737\n",
      "  iterations_since_restore: 1088\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.58749999999999\n",
      "    ram_util_percent: 64.65\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.265808886847001\n",
      "    mean_inference_ms: 1.013610747426584\n",
      "    mean_processing_ms: 0.7089125135402584\n",
      "  time_since_restore: 4092.443872451782\n",
      "  time_this_iter_s: 5.462224245071411\n",
      "  time_total_s: 4092.443872451782\n",
      "  timestamp: 1596125522\n",
      "  timesteps_since_restore: 2828800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2828800\n",
      "  training_iteration: 1088\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4092 s, 1088 iter, 2828800 ts, 501 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-12-14\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 492.75939012980723\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 1131\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 62.195\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4722932577133179\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.998611385393815e-08\n",
      "        policy_loss: -0.0008770902641117573\n",
      "        total_loss: 38.11479187011719\n",
      "        vf_explained_var: 0.001546323299407959\n",
      "        vf_loss: 38.11567687988281\n",
      "    load_time_ms: 2.715\n",
      "    num_steps_sampled: 2834000\n",
      "    num_steps_trained: 2725000\n",
      "    sample_time_ms: 5249.398\n",
      "    update_time_ms: 11.132\n",
      "  iterations_since_restore: 1090\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.14444444444445\n",
      "    ram_util_percent: 64.67777777777778\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.2692658409074\n",
      "    mean_inference_ms: 1.0144011346152788\n",
      "    mean_processing_ms: 0.709172200202769\n",
      "  time_since_restore: 4103.833747148514\n",
      "  time_this_iter_s: 6.632237911224365\n",
      "  time_total_s: 4103.833747148514\n",
      "  timestamp: 1596125534\n",
      "  timesteps_since_restore: 2834000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2834000\n",
      "  training_iteration: 1090\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4103 s, 1090 iter, 2834000 ts, 493 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-12-19\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 486.57863338788263\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 1134\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 58.813\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4599229097366333\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.4648438195763447e-07\n",
      "        policy_loss: 0.0024635724257677794\n",
      "        total_loss: 27.181337356567383\n",
      "        vf_explained_var: 0.004266321659088135\n",
      "        vf_loss: 27.178869247436523\n",
      "    load_time_ms: 2.564\n",
      "    num_steps_sampled: 2836600\n",
      "    num_steps_trained: 2727500\n",
      "    sample_time_ms: 5246.393\n",
      "    update_time_ms: 11.146\n",
      "  iterations_since_restore: 1091\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.6625\n",
      "    ram_util_percent: 64.7\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.2733774882703806\n",
      "    mean_inference_ms: 1.0152731272067295\n",
      "    mean_processing_ms: 0.7094127378628662\n",
      "  time_since_restore: 4109.569921016693\n",
      "  time_this_iter_s: 5.736173868179321\n",
      "  time_total_s: 4109.569921016693\n",
      "  timestamp: 1596125539\n",
      "  timesteps_since_restore: 2836600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2836600\n",
      "  training_iteration: 1091\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4109 s, 1091 iter, 2836600 ts, 487 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-12-29\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 486.5786333878826\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1134\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 60.12\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.46067214012146\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.0393858218549212e-07\n",
      "        policy_loss: 0.0020248035434633493\n",
      "        total_loss: 40.009944915771484\n",
      "        vf_explained_var: 0.0017524361610412598\n",
      "        vf_loss: 40.0079231262207\n",
      "    load_time_ms: 2.711\n",
      "    num_steps_sampled: 2841800\n",
      "    num_steps_trained: 2732500\n",
      "    sample_time_ms: 5184.733\n",
      "    update_time_ms: 10.732\n",
      "  iterations_since_restore: 1093\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.53333333333333\n",
      "    ram_util_percent: 64.71666666666665\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.2733774882703806\n",
      "    mean_inference_ms: 1.0152731272067297\n",
      "    mean_processing_ms: 0.709412737862866\n",
      "  time_since_restore: 4118.672612190247\n",
      "  time_this_iter_s: 4.751626014709473\n",
      "  time_total_s: 4118.672612190247\n",
      "  timestamp: 1596125549\n",
      "  timesteps_since_restore: 2841800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2841800\n",
      "  training_iteration: 1093\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4118 s, 1093 iter, 2841800 ts, 487 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-12-37\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 483.5906785013027\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 1136\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 59.741\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4667267799377441\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.6900301602618129e-07\n",
      "        policy_loss: -0.0019981125369668007\n",
      "        total_loss: 39.96108627319336\n",
      "        vf_explained_var: 0.002183258533477783\n",
      "        vf_loss: 39.96309280395508\n",
      "    load_time_ms: 2.719\n",
      "    num_steps_sampled: 2847000\n",
      "    num_steps_trained: 2737500\n",
      "    sample_time_ms: 5014.434\n",
      "    update_time_ms: 11.028\n",
      "  iterations_since_restore: 1095\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.1\n",
      "    ram_util_percent: 64.7\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.276827225559751\n",
      "    mean_inference_ms: 1.0160633289275136\n",
      "    mean_processing_ms: 0.7096650775468164\n",
      "  time_since_restore: 4127.527336835861\n",
      "  time_this_iter_s: 4.265910387039185\n",
      "  time_total_s: 4127.527336835861\n",
      "  timestamp: 1596125557\n",
      "  timesteps_since_restore: 2847000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2847000\n",
      "  training_iteration: 1095\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4127 s, 1095 iter, 2847000 ts, 484 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-12-43\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 486.51899851933837\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 1139\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 60.126\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.459555983543396\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.629731051863928e-07\n",
      "        policy_loss: -0.0013613924384117126\n",
      "        total_loss: 34.90399169921875\n",
      "        vf_explained_var: 0.0032929182052612305\n",
      "        vf_loss: 34.90535354614258\n",
      "    load_time_ms: 2.702\n",
      "    num_steps_sampled: 2849600\n",
      "    num_steps_trained: 2740000\n",
      "    sample_time_ms: 5009.542\n",
      "    update_time_ms: 11.005\n",
      "  iterations_since_restore: 1096\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.974999999999994\n",
      "    ram_util_percent: 64.7125\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.280926531016858\n",
      "    mean_inference_ms: 1.016935723270401\n",
      "    mean_processing_ms: 0.7099042228588136\n",
      "  time_since_restore: 4132.803689002991\n",
      "  time_this_iter_s: 5.276352167129517\n",
      "  time_total_s: 4132.803689002991\n",
      "  timestamp: 1596125563\n",
      "  timesteps_since_restore: 2849600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2849600\n",
      "  training_iteration: 1096\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4132 s, 1096 iter, 2849600 ts, 487 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-12-52\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 486.5189985193384\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1139\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 52.065\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4676316976547241\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.424188541132025e-07\n",
      "        policy_loss: -0.003673546714708209\n",
      "        total_loss: 61.18732452392578\n",
      "        vf_explained_var: 0.0015227198600769043\n",
      "        vf_loss: 61.190982818603516\n",
      "    load_time_ms: 2.31\n",
      "    num_steps_sampled: 2854800\n",
      "    num_steps_trained: 2745000\n",
      "    sample_time_ms: 4891.114\n",
      "    update_time_ms: 10.288\n",
      "  iterations_since_restore: 1098\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.957142857142856\n",
      "    ram_util_percent: 64.7\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.280926531016859\n",
      "    mean_inference_ms: 1.0169357232704013\n",
      "    mean_processing_ms: 0.7099042228588136\n",
      "  time_since_restore: 4142.161009311676\n",
      "  time_this_iter_s: 4.939769744873047\n",
      "  time_total_s: 4142.161009311676\n",
      "  timestamp: 1596125572\n",
      "  timesteps_since_restore: 2854800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2854800\n",
      "  training_iteration: 1098\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4142 s, 1098 iter, 2854800 ts, 487 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-12-57\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 486.5189985193384\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1139\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 47.306\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4742515087127686\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.244374392532336e-07\n",
      "        policy_loss: 0.006646262481808662\n",
      "        total_loss: 67.13151550292969\n",
      "        vf_explained_var: 0.0013022422790527344\n",
      "        vf_loss: 67.1248779296875\n",
      "    load_time_ms: 2.12\n",
      "    num_steps_sampled: 2857400\n",
      "    num_steps_trained: 2747500\n",
      "    sample_time_ms: 4949.771\n",
      "    update_time_ms: 9.683\n",
      "  iterations_since_restore: 1099\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.724999999999994\n",
      "    ram_util_percent: 64.7\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.280926531016859\n",
      "    mean_inference_ms: 1.0169357232704013\n",
      "    mean_processing_ms: 0.7099042228588136\n",
      "  time_since_restore: 4147.436254739761\n",
      "  time_this_iter_s: 5.275245428085327\n",
      "  time_total_s: 4147.436254739761\n",
      "  timestamp: 1596125577\n",
      "  timesteps_since_restore: 2857400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2857400\n",
      "  training_iteration: 1099\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4147 s, 1099 iter, 2857400 ts, 487 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-13-03\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 487.47450965349685\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 1143\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 43.321\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4757450819015503\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.169321512861643e-05\n",
      "        policy_loss: 0.0038033814635127783\n",
      "        total_loss: 56.71189880371094\n",
      "        vf_explained_var: 0.001367807388305664\n",
      "        vf_loss: 56.70811080932617\n",
      "    load_time_ms: 2.038\n",
      "    num_steps_sampled: 2860000\n",
      "    num_steps_trained: 2750000\n",
      "    sample_time_ms: 4856.267\n",
      "    update_time_ms: 8.889\n",
      "  iterations_since_restore: 1100\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.5875\n",
      "    ram_util_percent: 64.7\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.287106147584973\n",
      "    mean_inference_ms: 1.0182096518402246\n",
      "    mean_processing_ms: 0.7103032736617488\n",
      "  time_since_restore: 4153.073935270309\n",
      "  time_this_iter_s: 5.637680530548096\n",
      "  time_total_s: 4153.073935270309\n",
      "  timestamp: 1596125583\n",
      "  timesteps_since_restore: 2860000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2860000\n",
      "  training_iteration: 1100\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4153 s, 1100 iter, 2860000 ts, 487 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-13-12\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 487.7700781896853\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1144\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 40.221\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4532819986343384\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.482199761288939e-06\n",
      "        policy_loss: 0.0032216659747064114\n",
      "        total_loss: 40.6644172668457\n",
      "        vf_explained_var: 0.001679539680480957\n",
      "        vf_loss: 40.66120147705078\n",
      "    load_time_ms: 1.957\n",
      "    num_steps_sampled: 2865200\n",
      "    num_steps_trained: 2755000\n",
      "    sample_time_ms: 4750.594\n",
      "    update_time_ms: 9.178\n",
      "  iterations_since_restore: 1102\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.82857142857142\n",
      "    ram_util_percent: 64.62857142857145\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.288412072094437\n",
      "    mean_inference_ms: 1.0185868809429095\n",
      "    mean_processing_ms: 0.7103928962842616\n",
      "  time_since_restore: 4162.070061922073\n",
      "  time_this_iter_s: 4.4596991539001465\n",
      "  time_total_s: 4162.070061922073\n",
      "  timestamp: 1596125592\n",
      "  timesteps_since_restore: 2865200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2865200\n",
      "  training_iteration: 1102\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4162 s, 1102 iter, 2865200 ts, 488 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-13-21\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 487.7700781896853\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1144\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 40.172\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4643497467041016\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.328966269895318e-07\n",
      "        policy_loss: 0.002924639731645584\n",
      "        total_loss: 51.71928787231445\n",
      "        vf_explained_var: 0.0015894770622253418\n",
      "        vf_loss: 51.716365814208984\n",
      "    load_time_ms: 1.935\n",
      "    num_steps_sampled: 2870400\n",
      "    num_steps_trained: 2760000\n",
      "    sample_time_ms: 4750.742\n",
      "    update_time_ms: 7.396\n",
      "  iterations_since_restore: 1104\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.84285714285715\n",
      "    ram_util_percent: 64.7\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.288412072094437\n",
      "    mean_inference_ms: 1.0185868809429095\n",
      "    mean_processing_ms: 0.7103928962842616\n",
      "  time_since_restore: 4171.39564204216\n",
      "  time_this_iter_s: 5.17189884185791\n",
      "  time_total_s: 4171.39564204216\n",
      "  timestamp: 1596125601\n",
      "  timesteps_since_restore: 2870400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2870400\n",
      "  training_iteration: 1104\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4171 s, 1104 iter, 2870400 ts, 488 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-13-27\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 488.5720029983505\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 1148\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 40.238\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4672454595565796\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.142093530390412e-06\n",
      "        policy_loss: -9.424643212696537e-05\n",
      "        total_loss: 42.812049865722656\n",
      "        vf_explained_var: 0.0020066499710083008\n",
      "        vf_loss: 42.812137603759766\n",
      "    load_time_ms: 1.93\n",
      "    num_steps_sampled: 2873000\n",
      "    num_steps_trained: 2762500\n",
      "    sample_time_ms: 4898.146\n",
      "    update_time_ms: 8.478\n",
      "  iterations_since_restore: 1105\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.05\n",
      "    ram_util_percent: 64.76249999999999\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.294505218359722\n",
      "    mean_inference_ms: 1.019842185648151\n",
      "    mean_processing_ms: 0.7107897311002382\n",
      "  time_since_restore: 4177.146755695343\n",
      "  time_this_iter_s: 5.751113653182983\n",
      "  time_total_s: 4177.146755695343\n",
      "  timestamp: 1596125607\n",
      "  timesteps_since_restore: 2873000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2873000\n",
      "  training_iteration: 1105\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4177 s, 1105 iter, 2873000 ts, 489 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-13-37\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 486.8769024530631\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1149\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 48.275\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4577770233154297\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.6273021401502774e-06\n",
      "        policy_loss: -0.0018339782254770398\n",
      "        total_loss: 42.886695861816406\n",
      "        vf_explained_var: 0.0008455514907836914\n",
      "        vf_loss: 42.88853454589844\n",
      "    load_time_ms: 2.198\n",
      "    num_steps_sampled: 2878200\n",
      "    num_steps_trained: 2767500\n",
      "    sample_time_ms: 4870.17\n",
      "    update_time_ms: 9.268\n",
      "  iterations_since_restore: 1107\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.7\n",
      "    ram_util_percent: 64.8\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.295793297365769\n",
      "    mean_inference_ms: 1.0202145622190897\n",
      "    mean_processing_ms: 0.7108790097393703\n",
      "  time_since_restore: 4186.674973964691\n",
      "  time_this_iter_s: 5.462175130844116\n",
      "  time_total_s: 4186.674973964691\n",
      "  timestamp: 1596125617\n",
      "  timesteps_since_restore: 2878200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2878200\n",
      "  training_iteration: 1107\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4186 s, 1107 iter, 2878200 ts, 487 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-13-43\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 486.8769024530631\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1149\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 52.395\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4686161279678345\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.2119026488762756e-07\n",
      "        policy_loss: -0.0001512145099695772\n",
      "        total_loss: 60.13019561767578\n",
      "        vf_explained_var: 0.0005095005035400391\n",
      "        vf_loss: 60.130348205566406\n",
      "    load_time_ms: 2.353\n",
      "    num_steps_sampled: 2880800\n",
      "    num_steps_trained: 2770000\n",
      "    sample_time_ms: 4950.854\n",
      "    update_time_ms: 10.017\n",
      "  iterations_since_restore: 1108\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.85\n",
      "    ram_util_percent: 64.76249999999999\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.295793297365769\n",
      "    mean_inference_ms: 1.0202145622190897\n",
      "    mean_processing_ms: 0.7108790097393703\n",
      "  time_since_restore: 4192.485754966736\n",
      "  time_this_iter_s: 5.810781002044678\n",
      "  time_total_s: 4192.485754966736\n",
      "  timestamp: 1596125623\n",
      "  timesteps_since_restore: 2880800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2880800\n",
      "  training_iteration: 1108\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4192 s, 1108 iter, 2880800 ts, 487 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-13-53\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 494.2122936807077\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 1153\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 55.339\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.462833285331726\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.5581154002575204e-05\n",
      "        policy_loss: 0.004459336865693331\n",
      "        total_loss: 44.5512580871582\n",
      "        vf_explained_var: 0.003140270709991455\n",
      "        vf_loss: 44.54680633544922\n",
      "    load_time_ms: 2.417\n",
      "    num_steps_sampled: 2886000\n",
      "    num_steps_trained: 2775000\n",
      "    sample_time_ms: 4894.547\n",
      "    update_time_ms: 11.854\n",
      "  iterations_since_restore: 1110\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.588888888888896\n",
      "    ram_util_percent: 64.7\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.301929645760937\n",
      "    mean_inference_ms: 1.0214776575605071\n",
      "    mean_processing_ms: 0.7112706839451828\n",
      "  time_since_restore: 4202.896879196167\n",
      "  time_this_iter_s: 6.027233839035034\n",
      "  time_total_s: 4202.896879196167\n",
      "  timestamp: 1596125633\n",
      "  timesteps_since_restore: 2886000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2886000\n",
      "  training_iteration: 1110\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4202 s, 1110 iter, 2886000 ts, 494 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-14-03\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 492.35918721390766\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1154\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 60.074\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4480671882629395\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.1448859993379301e-07\n",
      "        policy_loss: -0.0011857608333230019\n",
      "        total_loss: 19.656476974487305\n",
      "        vf_explained_var: 0.0020966529846191406\n",
      "        vf_loss: 19.65766143798828\n",
      "    load_time_ms: 2.583\n",
      "    num_steps_sampled: 2891200\n",
      "    num_steps_trained: 2780000\n",
      "    sample_time_ms: 4945.526\n",
      "    update_time_ms: 11.713\n",
      "  iterations_since_restore: 1112\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.0375\n",
      "    ram_util_percent: 64.7625\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.303191854349911\n",
      "    mean_inference_ms: 1.02184436327661\n",
      "    mean_processing_ms: 0.7113602641091813\n",
      "  time_since_restore: 4212.460055112839\n",
      "  time_this_iter_s: 5.114404201507568\n",
      "  time_total_s: 4212.460055112839\n",
      "  timestamp: 1596125643\n",
      "  timesteps_since_restore: 2891200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2891200\n",
      "  training_iteration: 1112\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4212 s, 1112 iter, 2891200 ts, 492 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-14-13\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 485.2526390961122\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 1156\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 57.011\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4625846147537231\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 7.347106816268933e-07\n",
      "        policy_loss: -0.0015849132323637605\n",
      "        total_loss: 35.96291732788086\n",
      "        vf_explained_var: 0.0023792386054992676\n",
      "        vf_loss: 35.964500427246094\n",
      "    load_time_ms: 2.473\n",
      "    num_steps_sampled: 2896400\n",
      "    num_steps_trained: 2785000\n",
      "    sample_time_ms: 5084.436\n",
      "    update_time_ms: 13.093\n",
      "  iterations_since_restore: 1114\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.962500000000006\n",
      "    ram_util_percent: 64.75\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.306284581427494\n",
      "    mean_inference_ms: 1.0224774543080815\n",
      "    mean_processing_ms: 0.7115357316049034\n",
      "  time_since_restore: 4223.150556087494\n",
      "  time_this_iter_s: 5.8362298011779785\n",
      "  time_total_s: 4223.150556087494\n",
      "  timestamp: 1596125653\n",
      "  timesteps_since_restore: 2896400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2896400\n",
      "  training_iteration: 1114\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4223 s, 1114 iter, 2896400 ts, 485 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-14-19\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 489.6316249341289\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 1158\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 58.586\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4592093229293823\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.496667879218876e-07\n",
      "        policy_loss: 0.0027992534451186657\n",
      "        total_loss: 35.64533996582031\n",
      "        vf_explained_var: 0.003308117389678955\n",
      "        vf_loss: 35.64254379272461\n",
      "    load_time_ms: 2.542\n",
      "    num_steps_sampled: 2899000\n",
      "    num_steps_trained: 2787500\n",
      "    sample_time_ms: 5067.253\n",
      "    update_time_ms: 12.007\n",
      "  iterations_since_restore: 1115\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.45\n",
      "    ram_util_percent: 64.75\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.309144177359109\n",
      "    mean_inference_ms: 1.023160292479345\n",
      "    mean_processing_ms: 0.7117379186608686\n",
      "  time_since_restore: 4228.738979101181\n",
      "  time_this_iter_s: 5.588423013687134\n",
      "  time_total_s: 4228.738979101181\n",
      "  timestamp: 1596125659\n",
      "  timesteps_since_restore: 2899000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2899000\n",
      "  training_iteration: 1115\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4228 s, 1115 iter, 2899000 ts, 490 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-14-28\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 490.2721328138382\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1159\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 51.218\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.452762246131897\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.2378683297574753e-06\n",
      "        policy_loss: -0.0025865326169878244\n",
      "        total_loss: 32.24443435668945\n",
      "        vf_explained_var: 0.0013353228569030762\n",
      "        vf_loss: 32.24702072143555\n",
      "    load_time_ms: 2.311\n",
      "    num_steps_sampled: 2904200\n",
      "    num_steps_trained: 2792500\n",
      "    sample_time_ms: 4980.793\n",
      "    update_time_ms: 12.059\n",
      "  iterations_since_restore: 1117\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 66.01666666666667\n",
      "    ram_util_percent: 64.73333333333333\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.310521677798301\n",
      "    mean_inference_ms: 1.023460318510837\n",
      "    mean_processing_ms: 0.7118374671025909\n",
      "  time_since_restore: 4237.313606739044\n",
      "  time_this_iter_s: 4.42642617225647\n",
      "  time_total_s: 4237.313606739044\n",
      "  timestamp: 1596125668\n",
      "  timesteps_since_restore: 2904200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2904200\n",
      "  training_iteration: 1117\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4237 s, 1117 iter, 2904200 ts, 490 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-14-34\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 492.6003348216782\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1160\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 47.549\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4586327075958252\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.7123460338552832e-06\n",
      "        policy_loss: 0.005022676661610603\n",
      "        total_loss: 37.7634162902832\n",
      "        vf_explained_var: 0.00015789270401000977\n",
      "        vf_loss: 37.758384704589844\n",
      "    load_time_ms: 2.29\n",
      "    num_steps_sampled: 2906800\n",
      "    num_steps_trained: 2795000\n",
      "    sample_time_ms: 5006.746\n",
      "    update_time_ms: 11.239\n",
      "  iterations_since_restore: 1118\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 51.34444444444444\n",
      "    ram_util_percent: 64.7\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.312291009818124\n",
      "    mean_inference_ms: 1.0239202714872402\n",
      "    mean_processing_ms: 0.7119579816023763\n",
      "  time_since_restore: 4243.324261665344\n",
      "  time_this_iter_s: 6.010654926300049\n",
      "  time_total_s: 4243.324261665344\n",
      "  timestamp: 1596125674\n",
      "  timesteps_since_restore: 2906800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2906800\n",
      "  training_iteration: 1118\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4243 s, 1118 iter, 2906800 ts, 493 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-14-44\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 489.07994700659214\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 1164\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 53.119\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4596744775772095\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 7.643938033652375e-07\n",
      "        policy_loss: 0.0015083224279806018\n",
      "        total_loss: 60.01890563964844\n",
      "        vf_explained_var: 0.001955568790435791\n",
      "        vf_loss: 60.01737976074219\n",
      "    load_time_ms: 2.444\n",
      "    num_steps_sampled: 2912000\n",
      "    num_steps_trained: 2800000\n",
      "    sample_time_ms: 4976.332\n",
      "    update_time_ms: 10.102\n",
      "  iterations_since_restore: 1120\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.1125\n",
      "    ram_util_percent: 64.775\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.317724392220363\n",
      "    mean_inference_ms: 1.0250457606284735\n",
      "    mean_processing_ms: 0.7123040028527867\n",
      "  time_since_restore: 4253.489203214645\n",
      "  time_this_iter_s: 5.787468671798706\n",
      "  time_total_s: 4253.489203214645\n",
      "  timestamp: 1596125684\n",
      "  timesteps_since_restore: 2912000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2912000\n",
      "  training_iteration: 1120\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4253 s, 1120 iter, 2912000 ts, 489 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-14-49\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 489.07994700659214\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1164\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 56.109\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4579551219940186\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.216362074454082e-06\n",
      "        policy_loss: 0.002392319031059742\n",
      "        total_loss: 84.00028228759766\n",
      "        vf_explained_var: 0.002612769603729248\n",
      "        vf_loss: 83.99787902832031\n",
      "    load_time_ms: 2.588\n",
      "    num_steps_sampled: 2914600\n",
      "    num_steps_trained: 2802500\n",
      "    sample_time_ms: 5069.848\n",
      "    update_time_ms: 10.556\n",
      "  iterations_since_restore: 1121\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.15\n",
      "    ram_util_percent: 64.75\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.317724392220363\n",
      "    mean_inference_ms: 1.0250457606284735\n",
      "    mean_processing_ms: 0.7123040028527867\n",
      "  time_since_restore: 4258.91419005394\n",
      "  time_this_iter_s: 5.424986839294434\n",
      "  time_total_s: 4258.91419005394\n",
      "  timestamp: 1596125689\n",
      "  timesteps_since_restore: 2914600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2914600\n",
      "  training_iteration: 1121\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4258 s, 1121 iter, 2914600 ts, 489 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-14-55\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 925.9889134036155\n",
      "  episode_reward_mean: 489.07994700659214\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1164\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 57.134\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4638804197311401\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.663633146468783e-06\n",
      "        policy_loss: 0.0008554414962418377\n",
      "        total_loss: 93.17901611328125\n",
      "        vf_explained_var: 0.0015859007835388184\n",
      "        vf_loss: 93.17816925048828\n",
      "    load_time_ms: 2.611\n",
      "    num_steps_sampled: 2917200\n",
      "    num_steps_trained: 2805000\n",
      "    sample_time_ms: 5078.785\n",
      "    update_time_ms: 10.724\n",
      "  iterations_since_restore: 1122\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.1875\n",
      "    ram_util_percent: 64.7625\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.317724392220363\n",
      "    mean_inference_ms: 1.0250457606284735\n",
      "    mean_processing_ms: 0.7123040028527867\n",
      "  time_since_restore: 4264.131492853165\n",
      "  time_this_iter_s: 5.2173027992248535\n",
      "  time_total_s: 4264.131492853165\n",
      "  timestamp: 1596125695\n",
      "  timesteps_since_restore: 2917200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2917200\n",
      "  training_iteration: 1122\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4264 s, 1122 iter, 2917200 ts, 489 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-15-05\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1035.1014877303473\n",
      "  episode_reward_mean: 495.91867400235054\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1166\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 57.229\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4663869142532349\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.023098881589249e-06\n",
      "        policy_loss: 0.0019006355432793498\n",
      "        total_loss: 69.53973388671875\n",
      "        vf_explained_var: 0.0007635354995727539\n",
      "        vf_loss: 69.53783416748047\n",
      "    load_time_ms: 2.723\n",
      "    num_steps_sampled: 2922400\n",
      "    num_steps_trained: 2810000\n",
      "    sample_time_ms: 5030.479\n",
      "    update_time_ms: 10.09\n",
      "  iterations_since_restore: 1124\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.771428571428565\n",
      "    ram_util_percent: 64.78571428571429\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.320775789275155\n",
      "    mean_inference_ms: 1.0256684957642477\n",
      "    mean_processing_ms: 0.712480451770919\n",
      "  time_since_restore: 4274.331509590149\n",
      "  time_this_iter_s: 5.445902109146118\n",
      "  time_total_s: 4274.331509590149\n",
      "  timestamp: 1596125705\n",
      "  timesteps_since_restore: 2922400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2922400\n",
      "  training_iteration: 1124\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4274 s, 1124 iter, 2922400 ts, 496 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-15-11\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1035.1014877303473\n",
      "  episode_reward_mean: 493.50351841718395\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 1169\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 59.461\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4534395933151245\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.3385296142587322e-06\n",
      "        policy_loss: 0.00046102391206659377\n",
      "        total_loss: 38.74522399902344\n",
      "        vf_explained_var: 0.0031498074531555176\n",
      "        vf_loss: 38.7447624206543\n",
      "    load_time_ms: 2.82\n",
      "    num_steps_sampled: 2925000\n",
      "    num_steps_trained: 2812500\n",
      "    sample_time_ms: 5070.527\n",
      "    update_time_ms: 10.374\n",
      "  iterations_since_restore: 1125\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.68888888888889\n",
      "    ram_util_percent: 64.74444444444445\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.324965501807212\n",
      "    mean_inference_ms: 1.0266405165797128\n",
      "    mean_processing_ms: 0.7127766304383097\n",
      "  time_since_restore: 4280.354746580124\n",
      "  time_this_iter_s: 6.023236989974976\n",
      "  time_total_s: 4280.354746580124\n",
      "  timestamp: 1596125711\n",
      "  timesteps_since_restore: 2925000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2925000\n",
      "  training_iteration: 1125\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4280 s, 1125 iter, 2925000 ts, 494 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-15-16\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1035.1014877303473\n",
      "  episode_reward_mean: 493.503518417184\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1169\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 57.338\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4524730443954468\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 7.021426995379443e-08\n",
      "        policy_loss: -0.0034713284112513065\n",
      "        total_loss: 45.98269271850586\n",
      "        vf_explained_var: 0.0029116272926330566\n",
      "        vf_loss: 45.98616409301758\n",
      "    load_time_ms: 2.818\n",
      "    num_steps_sampled: 2927600\n",
      "    num_steps_trained: 2815000\n",
      "    sample_time_ms: 5169.37\n",
      "    update_time_ms: 10.903\n",
      "  iterations_since_restore: 1126\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.471428571428575\n",
      "    ram_util_percent: 64.7\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.324965501807213\n",
      "    mean_inference_ms: 1.0266405165797128\n",
      "    mean_processing_ms: 0.7127766304383097\n",
      "  time_since_restore: 4285.461126565933\n",
      "  time_this_iter_s: 5.106379985809326\n",
      "  time_total_s: 4285.461126565933\n",
      "  timestamp: 1596125716\n",
      "  timesteps_since_restore: 2927600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2927600\n",
      "  training_iteration: 1126\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4285 s, 1126 iter, 2927600 ts, 494 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-15-25\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1035.1014877303473\n",
      "  episode_reward_mean: 495.9054792652878\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1170\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 58.882\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4691940546035767\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.075143801353988e-07\n",
      "        policy_loss: 0.0030545578338205814\n",
      "        total_loss: 80.33191680908203\n",
      "        vf_explained_var: 0.0013538002967834473\n",
      "        vf_loss: 80.32886505126953\n",
      "    load_time_ms: 2.619\n",
      "    num_steps_sampled: 2932800\n",
      "    num_steps_trained: 2820000\n",
      "    sample_time_ms: 5020.187\n",
      "    update_time_ms: 10.213\n",
      "  iterations_since_restore: 1128\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 66.86666666666666\n",
      "    ram_util_percent: 64.78333333333335\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.326753421077976\n",
      "    mean_inference_ms: 1.0271035096149417\n",
      "    mean_processing_ms: 0.7128954698296901\n",
      "  time_since_restore: 4294.425396442413\n",
      "  time_this_iter_s: 4.459805965423584\n",
      "  time_total_s: 4294.425396442413\n",
      "  timestamp: 1596125725\n",
      "  timesteps_since_restore: 2932800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2932800\n",
      "  training_iteration: 1128\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4294 s, 1128 iter, 2932800 ts, 496 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-15-34\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1035.1014877303473\n",
      "  episode_reward_mean: 492.491194968742\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 1174\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 53.011\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4481477737426758\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 7.044315566417936e-07\n",
      "        policy_loss: 0.0035147303715348244\n",
      "        total_loss: 23.131839752197266\n",
      "        vf_explained_var: 0.003848254680633545\n",
      "        vf_loss: 23.12832260131836\n",
      "    load_time_ms: 2.431\n",
      "    num_steps_sampled: 2938000\n",
      "    num_steps_trained: 2825000\n",
      "    sample_time_ms: 4945.589\n",
      "    update_time_ms: 10.644\n",
      "  iterations_since_restore: 1130\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.04999999999999\n",
      "    ram_util_percent: 64.89999999999999\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.332156637067573\n",
      "    mean_inference_ms: 1.0282240530063378\n",
      "    mean_processing_ms: 0.7132412350500139\n",
      "  time_since_restore: 4303.774461507797\n",
      "  time_this_iter_s: 4.436093807220459\n",
      "  time_total_s: 4303.774461507797\n",
      "  timestamp: 1596125734\n",
      "  timesteps_since_restore: 2938000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2938000\n",
      "  training_iteration: 1130\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4303 s, 1130 iter, 2938000 ts, 492 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-15-44\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1035.1014877303473\n",
      "  episode_reward_mean: 492.49119496874204\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1174\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 45.977\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.456620693206787\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.016208549728617e-06\n",
      "        policy_loss: -0.0002871963370125741\n",
      "        total_loss: 47.87030792236328\n",
      "        vf_explained_var: 0.002409636974334717\n",
      "        vf_loss: 47.87059020996094\n",
      "    load_time_ms: 2.096\n",
      "    num_steps_sampled: 2943200\n",
      "    num_steps_trained: 2830000\n",
      "    sample_time_ms: 4854.267\n",
      "    update_time_ms: 10.282\n",
      "  iterations_since_restore: 1132\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 67.62857142857142\n",
      "    ram_util_percent: 64.85714285714285\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.332156637067574\n",
      "    mean_inference_ms: 1.0282240530063378\n",
      "    mean_processing_ms: 0.7132412350500138\n",
      "  time_since_restore: 4313.426242351532\n",
      "  time_this_iter_s: 4.877857446670532\n",
      "  time_total_s: 4313.426242351532\n",
      "  timestamp: 1596125744\n",
      "  timesteps_since_restore: 2943200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2943200\n",
      "  training_iteration: 1132\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4313 s, 1132 iter, 2943200 ts, 492 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-15-53\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1035.1014877303473\n",
      "  episode_reward_mean: 487.8515348712634\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 1177\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 45.186\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4518654346466064\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.061081889019988e-06\n",
      "        policy_loss: -0.0025381878949701786\n",
      "        total_loss: 27.567325592041016\n",
      "        vf_explained_var: 0.0027671456336975098\n",
      "        vf_loss: 27.569866180419922\n",
      "    load_time_ms: 1.922\n",
      "    num_steps_sampled: 2948400\n",
      "    num_steps_trained: 2835000\n",
      "    sample_time_ms: 4710.054\n",
      "    update_time_ms: 10.804\n",
      "  iterations_since_restore: 1134\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.2\n",
      "    ram_util_percent: 64.86666666666666\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.336288429063565\n",
      "    mean_inference_ms: 1.0292211984256008\n",
      "    mean_processing_ms: 0.7135097593343304\n",
      "  time_since_restore: 4322.176631450653\n",
      "  time_this_iter_s: 4.389937162399292\n",
      "  time_total_s: 4322.176631450653\n",
      "  timestamp: 1596125753\n",
      "  timesteps_since_restore: 2948400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2948400\n",
      "  training_iteration: 1134\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4322 s, 1134 iter, 2948400 ts, 488 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-16-02\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1035.1014877303473\n",
      "  episode_reward_mean: 487.77342859560156\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1179\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 42.415\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4462226629257202\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 8.458614502160344e-07\n",
      "        policy_loss: -0.0028524419758468866\n",
      "        total_loss: 22.362966537475586\n",
      "        vf_explained_var: 0.003202199935913086\n",
      "        vf_loss: 22.36581802368164\n",
      "    load_time_ms: 1.811\n",
      "    num_steps_sampled: 2953600\n",
      "    num_steps_trained: 2840000\n",
      "    sample_time_ms: 4527.609\n",
      "    update_time_ms: 10.174\n",
      "  iterations_since_restore: 1136\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.99999999999999\n",
      "    ram_util_percent: 64.86666666666666\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.339341296768161\n",
      "    mean_inference_ms: 1.0298081099190213\n",
      "    mean_processing_ms: 0.7136882219945295\n",
      "  time_since_restore: 4331.43915104866\n",
      "  time_this_iter_s: 4.528167486190796\n",
      "  time_total_s: 4331.43915104866\n",
      "  timestamp: 1596125762\n",
      "  timesteps_since_restore: 2953600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2953600\n",
      "  training_iteration: 1136\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4331 s, 1136 iter, 2953600 ts, 488 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-16-12\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1035.1014877303473\n",
      "  episode_reward_mean: 484.33178183206905\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1180\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 45.598\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.448222279548645\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.321171677976963e-06\n",
      "        policy_loss: 0.0018274750327691436\n",
      "        total_loss: 23.367443084716797\n",
      "        vf_explained_var: 0.001909792423248291\n",
      "        vf_loss: 23.36561393737793\n",
      "    load_time_ms: 1.973\n",
      "    num_steps_sampled: 2958800\n",
      "    num_steps_trained: 2845000\n",
      "    sample_time_ms: 4571.911\n",
      "    update_time_ms: 11.058\n",
      "  iterations_since_restore: 1138\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.128571428571426\n",
      "    ram_util_percent: 64.94285714285714\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.341006661794029\n",
      "    mean_inference_ms: 1.0302415946303243\n",
      "    mean_processing_ms: 0.7138102443120735\n",
      "  time_since_restore: 4340.902654886246\n",
      "  time_this_iter_s: 4.681929111480713\n",
      "  time_total_s: 4340.902654886246\n",
      "  timestamp: 1596125772\n",
      "  timesteps_since_restore: 2958800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2958800\n",
      "  training_iteration: 1138\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4340 s, 1138 iter, 2958800 ts, 484 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-16-21\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1035.1014877303473\n",
      "  episode_reward_mean: 479.6972252324823\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 1184\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 45.26\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4443869590759277\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.577014914910251e-07\n",
      "        policy_loss: 0.0013120610965415835\n",
      "        total_loss: 24.09308433532715\n",
      "        vf_explained_var: 0.003296077251434326\n",
      "        vf_loss: 24.09177589416504\n",
      "    load_time_ms: 1.955\n",
      "    num_steps_sampled: 2964000\n",
      "    num_steps_trained: 2850000\n",
      "    sample_time_ms: 4583.18\n",
      "    update_time_ms: 10.568\n",
      "  iterations_since_restore: 1140\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.53333333333334\n",
      "    ram_util_percent: 64.86666666666666\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.346265535231645\n",
      "    mean_inference_ms: 1.031324822441301\n",
      "    mean_processing_ms: 0.7141304761200238\n",
      "  time_since_restore: 4350.353163957596\n",
      "  time_this_iter_s: 4.618831634521484\n",
      "  time_total_s: 4350.353163957596\n",
      "  timestamp: 1596125781\n",
      "  timesteps_since_restore: 2964000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2964000\n",
      "  training_iteration: 1140\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4350 s, 1140 iter, 2964000 ts, 480 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-16-26\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1035.1014877303473\n",
      "  episode_reward_mean: 479.6972252324823\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1184\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 49.183\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4490296840667725\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.13379484093457e-07\n",
      "        policy_loss: -0.0038248207420110703\n",
      "        total_loss: 35.48134231567383\n",
      "        vf_explained_var: 0.0035058259963989258\n",
      "        vf_loss: 35.48514938354492\n",
      "    load_time_ms: 2.104\n",
      "    num_steps_sampled: 2966600\n",
      "    num_steps_trained: 2852500\n",
      "    sample_time_ms: 4625.236\n",
      "    update_time_ms: 10.877\n",
      "  iterations_since_restore: 1141\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.7\n",
      "    ram_util_percent: 64.8625\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.3462655352316455\n",
      "    mean_inference_ms: 1.031324822441301\n",
      "    mean_processing_ms: 0.7141304761200238\n",
      "  time_since_restore: 4355.592821121216\n",
      "  time_this_iter_s: 5.239657163619995\n",
      "  time_total_s: 4355.592821121216\n",
      "  timestamp: 1596125786\n",
      "  timesteps_since_restore: 2966600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2966600\n",
      "  training_iteration: 1141\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4355 s, 1141 iter, 2966600 ts, 480 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-16-35\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1035.1014877303473\n",
      "  episode_reward_mean: 477.75258415607027\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1185\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 52.034\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4564411640167236\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.7579546895140084e-06\n",
      "        policy_loss: -0.0027112949173897505\n",
      "        total_loss: 54.47321701049805\n",
      "        vf_explained_var: 0.0009030699729919434\n",
      "        vf_loss: 54.47592544555664\n",
      "    load_time_ms: 2.238\n",
      "    num_steps_sampled: 2971800\n",
      "    num_steps_trained: 2857500\n",
      "    sample_time_ms: 4568.307\n",
      "    update_time_ms: 10.775\n",
      "  iterations_since_restore: 1143\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.68333333333334\n",
      "    ram_util_percent: 64.81666666666668\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.347888857904435\n",
      "    mean_inference_ms: 1.0317451316325787\n",
      "    mean_processing_ms: 0.7142470307425991\n",
      "  time_since_restore: 4364.298442363739\n",
      "  time_this_iter_s: 4.354902029037476\n",
      "  time_total_s: 4364.298442363739\n",
      "  timestamp: 1596125795\n",
      "  timesteps_since_restore: 2971800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2971800\n",
      "  training_iteration: 1143\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4364 s, 1143 iter, 2971800 ts, 478 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-16-41\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1035.1014877303473\n",
      "  episode_reward_mean: 473.09707202404496\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 1189\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 48.826\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4576658010482788\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.5251875083777122e-05\n",
      "        policy_loss: 0.004222216550260782\n",
      "        total_loss: 60.95781707763672\n",
      "        vf_explained_var: 0.0015711188316345215\n",
      "        vf_loss: 60.95359420776367\n",
      "    load_time_ms: 2.152\n",
      "    num_steps_sampled: 2974400\n",
      "    num_steps_trained: 2860000\n",
      "    sample_time_ms: 4744.698\n",
      "    update_time_ms: 10.452\n",
      "  iterations_since_restore: 1144\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.611111111111114\n",
      "    ram_util_percent: 64.85555555555555\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.353003158859639\n",
      "    mean_inference_ms: 1.0327903728392223\n",
      "    mean_processing_ms: 0.7145615707807774\n",
      "  time_since_restore: 4370.40708065033\n",
      "  time_this_iter_s: 6.108638286590576\n",
      "  time_total_s: 4370.40708065033\n",
      "  timestamp: 1596125801\n",
      "  timesteps_since_restore: 2974400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2974400\n",
      "  training_iteration: 1144\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4370 s, 1144 iter, 2974400 ts, 473 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-16-51\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1035.1014877303473\n",
      "  episode_reward_mean: 472.40898511954055\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1190\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 51.366\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.449819564819336\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.381346570880851e-06\n",
      "        policy_loss: -0.003025740385055542\n",
      "        total_loss: 50.88562774658203\n",
      "        vf_explained_var: 0.0004588961601257324\n",
      "        vf_loss: 50.88866424560547\n",
      "    load_time_ms: 2.244\n",
      "    num_steps_sampled: 2979600\n",
      "    num_steps_trained: 2865000\n",
      "    sample_time_ms: 4807.842\n",
      "    update_time_ms: 9.576\n",
      "  iterations_since_restore: 1146\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.5\n",
      "    ram_util_percent: 64.87142857142858\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.354610396588074\n",
      "    mean_inference_ms: 1.033207234659862\n",
      "    mean_processing_ms: 0.714679093447585\n",
      "  time_since_restore: 4380.3273005485535\n",
      "  time_this_iter_s: 5.152861595153809\n",
      "  time_total_s: 4380.3273005485535\n",
      "  timestamp: 1596125811\n",
      "  timesteps_since_restore: 2979600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2979600\n",
      "  training_iteration: 1146\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4380 s, 1146 iter, 2979600 ts, 472 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-17-03\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1035.1014877303473\n",
      "  episode_reward_mean: 469.6751761485048\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1191\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 52.535\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4579260349273682\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.067446757791913e-06\n",
      "        policy_loss: -0.0037440720479935408\n",
      "        total_loss: 60.726051330566406\n",
      "        vf_explained_var: 0.0006769895553588867\n",
      "        vf_loss: 60.72982406616211\n",
      "    load_time_ms: 2.25\n",
      "    num_steps_sampled: 2984800\n",
      "    num_steps_trained: 2870000\n",
      "    sample_time_ms: 4984.257\n",
      "    update_time_ms: 9.627\n",
      "  iterations_since_restore: 1148\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 51.25555555555556\n",
      "    ram_util_percent: 64.8\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.3556913740156045\n",
      "    mean_inference_ms: 1.0333680468289106\n",
      "    mean_processing_ms: 0.7147507342570536\n",
      "  time_since_restore: 4391.568094968796\n",
      "  time_this_iter_s: 6.541805744171143\n",
      "  time_total_s: 4391.568094968796\n",
      "  timestamp: 1596125823\n",
      "  timesteps_since_restore: 2984800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2984800\n",
      "  training_iteration: 1148\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4391 s, 1148 iter, 2984800 ts, 470 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-17-09\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1035.1014877303473\n",
      "  episode_reward_mean: 470.6750708838124\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 1193\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 55.988\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4590920209884644\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 6.790161251046811e-07\n",
      "        policy_loss: -0.005657343193888664\n",
      "        total_loss: 57.10554885864258\n",
      "        vf_explained_var: 0.002485990524291992\n",
      "        vf_loss: 57.1112060546875\n",
      "    load_time_ms: 2.344\n",
      "    num_steps_sampled: 2987400\n",
      "    num_steps_trained: 2872500\n",
      "    sample_time_ms: 5099.492\n",
      "    update_time_ms: 9.869\n",
      "  iterations_since_restore: 1149\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.06666666666667\n",
      "    ram_util_percent: 64.88888888888889\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.358370990717209\n",
      "    mean_inference_ms: 1.0339548756402224\n",
      "    mean_processing_ms: 0.7149255149968741\n",
      "  time_since_restore: 4397.60103392601\n",
      "  time_this_iter_s: 6.0329389572143555\n",
      "  time_total_s: 4397.60103392601\n",
      "  timestamp: 1596125829\n",
      "  timesteps_since_restore: 2987400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2987400\n",
      "  training_iteration: 1149\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4397 s, 1149 iter, 2987400 ts, 471 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-17-17\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1035.1014877303473\n",
      "  episode_reward_mean: 471.7504207207019\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1195\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 49.753\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.444427728652954\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.4519214346364606e-06\n",
      "        policy_loss: -0.0010829512029886246\n",
      "        total_loss: 30.36216163635254\n",
      "        vf_explained_var: 0.002878248691558838\n",
      "        vf_loss: 30.363252639770508\n",
      "    load_time_ms: 2.134\n",
      "    num_steps_sampled: 2992600\n",
      "    num_steps_trained: 2877500\n",
      "    sample_time_ms: 4976.272\n",
      "    update_time_ms: 9.939\n",
      "  iterations_since_restore: 1151\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 69.06666666666666\n",
      "    ram_util_percent: 64.95\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.36136737481022\n",
      "    mean_inference_ms: 1.0346754223229155\n",
      "    mean_processing_ms: 0.7151101915058561\n",
      "  time_since_restore: 4406.141961336136\n",
      "  time_this_iter_s: 4.400329113006592\n",
      "  time_total_s: 4406.141961336136\n",
      "  timestamp: 1596125837\n",
      "  timesteps_since_restore: 2992600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2992600\n",
      "  training_iteration: 1151\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4406 s, 1151 iter, 2992600 ts, 472 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-17-26\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1035.1014877303473\n",
      "  episode_reward_mean: 472.8754459912702\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1196\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 47.223\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4553993940353394\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.347968115325784e-06\n",
      "        policy_loss: -0.003063187701627612\n",
      "        total_loss: 45.05433654785156\n",
      "        vf_explained_var: 0.00037407875061035156\n",
      "        vf_loss: 45.057411193847656\n",
      "    load_time_ms: 2.02\n",
      "    num_steps_sampled: 2997800\n",
      "    num_steps_trained: 2882500\n",
      "    sample_time_ms: 5041.247\n",
      "    update_time_ms: 8.154\n",
      "  iterations_since_restore: 1153\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.24285714285715\n",
      "    ram_util_percent: 64.91428571428571\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.362501452658785\n",
      "    mean_inference_ms: 1.0348024757622343\n",
      "    mean_processing_ms: 0.715154834703724\n",
      "  time_since_restore: 4415.44274020195\n",
      "  time_this_iter_s: 5.397835969924927\n",
      "  time_total_s: 4415.44274020195\n",
      "  timestamp: 1596125846\n",
      "  timesteps_since_restore: 2997800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 2997800\n",
      "  training_iteration: 1153\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4415 s, 1153 iter, 2997800 ts, 473 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-17-32\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1035.1014877303473\n",
      "  episode_reward_mean: 473.53169805586106\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 1199\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 48.981\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4495922327041626\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 2.3411034817399923e-06\n",
      "        policy_loss: 0.001895192894153297\n",
      "        total_loss: 34.6044807434082\n",
      "        vf_explained_var: 0.002626955509185791\n",
      "        vf_loss: 34.60258865356445\n",
      "    load_time_ms: 2.068\n",
      "    num_steps_sampled: 3000400\n",
      "    num_steps_trained: 2885000\n",
      "    sample_time_ms: 4986.185\n",
      "    update_time_ms: 8.483\n",
      "  iterations_since_restore: 1154\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.9875\n",
      "    ram_util_percent: 64.9375\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.366403253656371\n",
      "    mean_inference_ms: 1.0356993794903757\n",
      "    mean_processing_ms: 0.7154199157751724\n",
      "  time_since_restore: 4421.0256016254425\n",
      "  time_this_iter_s: 5.582861423492432\n",
      "  time_total_s: 4421.0256016254425\n",
      "  timestamp: 1596125852\n",
      "  timesteps_since_restore: 3000400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 3000400\n",
      "  training_iteration: 1154\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4421 s, 1154 iter, 3000400 ts, 474 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-17-40\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1035.1014877303473\n",
      "  episode_reward_mean: 474.5806008628822\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1200\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 46.473\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4475078582763672\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.8322945152249304e-06\n",
      "        policy_loss: 0.00045680819312110543\n",
      "        total_loss: 37.09657669067383\n",
      "        vf_explained_var: 0.0025658011436462402\n",
      "        vf_loss: 37.096126556396484\n",
      "    load_time_ms: 1.974\n",
      "    num_steps_sampled: 3005600\n",
      "    num_steps_trained: 2890000\n",
      "    sample_time_ms: 4828.634\n",
      "    update_time_ms: 8.989\n",
      "  iterations_since_restore: 1156\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.1\n",
      "    ram_util_percent: 64.9\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.367727115637961\n",
      "    mean_inference_ms: 1.035984304226901\n",
      "    mean_processing_ms: 0.715505807603864\n",
      "  time_since_restore: 4429.341427326202\n",
      "  time_this_iter_s: 3.925271511077881\n",
      "  time_total_s: 4429.341427326202\n",
      "  timestamp: 1596125860\n",
      "  timesteps_since_restore: 3005600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 3005600\n",
      "  training_iteration: 1156\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4429 s, 1156 iter, 3005600 ts, 475 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-17-49\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1035.1014877303473\n",
      "  episode_reward_mean: 475.48123339540325\n",
      "  episode_reward_min: 151.4130383424371\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1201\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 41.652\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4521492719650269\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.0664343790267594e-06\n",
      "        policy_loss: -0.003895067609846592\n",
      "        total_loss: 37.72467041015625\n",
      "        vf_explained_var: 0.0018770098686218262\n",
      "        vf_loss: 37.72856521606445\n",
      "    load_time_ms: 1.853\n",
      "    num_steps_sampled: 3010800\n",
      "    num_steps_trained: 2895000\n",
      "    sample_time_ms: 4607.168\n",
      "    update_time_ms: 8.119\n",
      "  iterations_since_restore: 1158\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.25000000000001\n",
      "    ram_util_percent: 64.89999999999999\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.369084927612679\n",
      "    mean_inference_ms: 1.0362285172148715\n",
      "    mean_processing_ms: 0.7155756530488824\n",
      "  time_since_restore: 4438.287800073624\n",
      "  time_this_iter_s: 4.480081081390381\n",
      "  time_total_s: 4438.287800073624\n",
      "  timestamp: 1596125869\n",
      "  timesteps_since_restore: 3010800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 3010800\n",
      "  training_iteration: 1158\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4438 s, 1158 iter, 3010800 ts, 475 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-17-55\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1035.1014877303473\n",
      "  episode_reward_mean: 473.8131959305023\n",
      "  episode_reward_min: 140.2443830298491\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 1204\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 39.902\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4413940906524658\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.2979506891497294e-07\n",
      "        policy_loss: -0.0017853431636467576\n",
      "        total_loss: 15.387550354003906\n",
      "        vf_explained_var: 0.0022980570793151855\n",
      "        vf_loss: 15.38933277130127\n",
      "    load_time_ms: 1.811\n",
      "    num_steps_sampled: 3013400\n",
      "    num_steps_trained: 2897500\n",
      "    sample_time_ms: 4557.309\n",
      "    update_time_ms: 7.25\n",
      "  iterations_since_restore: 1159\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.974999999999994\n",
      "    ram_util_percent: 64.9375\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.37293722260525\n",
      "    mean_inference_ms: 1.0371120401886664\n",
      "    mean_processing_ms: 0.7158255939156377\n",
      "  time_since_restore: 4443.7888333797455\n",
      "  time_this_iter_s: 5.501033306121826\n",
      "  time_total_s: 4443.7888333797455\n",
      "  timestamp: 1596125875\n",
      "  timesteps_since_restore: 3013400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 3013400\n",
      "  training_iteration: 1159\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4443 s, 1159 iter, 3013400 ts, 474 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-18-04\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1035.1014877303473\n",
      "  episode_reward_mean: 474.17005211140946\n",
      "  episode_reward_min: 140.2443830298491\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1205\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 42.328\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4464162588119507\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 7.091045404195029e-07\n",
      "        policy_loss: 0.005356034729629755\n",
      "        total_loss: 32.094417572021484\n",
      "        vf_explained_var: 0.001802682876586914\n",
      "        vf_loss: 32.08906173706055\n",
      "    load_time_ms: 1.888\n",
      "    num_steps_sampled: 3018600\n",
      "    num_steps_trained: 2902500\n",
      "    sample_time_ms: 4585.523\n",
      "    update_time_ms: 7.037\n",
      "  iterations_since_restore: 1161\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.583333333333336\n",
      "    ram_util_percent: 65.0\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.374224547958039\n",
      "    mean_inference_ms: 1.037389157771731\n",
      "    mean_processing_ms: 0.7159112420230096\n",
      "  time_since_restore: 4452.642450094223\n",
      "  time_this_iter_s: 4.5639026165008545\n",
      "  time_total_s: 4452.642450094223\n",
      "  timestamp: 1596125884\n",
      "  timesteps_since_restore: 3018600\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 3018600\n",
      "  training_iteration: 1161\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4452 s, 1161 iter, 3018600 ts, 474 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-18-09\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1035.1014877303473\n",
      "  episode_reward_mean: 473.48531581656925\n",
      "  episode_reward_min: 140.2443830298491\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1206\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 44.432\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4514251947402954\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.1982917840214213e-06\n",
      "        policy_loss: 0.008381550200283527\n",
      "        total_loss: 43.58414077758789\n",
      "        vf_explained_var: 0.0011039376258850098\n",
      "        vf_loss: 43.57574462890625\n",
      "    load_time_ms: 1.957\n",
      "    num_steps_sampled: 3021200\n",
      "    num_steps_trained: 2905000\n",
      "    sample_time_ms: 4750.741\n",
      "    update_time_ms: 7.241\n",
      "  iterations_since_restore: 1162\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.1875\n",
      "    ram_util_percent: 64.9375\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.375545248491845\n",
      "    mean_inference_ms: 1.0376250869512185\n",
      "    mean_processing_ms: 0.7159810315243145\n",
      "  time_since_restore: 4458.2282609939575\n",
      "  time_this_iter_s: 5.585810899734497\n",
      "  time_total_s: 4458.2282609939575\n",
      "  timestamp: 1596125889\n",
      "  timesteps_since_restore: 3021200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 3021200\n",
      "  training_iteration: 1162\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4458 s, 1162 iter, 3021200 ts, 473 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-18-15\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1035.1014877303473\n",
      "  episode_reward_mean: 473.2754772218783\n",
      "  episode_reward_min: 140.2443830298491\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1207\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 41.565\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4485238790512085\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 3.262400696257828e-07\n",
      "        policy_loss: 0.0005876870127394795\n",
      "        total_loss: 41.71291732788086\n",
      "        vf_explained_var: 0.0022638440132141113\n",
      "        vf_loss: 41.71232986450195\n",
      "    load_time_ms: 1.873\n",
      "    num_steps_sampled: 3023800\n",
      "    num_steps_trained: 2907500\n",
      "    sample_time_ms: 4750.168\n",
      "    update_time_ms: 7.678\n",
      "  iterations_since_restore: 1163\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.050000000000004\n",
      "    ram_util_percent: 64.9\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.376809758198406\n",
      "    mean_inference_ms: 1.0378985065263915\n",
      "    mean_processing_ms: 0.7160610867608581\n",
      "  time_since_restore: 4463.584649562836\n",
      "  time_this_iter_s: 5.356388568878174\n",
      "  time_total_s: 4463.584649562836\n",
      "  timestamp: 1596125895\n",
      "  timesteps_since_restore: 3023800\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 3023800\n",
      "  training_iteration: 1163\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4463 s, 1163 iter, 3023800 ts, 473 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-18-23\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1035.1014877303473\n",
      "  episode_reward_mean: 469.54169434684974\n",
      "  episode_reward_min: 140.2443830298491\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1209\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 38.579\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.443091630935669\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.369901714402658e-07\n",
      "        policy_loss: 0.0017986358143389225\n",
      "        total_loss: 36.84474182128906\n",
      "        vf_explained_var: 0.0030093789100646973\n",
      "        vf_loss: 36.84294509887695\n",
      "    load_time_ms: 1.775\n",
      "    num_steps_sampled: 3029000\n",
      "    num_steps_trained: 2912500\n",
      "    sample_time_ms: 4553.296\n",
      "    update_time_ms: 7.012\n",
      "  iterations_since_restore: 1165\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.31666666666666\n",
      "    ram_util_percent: 64.89999999999999\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.379306568674726\n",
      "    mean_inference_ms: 1.0384876503873193\n",
      "    mean_processing_ms: 0.7162319898820084\n",
      "  time_since_restore: 4471.544662237167\n",
      "  time_this_iter_s: 4.127495288848877\n",
      "  time_total_s: 4471.544662237167\n",
      "  timestamp: 1596125903\n",
      "  timesteps_since_restore: 3029000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 3029000\n",
      "  training_iteration: 1165\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4471 s, 1165 iter, 3029000 ts, 470 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-18-33\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1035.1014877303473\n",
      "  episode_reward_mean: 474.99396199541195\n",
      "  episode_reward_min: 140.2443830298491\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1211\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 43.272\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4419293403625488\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.691460624897445e-07\n",
      "        policy_loss: 0.00043475342681631446\n",
      "        total_loss: 19.8030948638916\n",
      "        vf_explained_var: 0.002595245838165283\n",
      "        vf_loss: 19.80265998840332\n",
      "    load_time_ms: 1.964\n",
      "    num_steps_sampled: 3034200\n",
      "    num_steps_trained: 2917500\n",
      "    sample_time_ms: 4737.567\n",
      "    update_time_ms: 6.81\n",
      "  iterations_since_restore: 1167\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.5875\n",
      "    ram_util_percent: 65.0875\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.381663072003346\n",
      "    mean_inference_ms: 1.0390295667487104\n",
      "    mean_processing_ms: 0.7163752826269204\n",
      "  time_since_restore: 4481.84038233757\n",
      "  time_this_iter_s: 5.71860146522522\n",
      "  time_total_s: 4481.84038233757\n",
      "  timestamp: 1596125913\n",
      "  timesteps_since_restore: 3034200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 3034200\n",
      "  training_iteration: 1167\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.8/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4481 s, 1167 iter, 3034200 ts, 475 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-18-42\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1035.1014877303473\n",
      "  episode_reward_mean: 472.34411086379566\n",
      "  episode_reward_min: 140.2443830298491\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 1214\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 40.849\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4420839548110962\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 4.344463206962246e-07\n",
      "        policy_loss: -0.0020934762433171272\n",
      "        total_loss: 31.42441177368164\n",
      "        vf_explained_var: 0.0018312931060791016\n",
      "        vf_loss: 31.42650604248047\n",
      "    load_time_ms: 1.927\n",
      "    num_steps_sampled: 3039400\n",
      "    num_steps_trained: 2922500\n",
      "    sample_time_ms: 4658.922\n",
      "    update_time_ms: 8.014\n",
      "  iterations_since_restore: 1169\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.28571428571429\n",
      "    ram_util_percent: 65.0\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.3856067365574996\n",
      "    mean_inference_ms: 1.0398424594732492\n",
      "    mean_processing_ms: 0.7166259751669415\n",
      "  time_since_restore: 4491.0169723033905\n",
      "  time_this_iter_s: 4.9305336475372314\n",
      "  time_total_s: 4491.0169723033905\n",
      "  timestamp: 1596125922\n",
      "  timesteps_since_restore: 3039400\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 3039400\n",
      "  training_iteration: 1169\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4491 s, 1169 iter, 3039400 ts, 472 rew\n",
      "\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-18-48\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1035.1014877303473\n",
      "  episode_reward_mean: 472.3441108637957\n",
      "  episode_reward_min: 140.2443830298491\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 1214\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 44.349\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4462029933929443\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.0693311196519062e-06\n",
      "        policy_loss: 0.0016237804666161537\n",
      "        total_loss: 40.85136032104492\n",
      "        vf_explained_var: 0.002862989902496338\n",
      "        vf_loss: 40.84972381591797\n",
      "    load_time_ms: 2.084\n",
      "    num_steps_sampled: 3042000\n",
      "    num_steps_trained: 2925000\n",
      "    sample_time_ms: 4769.501\n",
      "    update_time_ms: 8.304\n",
      "  iterations_since_restore: 1170\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.474999999999994\n",
      "    ram_util_percent: 64.85\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.3856067365574996\n",
      "    mean_inference_ms: 1.0398424594732492\n",
      "    mean_processing_ms: 0.7166259751669415\n",
      "  time_since_restore: 4496.4605622291565\n",
      "  time_this_iter_s: 5.443589925765991\n",
      "  time_total_s: 4496.4605622291565\n",
      "  timestamp: 1596125928\n",
      "  timesteps_since_restore: 3042000\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 3042000\n",
      "  training_iteration: 1170\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4496 s, 1170 iter, 3042000 ts, 472 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=26004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=26005)\u001b[0m -----------------------\n",
      "Result for PPO_EnergyOptSPDEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-07-30_19-18-57\n",
      "  done: false\n",
      "  episode_len_mean: 2500.0\n",
      "  episode_reward_max: 1035.1014877303473\n",
      "  episode_reward_mean: 474.64640647136594\n",
      "  episode_reward_min: 140.2443830298491\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1216\n",
      "  experiment_id: 0227ad3d84eb4f9da7b6d7d230fb1c49\n",
      "  hostname: solom-XPS-13-9380\n",
      "  info:\n",
      "    grad_time_ms: 47.66\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4475589990615845\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 5.376339231588645e-07\n",
      "        policy_loss: 0.008351102471351624\n",
      "        total_loss: 32.87419509887695\n",
      "        vf_explained_var: 0.002024412155151367\n",
      "        vf_loss: 32.8658561706543\n",
      "    load_time_ms: 2.31\n",
      "    num_steps_sampled: 3047200\n",
      "    num_steps_trained: 2930000\n",
      "    sample_time_ms: 4654.878\n",
      "    update_time_ms: 9.57\n",
      "  iterations_since_restore: 1172\n",
      "  node_ip: 192.168.100.38\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.28571428571428\n",
      "    ram_util_percent: 64.82857142857144\n",
      "  pid: 26009\n",
      "  policy_reward_mean: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.3879514626566625\n",
      "    mean_inference_ms: 1.040380927753809\n",
      "    mean_processing_ms: 0.7167652821772529\n",
      "  time_since_restore: 4505.518894433975\n",
      "  time_this_iter_s: 4.732620716094971\n",
      "  time_total_s: 4505.518894433975\n",
      "  timestamp: 1596125937\n",
      "  timesteps_since_restore: 3047200\n",
      "  timesteps_this_iter: 2600\n",
      "  timesteps_total: 3047200\n",
      "  training_iteration: 1172\n",
      "  trial_id: d5215340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 10.7/16.5 GB\n",
      "Result logdir: /home/solom/ray_results/c_mpg+plus\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_EnergyOptSPDEnv-v0_0:\tRUNNING, [6 CPUs, 0 GPUs], [pid=26009], 4505 s, 1172 iter, 3047200 ts, 475 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=26008)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=26006)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=26007)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-30 19:19:03,582\tERROR import_thread.py:89 -- ImportThread: Connection closed by server.\n",
      "2020-07-30 19:19:03,584\tERROR worker.py:1716 -- listen_error_messages_raylet: Connection closed by server.\n",
      "2020-07-30 19:19:03,585\tERROR worker.py:1616 -- print_logs: Connection closed by server.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0c14170ed3d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;34m\"max_failures\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m999\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \"stop\": {  # stopping conditions\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0;34m\"training_iteration\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1500\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# number of iterations to stop after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         },\n\u001b[1;32m     14\u001b[0m     },\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun_experiments\u001b[0;34m(experiments, search_alg, scheduler, with_server, server_port, verbose, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mtrial_executor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mraise_on_failed_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_on_failed_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             return_trials=True)\n\u001b[0m\u001b[1;32m    325\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, stop, config, resources_per_trial, num_samples, local_dir, upload_dir, trial_name_creator, loggers, sync_to_cloud, sync_to_driver, checkpoint_freq, checkpoint_at_end, keep_checkpoints_num, checkpoint_score_attr, global_checkpoint_period, export_formats, max_failures, restore, search_alg, scheduler, with_server, server_port, verbose, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, return_trials, ray_auto_init, sync_function)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mlast_debug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlast_debug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mDEBUG_PRINT_INTERVAL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_running_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36m_process_events\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_available_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mwarn_if_slow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"process_trial\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\u001b[0m in \u001b[0;36mget_next_available_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# See https://github.com/ray-project/ray/issues/4211 for details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mresult_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0mwait_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait_time\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mNONTRIVIAL_WAIT_TIME_THRESHOLD_S\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_ids, num_returns, timeout)\u001b[0m\n\u001b[1;32m   2370\u001b[0m             \u001b[0mtimeout_milliseconds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2371\u001b[0m             \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2372\u001b[0;31m             \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_task_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2373\u001b[0m         )\n\u001b[1;32m   2374\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mready_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.RayletClient.wait\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ray/exceptions.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, client_exc)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_exc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient_exc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trials = run_experiments({\n",
    "    flow_params[\"exp_tag\"]: {\n",
    "        \"run\": alg_run,\n",
    "        \"env\": gym_name,\n",
    "        \"config\": {\n",
    "            **config\n",
    "        },\n",
    "        \"checkpoint_freq\": 20,  # number of iterations between checkpoints\n",
    "        \"checkpoint_at_end\": True,  # generate a checkpoint at the end\n",
    "        \"max_failures\": 999,\n",
    "        \"stop\": {  # stopping conditions\n",
    "            \"training_iteration\": 1500,  # number of iterations to stop after\n",
    "        },\n",
    "    },\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Visualizing the results\n",
    "\n",
    "The simulation results are saved within the `ray_results/training_example` directory (we defined `training_example` at the start of this tutorial). The `ray_results` folder is by default located at your root `~/ray_results`. \n",
    "\n",
    "You can run `tensorboard --logdir=~/ray_results/training_example` (install it with `pip install tensorboard`) to visualize the different data outputted by your simulation.\n",
    "\n",
    "For more instructions about visualizing, please see `tutorial05_visualize.ipynb`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Restart from a checkpoint / Transfer learning\n",
    "\n",
    "If you wish to do transfer learning, or to resume a previous training, you will need to start the simulation from a previous checkpoint. To do that, you can add a `restore` parameter in the `run_experiments` argument, as follows:\n",
    "\n",
    "```python\n",
    "trials = run_experiments({\n",
    "    flow_params[\"exp_tag\"]: {\n",
    "        \"run\": alg_run,\n",
    "        \"env\": gym_name,\n",
    "        \"config\": {\n",
    "            **config\n",
    "        },\n",
    "        \"restore\": \"/ray_results/experiment/dir/checkpoint_50/checkpoint-50\"\n",
    "        \"checkpoint_freq\": 1,\n",
    "        \"checkpoint_at_end\": True,\n",
    "        \"max_failures\": 999,\n",
    "        \"stop\": {\n",
    "            \"training_iteration\": 1,\n",
    "        },\n",
    "    },\n",
    "})\n",
    "```\n",
    "\n",
    "The `\"restore\"` path should be such that the `[restore]/.tune_metadata` file exists.\n",
    "\n",
    "There is also a `\"resume\"` parameter that you can set to `True` if you just wish to continue the training from a previously saved checkpoint, in case you are still training on the same experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trials = run_experiments({\n",
    "#     flow_params[\"exp_tag\"]: {\n",
    "#         \"run\": alg_run,\n",
    "#         \"env\": gym_name,\n",
    "#         \"config\": {\n",
    "#             **config\n",
    "#         },\n",
    "#         \"restore\": \"/ray_results/training_example13/PPO_EnergyOptPOEnv-v0_0_2020-07-23_13-30-07yze28sum/checkpoint_400/checkpoint-400\", \n",
    "#         \"checkpoint_freq\": 20,\n",
    "#         \"checkpoint_at_end\": True,\n",
    "#         \"max_failures\": 999,\n",
    "#         \"stop\": {\n",
    "#             \"training_iteration\": 700,\n",
    "#         },\n",
    "#     },\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.vehicles import Vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
