{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Calibrate LWR with Gipps\"\"\"\n",
    "from scipy.optimize import minimize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from flow.core.macroscopic import LWR\n",
    "from flow.core.macroscopic.lwr import PARAMS as LWR_PARAMS\n",
    "from flow.core.macroscopic.utils import run\n",
    "from flow.core.macroscopic.Calibration.aggregate_micro_to_macro import agg_func\n",
    "params = LWR_PARAMS.copy()\n",
    "\n",
    "dir = \"./Gipps/\"\n",
    "\n",
    "L = 2000\n",
    "dx = 10\n",
    "params['length'] = L\n",
    "params['dx'] = dx\n",
    "params['v_max_max'] = 100\n",
    "params['rho_max_max'] = 300\n",
    "params['total_time'] = 300\n",
    "params[\"boundary_conditions\"] = \"loop\"\n",
    "\n",
    "Avg_pos = pd.DataFrame()\n",
    "Avg_speed = pd.DataFrame()\n",
    "file_list = os.listdir(dir)\n",
    "for file in file_list:\n",
    "    if \"pos\" in file:\n",
    "        T = pd.read_csv(dir + file)\n",
    "        Avg_pos = pd.concat([Avg_pos, T])\n",
    "    if \"speed\" in file:\n",
    "        S = pd.read_csv(dir + file)\n",
    "        Avg_speed = pd.concat([Avg_speed, S])\n",
    "\n",
    "## mean positions from csv\n",
    "Pos = Avg_pos.groupby(\"time\").mean()\n",
    "## mean velocities from csv\n",
    "Speeds = Avg_speed.groupby(\"time\").mean()\n",
    "display(Pos.head())\n",
    "display(Speeds.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Run below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get densities amd velocities -> at specific time step t and t+1\n",
    "t1 = 20\n",
    "row = np.array(Pos.loc[t1])\n",
    "speed = np.array(Speeds.loc[t1])\n",
    "rho_init, vel_init = agg_func(row, speed, L, dx)\n",
    "params['initial_conditions'] = rho_init\n",
    "\n",
    "t2 = 21\n",
    "row = np.array(Pos.iloc[t2])\n",
    "speed = np.array(Speeds.iloc[t2])\n",
    "rho_final, vel_final = agg_func(row, speed, L, dx)\n",
    "##################################################################\n",
    "display(Pos.iloc[[t1]])\n",
    "display(Pos.iloc[[t2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.17258184, 0.24626816, 0.2675676 , 0.2509824 , 0.28986018,\n",
       "       0.25211482, 0.25      , 0.493125  , 0.5       , 0.5       ,\n",
       "       0.5       , 0.5       , 0.5       , 0.256875  , 0.25      ,\n",
       "       0.25      , 0.25      , 0.25      , 0.25      , 0.25      ,\n",
       "       0.25      , 0.25      , 0.25      , 0.25      , 0.25      ,\n",
       "       0.49327743, 0.53707257, 0.5       , 0.46292743, 0.25672257,\n",
       "       0.25      , 0.493125  , 0.5       , 0.256875  , 0.25      ,\n",
       "       0.25      , 0.25      , 0.25      , 0.25      , 0.26493475,\n",
       "       0.25084025, 0.23994823, 0.24940177, 0.586275  , 0.5       ,\n",
       "       0.1650675 , 0.0141575 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.229375  , 0.25      , 0.25      , 0.493125  ,\n",
       "       0.256875  , 0.020625  , 0.        , 0.22663543, 0.24983957,\n",
       "       0.2289577 , 0.4918423 , 0.43884206, 0.25645794, 0.19896418,\n",
       "       0.24668582, 0.26104787, 0.25062713, 0.21080817, 0.24751683,\n",
       "       0.21977885, 0.24812115, 0.20606166, 0.24718834, 0.493125  ,\n",
       "       0.5       , 0.5       , 0.5       , 0.256875  , 0.25      ,\n",
       "       0.25      , 0.25      , 0.49505   , 0.5       , 0.27558166,\n",
       "       0.25104334, 0.24280077, 0.24957423, 0.24440474, 0.24967026,\n",
       "       0.24232914, 0.24954586, 0.25      , 0.25      , 0.25      ,\n",
       "       0.25      , 0.25      , 0.25      , 0.493125  , 0.5       ,\n",
       "       0.256875  , 0.25      , 0.25      , 0.25      , 0.25      ,\n",
       "       0.42693901, 0.49951099, 0.32037189, 0.25317811, 0.25      ,\n",
       "       0.25      , 0.25      , 0.25      , 0.25      , 0.25      ,\n",
       "       0.25      , 0.25      , 0.493125  , 0.5       , 0.256875  ,\n",
       "       0.25      , 0.25      , 0.25      , 0.25      , 0.493125  ,\n",
       "       0.5       , 0.256875  , 0.25      , 0.25      , 0.25      ,\n",
       "       0.493125  , 0.5       , 0.256875  , 0.25      , 0.25      ,\n",
       "       0.25      , 0.25      , 0.25      , 0.25      , 0.25      ,\n",
       "       0.25      , 0.25      , 0.25      , 0.25      , 0.25      ,\n",
       "       0.25      , 0.25      , 0.25      , 0.25      , 0.25      ,\n",
       "       0.25      , 0.020625  , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.229375  , 0.25      , 0.493125  , 0.5       ,\n",
       "       0.256875  , 0.25      , 0.25      , 0.25      , 0.25      ,\n",
       "       0.25      , 0.493125  , 0.5       , 0.256875  , 0.25      ,\n",
       "       0.25      , 0.25      , 0.25      , 0.25      , 0.25      ,\n",
       "       0.25      , 0.020625  , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#single run\n",
    "params['rho_max'] =1\n",
    "params['v_max'] = 11\n",
    "params['CFL'] = 0.95\n",
    "params['initial_conditions'] = rho_init\n",
    "params['dt'] = 0.1\n",
    "env = LWR(params)\n",
    "obs = env.reset()\n",
    "obs, _, _, _ = env.step(rl_actions = params['v_max']) # one time step\n",
    "obs[:int(len(obs)/2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================\n",
      "Initial Values: => [1, 11, 0.95, 0.1]\n",
      "Initial Objective: =>0.13830729427250013\n",
      "===================\n",
      "Optimal values: =>[ 1.         11.00378865  0.95        0.5       ]\n",
      "Optimal min_value: =>0.13807037155605983\n"
     ]
    }
   ],
   "source": [
    "## run lwr model one step and get densities and velocities\n",
    "def objective(x):\n",
    "    \n",
    "    params['rho_max'] = x[0]\n",
    "    params['v_max'] = x[1]\n",
    "    params['CFL'] = x[2]\n",
    "    #params['dt'] = x[2] * dx / x[1]\n",
    "    params['dt'] = x[3]\n",
    "    \n",
    "    env = LWR(params)\n",
    "    obs = env.reset()\n",
    "    obs, _, _, _ = env.step(rl_actions = params['v_max']) # one time step\n",
    "    lwr_density_pred = obs[:int(obs.shape[0]/2)]\n",
    "    lwr_speeds_pred = obs[int(obs.shape[0]/2):]\n",
    "\n",
    "    #loss\n",
    "    loss = np.mean(np.abs(rho_final - lwr_density_pred))\n",
    "    #loss2 = np.mean(np.abs(vel_final - lwr_speeds_pred))\n",
    "    return loss\n",
    "\n",
    "#set contraints\n",
    "def constraint1(x):\n",
    "    return (x[2] * dx / x[1]) - x[3]\n",
    "con1 = {\"type\": \"ineq\", \"fun\":constraint1}\n",
    "\n",
    "#set inital values and bounds\n",
    "x0 = [1, 11, 0.95, 0.1]\n",
    "bnds = ((0.0,1.0),(0.0,30),(0.0,0.99),(0,0.5))\n",
    "\n",
    "\n",
    "# solve single run\n",
    "sol = minimize(objective,x0, method=\"SLSQP\", bounds=bnds, constraints=con1)\n",
    "print(\"===================\")\n",
    "print( \"Initial Values: => \" + str(x0))\n",
    "print(\"Initial Objective: =>\"  +str(objective(x0)))\n",
    "print(\"===================\")\n",
    "print(\"Optimal values: =>\" + str(sol.x))\n",
    "print(\"Optimal min_value: =>\"+ str(sol.fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Metrics=================\n",
      "     fun: 0.13807037155605983\n",
      "     jac: array([-2.99667753e-03, -2.63433903e-05,  0.00000000e+00, -5.79757616e-04])\n",
      " message: 'Optimization terminated successfully.'\n",
      "    nfev: 42\n",
      "     nit: 7\n",
      "    njev: 7\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([ 1.        , 11.00378865,  0.95      ,  0.5       ])\n"
     ]
    }
   ],
   "source": [
    "print(\"================Metrics=================\")\n",
    "print(sol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow setup w/Aboudy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be str, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2f434a64ce9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0minput_ph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-2f434a64ce9b>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(in_val)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mCFL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.95\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLWR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCFL\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# one time step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/flow/flow/core/macroscopic/lwr.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'length'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0;34m\"The 'length' variable in params must be divisible by 'dx'.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flow/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_SliceHelperVar\u001b[0;34m(var, slice_spec)\u001b[0m\n\u001b[1;32m    761\u001b[0m   \"\"\"\n\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_slice_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AsTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flow/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m       \u001b[0mbegin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m       \u001b[0mend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m       \u001b[0mstrides\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m       \u001b[0mshrink_axis_mask\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: must be str, not int"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# params['rho_max'] =1\n",
    "# params['v_max'] = 11\n",
    "# params['CFL'] = 0.95\n",
    "# params['initial_conditions'] = rho_init\n",
    "# params['dt'] = 0.1\n",
    "\n",
    "\n",
    "def build_model(in_val):\n",
    "    params = tf.Variable([1, 11], dtype=tf.float32)\n",
    "    rho_max = params[0]\n",
    "    v_max = params[1]\n",
    "    CFL = 0.95\n",
    "    \n",
    "    env = LWR(params)\n",
    "    env.reset()\n",
    "    obs = env._step(in_val, v_max, rho_max, CFL) # one time step\n",
    "\n",
    "    return obs\n",
    "\n",
    "input_ph = tf.placeholder(tf.float32, shape=(None, 100))\n",
    "\n",
    "y_pred = build_model(input_ph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[:-1]\n",
    "y_true = data[1:]\n",
    "y_true_ph = tf.placeholder(tf.float32, shape(None,None))\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(y_pred - y_val))\n",
    "\n",
    "# optimizer -> computes of gradients and updates our variables of interest (beta in our case)\n",
    "optimizer = tf.train.AdamOptimizer(0.1).minimize(loss) # propagates backwards in our\n",
    "\n",
    "####### run\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as session:\n",
    "    session.run(init) # assign values to variables. Run to execute node.\n",
    "    feed_dict = {input_ph: np.array(x), y_true_ph: np.array(y_true)} # static real data\n",
    "\n",
    "    for _ in np.arange(30):\n",
    "        #current beta\n",
    "        print(beta_val.eval())\n",
    "        #solve. Run to execute node.\n",
    "        loss_val, _ = session.run([loss, optimizer], feed_dict)\n",
    "        # current solve\n",
    "        print(loss_val)\n",
    "\n",
    "    # Plot results. Run to execute node.\n",
    "    plt.scatter(x, y)\n",
    "    plt.plot(x,session.run(y_pred_val,{x_val:x}), \"-r\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Run Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_t(Pos, size=10):\n",
    "    return np.random.choice(Pos.index[:-1],size,replace=False)\n",
    "index = sample_t(Pos, size=3)\n",
    "next_index = index+1\n",
    "index,next_index\n",
    "matrix_initial = Pos.iloc[index]\n",
    "matrix_final = Pos.iloc[next_index]\n",
    "# display(matrix_initial.head())\n",
    "# display(matrix_final.head())\n",
    "# get densities amd velocities -> at specific time step t and t+1\n",
    "A = matrix_initial.apply(lambda row : agg_func(row, row, L, dx)[0], axis = 1)\n",
    "B = matrix_final.apply(lambda row : agg_func(row, row, L, dx)[0], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Batch run\n",
    "params['rho_max'] =1\n",
    "params['v_max'] = 11\n",
    "params['CFL'] = 0.95\n",
    "params['initial_conditions'] = np.vstack(A)\n",
    "params['dt'] = 0.1\n",
    "params[\"boundary_conditions\"] = \"loop\"\n",
    "env = LWR(params)\n",
    "obs = env.reset()\n",
    "obs, _, _, _ = env.step(rl_actions = params['v_max']) # one time step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================\n",
      "Initial Values: => [1, 11, 0.95, 0.1]\n",
      "Initial Objective: =>0.01610539191483332\n",
      "===================\n",
      "Optimal values: =>[9.88857530e-01 1.09992027e+01 9.50000000e-01 4.16333634e-17]\n",
      "Optimal min_value: =>0.01497549999999985\n"
     ]
    }
   ],
   "source": [
    "# Batch run 2:\n",
    "rho_matrix = A.values\n",
    "def objective_batch(x):\n",
    "    \n",
    "    params['rho_max'] = x[0]\n",
    "    params['v_max'] = x[1]\n",
    "    params['CFL'] = x[2]\n",
    "    #params['dt'] = x[2] * dx / x[1]\n",
    "    params['dt'] = x[3]\n",
    "    lwr_pred =[]\n",
    "    \n",
    "    params['initial_conditions'] = np.vstack(A)\n",
    "    env = LWR(params)\n",
    "    obs = env.reset()\n",
    "    obs, _, _, _ = env.step(rl_actions = params['v_max']) # one time step\n",
    "\n",
    "    lwr_pred = obs[:int(len(obs)/2)]\n",
    "\n",
    "    #loss\n",
    "    loss = np.mean(np.abs(np.vstack(B) - lwr_pred))\n",
    "\n",
    "    return loss\n",
    "\n",
    "def constraint1(x):\n",
    "    return (x[2] * dx / x[1]) - x[3]\n",
    "con1 = {\"type\": \"ineq\", \"fun\":constraint1}\n",
    "\n",
    "#set inital values and bounds\n",
    "x0_ = [1, 11, 0.95, 0.1]\n",
    "bnds = ((0.0,1.0),(0.0,30),(0.0,0.99),(0,0.5))\n",
    "\n",
    "# solve single run\n",
    "sol2 = minimize(objective_batch,x0_, method=\"SLSQP\", bounds=bnds, constraints=con1)\n",
    "print(\"===================\")\n",
    "print( \"Initial Values: => \" + str(x0_))\n",
    "print(\"Initial Objective: =>\"  +str(objective_batch(x0_)))\n",
    "print(\"===================\")\n",
    "print(\"Optimal values: =>\" + str(sol2.x))\n",
    "print(\"Optimal min_value: =>\"+ str(sol2.fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Metrics=================\n",
      "     fun: 0.01497549999999985\n",
      "     jac: array([0.        , 0.        , 0.        , 0.00708009])\n",
      " message: 'Optimization terminated successfully.'\n",
      "    nfev: 24\n",
      "     nit: 4\n",
      "    njev: 4\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([9.88857530e-01, 1.09992027e+01, 9.50000000e-01, 4.16333634e-17])\n"
     ]
    }
   ],
   "source": [
    "print(\"================Metrics=================\")\n",
    "print(sol2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Tensor FLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "part_1_data = pd.read_csv(\"https://github.com/DS-100/fa19/raw/gh-pages/assets/datasets/hw7_data.csv\", index_col=0)\n",
    "\n",
    "x = part_1_data['x']\n",
    "y = part_1_data['y']\n",
    "\n",
    "# x\n",
    "x_val = tf.placeholder(tf.float64, shape=(None,))\n",
    "# y,\n",
    "y_val = tf.placeholder(tf.float64, shape=(None,))\n",
    "# beta -> this is the guys that gets updated magically\n",
    "beta_val = tf.Variable(np.array([0.0, 0.0]))\n",
    "# y_pred\n",
    "y_pred_val = tf.multiply(x_val, beta_val[0]) + tf.sin(tf.multiply(x_val, beta_val[1]))\n",
    "\n",
    "# loss\n",
    "loss = tf.reduce_mean(tf.square(y_pred_val - y_val))\n",
    "\n",
    "# optimizer -> computes of gradients and updates our variables of interest (beta in our case)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(loss) # propagates backwards in our\n",
    "\n",
    "####### run\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as session:\n",
    "    session.run(init) # assign values to variables. Run to execute node.\n",
    "    feed_dict = {x_val: np.array(x), y_val: np.array(y)} # static real data\n",
    "\n",
    "    for _ in np.arange(30):\n",
    "        #current beta\n",
    "        print(beta_val.eval())\n",
    "        #solve. Run to execute node.\n",
    "        loss_val, _ = session.run([loss, optimizer], feed_dict)\n",
    "        # current solve\n",
    "        print(loss_val)\n",
    "\n",
    "    # Plot results. Run to execute node.\n",
    "    plt.scatter(x, y)\n",
    "    plt.plot(x,session.run(y_pred_val,{x_val:x}), \"-r\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_flow",
   "language": "python",
   "name": "python_flow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
